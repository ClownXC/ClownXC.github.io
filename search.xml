<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="2021/05/15/TCP%20%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/"/>
      <url>2021/05/15/TCP%20%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。</strong></p><a id="more"></a><p>TCP 连接的双方主机都会为该 TCP 连接分配缓存和变量。当该 TCP 连接收到正确、按序的字节后，就将数据放入<code>接收缓存</code>。上层的应用进程会从该缓存中读取数据，但不必是数据一到达就立即读取，因为此时应用程序可能在做其他事务。而如果应用层读取数据相对缓慢，而发送方发送得太多、太快，发送的数据就会很容易地使该连接的<code>接收缓存</code>溢出。</p><p>TCP 为应用程序提供了<strong>流量控制服务</strong>（flow-control service），以消除发送方使接收方缓存溢出的可能性。</p><p><code>流量控制</code>是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配。</p><p>作为全双工协议，TCP会话的双方都各自维护一个<strong>发送窗口</strong>和一个<strong>接收窗口</strong>（receive window）的变量来提供流量控制。而<code>发送窗口</code>的大小是由对方<code>接收窗口</code>来决定的，<code>接收窗口</code>用于给发送方一个指示–该接收方还有多少可用的缓存空间。</p><p>发送方的发送缓存内的数据都可以被分为 4 类:</p><ol><li>已发送，已收到 ACK</li><li>已发送，未收到 ACK</li><li>未发送，但允许发送</li><li>未发送，但不允许发送</li></ol><p><code>rwnd </code>是随时间动态变化的，如果 <code>rwnd</code> 为0，则意味着接收缓存已经满了。<br>接收端在回复给发送端的 ACK 中会包含该 rwnd，发送端则会根据 ACK 中的接收窗口的值来控制发送窗口。</p><p>接收方发送 <code>rwnd</code> 为 0 的 <code>ACK</code> 后，发送端停止发送数据。等待一段时间后，接收方应用程序读取了一部分数据，接收端可以继续接收数据，于是给发送端发送报文告诉发送端其 <code>接收窗口</code> 大小，但这个报文丢失了，<strong>不含数据的 ACK 是不会超时重传的</strong>，于是就出现发送端等待接收端的 <code>ACK</code> 通知||接收端等待发送端发送数据的死锁状态。</p><p>TCP 引入了 <code>持续计时器</code>（Persistence timer），当发送端收到对方的 <code>rwnd=0</code> 的 <code>ACK</code> 通知时，就启用该计时器，时间到则发送一个1字节的探测报文，对方会在此时回应自身的<code>接收窗口</code>大小，如果结果仍未0，则重设持续计时器，继续等待。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/14/Http%20%E7%BC%93%E5%AD%98/"/>
      <url>2021/05/14/Http%20%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>浏览器第一次向一个 web 服务器发起 <code>http</code> 请求后，服务器会返回请求的资源，并且在响应头中添加一些有关缓存的字段如：<code>Cache-Control</code>、<code>Expires</code>、<code>Last-Modified</code>、<code>ETag</code>、<code>Date</code>等等。之后浏览器再向该服务器请求该资源就可以视情况使用<strong>强缓存</strong>和<strong>协商缓存</strong>。</p><a id="more"></a><ol><li>强缓存：浏览器直接从本地缓存中获取数据，不与服务器进行交互。</li><li>协商缓存：浏览器发送请求到服务器，服务器判定是否可使用本地缓存。</li></ol><p>联系与区别：两种缓存方式最终使用的都是本地缓存；前者无需与服务器交互，后者需要。</p><h2 id="1-强缓存"><a href="#1-强缓存" class="headerlink" title="1. 强缓存"></a>1. 强缓存</h2><p>用户发起了一个 <code>http</code> 请求后，浏览器发现先本地已有所请求资源的缓存，便开始检查缓存是否过期。有两个 http 头部字段控制缓存的有效期：<code>Expires</code> 和 <code>Cache-Control</code>，浏览器是根据以下两步来判定缓存是否过期的</p><ul><li>**Expires: ** response header 里的过期时间，浏览器再次加载资源时，如果在这个过期时间内，则命中强缓存。</li><li><strong>Cache-Control:</strong> 当值设为 max-age=300 时，则代表在这个请求正确返回时间的 5 分钟内再次加载资源，就会命中强缓存。</li></ul><blockquote><p>区别：Expires 是 http1.0 的产物，Cache-Control 是 http1.1 的产物两者同时存在的话，Cache-Control优先级高于 Expires。Expires 是过时的产物，现阶段它的存在只是一种兼容性的写法</p></blockquote><h2 id="2-协商缓存"><a href="#2-协商缓存" class="headerlink" title="2. 协商缓存"></a>2. 协商缓存</h2><p>当浏览器发现缓存过期后，缓存并不一定不能使用了，因为服务器端的资源可能仍然没有改变，所以需要与服务器协商，让服务器判断本地缓存是否还能使用。此时浏览器会判断缓存中是否有 <code>ETag</code> 或 <code>Last-Modified</code> 字段，如果没有，则发起一个 <code>http</code> 请求，服务器根据请求返回资源；</p><p>如果有这两个字段，则在请求头中添加 <code>If-None-Match</code> 字段（有<code>ETag</code>字段的话添加）、<code>If-Modified-Since</code>字段（有<code>Last-Modified</code>字段的话添加）。</p><p><strong>注意：</strong>如果同时发送<code>If-None-Match</code> 、<code>If-Modified-Since</code>字段，服务器只要比较<code>If-None-Match</code>和<code>ETag</code>的内容是否一致即可；如果内容一致，服务器认为缓存仍然可用，则返回状态码<code>304</code>，浏览器直接读取本地缓存，这就完成了协商缓存的过程，也就是图中的蓝线；如果内容不一致，则视情况返回其他状态码，并返回所请求资源。下面详细解释下这个过程：</p><h4 id="ETag-和-If-None-Match"><a href="#ETag-和-If-None-Match" class="headerlink" title="ETag 和 If-None-Match"></a><code>ETag</code> 和 <code>If-None-Match</code></h4><p>二者的值都是服务器为每份资源分配的唯一标识字符串。</p><ol><li>浏览器请求资源，服务器会在响应报文头中加入 <code>ETag</code> 字段。资源更新时，服务器端的 <code>ETag</code> 值也随之更新</li><li>浏览器再次请求资源时，会在请求报文头中添加 <code>If-None-Match</code> 字段，它的值就是上次响应报文中的 <code>ETag</code>的值</li><li>服务器会比对 <code>ETag</code> 与 <code>If-None-Match</code> 的值是否一致，如果不一致，服务器则接受请求，返回更新后的资源；如果一致，表明资源未更新，则返回状态码为 <code>304</code> 的响应，可继续使用本地缓存，要注意的是，此时响应头会加上 <code>ETag</code> 字段，即使它没有变化。</li></ol><h4 id="Last-Modified-和-If-Modified-Since"><a href="#Last-Modified-和-If-Modified-Since" class="headerlink" title="Last-Modified 和 If-Modified-Since"></a><code>Last-Modified</code> 和 <code>If-Modified-Since</code></h4><p>二者的值都是GMT格式的时间字符串。</p><ol><li>浏览器第一次向服务器请求资源后，服务器会在响应头中加上 <code>Last-Modified</code> 字段，表明该资源最后一次的修改时间</li><li>浏览器再次请求该资源时，会在请求报文头中添加 <code>If-Modified-Since</code> 字段，它的值就是上次服务器响应报文中的 <code>Last-Modified</code> 的值</li><li>服务器会比对 <code>Last-Modified</code> 与 <code>If-Modified-Since</code> 的值是否一致，如果不一致，服务器则接受请求，返回更新后的资源；如果一致，表明资源未更新，则返回状态码为 <code>304</code> 的响应，可继续使用本地缓存，与 <code>ETag</code> 不同的是：此时响应头中不会再添加 <code>Last-Modified</code> 字段。</li></ol><h4 id="ETag-较之-Last-Modified-的优势"><a href="#ETag-较之-Last-Modified-的优势" class="headerlink" title="ETag 较之 Last-Modified 的优势"></a><code>ETag</code> 较之 <code>Last-Modified</code> 的优势</h4><ol><li>一些文件也许会周期性的更改，但是内容并不改变(仅仅改变的修改时间)，这个时候我们并不希望客户端认为这个文件被修改了，而重新<code>GET</code>；</li><li>某些文件修改非常频繁，比如在秒以下的时间内进行修改，(比方说1s内修改了N次)，<code>If-Modified-Since</code>能检查到的粒度是s级的，这种修改无法判断；</li><li>某些服务器不能精确的得到文件的最后修改时间。</li></ol><p>这时，利用 <code>ETag</code> 能够更加准确的控制缓存，因为 <code>ETag</code> 是服务器自动生成的资源在服务器端的唯一标识符，资源每次变动，都会生成新的 <code>ETag</code> 值。<code>Last-Modified </code>与 <code>ETag</code>是可以一起使用的，但服务器会优先验证<code>ETag</code>。</p><p><strong>Web 缓存器</strong>又称 <strong>代理服务器</strong>（proxy server），它能够将最近的一些请求和响应暂存在本地磁盘中。当新请求到达时，如果代理服务器中没有这个请求，那么就会从互联网中访问该资源，将其返回给代理服务器，代理服务器会保存一份资源的副本，之后将资源返回给客户端。若代理服务器发现这个请求与暂时存放的请求相同，就返回暂存响应，而不需按URL的地址再次去互联网访问该资源。</p><ol><li><strong>大大减少对客户请求的响应的时间</strong>。</li><li><strong>可以避免多次从源服务器转发资源，大大减少了一个机构接入链路到因特网的通信量，从而降低了费用</strong>。</li></ol><h2 id="3-缓存相关-Header"><a href="#3-缓存相关-Header" class="headerlink" title="3. 缓存相关 Header"></a>3. 缓存相关 Header</h2><h2 id="截屏2021-05-14-下午7-54-13-Users-joker-Library-Application-Support-typora-user-images-截屏2021-05-14-下午7-54-13-png"><a href="#截屏2021-05-14-下午7-54-13-Users-joker-Library-Application-Support-typora-user-images-截屏2021-05-14-下午7-54-13-png" class="headerlink" title="![截屏2021-05-14 下午7.54.13](/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-14 下午7.54.13.png)"></a>![截屏2021-05-14 下午7.54.13](/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-14 下午7.54.13.png)</h2><h2 id="4-浏览器缓存过程"><a href="#4-浏览器缓存过程" class="headerlink" title="4. 浏览器缓存过程"></a>4. <strong>浏览器缓存过程</strong></h2><ol><li>浏览器<strong>第一次</strong>加载资源，服务器返回200，浏览器将资源文件从服务器上请求下载下来，并把 <strong>response header</strong> 及该请求的<strong>返回时间</strong>(要与 Cache-Control 和 Expires 对比)一并缓存；</li><li>下一次加载资源时，先比较当前时间和上一次返回 200 时的<strong>时间差</strong>，如果没有超过 Cache-Control 设置的 max-age，则没有过期，命中强缓存，不发请求直接从本地缓存读取该文件(如果浏览器不支持 HTTP1.1，则用 Expires 判断是否过期)；</li><li><strong>如果时间过期</strong>，则向服务器发送 header 带有 <strong>If-None-Match</strong> 和 <strong>If-Modified-Since</strong> 的请求；</li><li>服务器收到请求后，<strong>优先根据 Etag</strong> 的值判断被请求的文件有没有做修改，Etag 值一致则没有修改，命中协商缓存，返回304；如果不一致则有改动，直接返回新的资源文件带上新的Etag值并返回 200；</li><li>如果服务器收到的请求没有 Etag 值，则将 <strong>If-Modified-Since</strong> 和被请求文件的最后修改时间做比对，一致则命中协商缓存，返回304；不一致则返回新的<strong>last-modified和文件</strong>并返回 200；</li></ol><h2 id="5-如何不缓存？"><a href="#5-如何不缓存？" class="headerlink" title="5. 如何不缓存？"></a>5. <strong>如何不缓存</strong>？</h2><h3 id="5-1-Cache-Control"><a href="#5-1-Cache-Control" class="headerlink" title="5.1. Cache-Control"></a>5.1. <strong>Cache-Control</strong></h3><p>no-store: 不使用任何缓存</p><p>no-cache: 仍然对资源使用缓存，但每一次在使用缓存之前必须向服务器对缓存资源进行验证。</p><h3 id="5-2-Expires"><a href="#5-2-Expires" class="headerlink" title="5.2. Expires"></a>5.2. <strong>Expires</strong></h3><p><strong>设为当前时间之前</strong></p><h3 id="5-3-前端开发设置不缓存"><a href="#5-3-前端开发设置不缓存" class="headerlink" title="5.3. 前端开发设置不缓存"></a>5.3. <strong>前端开发设置不缓存</strong></h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">&quot;pragma&quot;</span> <span class="attr">content</span>=<span class="string">&quot;no-cache&quot;</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">&quot;Cache-Control&quot;</span> <span class="attr">content</span>=<span class="string">&quot;no-cache, must-revalidate&quot;</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">&quot;expires&quot;</span> <span class="attr">content</span>=<span class="string">&quot;Wed, 26 Feb 1997 00:00:00 GMT&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/14/SMTP%20%E5%8D%8F%E8%AE%AE/"/>
      <url>2021/05/14/SMTP%20%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>SMTP(Simple Mail Transfer Protocol) 即简单邮件传输协议,它是一组用于由源地址到目的地址传送邮件<br>的规则，由它来控制信件的中转方式。SMTP 协议属于 TCP/IP 协议簇，它帮助每台计算机在发送或中转信件<br>时找到下一个目的地。</p><a id="more"></a><p>SMTP 被设计基于以下交流模型：当用户需要发邮件时候，邮件发送者(sender-SMTP)建立一个与邮件接收者(receiver-SMTP)通信的通道，发送者发送 SMTP 命令给接收者，接收者收到后对命令做回复。</p><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><h2 id="2-SMTP-协议工作原理"><a href="#2-SMTP-协议工作原理" class="headerlink" title="2. SMTP 协议工作原理"></a>2. SMTP 协议工作原理</h2><p>通信通道被建立后，发送者发送 MAIL 命令来指定发送者的邮件，如果接受者接收这个邮件，就回复 OK ，接着发送者发送 RCPT 命令来指定接收者的邮箱，如果被接收同样回复 OK，如果不接受则拒绝(不会终止整个通话)。接收者邮箱确定后，发送者用 DATA 命令指示要发送数据，并用一个 <code>.</code> 结束发送。如果数据被接收，会收到 OK ，然后用 QUIT 结束会话。</p><ol><li>建立 TCP 连接。</li><li>客户端发送 HELO 命令以标识发件人自己的身份，然后客户端发送 MAIL 命令；服务器端以 OK 作为响应，表明准备接收。</li><li>客户端发送 RCPT 命令，以标识该电子邮件的计划接收人，可以有多个 RCPT 行；服务器端则表示是否愿意为收件人接收邮件。</li><li>协商结束，发送邮件，用命令 DATA 发送。</li><li>以“.”号表示结束输入内容一起发送出去，结束此次发送，用 QUIT 命令退出。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/14/OSPF%20%E5%8D%8F%E8%AE%AE/"/>
      <url>2021/05/14/OSPF%20%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/14/RIP%20%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/"/>
      <url>2021/05/14/RIP%20%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/14/PPP%20%E5%8D%8F%E8%AE%AE/"/>
      <url>2021/05/14/PPP%20%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>PPP 协议是一种在串行链路上传输IP数据包的一种方法，是一个协议的集合，不是单一的协议，支持建立链路的链路控制协议LCP 以及一系列的 NCP</p><a id="more"></a><h2 id="2-协议功能"><a href="#2-协议功能" class="headerlink" title="2. 协议功能"></a>2. 协议功能</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/13/ICMP%20%E5%8D%8F%E8%AE%AE/"/>
      <url>2021/05/13/ICMP%20%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>ICMP 是 Internet Control Message Protocol 的缩写，即互联网控制消息协议。它是互联网协议族的核心协议之一。它用于 TCP/IP 网络中发送控制消息，提供可能发生在通信环境中的各种问题反馈，通过这些信息，使网络管理者可以对所发生的问题作出诊断，然后采取适当的措施解决问题。</p><a id="more"></a><p>ICMP 是网络层协议，但是它不像 IP 协议和 ARP 协议一样直接传递给数据链路层，而是先封装成 IP 数据包然后再传递给数据链路层。所以在 IP 数据包中如果协议类型字段的值是 1 的话，就表示 IP 数据是 ICMP 报文。IP 数据包就是靠这个协议类型字段来区分不同的数据包的</p><h2 id="1-ICMP-协议类型"><a href="#1-ICMP-协议类型" class="headerlink" title="1. ICMP 协议类型"></a>1. <strong>ICMP 协议类型</strong></h2><p>ICMP协议的类型分为两大类，<strong>查询报文</strong>和<strong>差错报文</strong></p><h2 id="2-ICMP-报文格式"><a href="#2-ICMP-报文格式" class="headerlink" title="2. ICMP 报文格式"></a>2. <strong>ICMP 报文格式</strong></h2><p>从 ICMP 的报文格式来说，ICMP 是 IP 的上层协议。但是 ICMP 是分担了 IP 的一部分功能。所以，也被认为是与 IP 同层的协议</p><h2 id="3-ICMP-协议实现"><a href="#3-ICMP-协议实现" class="headerlink" title="3. ICMP 协议实现"></a>3. <strong>ICMP 协议实现</strong></h2><h3 id="3-1-ping-命令"><a href="#3-1-ping-命令" class="headerlink" title="3.1. ping 命令"></a>3.1. ping 命令</h3><p>ping 命令用来在IP 层次上调查与指定机器是否连通，调查数据包往复需要多少时间。为了实现这个功能，ping 命令使用了两个ICMP 报文。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-13 下午11.16.51.png" alt="截屏2021-05-13 下午11.16.51" style="zoom:50%;" /><h4 id="3-1-1-向目的服务器发送回显请求"><a href="#3-1-1-向目的服务器发送回显请求" class="headerlink" title="3.1.1. 向目的服务器发送回显请求"></a>3.1.1. <strong>向目的服务器发送回显请求</strong></h4><p>首先向目的服务器上执行 ping 命令，主机会构建一个 ICMP 回显请求消息数据包(类型是8，代码是0)</p><blockquote><p>在这个回显请求数据包中，除了类型和代码字段，还被追加了标识符和序号字段。标识符和序号字段分别是 16 位的字段。ping 命令在发送回显请求数据包时，会将进程号填写在标识符里。对于序号，每送出一个数据包数值就增加1。而且，回显请求的选项数据部分用来装任意数据。这个任意数据用来调整 ping 的交互数据包的大小。</p></blockquote><h4 id="3-1-2-目的服务器发送回显应答"><a href="#3-1-2-目的服务器发送回显应答" class="headerlink" title="3.1.2. 目的服务器发送回显应答"></a>3.1.2. <strong>目的服务器发送回显应答</strong></h4><p>当192.168.1.10送到 回显请求数据包后，192.168.1.1就会向发送方192.168.1.10发送回显应答（类型是0，代码是0），这个 ICMP 回显应答数据包在 IP 层来看，与被送来的回显请求数据包基本上一样。不同的只有源、目标 IP 地址字段被交换了，Type类型字段里填入了表示回显应答的0</p><h4 id="3-1-3-源服务器显示相关数据"><a href="#3-1-3-源服务器显示相关数据" class="headerlink" title="3.1.3. 源服务器显示相关数据"></a>3.1.3. <strong>源服务器显示相关数据</strong></h4><p>如果源服务器可以接收到回显应答数据包，那我们就认为192.168.1.1是正常工作着的。进一步，记住发送回显请求数据包的时间，与接收到回显应答数据包的时间差，就能计算出数据包一去一回所需要的时间。这个时候ping命令就会将目的服务器的 IP 地址，数据大小，往返花费的时间打印到屏幕上</p><p>ping 命令执行的时候，源主机首先会构建一个 ICMP 请求数据包，ICMP 数据包内包含多个字段。最重要的是两个，第一个是类型字段，对于请求数据包而言该字段为 8；另外一个是顺序号，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加 1。为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。</p><p>然后，由 ICMP 协议将这个数据包连同地址 192.168.1.2 一起交给 IP 层。IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，加上一些其他控制信息，构建一个 IP 数据包。</p><p>接下来，需要加入 MAC 头。如果在 ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 ARP 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。主机 B 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。主机 B 会构建一个 ICMP 应答包，应答数据包的类型字段为 0，顺序号为接收到的请求数据包中的顺序号，然后再发送出去给主机 A。在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 应答包，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。</p><h2 id="traceroute-命令"><a href="#traceroute-命令" class="headerlink" title="traceroute 命令"></a>traceroute 命令</h2><p>ping 使用查询报文，Traceroute 使用差错报文。</p><p>traceroute命令是一款充分利用 ICMP <strong>差错报文</strong>类型的应用，其主要用作追踪路由信息</p><p>首先 traceroute 会将 IP 包的 TTL 设置 为 1，然后发送 UDP 包，他会填入一个端口号作为 UDP 目标端口号（默认是：33434-33534）。</p><p>当目的主机收到 UDP 包后，会返回 ICMP 差错报文消息（类型 3，代码 3）。参照上面的表，该错报文类型是端口不可达，说明发送方发出的 UDP 包到达了目的主机。如下图</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/13/DHCP%E5%8D%8F%E8%AE%AE/"/>
      <url>2021/05/13/DHCP%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>DHCP(Dynamic Host Configuration Protocol),动态主机配置协议，是一个应用层协议。将客户主机 ip 地址设置为动态获取方式时，DHCP 服务器就会根据 DHCP 协议给客户端分配 IP，使得客户机能够利用这个 IP 上网。</p><a id="more"></a><h2 id="1-DHCP-简介"><a href="#1-DHCP-简介" class="headerlink" title="1. DHCP 简介"></a>1. DHCP 简介</h2><h2 id="2-DHCP-实现"><a href="#2-DHCP-实现" class="headerlink" title="2. DHCP 实现"></a>2. DHCP 实现</h2><ol><li>Client 端在局域网内发起一个 DHCP　Discover 包，目的是想发现能够给它提供 IP 的 DHCP Server。 </li><li>可用的 DHCP Server 接收到 Discover 包之后，通过发送 DHCP Offer 包给予 Client 端应答，意在告诉 Client 端它可以提供 IP 地址。  </li><li>Client 端接收到 Offer 包之后，发送 DHCP Request 包请求分配 IP。 </li><li>DHCP Server 发送 ACK 数据包，确认信息。</li></ol><h2 id="3-利用-Wireshark-抓取-DHCP-包"><a href="#3-利用-Wireshark-抓取-DHCP-包" class="headerlink" title="3. 利用 Wireshark 抓取 DHCP 包"></a>3. 利用 Wireshark 抓取 DHCP 包</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/13/ARP%E5%8D%8F%E8%AE%AE/"/>
      <url>2021/05/13/ARP%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>ARP 协议 是Address Resolution Protocol”（地址解析协议）的缩写。以太网环境中，数据的传输所依懒的是 MAC 地址而非 IP 地址，而将已知 IP 地址转换为 MAC 地址的工作是由 ARP 协议来完成的。</p><a id="more"></a><p>在局域网中，网络中实际传输的是 <code>帧</code>，帧里面是有目标主机的 MAC 地址的。在以太网中，一个主机和另一个主机进行直接通信，必须要知道目标主机的 MAC 地址。“地址解析”就是主机在发送帧前将目标 IP 地址转换成目标 MAC 地址的过程。ARP协议的基本功能就是通过目标设备的 IP 地址，查询目标设备的MAC地址，以保证通信的顺利进行。</p><h2 id="1-ARP-映射方式"><a href="#1-ARP-映射方式" class="headerlink" title="1. ARP 映射方式"></a>1. <strong>ARP 映射方式</strong></h2><h3 id="1-1-静态映射"><a href="#1-1-静态映射" class="headerlink" title="1.1. 静态映射"></a>1.1. <strong>静态映射</strong></h3><p>手动创建一张 ARP 表，把逻辑 (IP)地址和物理地址关联起来。ARP 表储存在网络中的每一台机器上。知道其机器的IP地址但不知道其物理地址的机器就可以通过查ARP表找出对应的物理地址。这样做有一定的局限性，因为物理地址可能发生变化：</p><ol><li><p>机器可能更换NIC（网络适配器），结果变成一个新的物理地址。</p></li><li><p>在某些局域网中，每当计算机加电时，物理地址都要改变一次。</p></li><li><p>移动电脑可以从一个物理网络转移到另一个物理网络，物理地址改变。</p></li></ol><p>要避免这些问题出现，必须定期维护更新 ARP 表，此类比较麻烦而且会影响网络性能。</p><h3 id="1-2-动态映射"><a href="#1-2-动态映射" class="headerlink" title="1.2. 动态映射"></a>1.2. <strong>动态映射</strong></h3><p>动态映射时，机器知道另一台机器的逻辑(IP)地址，就可以使用协议找出相对应的物理地址。已经设计出的实现了动态映射协议的有 ARP 和 RARP 两种。ARP把逻辑(IP)地址映射为物理地址。RARP 把物理地址映射为逻辑(IP)地址。</p><h2 id="2-ARP-原理及流程"><a href="#2-ARP-原理及流程" class="headerlink" title="2. ARP 原理及流程"></a>2. <strong>ARP 原理及流程</strong></h2><p>在任何时候，一台主机有 IP 数据报文发送给另一台主机，都要知道接收方的IP 地址。但是 IP 地址必须封装成帧才能通过物理网络。意味着发送方必须有接收方的物理 (MAC) 地址，因此需要完成逻辑地址到物理地址的映射。而 ARP 协议可以接收来自 IP 协议的逻辑地址，将其映射为相应的物理地址，然后把物理地址递交给数据链路层。</p><h3 id="2-1-ARP-请求"><a href="#2-1-ARP-请求" class="headerlink" title="2.1. ARP 请求"></a>2.1. <strong>ARP 请求</strong></h3><p>任何时候，当主机需要找出这个网络中的另一个主机的物理地址时，它就可以发送一个 ARP 请求报文，这个报文包含了**<font color='blue'>发送方的MAC 地址</font><strong>和 **<font color='blue'>IP 地址</font></strong> 以及 **<font color='blue'>接收方的 IP 地址</font>**。因为发送方不知道接收方的物理地址，所以这个查询分组会在网络层中进行广播。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-13 上午10.35.41.png" alt="截屏2021-05-13 上午10.35.41" style="zoom:50%;" /><h3 id="2-2-ARP-响应"><a href="#2-2-ARP-响应" class="headerlink" title="2.2. ARP 响应"></a>2.2. <strong>ARP 响应</strong></h3><p>局域网中的每一台主机都会接受并处理这个 ARP 请求报文，然后进行验证，查看接收方的 IP 地址是不是自己的地址，只有验证成功的主机才会返回一个 ARP 响应报文，这个响应报文包含接收方的 IP 地址和物理地址。这个报文利用收到的 ARP 请求报文中的请求方物理地址以单播的方式直接发送给 ARP 请求报文的请求方。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-13 上午10.36.14.png" alt="截屏2021-05-13 上午10.36.14" style="zoom:50%;" /><p>![截屏2021-05-13 上午10.09.12](/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-13 上午10.09.12.png)</p><h2 id="3-ARP-协议报文字段"><a href="#3-ARP-协议报文字段" class="headerlink" title="3. ARP 协议报文字段"></a>3. <strong>ARP 协议报文字段</strong></h2><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-13 上午10.45.16.png" alt="截屏2021-05-13 上午10.45.16" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-13 下午1.33.31.png" alt="截屏2021-05-13 下午1.33.31" style="zoom:35%;" />]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/12/Controller%20%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%BA%8B%E4%BB%B6%E9%98%9F%E5%88%97%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/"/>
      <url>2021/05/12/Controller%20%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%BA%8B%E4%BB%B6%E9%98%9F%E5%88%97%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Controller 端有多个线程向事件队列写入不同种类的事件，比如，ZooKeeper 端注册的 Watcher 线程、KafkaRequestHandler 线程、Kafka 定时任务线程，等等。而在事件队列的另一端，只有一个名为 ControllerEventThread 的线程专门负责“消费”或处理队列中的事件</p><a id="more"></a><p>参与实现这个模型的源码类有 4 个。</p><ol><li>ControllerEventProcessor: Controller 端的事件处理器接口</li><li>ControllerEvent: Controller 事件，也就是事件队列中被处理的对象</li><li>ControllerEventManager: 事件处理器，用于创建和管理 ControllerEventThread</li><li>ControllerEventThread: 专属的事件处理线程，唯一的作用是处理不同种类的 ControllEvent。这个类是 ControllerEventManager 类内部定义的线程类。</li></ol><h2 id="1-ControllerEventProcessor"><a href="#1-ControllerEventProcessor" class="headerlink" title="1. ControllerEventProcessor"></a>1. ControllerEventProcessor</h2><p>接口位于 controller 包下的 ControllerEventManager.scala 文件中。定义了一个支持**<font color='blue'>普通处理</font><strong>和</strong><font color='blue'>抢占处理</font>** Controller 事件的接口</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">ControllerEventProcessor</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(event: <span class="type">ControllerEvent</span>): <span class="type">Unit</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">preempt</span></span>(event: <span class="type">ControllerEvent</span>): <span class="type">Unit</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>process 接收一个 Controller 事件，并进行处理</li><li>preempt 接收一个 Controller 事件，并抢占队列之前的事件进行优先处理</li></ol><p>在 Kafka 源码中，KafkaController 类是 Controller 组件的功能实现类，它也是 ControllerEventProcessor 接口的唯一实现类。</p><h2 id="2-ControllerEvent"><a href="#2-ControllerEvent" class="headerlink" title="2. ControllerEvent"></a>2. ControllerEvent</h2><p>Controller 事件，在源码中对应的就是 ControllerEvent 接口。该接口定义在 KafkaController.scala 文件中</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sealed</span> <span class="class"><span class="keyword">trait</span> <span class="title">ControllerEvent</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">state</span></span>: <span class="type">ControllerState</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每个 ControllerEvent 都定义了一个状态。Controller 在处理具体的事件时，会对状态进行相应的变更。这个状态是由源码文件 ControllerState.scala 中的抽象类 ControllerState 定义的。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sealed</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ControllerState</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">value</span></span>: <span class="type">Byte</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">rateAndTimeMetricName</span></span>: <span class="type">Option</span>[<span class="type">String</span>] =</span><br><span class="line">    <span class="keyword">if</span> (hasRateAndTimeMetric) <span class="type">Some</span>(<span class="string">s&quot;<span class="subst">$&#123;toString&#125;</span>RateAndTimeMs&quot;</span>) <span class="keyword">else</span> <span class="type">None</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">hasRateAndTimeMetric</span></span>: <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每类 ControllerState 都定义一个 value 值，表示 Controller 状态的序号，从 0 开始。另外，rateAndTimeMetricName 方法是用于构造 Controller 状态速率的监控指标名称的。</p><p>Controller 总共定义了 25 类事件和 17 种状态，它们的对应关系如下表所示</p><p>当监控到某些 Controller 状态变更速率异常的时候，你可以通过这张表格，快速确定可能造成瓶颈的 Controller 事件，并定位处理该事件的函数代码，辅助进一步地调试问题。</p><p>多个 ControllerEvent 可能归属于相同的 ControllerState。</p><p>TopicChange 和 PartitionModifications 事件都属于 TopicChange 状态，它们都与 Topic 的变更有关。前者是创建 Topic，后者是修改 Topic 的属性，比如，分区数或副本因子，等等。BrokerChange 和 BrokerModifications 事件都属于 BrokerChange 状态，表征的都是对 Broker 属性的修改。</p><p>![截屏2021-05-12 上午8.52.26](/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-12 上午8.52.26.png)</p><h2 id="3-ControllerEventManager"><a href="#3-ControllerEventManager" class="headerlink" title="3. ControllerEventManager"></a>3. ControllerEventManager</h2><p>Controller 事件处理器代码位于 controller 包下的 ControllerEventManager.scala 文件，该文件主要由 4 个部分组成</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-12 上午9.32.56.png" alt="截屏2021-05-12 上午9.32.56" style="zoom:50%;" /><h3 id="3-1-QueuedEvent"><a href="#3-1-QueuedEvent" class="headerlink" title="3.1. QueuedEvent"></a>3.1. QueuedEvent</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 每个QueuedEvent定义了两个字段</span></span><br><span class="line"><span class="comment">// event: ControllerEvent类，表示Controller事件</span></span><br><span class="line"><span class="comment">// enqueueTimeMs：表示Controller事件被放入到事件队列的时间戳</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QueuedEvent</span>(<span class="params">val event: <span class="type">ControllerEvent</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                  val enqueueTimeMs: <span class="type">Long</span></span>) </span>&#123;</span><br><span class="line">  <span class="comment">// 标识事件是否开始被处理</span></span><br><span class="line">  <span class="keyword">val</span> processingStarted = <span class="keyword">new</span> <span class="type">CountDownLatch</span>(<span class="number">1</span>)</span><br><span class="line">  <span class="comment">// 标识事件是否被处理过</span></span><br><span class="line">  <span class="keyword">val</span> spent = <span class="keyword">new</span> <span class="type">AtomicBoolean</span>(<span class="literal">false</span>)</span><br><span class="line">  <span class="comment">// 处理事件</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(processor: <span class="type">ControllerEventProcessor</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (spent.getAndSet(<span class="literal">true</span>))</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    processingStarted.countDown()</span><br><span class="line">    processor.process(event)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 抢占式处理事件</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">preempt</span></span>(processor: <span class="type">ControllerEventProcessor</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (spent.getAndSet(<span class="literal">true</span>))</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    processor.preempt(event)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 阻塞等待事件被处理完成</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">awaitProcessing</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    processingStarted.await()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">toString</span></span>: <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="string">s&quot;QueuedEvent(event=<span class="subst">$event</span>, enqueueTimeMs=<span class="subst">$enqueueTimeMs</span>)&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-ControllerEventThread"><a href="#4-ControllerEventThread" class="headerlink" title="4. ControllerEventThread"></a>4. ControllerEventThread</h2><p>作为 Controller 唯一的事件处理线程，需要时刻关注这个线程的运行状态。因此，必须要知道这个线程在 JVM 上的名字，这样后续就能有针对性地对其展开监控。这个线程的名字是由 ControllerEventManager Object 中 ControllerEventThreadName 变量定义的，</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ControllerEventManager</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> <span class="type">ControllerEventThreadName</span> = <span class="string">&quot;controller-event-thread&quot;</span></span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-1-doWork"><a href="#4-1-doWork" class="headerlink" title="4.1. doWork()"></a>4.1. doWork()</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doWork</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 从事件队列中获取待处理的Controller事件，否则等待</span></span><br><span class="line">  <span class="keyword">val</span> dequeued = queue.take()</span><br><span class="line">  dequeued.event <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="comment">// 如果是关闭线程事件，什么都不用做。关闭线程由外部来执行</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">ShutdownEventThread</span> =&gt;</span><br><span class="line">    <span class="keyword">case</span> controllerEvent =&gt;</span><br><span class="line">      _state = controllerEvent.state</span><br><span class="line">      <span class="comment">// 更新对应事件在队列中保存的时间</span></span><br><span class="line">      eventQueueTimeHist.update(time.milliseconds() - dequeued.enqueueTimeMs)</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(): <span class="type">Unit</span> = dequeued.process(processor)</span><br><span class="line">        <span class="comment">// 处理事件，同时计算处理速率</span></span><br><span class="line">        rateAndTimeMetrics.get(state) <span class="keyword">match</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> <span class="type">Some</span>(timer) =&gt; timer.time &#123; process() &#125;</span><br><span class="line">          <span class="keyword">case</span> <span class="type">None</span> =&gt; process()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">s&quot;Uncaught error processing event <span class="subst">$controllerEvent</span>&quot;</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line">      _state = <span class="type">ControllerState</span>.<span class="type">Idle</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/11/Kafka%E5%88%86%E5%8C%BA%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2/"/>
      <url>2021/05/11/Kafka%E5%88%86%E5%8C%BA%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>PartitionStateMachine 负责管理 Kafka 分区状态的转换，和 ReplicaStateMachine 从代码结构、实现功能和设计原理来看，二者都有很多相似之处</p><a id="more"></a><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>PartitionStateMachine.scala 文件位于 controller 包</p><ol><li><p>PartitionStateMachine 分区状态机抽象类。</p><blockquote><p>定义了诸如 startup、shutdown 这样的公共方法，同时也给出了处理分区状态转换入口方法 handleStateChanges 的签名。</p></blockquote></li><li><p>ZkPartitionStateMachine PartitionStateMachine 唯一的继承子类。</p><blockquote><p>实现了分区状态机的主体逻辑功能。和 ZkReplicaStateMachine 类似，ZkPartitionStateMachine 重写了父类的 handleStateChanges 方法，并配以私有的 doHandleStateChanges 方法，共同实现分区状态转换的操作。</p></blockquote></li><li><p>PartitionState 接口及其实现对象</p><blockquote><p>定义 4 类分区状态，分别是 NewPartition、OnlinePartition、OfflinePartition 和 NonExistentPartition。除此之外，还定义了它们之间的流转关系。</p></blockquote></li><li><p>PartitionLeaderElectionStrategy 接口及其实现对象。定义 4 类分区 Leader 选举策略</p></li><li><p>PartitionLeaderElectionAlgorithms：分区 Leader 选举的算法实现。提供了这 4 类选举策略的实现代码。</p></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/01/FSImage/"/>
      <url>2021/05/01/FSImage/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/01/FSImage2/"/>
      <url>2021/05/01/FSImage2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>FSImage 类最重要的功能之一就是将当前时刻 Namenode 的命名空间保存到fsimage文件</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-01 下午4.04.09.png" alt="截屏2021-05-01 下午4.04.09" style="zoom:50%;" /><p><code>FSNameSystem</code> 会调用 <code>FSImage.saveNamespace()</code>方法触发命名空间的保存操作，<code>saveNamespace()</code> 会调用 <code>saveFSImageInAllDirs()</code> 方法执行具体的保存逻辑。</p><h2 id="1-saveFSImageInAllDirs"><a href="#1-saveFSImageInAllDirs" class="headerlink" title="1. saveFSImageInAllDirs()"></a>1. <code>saveFSImageInAllDirs()</code></h2><p>Namenode 可以定义多个存储路径来保存 fsimage 文件，对于每一个存储路径，saveFSImageInAllDirs() 方法都会启动一个线程负责在这个路径上保存 fsimage 文件。同时，为了防止保存过程中出现错误，命名空间信息首先会被保存在一个fsimage.ckpt 文件中，当保存操作全部完成之后，才会将 fsimage.ckpt 重命名为 fsimage 文件。之后saveFSImageInAllDirs() 方法会清理 Namenode 元数据存储文件夹中过期的 editlog 文件和 fsimage 文件。<br>saveFSImageInAllDirs0方法的代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">saveFSImageInAllDirs</span><span class="params">(FSNamesystem source,</span></span></span><br><span class="line"><span class="function"><span class="params">    NameNodeFile nnf, <span class="keyword">long</span> txid, Canceler canceler)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//ctx中保存了生成img文件所需要的上下文信息，最重要的，这个img文件的end txId,即这个checkpoint的目标偏移位置</span></span><br><span class="line">  SaveNamespaceContext ctx = <span class="keyword">new</span> SaveNamespaceContext(source, txid, canceler);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    List&lt;Thread&gt; saveThreads = <span class="keyword">new</span> ArrayList&lt;Thread&gt;();</span><br><span class="line">    <span class="comment">// save images into current</span></span><br><span class="line">    <span class="comment">//对于每一个 storage 目录，都创建一个独立线程，同时进行 image 文件的生成，提高生成效率</span></span><br><span class="line">    <span class="keyword">for</span> (Iterator&lt;StorageDirectory&gt; it</span><br><span class="line">           = storage.dirIterator(NameNodeDirType.IMAGE); it.hasNext();) &#123;</span><br><span class="line">      StorageDirectory sd = it.next();</span><br><span class="line">      <span class="comment">//fsimage.ckpt</span></span><br><span class="line">      FSImageSaver saver = <span class="keyword">new</span> FSImageSaver(ctx, sd, nnf);</span><br><span class="line">      Thread saveThread = <span class="keyword">new</span> Thread(saver, saver.toString());</span><br><span class="line">      saveThreads.add(saveThread);</span><br><span class="line">      saveThread.start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//等待所有的saveThread完成存储操作</span></span><br><span class="line">    waitForThreads(saveThreads);</span><br><span class="line">    saveThreads.clear();</span><br><span class="line">    <span class="comment">//移除掉有错误的目录（FSImage里面的run，cache住的异常）</span></span><br><span class="line">    storage.reportErrorsOnDirectories(ctx.getErrorSDs());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (storage.getNumStorageDirs(NameNodeDirType.IMAGE) == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(</span><br><span class="line">        <span class="string">&quot;Failed to save in any storage directories while saving namespace.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (canceler.isCancelled()) &#123;</span><br><span class="line">      deleteCancelledCheckpoint(txid);</span><br><span class="line">      ctx.checkCancelled(); <span class="comment">// throws</span></span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">false</span> : <span class="string">&quot;should have thrown above!&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//完成了img文件的存取，实际上是存为一个中间文件，以 NameNodeFile.IMAGE_NEW 开头。</span></span><br><span class="line">    <span class="comment">//这时候就可以把这些中间文件rename称为最终正式文件了</span></span><br><span class="line">    <span class="comment">//最后一个参数false，代表不需要rename md5文件，这是因为在FSImageSaver中生成临时文件的时候已经生成了最终的md5文件</span></span><br><span class="line">    renameCheckpoint(txid, NameNodeFile.IMAGE_NEW, nnf, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Since we now have a new checkpoint, we can clean up some</span></span><br><span class="line">    <span class="comment">// old edit logs and checkpoints.</span></span><br><span class="line">    purgeOldStorage(nnf);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">// Notify any threads waiting on the checkpoint to be canceled</span></span><br><span class="line">    <span class="comment">// that it is complete.</span></span><br><span class="line">    ctx.markComplete();</span><br><span class="line">    ctx = <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  prog.endPhase(Phase.SAVING_CHECKPOINT);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>命名空间具体的保存操作是由 FSImageSaver 类承担的，FSImageSaver 是 FSImage 中的内部类，也是一个线程类，它的run()方法调用了 saveFSImage() 方法来保存 fsimage 文件</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Save the contents of the FS image to the file.</span></span><br><span class="line"><span class="comment"> * 从 saveFSImage() 方法可以看到，生成 image 文件的时候，并不是直接将内存镜像 dump 到对应的 image 磁盘目录，</span></span><br><span class="line"><span class="comment"> * 而是会产生一个以 fsimage.ckpt 开头的中间文件；</span></span><br><span class="line"><span class="comment"> * 如：fsimage.ckpt_0000000000992806947，</span></span><br><span class="line"><span class="comment"> * 然后生成对应的MD5校验文件，如：fsimage.ckpt_0000000000992806947.md5。</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 当多目录 image 文件全部完成了中间文件的生成，再调用 renameCheckpoint(...) 方法，</span></span><br><span class="line"><span class="comment"> * 将所有目录的中间文件 rename 为最终的格式为 fsimage_0000000000992806947 的文件；</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">saveFSImage</span><span class="params">(SaveNamespaceContext context, StorageDirectory sd,</span></span></span><br><span class="line"><span class="function"><span class="params">    NameNodeFile dstType)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">//checkpoint的目标偏移位置</span></span><br><span class="line">  <span class="keyword">long</span> txid = context.getTxId();</span><br><span class="line">  <span class="comment">//保存image文件</span></span><br><span class="line">  File newFile = NNStorage.getStorageFile(sd, NameNodeFile.IMAGE_NEW, txid);</span><br><span class="line">  <span class="comment">//保存MD5文件</span></span><br><span class="line">  File dstFile = NNStorage.getStorageFile(sd, dstType, txid);</span><br><span class="line">  </span><br><span class="line">  FSImageFormatProtobuf.Saver saver = <span class="keyword">new</span> FSImageFormatProtobuf.Saver(context);</span><br><span class="line">  FSImageCompression compression = FSImageCompression.createCompression(conf);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//按照压缩配置，将img存入到以fsimage.ckpt开头的中间文件中</span></span><br><span class="line">  saver.save(newFile, compression);</span><br><span class="line">  <span class="comment">//保存md5文件</span></span><br><span class="line">  MD5FileUtils.saveMD5File(dstFile, saver.getSavedDigest());</span><br><span class="line">  <span class="comment">//此处保存，是为了做checkpoint的时候，能知道上一次checkpoint的位置</span></span><br><span class="line">  storage.setMostRecentCheckpointInfo(txid, Time.now());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>saveFSImage() 方法构造了一个 FSImageFormatProtobuf.Saver 对象来保存命名空间，FSImageFormatProtobuf 是一个工具类，提供了以 protobuf 格式读取和写入 fsimage 文件的方法。</p><h2 id="2-FSImageFormatProtobuf-Saver"><a href="#2-FSImageFormatProtobuf-Saver" class="headerlink" title="2. FSImageFormatProtobuf.Saver"></a>2. FSImageFormatProtobuf.Saver</h2><p>HDFS 2.6版本使用了protobuf作为fsimage文件序列化的工具</p><ul><li><p><strong>MAGIC</strong>: fsimage 的文件头，是 <code>HDFSIMG1</code> 这个字符串的二进制形式，MAGIC 头标识了当前 fsimage 文件是使用protobuf 格式序列化的。</p><blockquote><p>FSImage 类在读取 fsimage 文件时，会先判断 fsimage 文件是否包含了 MAGIC 头，如果包含了则使用 protobuf 格式反序列化 fsimage文件。</p></blockquote></li><li><p><strong>SECTIONS</strong>: fsimage 文件会将同一类型的 Namenode 元信息保存在一个 section 中，例如将文件系统元信息保存在 NameSystemSection 中，将文件系统目录树中的所有 INode 信息保存在 INodeSection 中，将快照信息保存在SnapshotSection 中等。</p></li><li><p><strong>FileSummary</strong>: FileSummary 记录了 fsimage 文件的元信息，以及 fsimage 文件保存的所有 section 的信息。- </p><ul><li><p>ondiskVersion 字段记录了 fsimage文件的版<br>本号（2.7版本中这个字段的值为1)</p></li><li><p>layoutVersion字段记录了当前 HDFS 的文件系统布局版本号</p></li><li><p>codec 字段记录了 fsimage 文件的压缩编码</p></li><li><p>sections 字段则记录了 fsimage 文件中各个 section 字段的元信息，每个 fsimage 文件中记录的 section 在 FileSummary 中都有一个与之对应的 section 字段。FileSummary 的 section 字段记录<br>了对应的 fsimage 中 section 的名称、在 fsimage 文件中的长度，以及这个 section 在 fsimage 中的起始位置。</p><blockquote><p>FSImage 类在读取 fsimage 文件时，会先从 fsimage 中读取出 FileSummary 部分，然后利 FileSummary 记录的元信息指导 fsimage 文件的反序列化操作。</p></blockquote></li></ul></li><li><p><strong>FileSummaryLength</strong>: FileSummaryLength 记录了 FileSummary 在 fsimage 文件中所占的长度，FSImage 类&gt;</p><blockquote><p>在读取 fsimage 文件时，会首先读取 FileSummaryLength 获取 FileSummary 部分的长度，然后根据这个长度从fsimage中反序列化出 FileSummary.</p></blockquote></li></ul><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-01 下午4.55.00.png" alt="截屏2021-05-01 下午4.55.00" style="zoom:30%;" />]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/05/01/EditLogOutputStream/"/>
      <url>2021/05/01/EditLogOutputStream/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>FSEditLog 类会调用 FSEditLog.editLogStream 字段的 write()方法在 editlog 文件中记录一个操作，数据会先被写入到 editlog 文件输出流的缓存中，然后 FSEditLog 类会调用 editLogStream.flush() 方法将缓存中的数据同步到磁盘上。FSEditLog 的 editLogStream 字段是 EditLogOutputStream 类型的，EditLogOutputStream类是一个抽象类，它定义了向持久化存储上写 editlog 文件的相关接口。</p><a id="more"></a><p>由于目前 Namenode 可以在多种类型的异构存储上保存 editlog 文件，例如普通文件系统、共享NFS、Bookkeeper以及Quorum集群等，所以 EditLogOutputStream 定义了多个子类来向不同存储系统上的 editlog 文件中写入数据。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-01 上午10.45.14.png" alt="截屏2021-05-01 上午10.45.14" style="zoom:40%;" /><p>由于 Namenode 可以同时向多个不同的存储上写入 editlog 文件，所以 EditLogOutputStream 还定义了子类 JournalSetOutputStream 执行聚合的写入操作</p><h2 id="1-JournalSetOutputStream"><a href="#1-JournalSetOutputStream" class="headerlink" title="1. JournalSetOutputStream"></a>1. JournalSetOutputStream</h2><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-01 上午11.04.28.png" alt="截屏2021-05-01 上午11.04.28" style="zoom:40%;" /><h2 id="2-EditLogFileOutputStream"><a href="#2-EditLogFileOutputStream" class="headerlink" title="2. EditLogFileOutputStream"></a>2. EditLogFileOutputStream</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/04/29/FSEditLog/"/>
      <url>2021/04/29/FSEditLog/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-29 下午4.20.02.png" alt="截屏2021-04-29 下午4.20.02" style="zoom:50%;" /><h2 id="1-transactionId"><a href="#1-transactionId" class="headerlink" title="1. transactionId"></a>1. transactionId</h2><h2 id="2-FSEditLog-状态机"><a href="#2-FSEditLog-状态机" class="headerlink" title="2. FSEditLog 状态机"></a>2. FSEditLog 状态机</h2><p>FSEditLog 类被设计成一个状态机，用内部类 FSEditLog.State 描述。FSEditLog 有以下 5 个状态。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-30 下午5.15.28.png" alt="截屏2021-04-30 下午5.15.28" style="zoom:40%;" /><p>对于非HA机制的情况，FSEditLog 开始于 <code>UNINITIALIZED</code> 或者 <code>CLOSED</code> 状态。FSEditLog 初始化完成之后进入<code>BETWEEN_LOG_SEGMENTS</code> 状态，表示前一个 segment 已经关闭，新的还没开始，日志已经做好准备了。当打开日志服务时，改变 FSEditLog 状态为</p><p><code>IN_SEGMENT</code> 状态，表示可以写 editlog 文件了。</p><p>对于 HA 机制的情况，FSEditLog 同样应该开始于 <code>UNINITIALIZED</code> 或者 <code>CLOSED</code> 状态，但在完成初始化后并不进入 <code>BETWEEN_LOG_SEGMENTS</code> 状态，而是进入<code>OPEN_FOR_READING</code> 状态 </p><blockquote><p>Namenode 启动时都是以 Standby 模式启动的，通过 DFSHAAdmin 发送命令把其中一个Standby NameNode 转换成 Active Namenode</p></blockquote><p>FSEditLog 的状态转移图如图所示</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-30 下午8.43.48.png" alt="截屏2021-04-30 下午8.43.48" style="zoom:50%;" /><h3 id="2-1-initJournalsForWrite"><a href="#2-1-initJournalsForWrite" class="headerlink" title="2.1. initJournalsForWrite()"></a>2.1. initJournalsForWrite()</h3><p>initJournalsForWrite() 方法会将 FSEditLog 从 <code>UNINITIALIZED</code> 状态转换为 <code>BETWEEN_LOG_SEGMENTS</code> 状态。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在 FSNamesystem.startActiveServices 中被调用，只有 ActiveNameNode 才有写权限</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">initJournalsForWrite</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Preconditions.checkState(state == State.UNINITIALIZED ||</span><br><span class="line">          state == State.CLOSED, <span class="string">&quot;Unexpected state: %s&quot;</span>, state);</span><br><span class="line">  <span class="comment">//初始化日志系统</span></span><br><span class="line">  initJournals(<span class="keyword">this</span>.editsDirs);</span><br><span class="line">  state = State.BETWEEN_LOG_SEGMENTS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>initJournalsForWrite() 方法调用了 initJournals() 方法，initJournals() 方法会根据传入的 dirs 变量(保存的是 editlog 文件的存储位置，都是 URI) 初始化 journalSet 字段 (JournalManager 对象的集合)。初始化之后，FSEditLog 就可以调用 journalSet 对象的方法向多个日志存储位置写 editlog 文件。<br>JournalManager 类是负责在特定存储目录上持久化 editlog 文件的类，它的format()方法负责格式化底层存储，startLogSegment() 方法负责从指定事务 id 开始记录一个操作的段落 finalizeLogSegmemt() 方法负责完成指定事务 id 区间的写操作。</p><p>![截屏2021-04-30 下午8.58.47](/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-30 下午8.58.47.png)</p><blockquote><p>Namenode 可能将 editlog 文件持久化到不同类型的存储上，也就需要不同类型的 JournalManager 来管理，所以需要定义一个抽象的接口。</p><p>JoumalManager 有多个子类，普通的文件系统由 FileJoumalManager 类管理、共享 NFS 由BackupJoumalManager 类管理、Quorum 集群则由 QuorumJoumalManager 类管理。</p></blockquote><h3 id="2-2-initSharedJournalsForRead"><a href="#2-2-initSharedJournalsForRead" class="headerlink" title="2.2. initSharedJournalsForRead()"></a>2.2. initSharedJournalsForRead()</h3><p>initSharedJournalsForRead() 方法是 FSEditLog 的 public 方法，用在 HA 情况下。调用这个方法会将 FSEditLog 从 <code>UNINITIALIZED</code> 状态转换为 <code>OPEN_FOR_READING</code> 状态。与initJounalsForWrite() 方法相同，initSharedJouralsForRead() 方法也调用了 initJournals()方法执行初始化操作，只不过 editlog 文件的存储位置不同，在 HA 的情况下，editlog 文件的存储目录为共享存储目录</p><h3 id="2-3-openForWrite"><a href="#2-3-openForWrite" class="headerlink" title="2.3. openForWrite()"></a>2.3. openForWrite()</h3><p>初始化 editlog 文件的输出流，并且打开第一个日志段落(log_segment)</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-29 下午4.29.23.png" alt="截屏2021-04-29 下午4.29.23" style="zoom:30%;" /><ol><li>getLastWrittenTxId(): 查找到已经写到 editlog 日志文件中的最新 transactionId(如上图: 返回 <code>31</code>)</li><li>journalSet.selectInputStreams(): 参数 segmentTxId,这个参数会作为这次操作的 transactionld,值为editlog 已经记录的最新的 transactionld 加 1(即: 31+1=32)。selectInputStreams() 方法会判断有没有一个以 segmentTxId(32) 开始的日志，如果没有则表示当前 transactionld 的值选择正确，可以<br>打开新的 editlog 文件记录以 segmentTxId 开始的日志段落。如果方法找到了包含这个 transactionId 的 editlog 文件，则表示出现了两个日志 transactionld 交叉的情况，抛出异常。</li><li>startLogSegment(): 开始记录 transactionld 为 32 的日志段落，新建 edits_inprogress_32 文件。同时将 FSEditlog 的状态转变为 IN_SEGMENT.</li></ol><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-30 下午9.52.30.png" alt="截屏2021-04-30 下午9.52.30" style="zoom:50%;" />  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Initialize the output stream for logging, opening the first</span></span><br><span class="line"><span class="comment"> * log segment.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">openForWrite</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  Preconditions.checkState(state == State.BETWEEN_LOG_SEGMENTS,</span><br><span class="line">          <span class="string">&quot;Bad state: %s&quot;</span>, state);</span><br><span class="line">  <span class="comment">//拿到输出流的最新事务ID+1</span></span><br><span class="line">  <span class="keyword">long</span> segmentTxId = getLastWrittenTxId() + <span class="number">1</span>;</span><br><span class="line">  <span class="comment">// Safety check: we should never start a segment if there are</span></span><br><span class="line">  <span class="comment">// newer txids readable.</span></span><br><span class="line">  List&lt;EditLogInputStream&gt; streams = <span class="keyword">new</span> ArrayList&lt;EditLogInputStream&gt;();</span><br><span class="line">  <span class="comment">//生成读取文件的输入流, namenode 获取 FileJournalManager   journalNode获取QuorumJournalManager</span></span><br><span class="line">  journalSet.selectInputStreams(streams, segmentTxId, <span class="keyword">true</span>);</span><br><span class="line">  <span class="keyword">if</span> (!streams.isEmpty()) &#123;</span><br><span class="line">    String error = String.format(<span class="string">&quot;Cannot start writing at txid %s &quot;</span> +</span><br><span class="line">                    <span class="string">&quot;when there is a stream available for read: %s&quot;</span>,</span><br><span class="line">            segmentTxId, streams.get(<span class="number">0</span>));</span><br><span class="line">    IOUtils.cleanup(LOG, streams.toArray(<span class="keyword">new</span> EditLogInputStream[<span class="number">0</span>]));</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(error);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 1：获取日志输出流（namenode写本地 和 远程的journalNode）</span></span><br><span class="line"><span class="comment">    * 2：启用双缓冲刷数据</span></span><br><span class="line"><span class="comment">    * */</span></span><br><span class="line">  startLogSegment(segmentTxId, <span class="keyword">true</span>);</span><br><span class="line">  <span class="keyword">assert</span> state == State.IN_SEGMENT : <span class="string">&quot;Bad state: &quot;</span> + state;</span><br></pre></td></tr></table></figure><h3 id="2-4-endCurrentLogSegment"><a href="#2-4-endCurrentLogSegment" class="headerlink" title="2.4. endCurrentLogSegment()"></a>2.4. endCurrentLogSegment()</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/04/29/INodeFile/"/>
      <url>2021/04/29/INodeFile/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>![截屏2021-04-29 下午4.04.44](/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-29 下午4.07.01.png)</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/04/29/INodeDirectory/"/>
      <url>2021/04/29/INodeDirectory/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-29 下午12.22.56.png" alt="截屏2021-04-29 下午12.22.56" style="zoom:50%;" />]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/04/29/INode/"/>
      <url>2021/04/29/INode/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>![截屏2021-04-29 上午9.11.52](/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-29 上午9.11.52.png)</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-29 上午9.18.53.png" alt="截屏2021-04-29 上午9.18.53" style="zoom:50%;" />]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/04/25/redis%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/"/>
      <url>2021/04/25/redis%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在切片集群中，数据会按照一定的分布规则分散到不同的实例上保存。比如，在使用 Redis Cluster 或 Codis 时，数据都会先按照 CRC 算法的计算值对 Slot（逻辑槽）取模，同时，所有的 Slot 又会由运维管理员分配到不同的实例上。这样，数据就被保存到相应的实例上了。</p><a id="more"></a><p>虽然方法实现起来比较简单，但是很容易导致一个问题：数据倾斜。</p><p>数据倾斜有两类</p><ol><li><p>数据量倾斜</p><blockquote><p>在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多。</p></blockquote></li><li><p>数据访问倾斜</p><blockquote><p>虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁。</p></blockquote></li></ol><p>如果发生了数据倾斜，那么保存了大量数据，或者是保存了热点数据的实例的处理压力就会增大，速度变慢，甚至还可能会引起这个实例的内存资源耗尽，从而崩溃。</p><h2 id="1-数据量倾斜的成因和应对方法"><a href="#1-数据量倾斜的成因和应对方法" class="headerlink" title="1. 数据量倾斜的成因和应对方法"></a>1. 数据量倾斜的成因和应对方法</h2><h3 id="1-1-bigkey-导致倾斜"><a href="#1-1-bigkey-导致倾斜" class="headerlink" title="1.1. bigkey 导致倾斜"></a>1.1. bigkey 导致倾斜</h3><p>bigkey 的 value 值很大(String 类型)，或者是 bigkey 保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加。而且，bigkey 的操作一般都会造成实例 IO 线程阻塞，如果 bigkey 的访问量比较大，会影响到这个实例上的其它请求被处理的速度。</p><p>为了避免 bigkey 造成的数据倾斜，一个根本的应对方法是，在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中。如果 bigkey 正好是集合类型，将 bigkey 拆分成很多个小的集合类型数据，分散保存在不同的实例上。</p><h3 id="1-2-Slot-分配不均衡导致倾斜"><a href="#1-2-Slot-分配不均衡导致倾斜" class="headerlink" title="1.2. Slot 分配不均衡导致倾斜"></a>1.2. Slot 分配不均衡导致倾斜</h3><h3 id="1-3-Hash-Tag-导致倾斜"><a href="#1-3-Hash-Tag-导致倾斜" class="headerlink" title="1.3. Hash Tag 导致倾斜"></a>1.3. Hash Tag 导致倾斜</h3><p>Hash Tag 是指加在键值对 key 中的一对花括号{}。这对括号会把 key 的一部分括起来，客户端在计算 key 的 CRC16 值时，只对 Hash Tag 花括号中的 key 内容进行计算。如果没用 Hash Tag 的话，客户端计算整个 key 的 CRC16 的值。</p><p>使用 Hash Tag 的好处是，如果不同 key 的 Hash Tag 内容都是一样的，那么，这些 key 对应的数据会被映射到同一个 Slot 中，同时会被分配到同一个实例上。</p><blockquote><p>Hash Tag 主要用在 Redis Cluster 和 Codis 中，支持事务操作和范围查询。因为 Redis Cluster 和 Codis 本身并不支持跨实例的事务操作和范围查询，当业务应用有这些需求时，就只能先把这些数据读取到业务层进行事务处理，或者是逐个查询每个实例，得到范围查询的结果。</p></blockquote><p>操作起来非常麻烦，可以使用 Hash Tag 把要执行事务操作或是范围查询的数据映射到同一个实例上，这样就能很轻松地实现事务或范围查询了。</p><p>使用 Hash Tag 潜在问题，就是大量的数据可能被集中到一个实例上，导致数据倾斜，集群中的负载不均衡</p><h2 id="2-数据访问倾斜的成因和应对方法"><a href="#2-数据访问倾斜的成因和应对方法" class="headerlink" title="2. 数据访问倾斜的成因和应对方法"></a>2. 数据访问倾斜的成因和应对方法</h2><p>发生数据访问倾斜的根本原因，就是实例上存在热点数据（比如新闻应用中的热点新闻内容、电商促销活动中的热门商品信息)</p><p>和数据量倾斜不同，热点数据通常是一个或几个数据，所以，直接重新分配 Slot 并不能解决热点数据的问题。通常来说，热点数据以服务读操作为主，在这种情况下，我们可以采用热点数据多副本的方法来应对。</p><p>把热点数据复制多份，在每一个数据副本的 key 中增加一个随机前缀，让它和其它副本数据不会被映射到同一个 Slot 中。热点数据既有多个副本可以同时服务请求，同时，这些副本数据的 key 又不一样，会被映射到不同的 Slot 中。在给这些 Slot 分配实例时，注意把它们分配到不同的实例上，那么，热点数据的访问压力就被分散到不同的实例上了。</p><blockquote><p>**<font color='red'>注: </font>**热点数据多副本方法只能针对只读的热点数据。如果热点数据是有读有写的话，就不适合采用多副本方法了，因为要保证多副本间的数据一致性，会带来额外的开销。对于有读有写的热点数据，我们就要给实例本身增加资源了，例如使用配置更高的机器，来应对大量的访问压力。</p></blockquote><h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h2><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-25 下午10.56.42.png" alt="截屏2021-04-25 下午10.56.42" style="zoom:50%;" />]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/04/25/Redis%E7%BC%93%E5%AD%98%E5%8C%BA/"/>
      <url>2021/04/25/Redis%E7%BC%93%E5%AD%98%E5%8C%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Redis 是典型的 client-server 架构，所有的操作命令都需要通过客户端发送给服务器端。缓冲区在 Redis 中的一个主要应用场景，就是在客户端和服务器端之间进行通信时，用来暂存客户端发送的命令数据，或者是服务器端返回给客户端的数据结果。此外，缓冲区的另一个主要应用场景，是在主从节点间进行数据同步时，用来暂存主节点接收的写命令和数据</p><a id="more"></a><h2 id="1-服务器端和客户端之间的缓冲区"><a href="#1-服务器端和客户端之间的缓冲区" class="headerlink" title="1. 服务器端和客户端之间的缓冲区"></a>1. 服务器端和客户端之间的缓冲区</h2><p>为了避免客户端和服务器端的请求发送和处理速度不匹配，服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区</p><p>输入缓冲区会先把客户端发送过来的命令暂存起来，Redis 主线程再从输入缓冲区中读取命令，进行处理。当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端</p><h3 id="1-1-输入缓冲区溢出"><a href="#1-1-输入缓冲区溢出" class="headerlink" title="1.1. 输入缓冲区溢出"></a>1.1. 输入缓冲区溢出</h3><p>输入缓冲区就是用来暂存客户端发送的请求命令的，所以可能导致溢出的情况主要是下面两种</p><ol><li><p>写入了 bigkey</p><p>比如一下子写入了多个百万级别的集合类型数据</p></li><li><p>服务器端处理请求的速度过慢</p><p>Redis 主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。</p></li></ol><h3 id="1-2-查看输入缓冲区的内存使用情况"><a href="#1-2-查看输入缓冲区的内存使用情况" class="headerlink" title="1.2. 查看输入缓冲区的内存使用情况"></a>1.2. 查看输入缓冲区的内存使用情况</h3><p>要查看和服务器端相连的每个客户端对输入缓冲区的使用情况，可以使用 <code>CLIENT LIST</code> 命令：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6379</span>&gt; client list</span><br><span class="line">id=<span class="number">4</span> addr=<span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">60403</span> fd=<span class="number">8</span> name= age=<span class="number">27059</span> idle=<span class="number">26959</span> flags=N db=<span class="number">0</span> sub=<span class="number">0</span> psub=<span class="number">0</span> multi=<span class="literal">-1</span> qbuf=<span class="number">0</span> qbuf<span class="literal">-free</span>=<span class="number">0</span> obl=<span class="number">0</span> oll=<span class="number">0</span> omem=<span class="number">0</span> events=<span class="built_in">r</span> cmd=xadd user=default</span><br><span class="line">id=<span class="number">5</span> addr=<span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">61001</span> fd=<span class="number">9</span> name= age=<span class="number">26526</span> idle=<span class="number">0</span> flags=N db=<span class="number">0</span> sub=<span class="number">0</span> psub=<span class="number">0</span> multi=<span class="literal">-1</span> qbuf=<span class="number">26</span> qbuf<span class="literal">-free</span>=<span class="number">32742</span> obl=<span class="number">0</span> oll=<span class="number">0</span> omem=<span class="number">0</span> events=<span class="built_in">r</span> cmd=client user=default</span><br></pre></td></tr></table></figure><p>与输入缓冲区相关的三个参数</p><ul><li><p>cmd</p><blockquote><p>表示客户端最新执行的命令</p></blockquote></li><li><p>qbuf</p><blockquote><p>表示输入缓冲区已经使用的大小</p></blockquote></li><li><p>qbuf-free</p><blockquote><p>表示输入缓冲区尚未使用的大小</p></blockquote></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/04/25/Redis%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/"/>
      <url>2021/04/25/Redis%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-内存碎片是如何形成的？"><a href="#1-内存碎片是如何形成的？" class="headerlink" title="1. 内存碎片是如何形成的？"></a>1. 内存碎片是如何形成的？</h2><p>内存碎片的形成有内因和外因两个层面的原因。简单来说，内因是操作系统的内存分配机制，外因是 Redis 的负载特征。</p><h3 id="1-1-内存分配器的分配策略"><a href="#1-1-内存分配器的分配策略" class="headerlink" title="1.1. 内存分配器的分配策略"></a>1.1. 内存分配器的分配策略</h3><p>Redis 可以使用 libc、jemalloc、tcmalloc 多种内存分配器来分配内存，默认使用 jemalloc。</p><p>jemalloc 的分配策略之一，是按照一系列固定的大小划分内存空间，例如 8 字节、16 字节、32 字节、48 字节，…, 2KB、4KB、8KB 等。当程序申请的内存最接近某个固定值时，jemalloc 会给它分配相应大小的空间。</p><p>这样的分配方式本身是为了减少分配次数。Redis 申请一个 20 字节的空间保存数据，jemalloc 就会分配 32 字节，此时，如果应用还要写入 10 字节的数据，Redis 就不用再向操作系统申请空间了。如果 Redis 每次向分配器申请的内存空间大小不一样，这种分配方式就会有形成碎片的风险，而这正好来源于 Redis 的外因了。</p><h3 id="1-2-键值对大小不一样和删改操作"><a href="#1-2-键值对大小不一样和删改操作" class="headerlink" title="1.2. 键值对大小不一样和删改操作"></a>1.2. 键值对大小不一样和删改操作</h3><p>Redis 通常作为共用的缓存系统或键值数据库对外提供服务，所以，不同业务应用的数据都可能保存在 Redis 中，这就会带来不同大小的键值对。这样一来，Redis 申请内存空间分配时，本身就会有大小不一的空间需求。</p><p>这些键值对会被修改和删除，这会导致空间的扩容和释放。具体来说，一方面，如果修改后的键值对变大或变小了，就需要占用额外的空间或者释放不用的空间。另一方面，删除的键值对就不再需要内存空间了，此时，就会把空间释放出来，形成空闲空间</p><h2 id="2-如何判断是否有内存碎片？"><a href="#2-如何判断是否有内存碎片？" class="headerlink" title="2. 如何判断是否有内存碎片？"></a>2. 如何判断是否有内存碎片？</h2><p>Redis 是内存数据库，内存利用率的高低直接关系到 Redis 运行效率的高低。为了让用户能监控到实时的内存使用情况，Redis 自身提供了 INFO 命令，可以用来查询内存使用的详细信息</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">6379</span>&gt; info memory</span><br><span class="line"></span><br><span class="line">used_memory:<span class="number">1082672</span></span><br><span class="line">mem_fragmentation_ratio:<span class="number">2.21</span></span><br><span class="line">mem_fragmentation_bytes:<span class="number">1252112</span></span><br></pre></td></tr></table></figure><p><code>mem_fragmentation_ratio</code> 的指标，它表示的就是 Redis 当前的内存碎片率</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mem_fragmentation_ratio = used_memory_rss/ used_memory</span><br></pre></td></tr></table></figure><p>used_memory_rss 是操作系统实际分配给 Redis 的物理内存空间，里面就包含了碎片；而 used_memory 是 Redis 为了保存数据实际申请使用的空间。</p><blockquote><p>如果 mem_fragmentation_ratio 大于 1，redis 存在内存碎片</p></blockquote><blockquote><p>如果 mem_fragmentation_ratio 小于 1，说明 used_memory_rss 小于了 used_memory，这意味着操作系统分配给 Redis 进程的物理内存，要小于 Redis 实际存储数据的内存，也就是说 Redis 没有足够的物理内存可以使用了，这会导致 Redis 一部分内存数据会被换到 Swap 中，之后当 Redis 访问 Swap 中的数据时，延迟会变大，性能下降。</p></blockquote><h2 id="3-如何清理内存碎片？"><a href="#3-如何清理内存碎片？" class="headerlink" title="3. 如何清理内存碎片？"></a>3. 如何清理内存碎片？</h2><h3 id="3-1-重启大法"><a href="#3-1-重启大法" class="headerlink" title="3.1. 重启大法"></a>3.1. 重启大法</h3><p>重启 Redis 实例。如果 Redis 中的数据没有持久化，那么，数据就会丢失，即使 Redis 数据持久化了，还需要通过 AOF 或 RDB 进行恢复，恢复时长取决于 AOF 或 RDB 的大小，如果只有一个 Redis 实例，恢复阶段无法提供服务</p><h3 id="3-2-碎片清理"><a href="#3-2-碎片清理" class="headerlink" title="3.2. 碎片清理"></a>3.2. 碎片清理</h3><p>Redis 自身提供了一种内存碎片自动清理的方法</p><p>碎片清理是有代价的，操作系统需要把多份数据拷贝到新位置，把原有空间释放出来，这会带来时间开销。Redis 是单线程，在数据拷贝时，Redis 无法及时处理请求，性能会降低。</p><p>Redis 专门为自动内存碎片清理功机制设置了参数，可以通过设置参数，来控制碎片清理的开始和结束时机，以及占用的 CPU 比例，从而减少碎片清理对 Redis 本身请求处理的性能影响。</p><p>Redis 需要启用自动内存碎片清理，可以把 activedefrag 配置项设置为 yes</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config <span class="built_in">set</span> activedefrag yes</span><br></pre></td></tr></table></figure><p>同时满足下面两个条件，开始清理。在清理的过程中，只要有一个条件不满足了，就停止自动清理</p><ul><li><p><code>active-defrag-ignore-bytes</code> 100mb</p><blockquote><p>表示内存碎片的字节数达到 100MB 时，开始清理</p></blockquote></li><li><p><code>active-defragthreshold-lower</code> 10</p><blockquote><p>表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理。</p></blockquote></li></ul><p>为了尽可能减少碎片清理对 Redis 正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的 CPU 时间，而且还设置了两个参数，分别用于控制清理操作占用的 CPU 时间比例的上、下限，既保证清理工作能正常进行，又避免了降低 Redis 性能。</p><ul><li><p><code>active-defrag-cycle-min</code> 25</p><blockquote><p>表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展；</p></blockquote></li><li><p><code>active-defrag-cycle-max</code> 75</p><blockquote><p>表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高。</p></blockquote></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/04/25/%E4%B8%BB%E4%BB%8E%E5%BA%93%E9%97%B4%E5%90%8C%E6%AD%A5/"/>
      <url>2021/04/25/%E4%B8%BB%E4%BB%8E%E5%BA%93%E9%97%B4%E5%90%8C%E6%AD%A5/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-主从库间如何进行第一次同步？"><a href="#1-主从库间如何进行第一次同步？" class="headerlink" title="1. 主从库间如何进行第一次同步？"></a>1. 主从库间如何进行第一次同步？</h2><p>启动多个 Redis 实例的时候，相互之间就可以通过 replicaof (Redis 5.0 之前使用 slaveof) 命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。</p><h3 id="1-1-第一阶段"><a href="#1-1-第一阶段" class="headerlink" title="1.1. 第一阶段"></a>1.1. 第一阶段</h3><p>主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。</p><p>从库给主库发送 <code>psync</code> 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。</p><p>psync 命令包含了主库的 runID 和复制进度 offset 两个参数。</p><ul><li><p>runID</p><blockquote><p>每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为 “?”。</p></blockquote></li><li><p>offset</p><blockquote><p>此时设为 -1，表示第一次复制。主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数: 主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。</p><p>FULLRESYNC 响应表示第一次复制采用的全量复制，主库会把当前所有的数据都复制给从库。</p></blockquote></li></ul><h3 id="1-2-第二阶段"><a href="#1-2-第二阶段" class="headerlink" title="1.2. 第二阶段"></a>1.2. 第二阶段</h3><p>主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件</p><p>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。</p><h3 id="1-3-第三阶段"><a href="#1-3-第三阶段" class="headerlink" title="1.3. 第三阶段"></a>1.3. 第三阶段</h3><p>主库会把第二阶段执行过程中新收到的写命令，再发送给从库。当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/04/20/InnoDB%20%E6%95%B0%E6%8D%AE%E9%A1%B5%E7%BB%93%E6%9E%84/"/>
      <url>2021/04/20/InnoDB%20%E6%95%B0%E6%8D%AE%E9%A1%B5%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="记录在页中的存储"><a href="#记录在页中的存储" class="headerlink" title="记录在页中的存储"></a>记录在页中的存储</h2><p>在页的7个组成部分中，我们自己存储的记录会按照我们指定的<code>行格式</code>存储到<code>User Records</code>部分。但是在一开始生成页的时候，其实并没有<code>User Records</code>这个部分，每当我们插入一条记录，都会从<code>Free Space</code>部分，也就是尚未使用的存储空间中申请一个记录大小的空间划分到<code>User Records</code>部分，当<code>Free Space</code>部分的空间全部被<code>User Records</code>部分替代掉之后，也就意味着这个页使用完了，如果还有新的记录插入的话，就需要去申请新的页了，这个过程的图示如下：</p><h2 id="记录头信息"><a href="#记录头信息" class="headerlink" title="记录头信息"></a>记录头信息</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/04/19/InnoDB%20%E8%AE%B0%E5%BD%95%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/"/>
      <url>2021/04/19/InnoDB%20%E8%AE%B0%E5%BD%95%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1InnoDB-页简介"><a href="#1InnoDB-页简介" class="headerlink" title="1InnoDB 页简介"></a>1InnoDB 页简介</h2><p><code>InnoDB</code> 是一个将表中的数据存储到磁盘上的存储引擎，即使关机后重启数据依然存在。而真正处理数据的过程是发生在内存中的，所以需要把磁盘中的数据加载到内存中，如果是处理写入或修改请求的话，还需要把内存中的内容刷新到磁盘上。而磁盘的速度非常慢，和内存读写差了几个数量级，所以当想从表中获取某些记录时，<code>InnoDB</code>存储引擎需要一条一条的把记录从磁盘上读出来么？不，那样会慢死，</p><p><code>InnoDB</code> 采取的方式是：将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小一般为 <em><strong>16</strong></em> KB。也就是在一般情况下，一次最少从磁盘中读取 16KB 的内容到内存中，一次最少把内存中的 16KB 内容刷新到磁盘中。</p><h2 id="2InnoDB-行格式"><a href="#2InnoDB-行格式" class="headerlink" title="2InnoDB 行格式"></a>2InnoDB 行格式</h2><p>数据记录在磁盘上的存放方式被称为 <code>行格式</code> 或者 <code>记录格式</code>。 <code>InnoDB</code>存储引擎有 4 种不同类型的<code>行格式</code>，分别是<code>Compact</code>、<code>Redundant</code>、<code>Dynamic</code>和<code>Compressed</code>行格式</p><h3 id="2指定行格式"><a href="#2指定行格式" class="headerlink" title="2指定行格式"></a>2指定行格式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE 表名 (列的信息) ROW_FORMAT&#x3D;行格式名称</span><br><span class="line">ALTER TABLE 表名 ROW_FORMAT&#x3D;行格式名称</span><br></pre></td></tr></table></figure><h3 id="2-2-COMPACT-行格式"><a href="#2-2-COMPACT-行格式" class="headerlink" title="2.2. COMPACT 行格式"></a>2.2. COMPACT 行格式</h3><p>一条完整的记录其实可以被分为<code>记录的额外信息</code>和<code>记录的真实数据</code>两大部分</p><h4 id="2-2-1-记录的额外信息"><a href="#2-2-1-记录的额外信息" class="headerlink" title="2.2.1. 记录的额外信息"></a>2.2.1. 记录的额外信息</h4><p>额外信息是服务器为了描述这条记录而不得不额外添加的一些信息，这些额外信息分为3类，分别是<code>变长字段长度列表</code>、<code>NULL值列表</code>和<code>记录头信息</code></p><ol><li><p><strong>变长字段长度列表</strong></p><p>在 <code>Compact</code> 行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头部位，从而形成一个变长字段长度列表，各变长字段数据占用的字节数按照列的顺序**<font color='blue'>逆序存放</font>**</p></li><li><p><strong>NULL 值列表</strong></p></li><li><p><strong>记录头信息</strong></p><p>除了 <code>变长字段长度列表</code>、 <code>NULL值列表</code> 之外，还有一个用于描述记录的<code>记录头信息</code>，它是由固定的<code>5</code>个字节组成。<code>5</code>个字节也就是<code>40</code>个二进制位，不同的位代表不同的意思![截屏2021-04-19 下午5.39.19](/Users/joker/Library/Application Support/typora-user-images/截屏2021-04-19 下午5.39.19.png)</p></li></ol><h2 id="2-3-Dynamic-和-Compressed-行格式"><a href="#2-3-Dynamic-和-Compressed-行格式" class="headerlink" title="2.3. Dynamic 和 Compressed 行格式"></a>2.3. Dynamic 和 Compressed 行格式</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/31/MySQL%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E7%AE%A1%E7%90%86/"/>
      <url>2021/03/31/MySQL%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="2-MySQL-服务器构成"><a href="#2-MySQL-服务器构成" class="headerlink" title="2. MySQL 服务器构成"></a>2. MySQL 服务器构成</h2><h3 id="2-1-实例"><a href="#2-1-实例" class="headerlink" title="2.1. 实例"></a>2.1. 实例</h3><p>MySQL 的后台进程+线程+预分配的内存结构</p><p>MySQL 在启动过程中会启动后台守护进程，并生成工作线程，与分配内存结构供 MySQL 处理数据使用</p><h3 id="2-2-MySqld-服务器程序构成"><a href="#2-2-MySqld-服务器程序构成" class="headerlink" title="2.2. MySqld 服务器程序构成"></a>2.2. MySqld 服务器程序构成</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/30/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
      <url>2021/03/30/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><img src="/Users/joker/Library/Application Support/typora-user-images/image-20210330143041151.png" alt="image-20210330143041151" style="zoom:50%;" /><h2 id="2-切换数据库"><a href="#2-切换数据库" class="headerlink" title="2. 切换数据库"></a>2. 切换数据库</h2><h2 id="3-数据库键空间"><a href="#3-数据库键空间" class="headerlink" title="3. 数据库键空间"></a>3. 数据库键空间</h2><p><img src="/Users/joker/Documents/redis/images/8.png" alt="截屏2021-03-30 下午3.10.32"></p><h3 id="3-1-添加新键"><a href="#3-1-添加新键" class="headerlink" title="3.1. 添加新键"></a>3.1. 添加新键</h3><p><img src="/Users/joker/Documents/redis/images/9.png" alt="截屏2021-03-30 下午3.09.49"></p><h3 id="3-2-删除键"><a href="#3-2-删除键" class="headerlink" title="3.2. 删除键"></a>3.2. 删除键</h3><h3 id="3-3-更新键"><a href="#3-3-更新键" class="headerlink" title="3.3. 更新键"></a>3.3. 更新键</h3><h3 id="3-4-对键取值"><a href="#3-4-对键取值" class="headerlink" title="3.4. 对键取值"></a>3.4. 对键取值</h3><h2 id="4-设置键的生存时间"><a href="#4-设置键的生存时间" class="headerlink" title="4. 设置键的生存时间"></a>4. 设置键的生存时间</h2><p><img src="/Users/joker/Documents/redis/images/6.png" alt="截屏2021-03-30 下午3.08.15"></p><h2 id="5-哈希表-rehash"><a href="#5-哈希表-rehash" class="headerlink" title="5. 哈希表 rehash"></a>5. 哈希表 rehash</h2><p>Redis 使用个哈希表来保存所有键值对。一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。每个哈希桶中保存了键值对数据。</p><p>哈希表的最大好处很明显，就是可以用 O(1) 的时间复杂度来快速查找到键值对，只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素</p><h3 id="5-1-哈希表操作变慢"><a href="#5-1-哈希表操作变慢" class="headerlink" title="5.1. 哈希表操作变慢"></a>5.1. 哈希表操作变慢</h3><p>当往哈希表中写入更多数据时，哈希冲突是不可避免的问题，两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。Redis 解决哈希冲突的方式，就是链式哈希，同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。</p><p>这里依然存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求”快”的 Redis 来说，这是不能接受的。</p><p>Redis 会对哈希表做 rehash 操作,增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。</p><p>为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步</p><ol><li>给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍</li><li>把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中</li><li>释放哈希表 1 的空间。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/30/Redis%20%E5%86%85%E9%83%A8%E7%9A%84%E9%98%BB%E5%A1%9E%E5%BC%8F%E6%93%8D%E4%BD%9C/"/>
      <url>2021/03/30/Redis%20%E5%86%85%E9%83%A8%E7%9A%84%E9%98%BB%E5%A1%9E%E5%BC%8F%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Redis 的网络 IO 和键值对读写是由主线程完成的。如果在主线程上执行的操作消耗的时间太长，就会引起主线程阻塞。但是，Redis 既有服务客户端请求的键值对增删改查操作，也有保证可靠性的持久化操作，还有进行主从复制时的数据同步操作，等。究竟哪些会引起阻塞呢？</p><a id="more"></a><p>Redis 实例在运行时，要和许多对象进行交互，这些不同的交互就会涉及不同的操作</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-30 上午11.21.30.png" alt="截屏2021-03-30 上午11.21.30" style="zoom:50%;" /><h2 id="1-客户端交互"><a href="#1-客户端交互" class="headerlink" title="1. 客户端交互"></a>1. 客户端交互</h2><h4 id="1-1-1-网络-IO"><a href="#1-1-1-网络-IO" class="headerlink" title="1.1.1. 网络 IO"></a>1.1.1. 网络 IO</h4><p>网络 IO 有时候会比较慢，但是 Redis 使用了 IO 多路复用机制，避免了主线程一直处在等待网络连接或请求到来的状态，所以，网络 IO 不是导致 Redis 阻塞的因素。</p><h4 id="1-1-2-键值对增删改查操作"><a href="#1-1-2-键值对增删改查操作" class="headerlink" title="1.1.2. 键值对增删改查操作"></a>1.1.2. 键值对增删改查操作</h4><p>键值对的增删改查操作是 Redis 和客户端交互的主要部分，也是 Redis 主线程执行的主要任务。所以，复杂度高的增删改查操作肯定会阻塞 Redis。</p><p>通过操作的复杂度是否为 O(N)，判断操作复杂度是不是高。</p><p>Redis 中涉及集合的操作复杂度通常为 O(N)，例如集合元素全量查询操作 HGETALL、SMEMBERS，以及集合的聚合统计操作，例如求交、并和差集。这些操作可以作为 **<font color='blue'>Redis 的第一个阻塞点: 集合全量查询和聚合操作</font>**。</p><p>删除操作的本质是要释放键值对占用的内存空间。</p><p>为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序，所以，如果一下释放大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞。</p><p>最典型的就是删除包含了大量元素的集合，也称为 bigkey 删除。**<font color='blue'>bigkey 删除操作就是 Redis 的第二个阻塞点</font>**。删除操作对 Redis 实例性能的负面影响很大</p><p>在 Redis 的数据库级别操作中，清空数据库(FLUSHDB 和 FLUSHALL 操作)也是一个潜在的阻塞风险，因为它涉及到删除和释放所有的键值对。这就是 **<font color='blue'>Redis 的第三个阻塞点: 清空数据库</font>**。</p><h2 id="2-磁盘交互"><a href="#2-磁盘交互" class="headerlink" title="2. 磁盘交互"></a>2. 磁盘交互</h2><p>磁盘 IO 一般都是比较费时费力的,Redis 设计为采用子进程的方式生成 RDB 快照文件，以及执行 AOF 日志重写操作。这样一来，这两个操作由子进程负责执行，慢速的磁盘 IO 就不会阻塞主线程了。</p><p>但是，Redis 直接记录 AOF 日志时，会根据不同的写回策略对数据做落盘保存。一个同步写磁盘的操作的耗时大约是 1～2ms，如果有大量的写操作需要记录在 AOF 日志中，并同步写回的话，就会阻塞主线程了。这就得到了 **<font color='blue'>Redis 的第四个阻塞点了: AOF 日志同步写</font>**。</p><h2 id="3-主从节点交互"><a href="#3-主从节点交互" class="headerlink" title="3. 主从节点交互"></a>3. 主从节点交互</h2><p>在主从集群中，主库需要生成 RDB 文件，并传输给从库。主库在复制的过程中，创建和传输 RDB 文件都是由子进程来完成的，不会阻塞主线程。但是，对于从库来说，它在接收了 RDB 文件后，需要使用 FLUSHDB 命令清空当前数据库，这就正好撞上了刚才我们分析的第三个阻塞点。此外，从库在清空当前数据库后，还需要把 RDB 文件加载到内存，这个过程的快慢和 RDB 文件的大小密切相关，RDB 文件越大，加载过程越慢，所以，**<font color='blue'>加载 RDB 文件就成为了 Redis 的第五个阻塞点。</font>**</p><h2 id="4-切片集群实例交互"><a href="#4-切片集群实例交互" class="headerlink" title="4. 切片集群实例交互"></a>4. 切片集群实例交互</h2><p>部署 Redis 切片集群时，每个 Redis 实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对 Redis 主线程的阻塞风险不大。不过，如果你使用了 Redis Cluster 方案，而且同时正好迁移的是 bigkey 的话，就会造成主线程的阻塞，因为 Redis Cluster 使用了同步迁移。我将在第 33 讲中向你介绍不同切片集群方案对数据迁移造成的阻塞的解决方法，这里你只需要知道，当没有 bigkey 时，切片集群的各实例在进行交互时不会阻塞主线程，就可以了。</p><h2 id="5-阻塞点异步执行"><a href="#5-阻塞点异步执行" class="headerlink" title="5. 阻塞点异步执行"></a>5. 阻塞点异步执行</h2><p>如果一个操作能被异步执行，就意味着，它并不是 Redis 主线程的关键路径上的操作。</p><h2 id="6-异步的子线程机制"><a href="#6-异步的子线程机制" class="headerlink" title="6. 异步的子线程机制"></a>6. 异步的子线程机制</h2><p>Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。</p><p>主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。因此，我们把这种异步删除也称为惰性删除（lazy free）。此时，删除或清空操作不会阻塞主线程，这就避免了对主线程的性能影响。</p><p>和惰性删除类似，当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/30/Redis-6.0%E7%9A%84%E6%96%B0%E7%89%B9%E6%80%A7/"/>
      <url>2021/03/30/Redis-6.0%E7%9A%84%E6%96%B0%E7%89%B9%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Redis 6.0 中的增加了几个关键新特性，分别是面向网络处理的多 IO 线程、客户端缓存、细粒度的权限控制，以及 RESP 3 协议的使用。</p><a id="more"></a><p>面向网络处理的多 IO 线程可以提高网络请求处理的速度，而客户端缓存可以让应用直接在客户端本地读取数据，这两个特性可以提升 Redis 的性能。除此之外，细粒度权限控制让 Redis 可以按照命令粒度控制不同用户的访问权限，加强了 Redis 的安全保护。RESP 3 协议则增强客户端的功能，可以让应用更加方便地使用 Redis 的不同数据类型。</p><h2 id="1-从单线程处理网络请求到多线程处理"><a href="#1-从单线程处理网络请求到多线程处理" class="headerlink" title="1. 从单线程处理网络请求到多线程处理"></a>1. 从单线程处理网络请求到多线程处理</h2><p>在 Redis 6.0 其中一个新特性就是多线程。这是因为，Redis 一直被熟知的是它的单线程架构，虽然有些命令操作可以用后台线程或子进程执行(比如数据删除、快照生成、AOF 重写)，但是，从网络 IO 处理到实际的读写命令处理，都是由单个线程完成的。随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 IO 的处理上，也就是说，单个主线程处理网络请求的速度跟不上底层网络硬件的速度。</p><p>Redis 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。Redis 处理请求时，网络处理经常是瓶颈，通过多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。</p><h3 id="1-1-多线程-IO-四个阶段"><a href="#1-1-多线程-IO-四个阶段" class="headerlink" title="1.1. 多线程 IO 四个阶段"></a>1.1. 多线程 IO 四个阶段</h3><p>可以把主线程和多 IO 线程的协作分成四个阶段。</p><h4 id="1-1-1-服务端和客户端建立-Socket-连接，并分配处理线程"><a href="#1-1-1-服务端和客户端建立-Socket-连接，并分配处理线程" class="headerlink" title="1.1.1. 服务端和客户端建立 Socket 连接，并分配处理线程"></a>1.1.1. 服务端和客户端建立 Socket 连接，并分配处理线程</h4><p>首先，主线程负责接收建立连接请求。当有客户端请求和实例建立 Socket 连接时，主线程会创建和客户端的连接，并把 Socket 放入全局等待队列中。紧接着，主线程通过轮询方法把 Socket 连接分配给 IO 线程。</p><h4 id="1-1-2-IO-线程读取并解析请求"><a href="#1-1-2-IO-线程读取并解析请求" class="headerlink" title="1.1.2. IO 线程读取并解析请求"></a>1.1.2. IO 线程读取并解析请求</h4><p>主线程一旦把 Socket 分配给 IO 线程，就会进入阻塞状态，等待 IO 线程完成客户端请求读取和解析。因为有多个 IO 线程在并行处理，所以，这个过程很快就可以完成。</p><h4 id="1-1-3-主线程执行请求操作"><a href="#1-1-3-主线程执行请求操作" class="headerlink" title="1.1.3. 主线程执行请求操作"></a>1.1.3. 主线程执行请求操作</h4><p>等到 IO 线程解析完请求，主线程还是会以单线程的方式执行这些命令操作。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-30 上午10.23.04.png" alt="截屏2021-03-30 上午10.23.04" style="zoom:75%;" /><h4 id="1-1-4-IO-线程回写-Socket-和主线程清空全局队列"><a href="#1-1-4-IO-线程回写-Socket-和主线程清空全局队列" class="headerlink" title="1.1.4. IO 线程回写 Socket 和主线程清空全局队列"></a>1.1.4. IO 线程回写 Socket 和主线程清空全局队列</h4><p>当主线程执行完请求操作后，会把需要返回的结果写入缓冲区，然后，主线程会阻塞等待 IO 线程把这些结果回写到 Socket 中，并返回给客户端。和 IO 线程读取和解析请求一样，IO 线程回写 Socket 时，也是有多个线程在并发执行，所以回写 Socket 的速度也很快。等到 IO 线程回写 Socket 完毕，主线程会清空全局队列，等待客户端的后续请求。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-30 上午10.29.02.png" alt="截屏2021-03-30 上午10.29.02" style="zoom:75%;" /><h3 id="1-2-启用多线程"><a href="#1-2-启用多线程" class="headerlink" title="1.2. 启用多线程"></a>1.2. 启用多线程</h3><p>在 Redis 6.0 中，多线程机制默认是关闭的，如果需要使用多线程功能，需要在 redis.conf 中完成两个设置。</p><h4 id="1-2-1-设置-io-thread-do-reads-配置项为-yes，表示启用多线程。"><a href="#1-2-1-设置-io-thread-do-reads-配置项为-yes，表示启用多线程。" class="headerlink" title="1.2.1. 设置 io-thread-do-reads 配置项为 yes，表示启用多线程。"></a>1.2.1. 设置 io-thread-do-reads 配置项为 yes，表示启用多线程。</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">io<span class="literal">-threads</span><span class="literal">-do</span><span class="literal">-reads</span> yes</span><br></pre></td></tr></table></figure><h4 id="1-2-2-设置线程个数"><a href="#1-2-2-设置线程个数" class="headerlink" title="1.2.2. 设置线程个数"></a>1.2.2. 设置线程个数</h4><p>一般来说，线程个数要小于 Redis 实例所在机器的 CPU 核个数，例如，对于一个 8 核的机器来说，Redis 官方建议配置 6 个 IO 线程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">io-threads  6</span><br></pre></td></tr></table></figure><h2 id="2-客户端缓存"><a href="#2-客户端缓存" class="headerlink" title="2. 客户端缓存"></a>2. 客户端缓存</h2><p>Redis 6.0 新增了一个重要的特性，实现了服务端协助的客户端缓存功能(跟踪 Tracking)功能。业务应用中的 Redis 客户端就可以把读取的数据缓存在业务应用本地了，应用就可以直接在本地快速读取数据了。</p><p><strong><font color='blue'>如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理？</font></strong></p><p>redis 6.0 Tracking 功能实现了两种模式</p><h3 id="2-1-普通模式"><a href="#2-1-普通模式" class="headerlink" title="2.1. 普通模式"></a>2.1. 普通模式</h3><p>在这个模式下，实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。</p><p>在使用普通模式时，服务端对于记录的 key 只会报告一次 invalidate 消息，也就是说，服务端在给客户端发送过一次 invalidate 消息后，如果 key 再被修改，此时，服务端就不会再次给客户端发送 invalidate 消息。</p><p>只有当客户端再次执行读命令时，服务端才会再次监测被读取的 key，并在 key 修改时发送 invalidate 消息。这样设计的考虑是节省有限的内存空间。毕竟，如果客户端不再访问这个 key 了，而服务端仍然记录 key 的修改情况，就会浪费内存资源。</p><p>可以通过执行下面的命令，打开或关闭普通模式下的 Tracking 功能</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLIENT TRACKING ON|OFF</span><br></pre></td></tr></table></figure><h3 id="2-2-广播模式"><a href="#2-2-广播模式" class="headerlink" title="2.2. 广播模式"></a>2.2. 广播模式</h3><p>在这个模式下，服务端会给客户端广播所有 key 的失效情况，如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。</p><p>在实际应用时，客户端注册希望跟踪的 key 的前缀，当带有注册前缀的 key 被修改时，服务端会把失效消息广播给所有注册的客户端。和普通模式不同，在广播模式下，即使客户端还没有读取过 key，但只要注册了要跟踪的 key，服务端都会把 key 失效消息通知给这个客户端。</p><p>在客户端执行下面的命令后，如果服务端更新了 <code>user:id:1003</code> 这个 key，那么，客户端就会收到 invalidate 消息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLIENT TRACKING ON BCAST PREFIX user</span><br></pre></td></tr></table></figure><p>普通模式和广播模式，需要客户端使用 RESP 3 协议，RESP 3 协议是 6.0 新启用的通信协议</p><h3 id="2-3-广播模式"><a href="#2-3-广播模式" class="headerlink" title="2.3. 广播模式"></a>2.3. 广播模式</h3><p>对于使用 RESP 2 协议的客户端来说，就需要使用重定向模式(redirect)。在重定向模式下，想要获得失效消息通知的客户端，就需要执行订阅命令 <code>SUBSCRIBE</code>，专门订阅用于发送失效消息的频道 <code>_redis_:invalidate</code>。同时，再使用另外一个客户端，执行 <code>CLIENT TRACKING</code> 命令，设置服务端将失效消息转发给使用 RESP 2 协议的客户端。</p><p>客户端 B 想要获取失效消息，但是客户端 B 只支持 RESP 2 协议，客户端 A 支持 RESP 3 协议。我们可以分别在客户端 B 和 A 上执行 SUBSCRIBE 和 CLIENT TRACKING，如下所示</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//客户端B执行，客户端B的ID号是303</span><br><span class="line">SUBSCRIBE _redis_:invalidate</span><br><span class="line">//客户端A执行</span><br><span class="line">CLIENT TRACKING ON BCAST REDIRECT 303</span><br></pre></td></tr></table></figure><p>如果有键值对被修改了，客户端 B 就可以通过 <em>redis</em>:invalidate 频道，获得失效消息了</p><h2 id="3-从简单的基于密码访问到细粒度的权限控制"><a href="#3-从简单的基于密码访问到细粒度的权限控制" class="headerlink" title="3. 从简单的基于密码访问到细粒度的权限控制"></a>3. 从简单的基于密码访问到细粒度的权限控制</h2><p>在 Redis 6.0 版本之前，要想实现实例的安全访问，只能通过设置密码来控制，例如，客户端连接实例前需要输入密码。此外，对于一些高风险的命令(例如 KEYS、FLUSHDB、FLUSHALL 等)</p><p>在 Redis 6.0 之前，只能通过 rename-command 来重新命名这些命令，避免客户端直接调用。Redis 6.0 提供了更加细粒度的访问权限控制，这主要有两方面的体现。</p><h3 id="3-1-支持创建不同用户来使用-Redis"><a href="#3-1-支持创建不同用户来使用-Redis" class="headerlink" title="3.1. 支持创建不同用户来使用 Redis"></a>3.1. 支持创建不同用户来使用 Redis</h3><p>在 6.0 版本前，所有客户端可以使用同一个密码进行登录使用，但是没有用户的概念，而在 6.0 中，可以使用 <code>ACL SETUSER</code> 命令创建用户。</p><p>可以执行下面的命令，创建并启用一个用户 normaluser，把它的密码设置为 abc</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ACL SETUSER normaluser on &gt; abc</span><br></pre></td></tr></table></figure><h3 id="3-2-以用户为粒度设置命令操作的访问权限。"><a href="#3-2-以用户为粒度设置命令操作的访问权限。" class="headerlink" title="3.2. 以用户为粒度设置命令操作的访问权限。"></a>3.2. 以用户为粒度设置命令操作的访问权限。</h3><p>加号（+）和减号（-）就分别表示给用户赋予或撤销命令的调用权限。</p><p>设置用户 normaluser 只能调用 Hash 类型的命令操作，而不能调用 String 类型的命令操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ACL SETUSER normaluser +@hash -@string</span><br></pre></td></tr></table></figure><p>除了设置某个命令或某类命令的访问控制权限，6.0 版本还支持以 key 为粒度设置访问权限。</p><p>使用波浪号<code>~</code>和 key 的前缀来表示控制访问的 key。</p><p>设置用户 normaluser 只能对以 <code>user:</code> 为前缀的 key 进行命令操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ACL SETUSER normaluser ~user:* +@all</span><br></pre></td></tr></table></figure><h2 id="4-启用-RESP-3-协议"><a href="#4-启用-RESP-3-协议" class="headerlink" title="4. 启用 RESP 3 协议"></a>4. 启用 RESP 3 协议</h2><p>Redis 6.0 实现了 RESP 3 通信协议，在 RESP 2 中，客户端和服务器端的通信内容都是以字节数组形式进行编码的，客户端需要根据操作的命令或是数据类型自行对传输的数据进行解码，增加了客户端开发复杂度。而 RESP 3 直接支持多种数据类型的区分编码，包括空值、浮点数、布尔值、有序的字典集合、无序的集合等。所谓区分编码，就是指直接通过不同的开头字符，区分不同的数据类型，这样一来，客户端就可以直接通过判断传递消息的开头字符，来实现数据转换操作了，提升了客户端的效率。除此之外，RESP 3 协议还可以支持客户端以普通模式和广播模式实现客户端缓存。</p><h2 id="5-小结"><a href="#5-小结" class="headerlink" title="5. 小结"></a>5. 小结</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/26/%E7%B4%A2%E5%BC%95%E6%A8%A1%E5%9E%8B/"/>
      <url>2021/03/26/%E7%B4%A2%E5%BC%95%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>索引提高了查询效率，实现索引的方式却有很多种，比较常见的有哈希表、有序数组和搜索树。</p><h2 id="1-哈希表"><a href="#1-哈希表" class="headerlink" title="1. 哈希表"></a>1. 哈希表</h2><p>哈希表是一种以键-值(key-value)存储数据的结构，只要输入待查找的键即 key，就可以找到其对应的值即 Value。用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置, 多个 key 值经过哈希函数的换算，会出现同一个值的情况。一般处理这种情况的一种方法是，拉出一个链表。哈希表适用于只有等值查询的场景，</p><h2 id="2-有序数组"><a href="#2-有序数组" class="headerlink" title="2. 有序数组"></a>2. 有序数组</h2><p>有序数组索引只适用于静态存储引擎，比如你要保存的是 2020 年某个城市的所有人口信息，这类不会再修改的数据。</p><h2 id="3-二叉搜索树"><a href="#3-二叉搜索树" class="headerlink" title="3. 二叉搜索树"></a>3. 二叉搜索树</h2><p>二叉搜索树的特点是：父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值。</p><p>二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。</p><blockquote><p>一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 * 10 ms 的时间,查询效率低。</p></blockquote><h2 id="4-N-叉树"><a href="#4-N-叉树" class="headerlink" title="4. N 叉树"></a>4. <code>N</code> 叉树</h2><p>为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。要使用 <code>N</code> 叉树。这里，<code>N</code> 叉树中的 <code>N</code> 取决于数据块的大小。</p><blockquote><p>以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</p></blockquote><p>N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。</p><h2 id="5-Innodb-索引模型"><a href="#5-Innodb-索引模型" class="headerlink" title="5. Innodb 索引模型"></a>5. Innodb 索引模型</h2><p>在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也不同。</p><p>在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。每一个索引在 InnoDB 里面对应一棵 B+ 树。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/26/%E8%A1%8C%E6%BA%A2%E5%87%BA/"/>
      <url>2021/03/26/%E8%A1%8C%E6%BA%A2%E5%87%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create table test_0326_01 (name varchar(65535), age int) charset&#x3D;utf8mb4 engine&#x3D;innodb  row_format&#x3D;compact;</span><br><span class="line">ERROR 1074 (42000): Column length too big for column &#39;name&#39; (max &#x3D; 16383); use BLOB or TEXT instead</span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/26/MySQL%20%E8%A1%A8%E7%BB%93%E6%9E%84%E5%AE%9A%E4%B9%89%E6%96%87%E4%BB%B6/"/>
      <url>2021/03/26/MySQL%20%E8%A1%A8%E7%BB%93%E6%9E%84%E5%AE%9A%E4%B9%89%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/26/%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97/"/>
      <url>2021/03/26/%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/25/checkpoint/"/>
      <url>2021/03/25/checkpoint/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>缓冲池的设计目的为了协调 CPU 速度与磁盘速度。因此页的操作首先都是在缓冲池中完成的。如果一条DML语句，如Update 或 Delete 改变了页中的记录，那么此时页是脏的，即缓冲池中的页的版本要比磁盘的新。数据库需要将新版本的页从缓冲池刷新到磁盘。</p><a id="more"></a><p>如果每次一个页发生变化，就将新页的版本刷新到磁盘，开销非常大。若热点数据集中在某几个页中，那么数据库的性能将变得非常差。同时，如果在从缓冲池将页的新版本刷新到磁盘时发生了宕机，那么数据就不能恢复了。为了避免发生数据丢失的问题，当前事务数据库系统普遍采用了 <code>Write Ahead Log</code> 策略，即当事务提交时，先写重做日志，再修改页。当由于发生宕机而导致数据丢失时，通过重做日志来完成数据的恢复。这也是事务 ACID 中 D(Durability持久性)的要求。</p><p>如果重做日志可以无限地增大，同时缓冲池也足够大，能够缓冲所有数据库的数据，那么是不需要将缓冲池中页的新版本刷新回磁盘。因为当发生宕机时，完全可以通过重做日志来恢复整个数据库系统中的数据到宕机发生的时刻。但是这<br>需要两个前提条候：缓冲池可以缓存数据库中所有的数据；<br>重做日志可以无限增大。对于第一个前提条件，有经验的用户都知道，当数据库刚开始创建时，表中没有任何数据。缓冲池的确可以缓存所有的数据库文件。然而随着市场的推广，用户的增加，产品越来越受到关注，使用量也越来越大。这时负责后台存储的数据库的容量必定会不断增大。当前3TB的MySQL数据库已并不少见，但3TB的内存却非常少见。目前<br>Oracle Exadata 旗舰数据库一体机也就只有2TB的内存。因此第一个假设对于生产环境<br>应用中的数据库是很难得到保证的。<br>再来看第二个前提条件：重做日志可以无限增大。也许是可以的，但是这对成本的<br>要求太高，同时不便于运维。DBA或SA不能知道什么时候重做日志是否已经接近于磁</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/22/undolog/"/>
      <url>2021/03/22/undolog/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Undo log 是 InnoDB MVCC 事务特性的重要组成部分。当对记录做了变更操作时就会产生 Undo 记录，Undo 记录默认被记录到系统表空间 (ibdata) 中，但从 5.6 开始，也可以使用独立的 Undo 表空间。</p><a id="more"></a><p>Undo 日志用于存放数据修改被修改前的值，假设修改 tba 表中 id=2 的行数据，把Name=’B’ 修改为 Name = ‘B2’ ，那么 Undo 日志就会用来存放 Name=’B’的记录，如果这个修改出现异常，可以使用 undo 日志来实现回滚操作，保证事务的一致性。</p><p>对数据的变更操作，主要来自 INSERT UPDATE DELETE，而 UNDO LOG 中分为两种类型，一种是 INSERT_UNDO(INSERT操作)，记录插入的唯一键值；一种是 UPDATE_UNDO (包含 UPDATE 及 DELETE 操作)，记录修改的唯一键值以及 old column 记录。 </p><p>在 Innodb 当中，INSERT 操作在事务提交前只对当前事务可见，Undo log 在事务提交后即会被删除，因为新插入的数据没有历史版本，所以无需维护 Undo log。而对于 UPDATE、DELETE，责需要维护多版本信息。 在 InnoDB 当中，UPDATE 和 DELETE 操作产生的 Undo log 都属于同一类型：update_undo。</p><h2 id="1-Undo-概述"><a href="#1-Undo-概述" class="headerlink" title="1. Undo 概述"></a>1. Undo 概述</h2><p>Session1(以下简称S1) 和 Session2(以下简称S2) 同时访问（不一定同时发起，但S1和S2事务有重叠）同一数据 A，S1 想将数据 A 修改为数据 B，S2 想读取数据 A 的数据。如果没有 MVCC 只能依赖加锁了，谁拥有锁谁先执行，另一个等待。但是高并发下效率很低。</p><p>InnoDB 存储引擎通过多版本控制的方式来读取当前执行时间数据库中行的数据，如果读取的行正在执行 DELETE 或 UPDATE操作，这是读取操作不会因此等待行上锁的释放。相反的，InnoDB 会去读取行的一个快照数据(Undo log)。</p><p>在 InnoDB 当中，要对一条数据进行处理，会先看这条数据的版本号是否大于自身事务版本(非 RU 隔离级别下当前事务发生之后的事务对当前事务来说是不可见的)，如果大于，则从历史快照 (undo log链) 中获取旧版本数据，来保证数据一致性。而由于历史版本数据存放在 undo 页当中，对数据修改所加的锁对于 undo 页没有影响，所以不会影响用户对历史数据的读，从而达到非一致性锁定读，提高并发性能。</p><p>如果出现了错误或者用户手动执行了 rollback，系统可以利用 undo log 中的备份将数据恢复到事务开始之前的状态。与redo log 不同的是，磁盘上不存在单独的 undo log 文件，他存放在数据库内部的特殊段（segment）中</p><h2 id="2-文件结构"><a href="#2-文件结构" class="headerlink" title="2. 文件结构"></a>2. 文件结构</h2><p>undo 是逻辑日志，在事务回滚时对数据库进行一些补偿性的修改，以使数据在逻辑上回到修改前的样子，它并不幂等。在Innodb 中使用表空间，回滚段，页等多级概念结构实现 undo 功能</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/17/%E4%BD%BF%E7%94%A8%20Redis%20%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
      <url>2021/03/17/%E4%BD%BF%E7%94%A8%20Redis%20%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Redis 属于分布式系统，当有多个客户端需要争抢锁时，我们必须要保证，这把锁不能是某个客户端本地的锁。否则的话，其它客户端是无法访问这把锁的，当然也就不能获取这把锁了。</p><a id="more"></a><p>锁是保存在一个共享存储系统中的，可以被多个客户端共享访问和获取。</p><h2 id="1-单机锁"><a href="#1-单机锁" class="headerlink" title="1. 单机锁"></a>1. 单机锁</h2><p>通常说的线程调用加锁和释放锁的操作，实际上，一个线程调用加锁操作，其实就是检查锁变量值是否为 0。如果是 0，就把锁的变量值设置为 1，表示获取到锁，如果不是 0，就返回错误信息，表示加锁失败，已经有别的线程获取到锁了。而一个线程调用释放锁操作，其实就是将锁变量的值置为 0，以便其它线程可以来获取锁。</p><h2 id="2-基于单个-Redis-节点实现分布式锁"><a href="#2-基于单个-Redis-节点实现分布式锁" class="headerlink" title="2. 基于单个 Redis 节点实现分布式锁"></a>2. 基于单个 Redis 节点实现分布式锁</h2><p>作为分布式锁实现过程中的共享存储系统，Redis 使用键值对来保存锁变量，再接收和处理不同客户端发送的加锁和释放锁的操作请求。赋予锁变量一个变量名，把这个变量名作为键值对的键，而锁变量的值，则是键值对的值，Redis 保存锁变量，客户端也可以通过 Redis 的命令操作来实现锁操作。</p><h3 id="2-1-读操作"><a href="#2-1-读操作" class="headerlink" title="2.1. 读操作"></a>2.1. 读操作</h3><h3 id="2-2-写操作"><a href="#2-2-写操作" class="headerlink" title="2.2. 写操作"></a>2.2. 写操作</h3><h3 id="2-3-潜在风险"><a href="#2-3-潜在风险" class="headerlink" title="2.3. 潜在风险"></a>2.3. 潜在风险</h3><p>使用 SETNX 和 DEL 命令组合实现分布锁，存在两个潜在的风险</p><h4 id="2-3-1-操作共享数据异常"><a href="#2-3-1-操作共享数据异常" class="headerlink" title="2.3.1. 操作共享数据异常"></a>2.3.1. 操作共享数据异常</h4><p>某个客户端在执行了 SETNX 命令、加锁之后，紧接着却在操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。因此，锁就一直被这个客户端持有，其它客户端无法拿到锁，也无法访问共享数据和执行后续操作，这会给业务应用带来影响。</p><h4 id="2-3-2-释放锁错误"><a href="#2-3-2-释放锁错误" class="headerlink" title="2.3.2. 释放锁错误"></a>2.3.2. 释放锁错误</h4><p>如果客户端 A 执行了 SETNX 命令加锁后，假设客户端 B 执行了 DEL 命令释放锁，此时，客户端 A 的锁就被误释放了。如果客户端 C 正好也在申请加锁，就可以成功获得锁，进而开始操作共享数据。这样一来，客户端 A 和 C 同时在对共享数据进行操作，数据就会被修改错误，这也是业务层不能接受的。</p><p>为了应对这个问题，需要能区分来自不同客户端的锁操作，可以在锁变量的值上想想办法。在使用 SETNX 命令进行加锁的方法中，通过把锁变量值设置为 1 或 0，表示是否加锁成功。1 和 0 只有两种状态，无法表示究竟是哪个客户端进行的锁操作。在加锁操作时，可以让每个客户端给锁变量设置一个唯一值，这里的唯一值就可以用来标识当前操作的客户端。在释放锁操作时，客户端需要判断，当前锁变量的值是否和自己的唯一标识相等，只有在相等的情况下，才能释放锁。这样一来，就不会出现误释放锁的问题了。</p><p>我们刚刚在说 SETNX 命令的时候提到，对于不存在的键值对，它会先创建再设置值（也就是“不存在即设置”），为了能达到和 SETNX 命令一样的效果，Redis 给 SET 命令提供了类似的选项 NX，用来实现“不存在即设置”。如果使用了 NX 选项，SET 命令只有在键值对不存在时，才会进行设置，否则不做赋值操作。此外，SET 命令在执行时还可以带上 EX 或 PX 选项，用来设置键值对的过期时间。举个例子，执行下面的命令时，只有 key 不存在时，SET 才会创建 key，并对 key 进行赋值。另外，key 的存活时间由 seconds 或者 milliseconds 选项值来决定。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/16/%E5%BF%AB%E9%80%9F%E7%9A%84%20Redis%20%E6%9C%89%E5%93%AA%E4%BA%9B%E6%85%A2%E6%93%8D%E4%BD%9C%EF%BC%9F/"/>
      <url>2021/03/16/%E5%BF%AB%E9%80%9F%E7%9A%84%20Redis%20%E6%9C%89%E5%93%AA%E4%BA%9B%E6%85%A2%E6%93%8D%E4%BD%9C%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-为什么-Redis-能那么快？"><a href="#1-为什么-Redis-能那么快？" class="headerlink" title="1. 为什么 Redis 能那么快？"></a>1. 为什么 Redis 能那么快？</h2><p>Redis 能有突出的表现一方面是因为它是内存数据库，所有操作都在内存上完成，内存的访问速度本身就很快。另一方面，归功于它的数据结构。这是因为，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是 Redis 快速处理数据的基础</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/12/%E4%B8%B4%E6%97%B6%E8%A1%A8/"/>
      <url>2021/03/12/%E4%B8%B4%E6%97%B6%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="2-临时表的应用"><a href="#2-临时表的应用" class="headerlink" title="2. 临时表的应用"></a>2. 临时表的应用</h1>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/12/redolog/"/>
      <url>2021/03/12/redolog/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>redo log 包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。</p><p><code>InnoDB</code> 作为 MySQL 的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘 IO，效率会很低。为此，<code>InnoDB</code> 提供了缓存(Buffer Pool)，<code>Buffer Pool</code> 中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从 <code>Buffer Pool</code> 中读取，如果 <code>Buffer Pool</code> 中没有，则从磁盘读取后放入 <code>Buffer Pool</code>；当向数据库写入数据时，会首先写入 <code>Buffer Pool</code>，<code>Buffer Pool</code> 中修改的数据会定期刷新到磁盘中(这一过程称为刷脏)。</p><p><code>Buffer Pool</code> 的使用大大提高了读写数据的效率，但是也带了新的问题: 如果 MySQL 宕机，而此时 <code>Buffer Pool</code> 中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。</p><p>redo log 被引入来解决这个问题：当数据修改时，除了修改 Buffer Pool 中的数据，还会在 redo log 记录这次操作；当事务提交时，会调用 fsync 接口对 redo log 进行刷盘。如果 MySQL 宕机，重启时可以读取 redo log 中的数据，对数据库进行恢复。redo log 采用的是 WAL(Write-ahead logging，预写式日志)，所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因 MySQL 宕机而丢失，从而满足了持久性要求。</p><h2 id="1-InnoDB-中的实现"><a href="#1-InnoDB-中的实现" class="headerlink" title="1. InnoDB 中的实现"></a>1. InnoDB 中的实现</h2><p>**redo log **每个 Innodb 存储引擎至少有一个重做日志文件组(group)，每个文件组下至少有2个重做日志文件，如默认的ib_logfile0 和 ib_logfile1，其默认路径位于引擎的数据目录。</p><p>设置多个日志文件时，其名字以 <code>ib_logfile[num]</code> 形式命名。多个日志文件循环利用，第一个文件写满时，换到第二个日志文件，最后一个文件写满时，回到第一个文件，组成逻辑上无限大的空间。在 Innodb1.2.x 前，重做日志文件的总大小不能大于等于4GB，1.2.x版本该限制以扩大到512GB.</p><p>重做日志文件设置的越大，越可以减少 checkpoint 刷新脏页的频率，这有时候对提升MySQL的性能非常重要，但缺点是增加了恢复时的耗时；如果设置的过小，则可能需要频繁地切换文件，甚至一个事务的日志要多次切换文件，导致性能的抖动。</p><h2 id="2-文件结构"><a href="#2-文件结构" class="headerlink" title="2. 文件结构"></a>2. 文件结构</h2><p>在存储结构上，redo log 文件以 block 块来组织，每个 block 大小为 512 字节。每个文件的开头有一个 2k 大小的File Header 区域用来保存一些控制信息，File Header 之后就是连续的 block。虽然每个 redo log 文件在头部划出了 File Header 区域，但实际存储信息的只有 group 中第一个 redo log 文件。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-25 上午9.30.36.png" alt="截屏2021-03-25 上午9.30.36" style="zoom:50%;" /><h3 id="2-1-File-Header"><a href="#2-1-File-Header" class="headerlink" title="2.1. File Header"></a>2.1. <strong>File Header</strong></h3><p>File Header 位于每个 redo log 文件的开始，大小为2k，格式如下</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-25 上午9.32.06.png" alt="截屏2021-03-25 上午9.32.06" style="zoom:50%;" /><p>log group 中的第一个文件实际存储这些信息，其他文件仅保留了空间。在写入日志时，除了完成 block 部分，还要更新File Header里的信息，这些信息对 Innodb 引擎的恢复操作非常关键。</p><h3 id="2-2-Block"><a href="#2-2-Block" class="headerlink" title="2.2. Block"></a>2.2. <strong>Block</strong></h3><p>一个 block 块有 512 字节大小，每块中还有块头和块尾，中间是日志本身。其中块头 Block Header 占有12字节大小，块尾 Block Trailer 占有 4 字节大小，中间实际的日志存储容量为496字节(512-12-4)</p><p>LOG_BLOCK_HDR_NO 在 log buffer 内部，可以看成是单位大小是512字节的 log block 组成的数组，LOG_BLOCK_HDR_NO 就用来标记数组中的位置。其根据该块的 LSN 计算转换而来，递增且循环使用，占有4个字节，第一位用来判断是否flush bit，所以总容量是2G。(LSN在之后一段说明)</p><p>LOG_BLOCK_HDR_DATA_LEN标识写入本block的日志长度，占有2个字节，当写满时用0X200表示，即有512字节。</p><p>LOG_BLOCK_FIRST_REC_GROUP占有2个字节，记录本block中第一个记录的偏移量。如果该值与LOG_BLOCK_HDR_DATA_LEN相同，说明此block被单一记录占有，不包含新的日志。如果有新日志写入，LOG_BLOCK_FIRST_REC_GROUP就是新日志的位置。</p><h3 id="2-3-LSN"><a href="#2-3-LSN" class="headerlink" title="2.3. LSN"></a>2.3. <strong>LSN</strong></h3><p>LSN 是 Log Sequence Number 的缩写，占有8字节，单调递增，记录重做日志写入的字节总量，也表示日志序列号。</p><p>LSN 除了记录在 redo 日志中，还存于每个页中。页的头部有一个FIL_PAGE_LSN用于记录该页的LSN，反应的是页的当前版本。</p><p>LSN同样也用于记录checkpoint的位置。使用SHOW ENGINE INNODB STATUS命令查看LSN情况时，Log sequence number是当前LSN，Log flushed up to 是刷新到重做日志文件的LSN，Last checkpoint at 是刷新到磁盘的LSN。</p><p>由于LSN具有单调增长性，如果重做日志中的LSN大于当前页中LSN，说明页是滞后的，如果日志记录的LSN对应的事务已经提交，那么当前页需要重做恢复。如果页被新事务修改了，页中LSN记录的是新写入的结束点的LSN，大于重做日志中的LSN，那么当前页是新数据，是脏页。脏页根据提交情况可能需要加入flush list中，此时flush list上的所以脏页也是以LSN排序。</p><p>写redo log时是追加写，需要保证写入顺序，或者说应保证LSN的有序。当并发写时可以通过加锁来控制顺序但效率低下，8.0中使用了无锁的方式完成并发写，mtr写时已经提前知道自己在log buffer上的区间位置，不必等待直接写入log buffer就可。这样大的LSN值可能先写到log buffer上，而小的LSN还没写入，即log buffer上有空洞。所以有一个单独的线程log_write，负责不断的扫描log buffer，检测新的连续内容并进行刷新，是真正的写线程。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-26 上午10.23.30.png" alt="截屏2021-03-26 上午10.23.30" style="zoom:50%;" /><p>![截屏2021-03-26 上午11.35.50](/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-26 上午11.35.50.png)</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/12/%E4%B8%80%E6%9D%A1SQL%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/"/>
      <url>2021/03/12/%E4%B8%80%E6%9D%A1SQL%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数(如日期、时间、数学和加密函数等)，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show processlist;</span><br><span class="line">+----+-----------------+-----------+------+---------+-------+----------------------+------------------+</span><br><span class="line">| Id | User            | Host      | db   | Command | Time  | State                  | Info             |</span><br><span class="line">+----+-----------------+-----------+------+---------+-------+----------------------+------------------+</span><br><span class="line">|  5 | event_scheduler | localhost | NULL | Daemon  | 47356 | Waiting on empty queue | NULL             |</span><br><span class="line">|  8 | root            | localhost | NULL | Query   |     0 | starting               | show processlist |</span><br><span class="line">|  9 | root            | localhost | NULL | Sleep   |    21 |                        | NULL             |</span><br><span class="line">+----+-----------------+-----------+------+---------+-------+----------------------+------------------+</span><br><span class="line">3 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure><h2 id="2-redo-log"><a href="#2-redo-log" class="headerlink" title="2. redo log"></a>2. redo log</h2><p>如果 MySQL 每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘</p><p>当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做</p><p>write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。</p><h2 id="3-binlog"><a href="#3-binlog" class="headerlink" title="3. binlog"></a>3. binlog</h2><p>MySQL 整体分为两层: 一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog。</p><ol><li>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</li><li>redo log 是物理日志，记录的是”在某个数据页上做了什么修改”；</li><li>binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。</li><li>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li></ol><blockquote><p> 注: </p><ul><li><p>redo log 是 InnoDB 引擎特有的; binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</p></li><li><p>redo log 是物理日志，记录的是 “在某个数据页上做了什么修改”;binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如”给 ID=2 这一行的 c 字段加 1”。</p></li><li><p>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</p></li></ul></blockquote><h2 id="4-Update-流程"><a href="#4-Update-流程" class="headerlink" title="4. Update 流程"></a>4. Update 流程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update T set c&#x3D;c+1 where ID&#x3D;2;</span><br></pre></td></tr></table></figure><ol><li>执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li><li>执行器拿到引擎给的行数据，把这个值加上 1，得到新的一行数据，再调用引擎接口写入这行新数据。</li><li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 <code>prepare</code> 状态。然后告知执行器执行完成，可以提交事务。</li><li>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。</li><li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交(commit)状态，更新完成。</li></ol><p><font color='blue'><strong>注: 将 redo log 的写入拆成了两个步骤: prepare 和 commit，这就是”两阶段提交”</strong></font></p><h2 id="5-两阶段提交"><a href="#5-两阶段提交" class="headerlink" title="5. 两阶段提交"></a>5. 两阶段提交</h2><p>由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。</p><h3 id="5-1-先写-redo-log-后写-binlog"><a href="#5-1-先写-redo-log-后写-binlog" class="headerlink" title="5.1. 先写 redo log 后写 binlog"></a>5.1. 先写 redo log 后写 binlog</h3><p>在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。</p><h3 id="5-2-先写-binlog-后写-redo-log"><a href="#5-2-先写-binlog-后写-redo-log" class="headerlink" title="5.2. 先写 binlog 后写 redo log"></a>5.2. 先写 binlog 后写 redo log</h3><p>如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了 “把 c 从 0 改成 1” 这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务，恢复出来的这一行 c 的值就是 1，与原库的值不同。</p><p>如果不使用”两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/12/%E4%B8%80%E6%9D%A1SQL%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/"/>
      <url>2021/03/12/%E4%B8%80%E6%9D%A1SQL%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-MySQL-的基本架构示意图"><a href="#1-MySQL-的基本架构示意图" class="headerlink" title="1. MySQL 的基本架构示意图"></a>1. MySQL 的基本架构示意图</h2><p>Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数(如日期、时间、数学和加密函数等)，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show processlist;</span><br><span class="line">+----+-----------------+-----------+------+---------+-------+----------------------+------------------+</span><br><span class="line">| Id | User            | Host      | db   | Command | Time  | State                  | Info             |</span><br><span class="line">+----+-----------------+-----------+------+---------+-------+----------------------+------------------+</span><br><span class="line">|  5 | event_scheduler | localhost | NULL | Daemon  | 47356 | Waiting on empty queue | NULL             |</span><br><span class="line">|  8 | root            | localhost | NULL | Query   |     0 | starting               | show processlist |</span><br><span class="line">|  9 | root            | localhost | NULL | Sleep   |    21 |                        | NULL             |</span><br><span class="line">+----+-----------------+-----------+------+---------+-------+----------------------+------------------+</span><br><span class="line">3 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure><h2 id="2-连接器"><a href="#2-连接器" class="headerlink" title="2. 连接器"></a>2. 连接器</h2><p>连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接器主要和身份认证和权限相关的功能相关。</p><p>主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。</p><h2 id="3-查询缓存"><a href="#3-查询缓存" class="headerlink" title="3. 查询缓存"></a>3. 查询缓存</h2><p>MySQL 拿到查询请求后，先到查询缓存查询，之前是否执行过这条语句，之前执行过的语句及其结果可能会以 <code>key-value</code> 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果查询能够直接在这个缓存中找到 key，则value 就会被直接返回给客户端。</p><p>如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。</p><blockquote><p><font color='blue'><strong>为什么建议不要使用查询缓存？</strong></font></p><p>因为查询缓存往往弊大于利。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。</p><p>对于更新压力大的数据库来说，查询缓存的命中率会非常低。如果业务有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。</p><p>MySQL 提供了这种”按需使用”的方式。将参数 <code>query_cache_type</code> 设置成 <code>DEMAND</code>，这样对于默认的 SQL 语句都不使用查询缓存。对于确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select SQL_CACHE * from T where ID&#x3D;10；</span><br></pre></td></tr></table></figure></blockquote><p><strong><font color='red'>注: MySQL 8.0 版本直接将查询缓存的整块功能删掉</font></strong></p><h2 id="4-分析器"><a href="#4-分析器" class="headerlink" title="4. 分析器"></a>4. 分析器</h2><p>如果没有命中查询缓存，开始执行语句</p><h3 id="4-1-词法分析"><a href="#4-1-词法分析" class="headerlink" title="4.1. 词法分析"></a>4.1. 词法分析</h3><p>分析器先会做 “词法分析”。</p><p>输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。</p><blockquote><p>MySQL 从输入的 “select” 这个关键字识别出来，这是一个查询语句。它也要把字符串 “T” 识别成 “表名 T”，把字符串 “ID” 识别成 “列 ID”。</p></blockquote><h3 id="4-2-语法分析"><a href="#4-2-语法分析" class="headerlink" title="4.2. 语法分析"></a>4.2. 语法分析</h3><p>根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。如果语句不对，会收到 <code>You have an error in your SQL syntax</code> 的错误提醒</p><h2 id="5-优化器"><a href="#5-优化器" class="headerlink" title="5. 优化器"></a>5. 优化器</h2><p>经过了分析器，在开始执行之前，还要先经过优化器的处理。</p><p>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。</p><h2 id="6-执行器"><a href="#6-执行器" class="headerlink" title="6. 执行器"></a>6. 执行器</h2><p>开始执行的时候，要先判断一下个表 T 执行权限，如果没有，就会返回没有权限的错误 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。</p><p>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/11/%E6%97%B6%E9%97%B4%E8%BD%AE/"/>
      <url>2021/03/11/%E6%97%B6%E9%97%B4%E8%BD%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/07/Redis-CPU/"/>
      <url>2021/03/07/Redis-CPU/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>title: Redis 删除策略<br>date: 2019-07-16 21:13:58<br>category: Redis<br>tags: 数据库</p><p>Redis 缓存淘汰策略与 Redis 键的过期删除策略并不完全相同，前者是在 Redis 内存使用超过一定值的时候（一般这个值可以配置）使用的淘汰策略；而后者是通过定期删除+惰性删除两者结合的方式进行内存淘汰的。缓存，不是存储，无法保证以前设置的缓存绝对存在。因为缓存容量是有上限的，即使 set 值的时候不设置过期时间，在内存不够的时候，会根据内存淘汰策略删除一些缓存。</p><a id="more"></a><h2 id="1-主流的-CPU-架构"><a href="#1-主流的-CPU-架构" class="headerlink" title="1. 主流的 CPU 架构"></a>1. 主流的 CPU 架构</h2><p>一个 CPU 处理器中一般有多个运行核心，把一个运行核心称为一个物理核，每个物理核都可以运行应用程序。每个物理核都拥有私有的一级缓存 (Level 1 cache，简称 L1 cache)，包括一级指令缓存和一级数据缓存，以及私有的二级缓存(Level 2 cache，简称 L2 cache)。</p><p>物理核的私有缓存。指缓存空间只能被当前的这个物理核使用，其他的物理核无法对这个核的缓存空间进行数据存取。</p><p>因为 L1 和 L2 缓存是每个物理核私有的，所以，当数据或指令保存在 L1、L2 缓存时，物理核访问它们的延迟不超过 10 纳秒，速度非常快。那么，如果 Redis 把要运行的指令或存取的数据保存在 L1 和 L2 缓存的话，就能高速地访问这些指令和数据。</p><p>但是，这些 L1 和 L2 缓存的大小受限于处理器的制造技术，一般只有 KB 级别，存不下太多的数据。如果 L1、L2 缓存中没有所需的数据，应用程序就需要访问内存来获取数据。而应用程序的访存延迟一般在百纳秒级别，是访问 L1、L2 缓存的延迟的近 10 倍，不可避免地会对性能造成影响。</p><p>不同的物理核还会共享一个共同的三级缓存(Level 3 cache，简称为 L3 cache)。L3 缓存能够使用的存储资源比较多，所以一般比较大，能达到几 MB 到几十 MB，这就能让应用程序缓存更多的数据。当 L1、L2 缓存中没有数据缓存时，可以访问 L3，尽可能避免访问内存。</p><p>现在主流的 CPU 处理器中，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存。</p><p>在主流的服务器上，一个 CPU 处理器会有 10 到 20 多个物理核。同时，为了提升服务器的处理能力，服务器上通常还会有多个 CPU 处理器（也称为多 CPU Socket），每个处理器有自己的物理核（包括 L1、L2 缓存），L3 缓存，以及连接的内存，同时，不同处理器间通过总线连接。</p><p>在多 CPU 架构上，应用程序可以在不同的处理器上运行。在刚才的图中，Redis 可以先在 Socket 1 上运行一段时间，然后再被调度到 Socket 2 上运行。</p><p>如果应用程序先在一个 Socket 上运行，并且把数据保存到了内存，然后被调度到另一个 Socket 上运行，此时，应用程序再进行内存访问时，就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。和访问 Socket 直接连接的内存相比，远端内存访问会增加应用程序的延迟。</p><p>在多 CPU 架构下，一个应用程序访问所在 Socket 的本地内存和访问远端内存的延迟并不一致，所以，这个架构称为非统一内存访问架构(Non-Uniform Memory Access，NUMA 架构)。</p><p>CPU 架构对应用程序运行的影响。</p><ol><li>L1、L2 缓存中的指令和数据的访问速度很快，所以，充分利用 L1、L2 缓存，可以有效缩短应用程序的执行时间；</li><li>在 NUMA 架构下，如果应用程序从一个 Socket 上调度到另一个 Socket 上，就可能会出现远端内存访问的情况，这会直接增加应用程序的执行时间。</li></ol><h2 id="2-CPU-多核对-Redis-性能的影响"><a href="#2-CPU-多核对-Redis-性能的影响" class="headerlink" title="2. CPU 多核对 Redis 性能的影响"></a>2. CPU 多核对 Redis 性能的影响</h2><p>在一个 CPU 核上运行时，应用程序需要记录自身使用的软硬件资源信息(例如栈指针、CPU 核的寄存器值等)，把这些信息称为运行时信息。同时，应用程序访问最频繁的指令和数据还会被缓存到 L1、L2 缓存上，以便提升执行速度。但是，在多核 CPU 的场景下，一旦应用程序需要在一个新的 CPU 核上运行，那么，运行时信息就需要重新加载到新的 CPU 核上。而且，新的 CPU 核的 L1、L2 缓存也需要重新加载数据和指令，这会导致程序的运行时间增加。</p><h3 id="2-1-context-switch"><a href="#2-1-context-switch" class="headerlink" title="2.1. context switch"></a>2.1. context switch</h3><p>context switch 是指线程的上下文切换，这里的上下文就是线程的运行时信息。在 CPU 多核的环境中，一个线程先在一个 CPU 核上运行，之后又切换到另一个 CPU 核上运行，这时就会发生 context switch。</p><p>当 context switch 发生后，Redis 主线程的运行时信息需要被重新加载到另一个 CPU 核上，而且，此时，另一个 CPU 核上的 L1、L2 缓存中，并没有 Redis 实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从 L3 缓存，甚至是内存中加载。这个重新加载的过程是需要花费一定时间的。而且，Redis 实例需要等待这个重新加载的过程完成后，才能开始处理请求，所以，这也会导致一些请求的处理时间增加。</p><h3 id="2-2-绑核"><a href="#2-2-绑核" class="headerlink" title="2.2. 绑核"></a>2.2. 绑核</h3><p>CPU 多核场景下，Redis 实例被频繁调度到不同 CPU 核上运行的话，那么，对 Redis 实例的请求处理时间影响就更大了。每调度一次，一些请求就会受到运行时信息、指令和数据重新加载过程的影响，这就会导致某些请求的延迟明显高于其他请求。</p><p>要避免 Redis 总是在不同 CPU 核上来回调度执行。于是，我们尝试着把 Redis 实例和 CPU 核绑定了，让一个 Redis 实例固定运行在一个 CPU 核上。我们可以使用 taskset 命令把一个程序绑定在一个核上运行。执行下面的命令，就把 Redis 实例绑在了 0 号核上，其中，”-c” 选项用于设置要绑定的核编号</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskset -c 0 ./redis-server</span><br></pre></td></tr></table></figure><p>在 CPU 多核的环境下，通过绑定 Redis 实例和 CPU 核，可以有效降低 Redis 的尾延迟。</p><h2 id="3-CPU-的-NUMA-架构对-Redis-性能的影响"><a href="#3-CPU-的-NUMA-架构对-Redis-性能的影响" class="headerlink" title="3. CPU 的 NUMA 架构对 Redis 性能的影响"></a>3. CPU 的 NUMA 架构对 Redis 性能的影响</h2><p>在实际应用 Redis 时，经常为了提升 Redis 的网络性能，把操作系统的网络中断处理程序和 CPU 核绑定,可以避免网络中断处理程序在不同核上来回调度执行，的确能有效提升 Redis 的网络处理性能。</p><p>但是，网络中断程序是要和 Redis 实例进行网络数据交互的，一旦把网络中断程序绑核后，需要注意 Redis 实例是绑在哪个核上了，这会关系到 Redis 访问网络数据的效率高低。</p><h3 id="3-1-Redis-实例和网络中断程序的数据交互"><a href="#3-1-Redis-实例和网络中断程序的数据交互" class="headerlink" title="3.1. Redis 实例和网络中断程序的数据交互"></a>3.1. Redis 实例和网络中断程序的数据交互</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/07/Redis-%E6%85%A2%E6%93%8D%E4%BD%9C/"/>
      <url>2021/03/07/Redis-%E6%85%A2%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>title: Redis 删除策略<br>date: 2019-07-16 21:13:58<br>category: Redis<br>tags: 数据库</p><p>Redis 缓存淘汰策略与 Redis 键的过期删除策略并不完全相同，前者是在 Redis 内存使用超过一定值的时候（一般这个值可以配置）使用的淘汰策略；而后者是通过定期删除+惰性删除两者结合的方式进行内存淘汰的。缓存，不是存储，无法保证以前设置的缓存绝对存在。因为缓存容量是有上限的，即使 set 值的时候不设置过期时间，在内存不够的时候，会根据内存淘汰策略删除一些缓存。</p><a id="more"></a><h2 id="Redis-为什么这么快？"><a href="#Redis-为什么这么快？" class="headerlink" title="Redis 为什么这么快？"></a>Redis 为什么这么快？</h2><p>一方面，这是因为它是内存数据库，所有操作都在内存上完成，内存的访问速度本身就很快。</p><p>另一方面，这要归功于它的数据结构。键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是 Redis 快速处理数据的基础。</p><h2 id="底层数据结构"><a href="#底层数据结构" class="headerlink" title="底层数据结构"></a>底层数据结构</h2><p>Redis 底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。</p><p>String 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 List、Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。通常情况下，把这四种类型称为集合类型，它们的特点是一个键对应了一个集合的数据。</p><h3 id="简单动态字符串"><a href="#简单动态字符串" class="headerlink" title="简单动态字符串"></a>简单动态字符串</h3><h2 id="键和值结构组织"><a href="#键和值结构组织" class="headerlink" title="键和值结构组织"></a>键和值结构组织</h2><p>为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/06/Controller%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E8%AF%B7%E6%B1%82%E5%8F%91%E9%80%81/"/>
      <url>2021/03/06/Controller%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E8%AF%B7%E6%B1%82%E5%8F%91%E9%80%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Controller 是 Kafka 最核心的组件。一方面，它要为集群中的所有主题分区选举领导者副本；另一方面，它还承载着集群的全部元数据信息，并负责将这些元数据信息同步到其他 Broker 上</p><a id="more"></a><h2 id="1-Controller-发送请求类型"><a href="#1-Controller-发送请求类型" class="headerlink" title="1. Controller 发送请求类型"></a>1. Controller 发送请求类型</h2><p>Controller 会给集群中的所有 Broker (包括它自己所在的 Broker) 机器发送网络请求。</p><p>当前，Controller 只会向 Broker 发送三类请求，</p><ol><li><p>LeaderAndIsrRequest</p><p>最主要的功能是，告诉 Broker 相关主题各个分区的 Leader 副本位于哪台 Broker 上、ISR 中的副本都在哪些 Broker 上</p></li><li><p>StopReplicaRequest</p><p>告知指定 Broker 停止它上面的副本对象，该请求甚至还能删除副本底层的日志数据。这个请求主要的使用场景，是分区副本迁移和删除主题。在这两个场景下，都要涉及停掉 Broker 上的副本操作。</p></li><li><p>UpdateMetadataRequest</p><p>该请求会更新 Broker 上的元数据缓存。集群上的所有元数据变更，都首先发生在 Controller 端，然后再经由这个请求广播给集群上的所有 Broker。</p></li></ol><p>这三类请求 Java 类的定义就封装在 clients 中，它们的抽象基类是 AbstractControlRequest 类，这个类定义了这三类请求的公共字段。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractControlRequest</span> <span class="keyword">extends</span> <span class="title">AbstractRequest</span> </span>&#123;</span><br><span class="line">    public static <span class="keyword">final</span> long <span class="type">UNKNOWN_BROKER_EPOCH</span> = <span class="number">-1</span>L;</span><br><span class="line">    public static <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder&lt;T</span> <span class="keyword">extends</span> <span class="title">AbstractRequest&gt;</span> <span class="keyword">extends</span> <span class="title">AbstractRequest</span>.<span class="title">Builder&lt;T&gt;</span> </span>&#123;</span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">final</span> int controllerId;</span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">final</span> int controllerEpoch;</span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">final</span> long brokerEpoch;</span><br><span class="line">        ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>区别于其他的数据类请求，抽象类请求必然包含 3 个字段。</p><ol><li>controllerId：Controller 所在的 Broker ID。</li><li>controllerEpoch：Controller 的版本信息。</li><li>brokerEpoch：目标 Broker 的 Epoch</li></ol><p>后面这两个 Epoch 字段用于隔离 Zombie Controller 和 Zombie Broker，以保证集群的一致性。</p><h2 id="2-RequestSendThread"><a href="#2-RequestSendThread" class="headerlink" title="2. RequestSendThread"></a>2. RequestSendThread</h2><p>Controller 事件处理线程负责向一个线程安全的阻塞队列写入待发送的请求，而 RequestSendThread 的线程负责执行真正的请求发送。</p><p>Controller 会为集群中的每个 Broker 都创建一个对应的 RequestSendThread 线程。Broker 上的这个线程，持续地从阻塞队列中获取待发送的请求。</p><h3 id="2-1-类定义"><a href="#2-1-类定义" class="headerlink" title="2.1. 类定义"></a>2.1. 类定义</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RequestSendThread</span>(<span class="params">val controllerId: <span class="type">Int</span>, // <span class="type">Controller</span>所在<span class="type">Broker</span>的<span class="type">Id</span></span></span></span><br><span class="line"><span class="class"><span class="params">    val controllerContext: <span class="type">ControllerContext</span>, // <span class="type">Controller</span>元数据信息</span></span></span><br><span class="line"><span class="class"><span class="params">    val queue: <span class="type">BlockingQueue</span>[<span class="type">QueueItem</span>], // 请求阻塞队列</span></span></span><br><span class="line"><span class="class"><span class="params">    val networkClient: <span class="type">NetworkClient</span>, // 用于执行发送的网络<span class="type">I</span>/<span class="type">O</span>类</span></span></span><br><span class="line"><span class="class"><span class="params">    val brokerNode: <span class="type">Node</span>, // 目标<span class="type">Broker</span>节点</span></span></span><br><span class="line"><span class="class"><span class="params">    val config: <span class="type">KafkaConfig</span>, // <span class="type">Kafka</span>配置信息</span></span></span><br><span class="line"><span class="class"><span class="params">    val time: <span class="type">Time</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">    val requestRateAndQueueTimeMetrics: <span class="type">Timer</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    val stateChangeLogger: <span class="type">StateChangeLogger</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    name: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">ShutdownableThread</span>(<span class="params">name = name</span>) </span>&#123;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-2-doWork"><a href="#2-2-doWork" class="headerlink" title="2.2. doWork()"></a>2.2. doWork()</h3><p>RequestSendThread 最重要的是它的 doWork 方法，也就是执行线程逻辑的方法</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doWork</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backoff</span></span>(): <span class="type">Unit</span> = pause(<span class="number">100</span>, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">    <span class="keyword">val</span> <span class="type">QueueItem</span>(apiKey, requestBuilder, callback, enqueueTimeMs) = queue.take() <span class="comment">// 以阻塞的方式从阻塞队列中取出请求</span></span><br><span class="line">    requestRateAndQueueTimeMetrics.update(time.milliseconds() - enqueueTimeMs, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>) <span class="comment">// 更新统计信息</span></span><br><span class="line">    <span class="keyword">var</span> clientResponse: <span class="type">ClientResponse</span> = <span class="literal">null</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">var</span> isSendSuccessful = <span class="literal">false</span></span><br><span class="line">      <span class="keyword">while</span> (isRunning &amp;&amp; !isSendSuccessful) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="comment">// 如果没有创建与目标Broker的TCP连接，或连接暂时不可用</span></span><br><span class="line">          <span class="keyword">if</span> (!brokerReady()) &#123;</span><br><span class="line">            isSendSuccessful = <span class="literal">false</span></span><br><span class="line">            backoff() <span class="comment">// 等待重试</span></span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">val</span> clientRequest = networkClient.newClientRequest(brokerNode.idString, requestBuilder,</span><br><span class="line">              time.milliseconds(), <span class="literal">true</span>)</span><br><span class="line">            <span class="comment">// 发送请求，等待接收Response</span></span><br><span class="line">            clientResponse = <span class="type">NetworkClientUtils</span>.sendAndReceive(networkClient, clientRequest, time)</span><br><span class="line">            isSendSuccessful = <span class="literal">true</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">            networkClient.close(brokerNode.idString)</span><br><span class="line">            isSendSuccessful = <span class="literal">false</span></span><br><span class="line">            backoff()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 如果接收到了Response</span></span><br><span class="line">      <span class="keyword">if</span> (clientResponse != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">val</span> requestHeader = clientResponse.requestHeader</span><br><span class="line">        <span class="keyword">val</span> api = requestHeader.apiKey</span><br><span class="line">        <span class="comment">// 此Response的请求类型必须是LeaderAndIsrRequest、StopReplicaRequest或UpdateMetadataRequest中的一种</span></span><br><span class="line">        <span class="keyword">if</span> (api != <span class="type">ApiKeys</span>.<span class="type">LEADER_AND_ISR</span> &amp;&amp; api != <span class="type">ApiKeys</span>.<span class="type">STOP_REPLICA</span> &amp;&amp; api != <span class="type">ApiKeys</span>.<span class="type">UPDATE_METADATA</span>)</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">s&quot;Unexpected apiKey received: <span class="subst">$apiKey</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> response = clientResponse.responseBody</span><br><span class="line">        stateChangeLogger.withControllerEpoch(controllerContext.epoch)</span><br><span class="line">          .trace(<span class="string">s&quot;Received response &quot;</span> +</span><br><span class="line">          <span class="string">s&quot;<span class="subst">$&#123;response.toString(requestHeader.apiVersion)&#125;</span> for request <span class="subst">$api</span> with correlation id &quot;</span> +</span><br><span class="line">          <span class="string">s&quot;<span class="subst">$&#123;requestHeader.correlationId&#125;</span> sent to broker <span class="subst">$brokerNode</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (callback != <span class="literal">null</span>) &#123;</span><br><span class="line">          callback(response) <span class="comment">// 处理回调</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        error(<span class="string">s&quot;Controller <span class="subst">$controllerId</span> fails to send a request to broker <span class="subst">$brokerNode</span>&quot;</span>, e)</span><br><span class="line">        networkClient.close(brokerNode.idString)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-11 下午8.27.57.png" alt="截屏2021-05-11 下午8.27.57" style="zoom:50%;" /><p>doWork 主要作用是从阻塞队列中取出待发送的请求，然后把它发送出去，之后等待 Response 的返回。在等待 Response 的过程中，线程将一直处于阻塞状态。当接收到 Response 之后，调用 callback 执行请求处理完成后的回调逻辑。需要注意的是，RequestSendThread 线程对请求发送的处理方式与 Broker 处理请求不太一样。它调用的 sendAndReceive 方法在发送完请求之后，会原地进入阻塞状态，等待 Response 返回。只有接收到 Response，并执行完回调逻辑之后，该线程才能从阻塞队列中取出下一个待发送请求进行处理。</p><h2 id="3-ControllerChannelManager"><a href="#3-ControllerChannelManager" class="headerlink" title="3. ControllerChannelManager"></a>3. ControllerChannelManager</h2><p>ControllerChannelManager 管理 Controller 与集群 Broker 之间的连接，并为每个 Broker 创建 RequestSendThread 线程实例并将要发送的请求放入到指定 Broker 的阻塞队列中，等待该 Broker 专属的 RequestSendThread 线程进行处理。</p><h3 id="3-1-定义"><a href="#3-1-定义" class="headerlink" title="3.1. 定义"></a>3.1. 定义</h3><p>ControllerChannelManager 类最重要的数据结构是 brokerStateInfo</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">val</span> brokerStateInfo = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">ControllerBrokerStateInfo</span>]</span><br></pre></td></tr></table></figure><p>是一个 HashMap 类型，Key 是 Integer 类型，就是集群中 Broker 的 ID 信息，而 Value 是一个 ControllerBrokerStateInfo</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">ControllerBrokerStateInfo</span>(<span class="params">networkClient: <span class="type">NetworkClient</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    brokerNode: <span class="type">Node</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    messageQueue: <span class="type">BlockingQueue</span>[<span class="type">QueueItem</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    requestSendThread: <span class="type">RequestSendThread</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">    queueSizeGauge: <span class="type">Gauge</span>[<span class="type">Int</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    requestRateAndTimeMetrics: <span class="type">Timer</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">reconfigurableChannelBuilder: <span class="type">Option</span>[<span class="type">Reconfigurable</span>]</span>)</span></span><br></pre></td></tr></table></figure><ol><li>brokerNode 目标 Broker 节点对象，里面封装了目标 Broker 的连接信息，比如主机名、端口号等</li><li>messageQueue 请求消息阻塞队列。Controller 为每个目标 Broker 都创建了一个消息队列</li><li>requestSendThread Controller 使用这个线程给目标 Broker 发送请求</li></ol><h3 id="3-2-方法"><a href="#3-2-方法" class="headerlink" title="3.2. 方法"></a>3.2. 方法</h3><h4 id="3-2-1-startup"><a href="#3-2-1-startup" class="headerlink" title="3.2.1. startup()"></a>3.2.1. startup()</h4><p>Controller 组件在启动时，会调用 ControllerChannelManager 的 startup 方法。该方法会从元数据信息中找到集群的 Broker 列表，然后依次为它们调用 addBroker 方法，把它们加到 brokerStateInfo 变量中，最后再依次启动 brokerStateInfo 中的 RequestSendThread 线程。</p><h4 id="3-2-2-shutdown"><a href="#3-2-2-shutdown" class="headerlink" title="3.2.2. shutdown()"></a>3.2.2. shutdown()</h4><p>关闭所有 RequestSendThread 线程，并清空必要的资源。</p><h4 id="3-2-3-sendRequest"><a href="#3-2-3-sendRequest" class="headerlink" title="3.2.3. sendRequest()"></a>3.2.3. sendRequest()</h4><p>请求对象提交到请求队列。</p><h4 id="3-2-4-addBroker"><a href="#3-2-4-addBroker" class="headerlink" title="3.2.4. addBroker()"></a>3.2.4. addBroker()</h4><p>添加目标 Broker 到 brokerStateInfo 数据结构中，并创建必要的配套资源，如请求队列、RequestSendThread 线程对象等，最后，RequestSendThread 启动线程。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addBroker</span></span>(broker: <span class="type">Broker</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    brokerLock synchronized &#123;</span><br><span class="line">      <span class="comment">// 如果该Broker是新Broker的话</span></span><br><span class="line">      <span class="keyword">if</span> (!brokerStateInfo.contains(broker.id)) &#123;</span><br><span class="line">        <span class="comment">// 将新Broker加入到Controller管理，并创建对应的RequestSendThread线程</span></span><br><span class="line">        addNewBroker(broker) </span><br><span class="line">        <span class="comment">// 启动RequestSendThread线程</span></span><br><span class="line">        startRequestSendThread(broker.id)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>判断目标 Broker 的序号，是否已经保存在 brokerStateInfo 中。如果是，没必要再次添加了；否则，addBroker 方法会对目前的 Broker 执行两个操作：把该 Broker 节点添加到 brokerStateInfo 中；启动与该 Broker 对应的 RequestSendThread 线程。</p><h5 id="addNewBroker"><a href="#addNewBroker" class="headerlink" title="addNewBroker()"></a>addNewBroker()</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">addNewBroker</span></span>(broker: <span class="type">Broker</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 为该Broker构造请求阻塞队列</span></span><br><span class="line">  <span class="keyword">val</span> messageQueue = <span class="keyword">new</span> <span class="type">LinkedBlockingQueue</span>[<span class="type">QueueItem</span>]</span><br><span class="line">  <span class="keyword">val</span> controllerToBrokerListenerName = config.controlPlaneListenerName.getOrElse(config.interBrokerListenerName)</span><br><span class="line">  <span class="keyword">val</span> controllerToBrokerSecurityProtocol = config.controlPlaneSecurityProtocol.getOrElse(config.interBrokerSecurityProtocol)</span><br><span class="line">  <span class="comment">// 获取待连接Broker节点对象信息</span></span><br><span class="line">  <span class="keyword">val</span> brokerNode = broker.node(controllerToBrokerListenerName)</span><br><span class="line">  <span class="keyword">val</span> logContext = <span class="keyword">new</span> <span class="type">LogContext</span>(<span class="string">s&quot;[Controller id=<span class="subst">$&#123;config.brokerId&#125;</span>, targetBrokerId=<span class="subst">$&#123;brokerNode.idString&#125;</span>] &quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> (networkClient, reconfigurableChannelBuilder) = &#123;</span><br><span class="line">    <span class="keyword">val</span> channelBuilder = <span class="type">ChannelBuilders</span>.clientChannelBuilder(</span><br><span class="line">      controllerToBrokerSecurityProtocol,</span><br><span class="line">      <span class="type">JaasContext</span>.<span class="type">Type</span>.<span class="type">SERVER</span>,</span><br><span class="line">      config,</span><br><span class="line">      controllerToBrokerListenerName,</span><br><span class="line">      config.saslMechanismInterBrokerProtocol,</span><br><span class="line">      time,</span><br><span class="line">      config.saslInterBrokerHandshakeRequestEnable,</span><br><span class="line">      logContext</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">val</span> reconfigurableChannelBuilder = channelBuilder <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> reconfigurable: <span class="type">Reconfigurable</span> =&gt;</span><br><span class="line">        config.addReconfigurable(reconfigurable)</span><br><span class="line">        <span class="type">Some</span>(reconfigurable)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt; <span class="type">None</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 创建NIO Selector实例用于网络数据传输</span></span><br><span class="line">    <span class="keyword">val</span> selector = <span class="keyword">new</span> <span class="type">Selector</span>(</span><br><span class="line">      <span class="type">NetworkReceive</span>.<span class="type">UNLIMITED</span>,</span><br><span class="line">      <span class="type">Selector</span>.<span class="type">NO_IDLE_TIMEOUT_MS</span>,</span><br><span class="line">      metrics,</span><br><span class="line">      time,</span><br><span class="line">      <span class="string">&quot;controller-channel&quot;</span>,</span><br><span class="line">      <span class="type">Map</span>(<span class="string">&quot;broker-id&quot;</span> -&gt; brokerNode.idString).asJava,</span><br><span class="line">      <span class="literal">false</span>,</span><br><span class="line">      channelBuilder,</span><br><span class="line">      logContext</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">// 创建NetworkClient实例</span></span><br><span class="line">    <span class="comment">// NetworkClient类是Kafka clients工程封装的顶层网络客户端API</span></span><br><span class="line">    <span class="comment">// 提供了丰富的方法实现网络层IO数据传输</span></span><br><span class="line">    <span class="keyword">val</span> networkClient = <span class="keyword">new</span> <span class="type">NetworkClient</span>(</span><br><span class="line">      selector,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ManualMetadataUpdater</span>(<span class="type">Seq</span>(brokerNode).asJava),</span><br><span class="line">      config.brokerId.toString,</span><br><span class="line">      <span class="number">1</span>,</span><br><span class="line">      <span class="number">0</span>,</span><br><span class="line">      <span class="number">0</span>,</span><br><span class="line">      <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>,</span><br><span class="line">      <span class="type">Selectable</span>.<span class="type">USE_DEFAULT_BUFFER_SIZE</span>,</span><br><span class="line">      config.requestTimeoutMs,</span><br><span class="line">      <span class="type">ClientDnsLookup</span>.<span class="type">DEFAULT</span>,</span><br><span class="line">      time,</span><br><span class="line">      <span class="literal">false</span>,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ApiVersions</span>,</span><br><span class="line">      logContext</span><br><span class="line">    )</span><br><span class="line">    (networkClient, reconfigurableChannelBuilder)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 为这个RequestSendThread线程设置线程名称</span></span><br><span class="line">  <span class="keyword">val</span> threadName = threadNamePrefix <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="string">s&quot;Controller-<span class="subst">$&#123;config.brokerId&#125;</span>-to-broker-<span class="subst">$&#123;broker.id&#125;</span>-send-thread&quot;</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(name) =&gt; <span class="string">s&quot;<span class="subst">$name</span>:Controller-<span class="subst">$&#123;config.brokerId&#125;</span>-to-broker-<span class="subst">$&#123;broker.id&#125;</span>-send-thread&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 构造请求处理速率监控指标</span></span><br><span class="line">  <span class="keyword">val</span> requestRateAndQueueTimeMetrics = newTimer(</span><br><span class="line">    <span class="type">RequestRateAndQueueTimeMetricName</span>, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>, <span class="type">TimeUnit</span>.<span class="type">SECONDS</span>, brokerMetricTags(broker.id)</span><br><span class="line">  )</span><br><span class="line">  <span class="comment">// 创建RequestSendThread实例</span></span><br><span class="line">  <span class="keyword">val</span> requestThread = <span class="keyword">new</span> <span class="type">RequestSendThread</span>(config.brokerId, controllerContext, messageQueue, networkClient,</span><br><span class="line">    brokerNode, config, time, requestRateAndQueueTimeMetrics, stateChangeLogger, threadName)</span><br><span class="line">  requestThread.setDaemon(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> queueSizeGauge = newGauge(<span class="type">QueueSizeMetricName</span>, () =&gt; messageQueue.size, brokerMetricTags(broker.id))</span><br><span class="line">  <span class="comment">// 创建该Broker专属的ControllerBrokerStateInfo实例</span></span><br><span class="line">  <span class="comment">// 并将其加入到brokerStateInfo统一管理</span></span><br><span class="line">  brokerStateInfo.put(broker.id, <span class="type">ControllerBrokerStateInfo</span>(networkClient, brokerNode, messageQueue,</span><br><span class="line">    requestThread, queueSizeGauge, requestRateAndQueueTimeMetrics, reconfigurableChannelBuilder))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-11 下午10.41.52.png" alt="截屏2021-05-11 下午10.41.52" style="zoom:50%;" /><h4 id="3-2-5-removeBroker"><a href="#3-2-5-removeBroker" class="headerlink" title="3.2.5. removeBroker()"></a>3.2.5. removeBroker()</h4><p>从 brokerStateInfo 移除目标 Broker 的相关数据。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/06/Controller%E9%80%89%E4%B8%BE/"/>
      <url>2021/03/06/Controller%E9%80%89%E4%B8%BE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Controller 是 Kafka 最核心的组件。一方面，它要为集群中的所有主题分区选举领导者副本；另一方面，它还承载着集群的全部元数据信息，并负责将这些元数据信息同步到其他 Broker 上</p><a id="more"></a><h2 id="1-概览"><a href="#1-概览" class="headerlink" title="1. 概览"></a>1. 概览</h2><p>在一个 Kafka 集群中，某段时间内只能有一台 Broker 被选举为 Controller。随着时间的推移，可能会有不同的 Broker 陆续担任过 Controller 的角色，但是在某一时刻，Controller 只能由一个 Broker 担任</p><p>Controller 的选举过程依赖 ZooKeeper 完成。ZooKeeper 除了扮演集群元数据的“真理之源”角色，还定义了 /controller 临时节点（Ephemeral Node），以协助完成 Controller 的选举。</p><p>集群上所有的 Broker 都在实时监听 ZooKeeper 上 /controller 的节点。</p><ol><li>监听这个节点是否存在。倘若发现这个节点不存在，Broker 会立即 “抢注” 该节点，即创建 /controller 节点。创建成功的那个 Broker，即当选为新一届的 Controller。</li><li>监听这个节点数据是否发生了变更。同样，一旦发现该节点的内容发生了变化，Broker 也会立即启动新一轮的 Controller 选举</li></ol><h2 id="2-KafkaController"><a href="#2-KafkaController" class="headerlink" title="2. KafkaController"></a>2. KafkaController</h2><h3 id="2-1-原生字段"><a href="#2-1-原生字段" class="headerlink" title="2.1. 原生字段"></a>2.1. 原生字段</h3><p>KafkaController 类的定义</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaController</span>(<span class="params">val config: <span class="type">KafkaConfig</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      zkClient: <span class="type">KafkaZkClient</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      time: <span class="type">Time</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      metrics: <span class="type">Metrics</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      initialBrokerInfo: <span class="type">BrokerInfo</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      initialBrokerEpoch: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      tokenManager: <span class="type">DelegationTokenManager</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                      threadNamePrefix: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span></span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">ControllerEventProcessor</span> <span class="keyword">with</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-12 上午10.21.56.png" alt="截屏2021-05-12 上午10.21.56" style="zoom:50%;" /><h3 id="2-2-辅助字段"><a href="#2-2-辅助字段" class="headerlink" title="2.2. 辅助字段"></a>2.2. 辅助字段</h3><p>除了原生字段之外，KafkaController 还定义了很多辅助字段，帮助实现 Controller 的各类功能。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"><span class="comment">// 集群元数据类，保存集群所有元数据</span></span><br><span class="line"><span class="keyword">val</span> controllerContext = <span class="keyword">new</span> <span class="type">ControllerContext</span></span><br><span class="line"><span class="comment">// Controller端通道管理器类，负责Controller向Broker发送请求</span></span><br><span class="line"><span class="keyword">var</span> controllerChannelManager = <span class="keyword">new</span> <span class="type">ControllerChannelManager</span>(controllerContext, config, time, metrics,</span><br><span class="line">  stateChangeLogger, threadNamePrefix)</span><br><span class="line"><span class="comment">// 线程调度器，当前唯一负责定期执行Leader重选举</span></span><br><span class="line"><span class="keyword">private</span>[controller] <span class="keyword">val</span> kafkaScheduler = <span class="keyword">new</span> <span class="type">KafkaScheduler</span>(<span class="number">1</span>)</span><br><span class="line"><span class="comment">// Controller事件管理器，负责管理事件处理线程</span></span><br><span class="line"><span class="keyword">private</span>[controller] <span class="keyword">val</span> eventManager = <span class="keyword">new</span> <span class="type">ControllerEventManager</span>(config.brokerId, <span class="keyword">this</span>, time,</span><br><span class="line">  controllerContext.stats.rateAndTimeMetrics)</span><br><span class="line">......</span><br><span class="line"><span class="comment">// 副本状态机，负责副本状态转换</span></span><br><span class="line"><span class="keyword">val</span> replicaStateMachine: <span class="type">ReplicaStateMachine</span> = <span class="keyword">new</span> <span class="type">ZkReplicaStateMachine</span>(config, stateChangeLogger, controllerContext, zkClient,</span><br><span class="line">  <span class="keyword">new</span> <span class="type">ControllerBrokerRequestBatch</span>(config, controllerChannelManager, eventManager, controllerContext, stateChangeLogger))</span><br><span class="line"><span class="comment">// 分区状态机，负责分区状态转换</span></span><br><span class="line"><span class="keyword">val</span> partitionStateMachine: <span class="type">PartitionStateMachine</span> = <span class="keyword">new</span> <span class="type">ZkPartitionStateMachine</span>(config, stateChangeLogger, controllerContext, zkClient,</span><br><span class="line">  <span class="keyword">new</span> <span class="type">ControllerBrokerRequestBatch</span>(config, controllerChannelManager, eventManager, controllerContext, stateChangeLogger))</span><br><span class="line"><span class="comment">// 主题删除管理器，负责删除主题及日志</span></span><br><span class="line"><span class="keyword">val</span> topicDeletionManager = <span class="keyword">new</span> <span class="type">TopicDeletionManager</span>(config, controllerContext, replicaStateMachine,</span><br><span class="line">  partitionStateMachine, <span class="keyword">new</span> <span class="type">ControllerDeletionClient</span>(<span class="keyword">this</span>, zkClient))</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>其中，有 7 个字段是重中之重。</p><ol><li>controllerContext: 集群元数据类，保存集群所有元数据。</li><li>controllerChannelManager: Controller 端通道管理器类，负责 Controller 向 Broker 发送请求</li><li>kafkaScheduler: 线程调度器，当前唯一负责定期执行分区重平衡 Leader 选举。</li><li>eventManager: Controller 事件管理器，负责管理事件处理线程。</li><li>replicaStateMachine: 副本状态机，负责副本状态转换。</li><li>partitionStateMachine: 分区状态机，负责分区状态转换。</li><li>topicDeletionManager: 主题删除管理器，负责删除主题及日志。</li></ol><h3 id="2-3-各类-ZooKeeper-监听器"><a href="#2-3-各类-ZooKeeper-监听器" class="headerlink" title="2.3. 各类 ZooKeeper 监听器"></a>2.3. 各类 ZooKeeper 监听器</h3><h3 id="2-4-统计字段"><a href="#2-4-统计字段" class="headerlink" title="2.4. 统计字段"></a>2.4. 统计字段</h3><p>这些统计字段大多用于计算统计指标。有的监控指标甚至是非常重要的 Controller 监控项，比如 ActiveControllerCount 指标。</p><h2 id="3-Controller-选举流程"><a href="#3-Controller-选举流程" class="headerlink" title="3. Controller 选举流程"></a>3. Controller 选举流程</h2><p>所谓的 Controller 选举，是指 Kafka 选择集群中一台 Broker 行使 Controller 职责。整个选举过程分为两个步骤：触发选举和开始选举。</p><h3 id="3-1-触发选举"><a href="#3-1-触发选举" class="headerlink" title="3.1. 触发选举"></a>3.1. 触发选举</h3><p>可能触发 Controller 选举的三个场景</p><ol><li>集群从零启动时</li><li>Broker 侦测 /controller 节点消失时</li><li>Broker 侦测到 /controller 节点数据发生变更时</li></ol><h4 id="3-1-1-集群从零启动"><a href="#3-1-1-集群从零启动" class="headerlink" title="3.1.1.集群从零启动"></a>3.1.1.集群从零启动</h4><p>集群首次启动时，Controller 尚未被选举出来。于是，Broker 启动后，首先将 Startup 这个 ControllerEvent 写入到事件队列中，然后启动对应的事件处理线程和 ControllerChangeHandler ZooKeeper 监听器，最后依赖事件处理线程进行 Controller 的选举。在源码中，KafkaController 类的 startup 方法就是做这些事情的。当 Broker 启动时，它会调用这个方法启动 ControllerEventThread 线程。值得注意的是，每个 Broker 都需要做这些事情，不是说只有 Controller 所在的 Broker 才需要执行这些逻辑。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/06/Controller%E6%A8%A1%E5%9D%97/"/>
      <url>2021/03/06/Controller%E6%A8%A1%E5%9D%97/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Controller 是 Kafka 最核心的组件。一方面，它要为集群中的所有主题分区选举领导者副本；另一方面，它还承载着集群的全部元数据信息，并负责将这些元数据信息同步到其他 Broker 上</p><a id="more"></a><h2 id="1-集群元数据"><a href="#1-集群元数据" class="headerlink" title="1. 集群元数据"></a>1. 集群元数据</h2><p>集群 Broker 是不会与 ZooKeeper 直接交互去获取元数据的。相反地，它们总是与 Controller 进行通信，获取和更新最新的集群数据。</p><h2 id="2-ControllerContext"><a href="#2-ControllerContext" class="headerlink" title="2. ControllerContext"></a>2. ControllerContext</h2><p>Controller 组件的源代码位于 core 包的 src/main/scala/kafka/controller 路径下，这里面有很多 Scala 源文件，ControllerContext 类就位于这个路径下的 ControllerContext.scala 文件中,它定义了前面提到的所有元数据信息，以及许多实用的工具方法。比如，获取集群上所有主题分区对象的 allPartitions 方法、获取某主题分区副本列表的 partitionReplicaAssignment 方法，等等。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ControllerContext</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> stats = <span class="keyword">new</span> <span class="type">ControllerStats</span> <span class="comment">// Controller 统计信息类 </span></span><br><span class="line">  <span class="keyword">var</span> offlinePartitionCount = <span class="number">0</span>   <span class="comment">// 离线分区计数器</span></span><br><span class="line">  <span class="keyword">val</span> shuttingDownBrokerIds = mutable.<span class="type">Set</span>.empty[<span class="type">Int</span>]  <span class="comment">// 关闭中Broker的Id列表</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> liveBrokers = mutable.<span class="type">Set</span>.empty[<span class="type">Broker</span>] <span class="comment">// 当前运行中Broker对象列表</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> liveBrokerEpochs = mutable.<span class="type">Map</span>.empty[<span class="type">Int</span>, <span class="type">Long</span>]   <span class="comment">// 运行中Broker Epoch列表</span></span><br><span class="line">  <span class="keyword">var</span> epoch: <span class="type">Int</span> = <span class="type">KafkaController</span>.<span class="type">InitialControllerEpoch</span>   <span class="comment">// Controller当前Epoch值</span></span><br><span class="line">  <span class="comment">// Controller 对应 ZooKeeper 节点的 Epoch 值</span></span><br><span class="line">  <span class="keyword">var</span> epochZkVersion: <span class="type">Int</span> = <span class="type">KafkaController</span>.<span class="type">InitialControllerEpochZkVersion</span>  </span><br><span class="line">  <span class="keyword">val</span> allTopics = mutable.<span class="type">Set</span>.empty[<span class="type">String</span>]  <span class="comment">// 集群主题列表</span></span><br><span class="line">  <span class="comment">// 主题分区的副本列表</span></span><br><span class="line">  <span class="keyword">val</span> partitionAssignments = mutable.<span class="type">Map</span>.empty[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">ReplicaAssignment</span>]]  </span><br><span class="line">  <span class="comment">// 主题分区的Leader/ISR副本信息</span></span><br><span class="line">  <span class="keyword">val</span> partitionLeadershipInfo = mutable.<span class="type">Map</span>.empty[<span class="type">TopicPartition</span>, <span class="type">LeaderIsrAndControllerEpoch</span>]  </span><br><span class="line">  <span class="keyword">val</span> partitionsBeingReassigned = mutable.<span class="type">Set</span>.empty[<span class="type">TopicPartition</span>]  <span class="comment">// 正处于副本重分配过程的主题分区列表</span></span><br><span class="line">  <span class="keyword">val</span> partitionStates = mutable.<span class="type">Map</span>.empty[<span class="type">TopicPartition</span>, <span class="type">PartitionState</span>] <span class="comment">// 主题分区状态列表 </span></span><br><span class="line">  <span class="keyword">val</span> replicaStates = mutable.<span class="type">Map</span>.empty[<span class="type">PartitionAndReplica</span>, <span class="type">ReplicaState</span>]  <span class="comment">// 主题分区的副本状态列表</span></span><br><span class="line">  <span class="keyword">val</span> replicasOnOfflineDirs = mutable.<span class="type">Map</span>.empty[<span class="type">Int</span>, <span class="type">Set</span>[<span class="type">TopicPartition</span>]]  <span class="comment">// 不可用磁盘路径上的副本列表</span></span><br><span class="line">  <span class="keyword">val</span> topicsToBeDeleted = mutable.<span class="type">Set</span>.empty[<span class="type">String</span>]  <span class="comment">// 待删除主题列表</span></span><br><span class="line">  <span class="keyword">val</span> topicsWithDeletionStarted = mutable.<span class="type">Set</span>.empty[<span class="type">String</span>]  <span class="comment">// 已开启删除的主题列表</span></span><br><span class="line">  <span class="keyword">val</span> topicsIneligibleForDeletion = mutable.<span class="type">Set</span>.empty[<span class="type">String</span>]  <span class="comment">// 暂时无法执行删除的主题列表</span></span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-1-ControllerStats"><a href="#2-1-ControllerStats" class="headerlink" title="2.1. ControllerStats"></a>2.1. ControllerStats</h3><p>表征的是 Controller 的一些统计信息。</p><p>目前，源码中定义了两大类统计指标：</p><ol><li><p>UncleanLeaderElectionsPerSec </p><blockquote><p>计算 Controller 每秒执行的 Unclean Leader 选举数量，通常情况下，执行 Unclean Leader 选举可能造成数据丢失，一般不建议开启它。一旦开启，你就需要时刻关注这个监控指标的值，确保 Unclean Leader 选举的速率维持在一个很低的水平，否则会出现很多数据丢失的情况</p></blockquote></li><li><p>Controller 事件状态的执行速率与时间</p><blockquote><p>统计所有 Controller 状态的速率和时间信息，单位是毫秒。当前，Controller 定义了很多事件，比如，TopicDeletion 是执行主题删除的 Controller 事件、ControllerChange 是执行 Controller 重选举的事件。ControllerStats 的这个指标通过在每个事件名后拼接字符串 RateAndTimeMs 的方式，为每类 Controller 事件都创建了对应的速率监控指标。</p></blockquote></li></ol><h3 id="2-2-offlinePartitionCount"><a href="#2-2-offlinePartitionCount" class="headerlink" title="2.2. offlinePartitionCount"></a>2.2. offlinePartitionCount</h3><p>该字段统计集群中所有离线或处于不可用状态的主题分区数量</p><p>所谓的不可用状态，即 <code>Leader=-1</code> 的情况</p><p>ControllerContext 中的 updatePartitionStateMetrics 方法根据给定主题分区的当前状态和目标状态，来判断该分区是否是离线状态的分区。如果是，则累加 offlinePartitionCount 字段的值，否则递减该值</p><h3 id="2-3-shuttingDownBrokerIds"><a href="#2-3-shuttingDownBrokerIds" class="headerlink" title="2.3. shuttingDownBrokerIds"></a>2.3. shuttingDownBrokerIds</h3><p>该字段保存所有正在关闭中的 Broker ID 列表。当 Controller 在管理集群 Broker 时，它要依靠这个字段来甄别 Broker 当前是否已关闭，因为处于关闭状态的 Broker 是不适合执行某些操作的，如分区重分配（Reassignment）以及主题删除等。另外，Kafka 必须要为这些关闭中的 Broker 执行很多清扫工作，Controller 定义了一个 onBrokerFailure 方法，它就是用来做这个的。</p><h3 id="2-4-liveBrokers"><a href="#2-4-liveBrokers" class="headerlink" title="2.4. liveBrokers"></a>2.4. liveBrokers</h3><p>该字段保存当前所有运行中的 Broker 对象。每个 Broker 对象就是一个 <code>&lt;Id, EndPoint, 机架信息&gt;</code> 的三元组。</p><p>ControllerContext 中定义了很多方法来管理该字段，如 addLiveBrokersAndEpochs、removeLiveBrokers 和 updateBrokerMetadata 等</p><h3 id="2-5-liveBrokerEpochs"><a href="#2-5-liveBrokerEpochs" class="headerlink" title="2.5. liveBrokerEpochs"></a>2.5. liveBrokerEpochs</h3><p>该字段保存所有运行中 Broker 的 Epoch 信息。Kafka 使用 Epoch 数据防止 Zombie Broker，即一个非常老的 Broker 被选举成为 Controller。</p><p>liveBrokerEpochs 的 keySet 方法返回 Broker 序号列表，然后从中移除关闭中的 Broker 序号，剩下的自然就是处于运行中的 Broker 序号列表了。</p><h3 id="2-6-epoch-amp-epochZkVersion"><a href="#2-6-epoch-amp-epochZkVersion" class="headerlink" title="2.6. epoch &amp; epochZkVersion"></a>2.6. <code>epoch</code> &amp; <code>epochZkVersion</code></h3><p>epoch 实际上就是 ZooKeeper 中 /controller_epoch 节点的值，你可以认为它就是 Controller 在整个 Kafka 集群的版本号，而 epochZkVersion 实际上是 /controller_epoch 节点的 dataVersion 值。Kafka 使用 epochZkVersion 来判断和防止 Zombie Controller。这也就是说，原先在老 Controller 任期内的 Controller 操作在新 Controller 不能成功执行，因为新 Controller 的 epochZkVersion 要比老 Controller 的大。</p><h3 id="2-7-allTopics"><a href="#2-7-allTopics" class="headerlink" title="2.7. allTopics"></a>2.7. allTopics</h3><p>该字段保存集群上所有的主题名称。每当有主题的增减，Controller 就要更新该字段的值。</p><h3 id="2-8-partitionAssignments"><a href="#2-8-partitionAssignments" class="headerlink" title="2.8. partitionAssignments"></a>2.8. partitionAssignments</h3><p>该字段保存所有主题分区的副本分配情况。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/LEO&amp;HW/"/>
      <url>2021/03/04/LEO&amp;HW/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>对于副本而言，还有两个概念：本地副本(Local Replica)和远程副本(Remote Replica),本地副本是指对应的 Log 分配在当前的 broker 节点上，远程副本是指对应的 Log 分配在其他的 broker 节点上。在 Kafka 中，同一个分区的信息会存在多个broker节点上，并被其上的副本管理器所管理，这样在逻辑层面每个broker节点上的分区就有了多个副本，但是只有本地副本才有对应的日志。如图</p><p>某个分区有 3 个副本分别位于 broker0、broker1 和 broker2 节点中，其中带阴影的方框表示本地副本。假设 broker0上的副本1为当前分区的 leader 副本，那么副本2和副本3就是 follower 副本，整个消息追加的过程可以概括如下：</p><ol><li>生产者客户端发送消息至leader副本</li><li>消息被追加到 leader 副本的本地日志，并且会更新日志的偏移量</li><li>follower 副本向 leader 副本请求同步数据。</li><li>leader 副本所在的服务器读取本地日志，并更新对应拉取的 follower 副本的信息。</li><li>leader 副本所在的服务器将拉取结果返回给 follower 副本。</li><li>follower 副本收到 leader 副本返回的拉取结果，将消息追加到本地日志中，并更新日志的偏移量信息。</li></ol><h2 id="LEO-amp-HW-变化"><a href="#LEO-amp-HW-变化" class="headerlink" title="LEO&amp;HW 变化"></a>LEO&amp;HW 变化</h2><p>生产者一直在往 leader 副本中写入消息。某一时刻，leader 副本的 LEO 增加至 5,并且所有副本的 HW 还都为 0</p><ol><li><p>follower 副本向 leader 副本拉取消息，在拉取的请求中会带有自身的 LEO 信息</p><blockquote><p>LEO 信息对应的是 FetchRequest 请求中的 fetch_offset.leader 副本返回给 follower 副本相应的消息，并且还带有自身的 HW 信息</p></blockquote></li><li><p>leader 副本返回给 follower 副本相应的消息，并且还带有自身的 HW 信息</p></li><li><p>follower 副本各自拉取到了消息，并更新各自的 LEO 为 3 和 4 与此同时，follower 副本还会更新自己的 HW</p><p>follower 副本再次请求拉取 leader 副本中的消息，leader 副本收到来自 follower 副本的 FetchRequest 请求，其中带有 LEO 的相关信息，选取其中的最小值作为新的 HW,即 <code>min(15,3,4)=3</code>.然后连同消息和 HW 一起返回FetchResponse 给follower副本</p></li><li><p>两个 follower 副本在收到新的消息之后更新 LEO 并且更新自己的HW为3(min(LEO,3)=3).</p><blockquote><p>更新 HW 的算法是比较当前 LEO 和 leader 副本中传送过来的 HW 的值，取较小值作为自己的 HW 值。当前两个follower 副本的 HW 都等于0(min(0,0)-0)</p></blockquote></li></ol><p>![截屏2021-03-11 下午7.13.20](/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-11 下午7.13.20.png)</p><p>在一个分区中，leader 副本所在的节点会记录所有副本的 LEO,而 follower 副本所在的节点只会记录自身的 LEO,而不会记录其他副本的 LEO.对 HW 而言，各个副本所在的节点都只记录它自身的 HW.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/Leader_Epoch/"/>
      <url>2021/03/04/Leader_Epoch/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>对于副本而言，还有两个概念：本地副本(Local Replica)和远程副本(Remote Replica),本地副本是指对应的 Log 分配在当前的 broker 节点上，远程副本是指对应的 Log 分配在其他的 broker 节点上。在 Kafka 中，同一个分区的信息会存在多个broker节点上，并被其上的副本管理器所管理，这样在逻辑层面每个broker节点上的分区就有了多个副本，但是只有本地副本才有对应的日志。如图</p><p>某个分区有 3 个副本分别位于 broker0、broker1 和 broker2 节点中，其中带阴影的方框表示本地副本。假设 broker0上的副本1为当前分区的 leader 副本，那么副本2和副本3就是 follower 副本，整个消息追加的过程可以概括如下：</p><ol><li>生产者客户端发送消息至leader副本</li><li>消息被追加到 leader 副本的本地日志，并且会更新日志的偏移量</li><li>follower 副本向 leader 副本请求同步数据。</li><li>leader 副本所在的服务器读取本地日志，并更新对应拉取的 follower 副本的信息。</li><li>leader 副本所在的服务器将拉取结果返回给 follower 副本。</li><li>follower 副本收到 leader 副本返回的拉取结果，将消息追加到本地日志中，并更新日志的偏移量信息。</li></ol><h2 id="LEO-amp-HW-变化"><a href="#LEO-amp-HW-变化" class="headerlink" title="LEO&amp;HW 变化"></a>LEO&amp;HW 变化</h2><p>生产者一直在往 leader 副本中写入消息。某一时刻，leader 副本的 LEO 增加至 5,并且所有副本的 HW 还都为 0</p><ol><li><p>follower 副本向 leader 副本拉取消息，在拉取的请求中会带有自身的 LEO 信息</p><blockquote><p>LEO 信息对应的是 FetchRequest 请求中的 fetch_offset.leader 副本返回给 follower 副本相应的消息，并且还带有自身的 HW 信息</p></blockquote></li><li><p>leader 副本返回给 follower 副本相应的消息，并且还带有自身的 HW 信息</p></li><li><p>follower 副本各自拉取到了消息，并更新各自的 LEO 为 3 和 4 与此同时，follower 副本还会更新自己的 HW</p><p>follower 副本再次请求拉取 leader 副本中的消息，leader 副本收到来自 follower 副本的 FetchRequest 请求，其中带有 LEO 的相关信息，选取其中的最小值作为新的 HW,即 <code>min(15,3,4)=3</code>.然后连同消息和 HW 一起返回FetchResponse 给follower副本</p></li><li><p>两个 follower 副本在收到新的消息之后更新 LEO 并且更新自己的HW为3(min(LEO,3)=3).</p><blockquote><p>更新 HW 的算法是比较当前 LEO 和 leader 副本中传送过来的 HW 的值，取较小值作为自己的 HW 值。当前两个follower 副本的 HW 都等于0(min(0,0)-0)</p></blockquote></li></ol><p>![截屏2021-03-11 下午7.13.20](/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-11 下午7.13.20.png)</p><p>在一个分区中，leader 副本所在的节点会记录所有副本的 LEO,而 follower 副本所在的节点只会记录自身的 LEO,而不会记录其他副本的 LEO.对 HW 而言，各个副本所在的节点都只记录它自身的 HW.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/%E7%BC%96%E8%AF%91%20Kafka%20%E5%B7%A5%E7%A8%8B/"/>
      <url>2021/03/04/%E7%BC%96%E8%AF%91%20Kafka%20%E5%B7%A5%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>下载 Kafka 源代码</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/apache/kafka.git</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97_%E5%85%B3%E9%94%AE%E4%BD%8D%E7%A7%BB%E5%80%BC%E7%AE%A1%E7%90%86/"/>
      <url>2021/03/04/Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97_%E5%85%B3%E9%94%AE%E4%BD%8D%E7%A7%BB%E5%80%BC%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>高水位的概念在 Kafka 中举足轻重，对它的管理，是 Log 最重要的功能之一,社区关于日志代码的很多改进都是基于高水位机制的，有的甚至是为了替代高水位机制而做的更新。</p><a id="more"></a><h2 id="1-日志段管理"><a href="#1-日志段管理" class="headerlink" title="1. 日志段管理"></a>1. 日志段管理</h2><p>源码中日志对象定义高水位的语句只有一行：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> segments: <span class="type">ConcurrentNavigableMap</span>[java.lang.<span class="type">Long</span>, <span class="type">LogSegment</span>] = <span class="keyword">new</span> <span class="type">ConcurrentSkipListMap</span>[java.lang.<span class="type">Long</span>, <span class="type">LogSegment</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-增加日志段"><a href="#2-增加日志段" class="headerlink" title="2. 增加日志段"></a>2. 增加日志段</h2><p>Log 对象中定义了添加日志段对象的方法: addSegment。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addSegment</span></span>(segment: <span class="type">LogSegment</span>): <span class="type">LogSegment</span> = <span class="keyword">this</span>.segments.put(segment.baseOffset, segment)</span><br></pre></td></tr></table></figure><h2 id="3-删除日志段"><a href="#3-删除日志段" class="headerlink" title="3. 删除日志段"></a>3. 删除日志段</h2><p>删除操作相对来说复杂,Kafka 有很多留存策略，包括基于时间维度的、基于空间维度的和基于 Log Start Offset 维度</p><p>Log 中控制删除操作的总入口是 deleteOldSegments 无参方法</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deleteOldSegments</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (config.delete) &#123;</span><br><span class="line">      deleteRetentionMsBreachedSegments() + deleteRetentionSizeBreachedSegments() + deleteLogStartOffsetBreachedSegments()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      deleteLogStartOffsetBreachedSegments()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>deleteRetentionMsBreachedSegments、deleteRetentionSizeBreachedSegments 和 deleteLogStartOffsetBreachedSegments 分别对应于 3 个留存策略。</p><p>3 个留存策略方法底层都会调用带参数版本的 deleteOldSegments 方法，而这个方法又相继调用了 deletableSegments 和 deleteSegments 方法。。</p><h3 id="3-1-deleteOldSegments-带参"><a href="#3-1-deleteOldSegments-带参" class="headerlink" title="3.1. deleteOldSegments 带参"></a>3.1. deleteOldSegments 带参</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">deleteOldSegments</span></span>(predicate: (<span class="type">LogSegment</span>, <span class="type">Option</span>[<span class="type">LogSegment</span>]) =&gt; <span class="type">Boolean</span>, reason: <span class="type">String</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    lock synchronized &#123;</span><br><span class="line">      <span class="keyword">val</span> deletable = deletableSegments(predicate)</span><br><span class="line">      <span class="keyword">if</span> (deletable.nonEmpty)</span><br><span class="line">        info(<span class="string">s&quot;Found deletable segments with base offsets [<span class="subst">$&#123;deletable.map(_.baseOffset).mkString(&quot;,&quot;)&#125;</span>] due to <span class="subst">$reason</span>&quot;</span>)</span><br><span class="line">      deleteSegments(deletable)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ol><li>使用传入的函数计算哪些日志段对象能够被删除</li><li>调用 deleteSegments 方法删除这些日志段</li></ol><h3 id="3-2-deleteSegments"><a href="#3-2-deleteSegments" class="headerlink" title="3.2. deleteSegments"></a>3.2. deleteSegments</h3><p>deleteSegments 执行真正的日志段删除操作</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">deleteSegments</span></span>(deletable: <span class="type">Iterable</span>[<span class="type">LogSegment</span>]): <span class="type">Int</span> = &#123;</span><br><span class="line">    maybeHandleIOException(<span class="string">s&quot;Error while deleting segments for <span class="subst">$topicPartition</span> in dir <span class="subst">$&#123;dir.getParent&#125;</span>&quot;</span>) &#123;</span><br><span class="line">      <span class="keyword">val</span> numToDelete = deletable.size</span><br><span class="line">      <span class="keyword">if</span> (numToDelete &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 不允许删除所有日志段对象。如果一定要做，先创建出一个新的来，然后再把前面N个删掉</span></span><br><span class="line">        <span class="keyword">if</span> (segments.size == numToDelete)</span><br><span class="line">          roll()</span><br><span class="line">        lock synchronized &#123;</span><br><span class="line">          checkIfMemoryMappedBufferClosed() <span class="comment">// 确保Log对象没有被关闭</span></span><br><span class="line">          <span class="comment">// 删除给定的日志段对象以及底层的物理文件</span></span><br><span class="line">          removeAndDeleteSegments(deletable, asyncDelete = <span class="literal">true</span>)</span><br><span class="line">          <span class="comment">// 尝试更新日志的Log Start Offset值 </span></span><br><span class="line">          maybeIncrementLogStartOffset(</span><br><span class="line"> segments.firstEntry.getValue.baseOffset)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      numToDelete</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>Log Start Offset 值是整个 Log 对象对外可见消息的最小位移值。如果我们删除了日志段对象，很有可能对外可见消息的范围发生了变化，自然要看一下是否需要更新 Log Start Offset 值。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97_%E8%AF%BB%E5%86%99%E6%93%8D%E4%BD%9C/"/>
      <url>2021/03/04/Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97_%E8%AF%BB%E5%86%99%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>高水位的概念在 Kafka 中举足轻重，对它的管理，是 Log 最重要的功能之一,社区关于日志代码的很多改进都是基于高水位机制的，有的甚至是为了替代高水位机制而做的更新。</p><a id="more"></a><h2 id="1-写操作"><a href="#1-写操作" class="headerlink" title="1. 写操作"></a>1. 写操作</h2><p>在 Log 中，涉及写操作的方法有 3 个：appendAsLeader、appendAsFollower 和 append。它们的调用关系如下图所示</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-12 下午10.21.24.png" alt="截屏2021-05-12 下午10.21.24" style="zoom:50%;" /><p>appendAsLeader 用于写 Leader 副本的，appendAsFollower 是用于 Follower 副本同步的。它们的底层都调用了 append 方法。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-12 下午10.18.02.png" alt="截屏2021-05-12 下午10.18.02" style="zoom:30%;" /><h3 id="1-1-消息校验"><a href="#1-1-消息校验" class="headerlink" title="1.1. 消息校验"></a>1.1. 消息校验</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 第1步：分析和验证待写入消息集合，并返回校验结果 </span></span><br><span class="line"><span class="keyword">val</span> appendInfo = analyzeAndValidateRecords(records, origin) </span><br><span class="line"><span class="comment">// 如果不需要写入任何消息，直接返回</span></span><br><span class="line"><span class="keyword">if</span> (appendInfo.shallowCount == <span class="number">0</span>) <span class="keyword">return</span> appendInfo</span><br></pre></td></tr></table></figure><h3 id="1-2-消息格式规整"><a href="#1-2-消息格式规整" class="headerlink" title="1.2. 消息格式规整"></a>1.2. 消息格式规整</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 第2步：消息格式规整，即删除无效格式消息或无效字节 </span></span><br><span class="line"><span class="keyword">var</span> validRecords = trimInvalidBytes(records, appendInfo)</span><br></pre></td></tr></table></figure><h2 id="2-读操作"><a href="#2-读操作" class="headerlink" title="2. 读操作"></a>2. 读操作</h2><h3 id="2-1-read-参数"><a href="#2-1-read-参数" class="headerlink" title="2.1. read() 参数"></a>2.1. read() 参数</h3><p>startOffset，即从 Log 对象的哪个位移值开始读消息。maxLength，即最多能读取多少字节。isolation，设置读取隔离级别，主要控制能够读取的最大位移值，多用于 Kafka 事务。minOneMessage，即是否允许至少读一条消息。设想如果消息很大，超过了 maxLength，正常情况下 read 方法永远不会返回任何消息。但如果设置了该参数为 true，read 方法就保证至少能够返回一条消息。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97_%E6%97%A5%E5%BF%97%E6%AE%B5%E7%AE%A1%E7%90%86/"/>
      <url>2021/03/04/Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97_%E6%97%A5%E5%BF%97%E6%AE%B5%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>高水位的概念在 Kafka 中举足轻重，对它的管理，是 Log 最重要的功能之一,社区关于日志代码的很多改进都是基于高水位机制的，有的甚至是为了替代高水位机制而做的更新。</p><a id="more"></a><h2 id="1-日志段管理"><a href="#1-日志段管理" class="headerlink" title="1. 日志段管理"></a>1. 日志段管理</h2><p>源码中日志对象定义高水位的语句只有一行：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> segments: <span class="type">ConcurrentNavigableMap</span>[java.lang.<span class="type">Long</span>, <span class="type">LogSegment</span>] = <span class="keyword">new</span> <span class="type">ConcurrentSkipListMap</span>[java.lang.<span class="type">Long</span>, <span class="type">LogSegment</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-增加日志段"><a href="#2-增加日志段" class="headerlink" title="2. 增加日志段"></a>2. 增加日志段</h2><p>Log 对象中定义了添加日志段对象的方法: addSegment。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addSegment</span></span>(segment: <span class="type">LogSegment</span>): <span class="type">LogSegment</span> = <span class="keyword">this</span>.segments.put(segment.baseOffset, segment)</span><br></pre></td></tr></table></figure><h2 id="3-删除日志段"><a href="#3-删除日志段" class="headerlink" title="3. 删除日志段"></a>3. 删除日志段</h2><p>删除操作相对来说复杂,Kafka 有很多留存策略，包括基于时间维度的、基于空间维度的和基于 Log Start Offset 维度</p><p>Log 中控制删除操作的总入口是 deleteOldSegments 无参方法</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deleteOldSegments</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (config.delete) &#123;</span><br><span class="line">      deleteRetentionMsBreachedSegments() + deleteRetentionSizeBreachedSegments() + deleteLogStartOffsetBreachedSegments()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      deleteLogStartOffsetBreachedSegments()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>deleteRetentionMsBreachedSegments、deleteRetentionSizeBreachedSegments 和 deleteLogStartOffsetBreachedSegments 分别对应于 3 个留存策略。</p><p>3 个留存策略方法底层都会调用带参数版本的 deleteOldSegments 方法，而这个方法又相继调用了 deletableSegments 和 deleteSegments 方法。。</p><h3 id="3-1-deleteOldSegments-带参"><a href="#3-1-deleteOldSegments-带参" class="headerlink" title="3.1. deleteOldSegments 带参"></a>3.1. deleteOldSegments 带参</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">deleteOldSegments</span></span>(predicate: (<span class="type">LogSegment</span>, <span class="type">Option</span>[<span class="type">LogSegment</span>]) =&gt; <span class="type">Boolean</span>, reason: <span class="type">String</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    lock synchronized &#123;</span><br><span class="line">      <span class="keyword">val</span> deletable = deletableSegments(predicate)</span><br><span class="line">      <span class="keyword">if</span> (deletable.nonEmpty)</span><br><span class="line">        info(<span class="string">s&quot;Found deletable segments with base offsets [<span class="subst">$&#123;deletable.map(_.baseOffset).mkString(&quot;,&quot;)&#125;</span>] due to <span class="subst">$reason</span>&quot;</span>)</span><br><span class="line">      deleteSegments(deletable)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ol><li>使用传入的函数计算哪些日志段对象能够被删除</li><li>调用 deleteSegments 方法删除这些日志段</li></ol><h3 id="3-2-deleteSegments"><a href="#3-2-deleteSegments" class="headerlink" title="3.2. deleteSegments"></a>3.2. deleteSegments</h3><p>deleteSegments 执行真正的日志段删除操作</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">deleteSegments</span></span>(deletable: <span class="type">Iterable</span>[<span class="type">LogSegment</span>]): <span class="type">Int</span> = &#123;</span><br><span class="line">    maybeHandleIOException(<span class="string">s&quot;Error while deleting segments for <span class="subst">$topicPartition</span> in dir <span class="subst">$&#123;dir.getParent&#125;</span>&quot;</span>) &#123;</span><br><span class="line">      <span class="keyword">val</span> numToDelete = deletable.size</span><br><span class="line">      <span class="keyword">if</span> (numToDelete &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 不允许删除所有日志段对象。如果一定要做，先创建出一个新的来，然后再把前面N个删掉</span></span><br><span class="line">        <span class="keyword">if</span> (segments.size == numToDelete)</span><br><span class="line">          roll()</span><br><span class="line">        lock synchronized &#123;</span><br><span class="line">          checkIfMemoryMappedBufferClosed() <span class="comment">// 确保Log对象没有被关闭</span></span><br><span class="line">          <span class="comment">// 删除给定的日志段对象以及底层的物理文件</span></span><br><span class="line">          removeAndDeleteSegments(deletable, asyncDelete = <span class="literal">true</span>)</span><br><span class="line">          <span class="comment">// 尝试更新日志的Log Start Offset值 </span></span><br><span class="line">          maybeIncrementLogStartOffset(</span><br><span class="line"> segments.firstEntry.getValue.baseOffset)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      numToDelete</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>Log Start Offset 值是整个 Log 对象对外可见消息的最小位移值。如果我们删除了日志段对象，很有可能对外可见消息的范围发生了变化，自然要看一下是否需要更新 Log Start Offset 值。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97_%E9%AB%98%E6%B0%B4%E4%BD%8D%E7%AE%A1%E7%90%86/"/>
      <url>2021/03/04/Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97_%E9%AB%98%E6%B0%B4%E4%BD%8D%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>高水位的概念在 Kafka 中举足轻重，对它的管理，是 Log 最重要的功能之一,社区关于日志代码的很多改进都是基于高水位机制的，有的甚至是为了替代高水位机制而做的更新。</p><a id="more"></a><h2 id="1-高水位管理操作"><a href="#1-高水位管理操作" class="headerlink" title="1. 高水位管理操作"></a>1. 高水位管理操作</h2><p>源码中日志对象定义高水位的语句只有一行：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> highWatermarkMetadata: <span class="type">LogOffsetMetadata</span> = <span class="type">LogOffsetMetadata</span>(logStartOffset)</span><br></pre></td></tr></table></figure><ol><li><p>高水位值 volatile </p><blockquote><p>因为多个线程可能同时读取它，因此需要设置成 volatile，保证内存可见性。另外，由于高水位值可能被多个线程同时修改，使用 Java Monitor 锁来确保并发修改的线程安全。</p></blockquote></li><li><p>高水位值的初始值是 Log Start Offset</p><blockquote><p>每个 Log 对象都会维护一个 Log Start Offset 值。当首次构建高水位时，它会被赋值成 Log Start Offset 值。</p></blockquote></li></ol><h2 id="2-LogOffsetMetadata"><a href="#2-LogOffsetMetadata" class="headerlink" title="2. LogOffsetMetadata"></a>2. LogOffsetMetadata</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">LogOffsetMetadata</span>(<span class="params">messageOffset: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                             segmentBaseOffset: <span class="type">Long</span> = <span class="type">LogOffsetMetadata</span>.<span class="type">UnknownSegBaseOffset</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                             relativePositionInSegment: <span class="type">Int</span> = <span class="type">LogOffsetMetadata</span>.<span class="type">UnknownFilePosition</span></span>)</span></span><br></pre></td></tr></table></figure><ol><li><p>messageOffset</p><p>消息位移值，这是最重要的信息。高水位值，其实指的就是这个变量的值</p></li><li><p>segmentBaseOffset</p><p>保存该位移值所在日志段的起始位移。日志段起始位移值辅助计算两条消息在物理磁盘文件中位置的差值，即两条消息彼此隔了多少字节。这个计算有个前提条件，即两条消息必须处在同一个日志段对象上，不能跨日志段对象。否则它们就位于不同的物理文件上，计算这个值就没有意义了。segmentBaseOffset，就是用来判断两条消息是否处于同一个日志段的</p></li><li><p>relativePositionSegment</p><p>保存该位移值所在日志段的物理磁盘位置。</p><blockquote><p>Kafka 什么时候需要计算位置之间的字节数呢？</p><p>在读取日志的时候。假设每次读取时只能读 1MB 的数据，那么，源码肯定需要关心两个位移之间所有消息的总字节数是否超过了 1MB。</p></blockquote></li></ol><h2 id="3-获取和设置高水位值"><a href="#3-获取和设置高水位值" class="headerlink" title="3. 获取和设置高水位值"></a>3. 获取和设置高水位值</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// getter method：读取高水位的位移值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">highWatermark</span></span>: <span class="type">Long</span> = highWatermarkMetadata.messageOffset</span><br><span class="line"></span><br><span class="line"><span class="comment">// setter method：设置高水位值</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">updateHighWatermarkMetadata</span></span>(newHighWatermark: <span class="type">LogOffsetMetadata</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (newHighWatermark.messageOffset &lt; <span class="number">0</span>) <span class="comment">// 高水位值不能是负数</span></span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">&quot;High watermark offset should be non-negative&quot;</span>)</span><br><span class="line"></span><br><span class="line">    lock synchronized &#123; <span class="comment">// 保护Log对象修改的Monitor锁</span></span><br><span class="line">      highWatermarkMetadata = newHighWatermark <span class="comment">// 赋值新的高水位值</span></span><br><span class="line">      producerStateManager.onHighWatermarkUpdated(newHighWatermark.messageOffset) <span class="comment">// 处理事务状态管理器的高水位值更新逻辑，忽略它……</span></span><br><span class="line">      maybeIncrementFirstUnstableOffset() <span class="comment">// First Unstable Offset是Kafka事务机制的一部分，忽略它……</span></span><br><span class="line">    &#125;</span><br><span class="line">    trace(<span class="string">s&quot;Setting high watermark <span class="subst">$newHighWatermark</span>&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="4-更新高水位值"><a href="#4-更新高水位值" class="headerlink" title="4. 更新高水位值"></a>4. 更新高水位值</h2><p>源码定义了两个更新高水位值的方法: <code>updateHighWatermark</code> 和 <code>maybeIncrementHighWatermark</code>。这两个方法有着不同的用途。</p><ol><li>updateHighWatermark 主要用在 Follower 副本从 Leader 副本获取到消息后更新高水位值。一旦拿到新的消息，就必须要更新高水位值</li><li>maybeIncrementHighWatermark 方法，主要是用来更新 Leader 副本的高水位值。Leader 副本高水位值的更新是有条件的——某些情况下会更新高水位值，某些情况下可能不会。</li></ol><h3 id="4-2-updateHighWatermark"><a href="#4-2-updateHighWatermark" class="headerlink" title="4.2. updateHighWatermark"></a>4.2. updateHighWatermark</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// updateHighWatermark method</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateHighWatermark</span></span>(hw: <span class="type">Long</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">    <span class="comment">// 新高水位值一定介于[Log Start Offset，Log End Offset]之间</span></span><br><span class="line">    <span class="keyword">val</span> newHighWatermark = <span class="keyword">if</span> (hw &lt; logStartOffset)  </span><br><span class="line">      logStartOffset</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (hw &gt; logEndOffset)</span><br><span class="line">      logEndOffset</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">  hw</span><br><span class="line">    <span class="comment">// 调用Setter方法来更新高水位值</span></span><br><span class="line">    updateHighWatermarkMetadata(<span class="type">LogOffsetMetadata</span>(newHighWatermark))</span><br><span class="line">    newHighWatermark  <span class="comment">// 最后返回新高水位值</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="4-3-maybeIncrementHighWatermark"><a href="#4-3-maybeIncrementHighWatermark" class="headerlink" title="4.3. maybeIncrementHighWatermark"></a>4.3. maybeIncrementHighWatermark</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maybeIncrementHighWatermark</span></span>(newHighWatermark: <span class="type">LogOffsetMetadata</span>): <span class="type">Option</span>[<span class="type">LogOffsetMetadata</span>] = &#123;</span><br><span class="line">    <span class="comment">// 新高水位值不能越过Log End Offset</span></span><br><span class="line">    <span class="keyword">if</span> (newHighWatermark.messageOffset &gt; logEndOffset)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s&quot;High watermark <span class="subst">$newHighWatermark</span> update exceeds current &quot;</span> +</span><br><span class="line">        <span class="string">s&quot;log end offset <span class="subst">$logEndOffsetMetadata</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    lock.synchronized &#123;</span><br><span class="line">      <span class="keyword">val</span> oldHighWatermark = fetchHighWatermarkMetadata  <span class="comment">// 获取老的高水位值</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// 新高水位值要比老高水位值大以维持单调增加特性，否则就不做更新！</span></span><br><span class="line">      <span class="comment">// 另外，如果新高水位值在新日志段上，也可执行更新高水位操作</span></span><br><span class="line">      <span class="keyword">if</span> (oldHighWatermark.messageOffset &lt; newHighWatermark.messageOffset ||</span><br><span class="line">        (oldHighWatermark.messageOffset == newHighWatermark.messageOffset &amp;&amp; oldHighWatermark.onOlderSegment(newHighWatermark))) &#123;</span><br><span class="line">        updateHighWatermarkMetadata(newHighWatermark)</span><br><span class="line">        <span class="type">Some</span>(oldHighWatermark) <span class="comment">// 返回老的高水位值</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">None</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h2 id="5-读取高水位值"><a href="#5-读取高水位值" class="headerlink" title="5. 读取高水位值"></a>5. 读取高水位值</h2><p>fetchHighWatermarkMetadata 方法,不仅仅获取高水位值，还要获取高水位的其他元数据信息，即日志段起始位移和物理位置信息。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">fetchHighWatermarkMetadata</span></span>: <span class="type">LogOffsetMetadata</span> = &#123;</span><br><span class="line">    checkIfMemoryMappedBufferClosed() <span class="comment">// 读取时确保日志不能被关闭</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> offsetMetadata = highWatermarkMetadata <span class="comment">// 保存当前高水位值到本地变量，避免多线程访问干扰</span></span><br><span class="line">    <span class="keyword">if</span> (offsetMetadata.messageOffsetOnly) &#123; <span class="comment">//没有获得到完整的高水位元数据</span></span><br><span class="line">      lock.synchronized &#123;</span><br><span class="line">        <span class="comment">// 通过读日志文件的方式把完整的高水位元数据信息拉出来</span></span><br><span class="line">        <span class="keyword">val</span> fullOffset = convertToOffsetMetadataOrThrow(highWatermark) </span><br><span class="line">        <span class="comment">// 然后再更新一下高水位对象</span></span><br><span class="line">        updateHighWatermarkMetadata(fullOffset) </span><br><span class="line">        fullOffset</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// 否则，直接返回即可</span></span><br><span class="line">      offsetMetadata</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka_%E5%BB%B6%E8%BF%9F%E6%93%8D%E4%BD%9C(1)_TimingWheel/"/>
      <url>2021/03/04/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka_%E5%BB%B6%E8%BF%9F%E6%93%8D%E4%BD%9C(1)_TimingWheel/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>延时请求(Delayed Operation)也称延迟请求，是指因未满足条件而暂时无法被处理的 Kafka 请求。如配置了 acks=all 的生产者发送的请求可能一时无法完成，因为 Kafka 必须确保 ISR 中的所有副本都要成功响应这次写入。通常情况下，这些请求没法被立即处理。只有满足了条件或发生了超时，Kafka 才会把该请求标记为完成状态。这就是所谓的延时请求。<a id="more"></a></p><h2 id="1-时间轮简介"><a href="#1-时间轮简介" class="headerlink" title="1. 时间轮简介"></a>1. 时间轮简介</h2><p>Kafka 的第一版延时请求使用 DelayQueue, 这个类是 Java 天然提供的延时队列</p><p>DelayQueue 有一个弊端：它插入和删除队列元素的时间复杂度是 O(logN)。对于 Kafka 这种非常容易积攒几十万个延时请求的场景来说，该数据结构的性能是瓶颈。当然，这一版的设计还有其他弊端，比如，它在清除已过期的延迟请求方面不够高效，可能会出现内存溢出的情形。后来，社区改造了延时请求的实现机制，采用了基于时间轮的方案。</p><p>时间轮有简单时间轮（Simple Timing Wheel）和分层时间轮（Hierarchical Timing Wheel）两类。两者各有利弊，也都有各自的使用场景。Kafka 采用的是分层时间轮，</p><h2 id="2-Kafka-时间轮实现"><a href="#2-Kafka-时间轮实现" class="headerlink" title="2. Kafka 时间轮实现"></a>2. Kafka 时间轮实现</h2><p>在 Kafka 源码中，时间轮对应 utils.timer 包下的 TimingWheel 类，每个 Bucket 下的链表对应 TimerTaskList 类，链表元素对应 TimerTaskEntry 类，而每个链表元素里面保存的延时任务对应 TimerTask。</p><p>在这些类中，TimerTaskEntry 与 TimerTask 是 1 对 1 的关系，TimerTaskList 下包含多个 TimerTaskEntry，TimingWheel 包含多个 TimerTaskList。</p><h2 id="3-TimerTask"><a href="#3-TimerTask" class="headerlink" title="3. TimerTask"></a>3. TimerTask</h2><p>位于 utils.timer 包下的 TimerTask.scala 文件中</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">TimerTask</span> <span class="keyword">extends</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> delayMs: <span class="type">Long</span> <span class="comment">// 通常是request.timeout.ms参数值</span></span><br><span class="line">  <span class="comment">// 每个TimerTask实例关联一个TimerTaskEntry</span></span><br><span class="line">  <span class="comment">// 就是说每个定时任务需要知道它在哪个Bucket链表下的哪个链表元素上</span></span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> timerTaskEntry: <span class="type">TimerTaskEntry</span> = <span class="literal">null</span></span><br><span class="line">  <span class="comment">// 取消定时任务，原理就是将关联的 timerTaskEntry 置空</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">cancel</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    synchronized &#123;</span><br><span class="line">      <span class="keyword">if</span> (timerTaskEntry != <span class="literal">null</span>) timerTaskEntry.remove()</span><br><span class="line">      timerTaskEntry = <span class="literal">null</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 关联 timerTaskEntry，原理是给 timerTaskEntry 字段赋值</span></span><br><span class="line">  <span class="keyword">private</span>[timer] <span class="function"><span class="keyword">def</span> <span class="title">setTimerTaskEntry</span></span>(entry: <span class="type">TimerTaskEntry</span>)</span><br><span class="line">    : <span class="type">Unit</span> = &#123;</span><br><span class="line">    synchronized &#123;</span><br><span class="line">      <span class="keyword">if</span> (timerTaskEntry != <span class="literal">null</span> &amp;&amp; timerTaskEntry != entry)</span><br><span class="line">        timerTaskEntry.remove()</span><br><span class="line">      timerTaskEntry = entry</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 获取关联的 timerTaskEntry 实例</span></span><br><span class="line">  <span class="keyword">private</span>[timer] <span class="function"><span class="keyword">def</span> <span class="title">getTimerTaskEntry</span></span>(): <span class="type">TimerTaskEntry</span> = &#123;</span><br><span class="line">    timerTaskEntry</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-TimerTaskEntry"><a href="#4-TimerTaskEntry" class="headerlink" title="4. TimerTaskEntry"></a>4. TimerTaskEntry</h2><p>TimerTaskEntry 表征的是 Bucket 链表下的一个元素</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[timer] <span class="class"><span class="keyword">class</span> <span class="title">TimerTaskEntry</span>(<span class="params">val timerTask: <span class="type">TimerTask</span>, val expirationMs: <span class="type">Long</span></span>) <span class="keyword">extends</span> <span class="title">Ordered</span>[<span class="type">TimerTaskEntry</span>] </span>&#123;</span><br><span class="line">  <span class="meta">@volatile</span></span><br><span class="line">  <span class="keyword">var</span> list: <span class="type">TimerTaskList</span> = <span class="literal">null</span>   <span class="comment">// 绑定的Bucket链表实例 </span></span><br><span class="line">  <span class="keyword">var</span> next: <span class="type">TimerTaskEntry</span> = <span class="literal">null</span>  <span class="comment">// next指针</span></span><br><span class="line">  <span class="keyword">var</span> prev: <span class="type">TimerTaskEntry</span> = <span class="literal">null</span>  <span class="comment">// prev指针</span></span><br><span class="line">  <span class="comment">// 关联给定的定时任务</span></span><br><span class="line">  <span class="keyword">if</span> (timerTask != <span class="literal">null</span>) timerTask.setTimerTaskEntry(<span class="keyword">this</span>)</span><br><span class="line">  <span class="comment">// 关联定时任务是否已经被取消了</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">cancelled</span></span>: <span class="type">Boolean</span> = &#123;</span><br><span class="line">    timerTask.getTimerTaskEntry != <span class="keyword">this</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 从Bucket链表中移除自己</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">remove</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">var</span> currentList = list</span><br><span class="line">    <span class="keyword">while</span> (currentList != <span class="literal">null</span>) &#123;</span><br><span class="line">      currentList.remove(<span class="keyword">this</span>)</span><br><span class="line">      currentList = list</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="5-TimerTaskList"><a href="#5-TimerTaskList" class="headerlink" title="5. TimerTaskList"></a>5. TimerTaskList</h2><p>TimerTaskList 由双向循环链表实现。定义了一个 Root 节点，同时还定义了两个字段：</p><ol><li>taskCounter，用于标识当前这个链表中的总定时任务数</li><li>expiration，表示这个链表所在 Bucket 的过期时间戳。</li></ol><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[timer] <span class="class"><span class="keyword">class</span> <span class="title">TimerTaskList</span>(<span class="params">taskCounter: <span class="type">AtomicInteger</span></span>) <span class="keyword">extends</span> <span class="title">Delayed</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> root = <span class="keyword">new</span> <span class="type">TimerTaskEntry</span>(<span class="literal">null</span>, <span class="number">-1</span>)</span><br><span class="line">  root.next = root</span><br><span class="line">  root.prev = root</span><br><span class="line">  <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">val</span> expiration = <span class="keyword">new</span> <span class="type">AtomicLong</span>(<span class="number">-1</span>L)</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97(2)%20/"/>
      <url>2021/03/04/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97(2)%20/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>日志是 Kafka 服务器端代码的重要组件之一，很多其他的核心组件都是以日志为基础的</p><p>kafka 消息是通过主题来进行组织和区分的，每个主题有分为零个或多个分区，分区数量可以在创建时指定也可以后期修改，不过修改只能增加不能删除，每个分区又有一个或多个副本，副本中会有一个副本被选做 Leader 副本，该副本对外提供读写操作，其他副本则是Follower。</p><p>分区的每个副本对应到一个 Log 对象，每个 Log 有划分为多个 LogSegment，每个 LogSegment 包括一个日志文件和两个索引文件，其中两个索引文件分别是偏移量索引文件和时间戳索引文件。</p><a id="more"></a><h2 id="1-Log-源码结构"><a href="#1-Log-源码结构" class="headerlink" title="1. Log 源码结构"></a>1. Log 源码结构</h2><p>Log 源码位于 Kafka core 工程的 log 源码包下，文件名是 Log.scala。总体上，该文件定义了 10 个类和对象，如下图所示：</p><p>![截屏2021-03-12 下午4.48.00](/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-12 下午4.48.00.png)</p><h2 id="2-Log-类及其伴生对象"><a href="#2-Log-类及其伴生对象" class="headerlink" title="2. Log 类及其伴生对象"></a>2. Log 类及其伴生对象</h2><h3 id="2-1-Log-伴生对象"><a href="#2-1-Log-伴生对象" class="headerlink" title="2.1. Log 伴生对象"></a>2.1. Log 伴生对象</h3><p>伴生对象多用于保存静态变量和静态方法</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Log</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> <span class="type">LogFileSuffix</span> = <span class="string">&quot;.log&quot;</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">IndexFileSuffix</span> = <span class="string">&quot;.index&quot;</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">TimeIndexFileSuffix</span> = <span class="string">&quot;.timeindex&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> <span class="type">DeletedFileSuffix</span> = <span class="string">&quot;.deleted&quot;</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">CleanedFileSuffix</span> = <span class="string">&quot;.cleaned&quot;</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">SwapFileSuffix</span> = <span class="string">&quot;.swap&quot;</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">CleanShutdownFile</span> = <span class="string">&quot;.kafka_cleanshutdown&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Kafka 定义的各种文件类型</p><ol><li><p><code>.snapshot</code> 是 Kafka 为幂等型或事务型 Producer 所做的快照文件。</p></li><li><p><code>.deleted</code> 是删除日志段操作创建的文件。目前删除日志段文件是异步操作，Broker 端把日志段文件从 .log 后缀修改为.deleted 后缀。</p></li><li><p><code>.cleaned</code> 和 <code>.swap</code> 都是 Compaction 操作的产物</p></li><li><p><code>-delete</code> 则是应用于文件夹的。当你删除一个主题的时候，主题的分区文件夹会被加上这个后缀。</p></li><li><p><code>-future</code> 是用于变更主题分区文件夹地址的，属于比较高阶的用法。</p><h3 id="2-2-Log-类"><a href="#2-2-Log-类" class="headerlink" title="2.2. Log 类"></a>2.2. Log 类</h3></li></ol><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Log</span>(<span class="params">@volatile var dir: <span class="type">File</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          @volatile var config: <span class="type">LogConfig</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          @volatile var logStartOffset: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          @volatile var recoveryPoint: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          scheduler: <span class="type">Scheduler</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          brokerTopicStats: <span class="type">BrokerTopicStats</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          val time: <span class="type">Time</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          val maxProducerIdExpirationMs: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          val producerIdExpirationCheckIntervalMs: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          val topicPartition: <span class="type">TopicPartition</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          val producerStateManager: <span class="type">ProducerStateManager</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">          logDirFailureChannel: <span class="type">LogDirFailureChannel</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</span><br><span class="line">……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-2-1-属性"><a href="#2-2-1-属性" class="headerlink" title="2.2.1. 属性"></a>2.2.1. 属性</h3><p>Log 类还定义了一些很重要的属性，比如下面这段代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> nextOffsetMetadata: <span class="type">LogOffsetMetadata</span> = _</span><br><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> highWatermarkMetadata: <span class="type">LogOffsetMetadata</span> = <span class="type">LogOffsetMetadata</span>(logStartOffset)</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> segments: <span class="type">ConcurrentNavigableMap</span>[java.lang.<span class="type">Long</span>, <span class="type">LogSegment</span>] = <span class="keyword">new</span> <span class="type">ConcurrentSkipListMap</span>[java.lang.<span class="type">Long</span>, <span class="type">LogSegment</span>]</span><br><span class="line"><span class="meta">@volatile</span> <span class="keyword">var</span> leaderEpochCache: <span class="type">Option</span>[<span class="type">LeaderEpochFileCache</span>] = <span class="type">None</span></span><br></pre></td></tr></table></figure><ol><li><p>nextOffsetMetadata</p><p>封装了下一条待插入消息的位移值，基本上可以把这个属性和 LEO 等同起来。</p></li><li><p>highWatermarkMetadata</p><p>是分区日志高水位值</p></li><li><p>segments</p><p>保存了分区日志下所有的日志段信息，只不过是用 Map 的数据结构来保存的。Map 的 Key 值是日志段的起始位移值，Value 则是日志段对象本身。使用 ConcurrentNavigableMap 数据结构来保存日志段对象，就可以很轻松地利用该类提供的线程安全和各种支持排序的方法，来管理所有日志段对象。</p></li><li><p>Leader Epoch Cache 对象</p><p>Leader Epoch 是社区于 0.11.0.0 版本引入源码中的，主要是用来判断出现 Failure 时是否执行日志截断操作(Truncation)。之前靠高水位来判断的机制，可能会造成副本间数据不一致的情形。这里的 Leader Epoch Cache 是一个缓存类数据，里面保存了分区 Leader 的 Epoch 值与对应位移值的映射关系</p></li></ol><h3 id="2-3-Log-类的初始化"><a href="#2-3-Log-类的初始化" class="headerlink" title="2.3. Log 类的初始化"></a>2.3. Log 类的初始化</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">locally &#123;</span><br><span class="line">        <span class="keyword">val</span> startMs = time.milliseconds</span><br><span class="line">        <span class="comment">// create the log directory if it doesn&#x27;t exist</span></span><br><span class="line">        <span class="type">Files</span>.createDirectories(dir.toPath)</span><br><span class="line">        initializeLeaderEpochCache() </span><br><span class="line">        <span class="keyword">val</span> nextOffset = loadSegments() </span><br><span class="line">        <span class="comment">/* Calculate the offset of the next message */</span></span><br><span class="line">        nextOffsetMetadata = <span class="type">LogOffsetMetadata</span>(nextOffset, activeSegment.baseOffset, activeSegment.size)  </span><br><span class="line">        leaderEpochCache.foreach(_.truncateFromEnd(nextOffsetMetadata.messageOffset))  </span><br><span class="line">        logStartOffset = math.max(logStartOffset, segments.firstEntry.getValue.baseOffset)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">        <span class="comment">// The earliest leader epoch may not be flushed during a hard failure. Recover it here.</span></span><br><span class="line">        leaderEpochCache.foreach(_.truncateFromStart(logStartOffset))</span><br><span class="line">       </span><br><span class="line">        <span class="comment">// Any segment loading or recovery code must not use producerStateManager, so that we can build      the full state here</span></span><br><span class="line">        <span class="comment">// from scratch.</span></span><br><span class="line">        <span class="keyword">if</span> (!producerStateManager.isEmpty)</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">&quot;Producer state must be empty during log initialization&quot;</span>)</span><br><span class="line">        loadProducerState(logEndOffset, reloadFromCleanShutdown = hasCleanShutdownFile)</span><br><span class="line">    </span><br><span class="line">        info(<span class="string">s&quot;Completed load of log with <span class="subst">$&#123;segments.size&#125;</span> segments, log start offset <span class="subst">$logStartOffset</span> and &quot;</span> +</span><br><span class="line">          <span class="string">s&quot;log end offset <span class="subst">$logEndOffset</span> in <span class="subst">$&#123;time.milliseconds() - startMs&#125;</span> </span></span><br></pre></td></tr></table></figure><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-12 下午5.12.53.png" alt="截屏2021-03-12 下午5.12.53" style="zoom:50%;" /><h2 id="4-加载日志段机制"><a href="#4-加载日志段机制" class="headerlink" title="4. 加载日志段机制"></a>4. 加载日志段机制</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">loadSegments</span></span>(): <span class="type">Long</span> = &#123;</span><br><span class="line">       </span><br><span class="line">       <span class="keyword">val</span> swapFiles = removeTempFilesAndCollectSwapFiles()</span><br><span class="line">  </span><br><span class="line">       retryOnOffsetOverflow &#123;</span><br><span class="line">         logSegments.foreach(_.close())</span><br><span class="line">         segments.clear()</span><br><span class="line">         loadSegmentFiles()</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       completeSwapOperations(swapFiles)</span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span> (!dir.getAbsolutePath.endsWith(<span class="type">Log</span>.<span class="type">DeleteDirSuffix</span>)) &#123;</span><br><span class="line">         <span class="keyword">val</span> nextOffset = retryOnOffsetOverflow &#123;</span><br><span class="line">           recoverLog()</span><br><span class="line">         &#125;</span><br><span class="line">   </span><br><span class="line">         activeSegment.resizeIndexes(config.maxIndexSize)</span><br><span class="line">         nextOffset</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">if</span> (logSegments.isEmpty) &#123;</span><br><span class="line">             addSegment(<span class="type">LogSegment</span>.open(dir = dir,</span><br><span class="line">               baseOffset = <span class="number">0</span>,</span><br><span class="line">               config,</span><br><span class="line">               time = time,</span><br><span class="line">               fileAlreadyExists = <span class="literal">false</span>,</span><br><span class="line">               initFileSize = <span class="keyword">this</span>.initFileSize,</span><br><span class="line">               preallocate = <span class="literal">false</span>))</span><br><span class="line">          &#125;</span><br><span class="line">         <span class="number">0</span></span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码会对分区日志路径遍历两次。</p><p>首先，它会移除上次 Failure 遗留下来的各种临时文件(包括.cleaned、.swap、.deleted 文件等)，removeTempFilesAndCollectSwapFiles 方法实现了这个逻辑。</p><p>之后，它会清空所有日志段对象，并且再次遍历分区路径，重建日志段 segments Map 并删除无对应日志段文件的孤立索引文件。</p><p>待执行完这两次遍历之后，它会完成未完成的 swap 操作，即调用 completeSwapOperations 方法。等这些都做完之后，再调用 recoverLog 方法恢复日志段对象，然后返回恢复之后的分区日志 LEO 值。</p><h2 id="2-日志段代码解析"><a href="#2-日志段代码解析" class="headerlink" title="2. 日志段代码解析"></a>2. 日志段代码解析</h2><p>日志段源码位于 Kafka 的 core 工程下，具体文件位置是 <code>core/src/main/scala/kafka/log/LogSegment.scala</code>。实际上，所有日志结构部分的源码都在 core 的 kafka.log 包下。</p><p>该文件下定义了三个 Scala 对象：</p><ol><li>LogSegment class</li><li>LogSegment object</li><li>LogFlushStats object</li></ol><p>LogFlushStats 结尾有个 Stats，它是做统计用的，主要负责为日志落盘进行计时。</p><h3 id="2-1-日志段类声明"><a href="#2-1-日志段类声明" class="headerlink" title="2.1. 日志段类声明"></a>2.1. 日志段类声明</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogSegment</span> <span class="title">private</span>[log] (<span class="params">val log: <span class="type">FileRecords</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val lazyOffsetIndex: <span class="type">LazyIndex</span>[<span class="type">OffsetIndex</span>], </span></span></span><br><span class="line"><span class="class"><span class="params">                               val lazyTimeIndex: <span class="type">LazyIndex</span>[<span class="type">TimeIndex</span>], </span></span></span><br><span class="line"><span class="class"><span class="params">                               val txnIndex: <span class="type">TransactionIndex</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val baseOffset: <span class="type">Long</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val indexIntervalBytes: <span class="type">Int</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val rollJitterMs: <span class="type">Long</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val time: <span class="type">Time</span></span>) </span></span><br><span class="line"><span class="class"><span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123; … &#125;</span><br></pre></td></tr></table></figure><ol><li><p><strong>lazyOffsetIndex</strong></p><p>位移索引文件</p></li><li><p><strong>lazyTimeIndex</strong></p><p>时间戳索引文件</p></li><li><p><strong>txnIndex</strong></p><p>已中止事务索引文件</p></li><li><p><strong>baseOffset</strong></p><p>每个日志段对象保存自己的起始位移 baseOffset, 磁盘上日志文件名就是 baseOffset 的值。每个 LogSegment 对象实例一旦被创建，它的起始位移已经固定，不能再被更改。</p></li><li><p><strong>indexIntervalBytes</strong></p><p>Broker 端参数 log.index.interval.bytes 值，它控制了日志段对象新增索引项的频率。默认情况下，日志段至少新写入 4KB 的消息数据才会新增一条索引项。</p></li><li><p><strong>rollJitterMs</strong> </p><p>日志段对象新增倒计时的 “扰动值”。因为目前 Broker 端日志段新增倒计时是全局设置，这就是说，在未来的某个时刻可能同时创建多个日志段对象，这将极大地增加物理磁盘 I/O 压力。有了 rollJitterMs 值的干扰，每个新增日志段在创建时会彼此岔开一小段时间，这样可以缓解物理磁盘的 I/O 负载瓶颈。</p></li><li><p><strong>time</strong></p><p>它就是用于统计计时的一个实现类</p></li></ol><h2 id="2-2-append-方法"><a href="#2-2-append-方法" class="headerlink" title="2.2. append 方法"></a>2.2. append 方法</h2><p>append 方法接收 4 个参数，分别表示待写入消息批次中消息的<code>最大位移值</code>、<code>最大时间戳</code>、<code>最大时间戳对应消息的位移</code>以<code>及真正要写入的消息集合</code>。下面这张图展示了 append 方法的完整执行流程：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append</span></span>(largestOffset: <span class="type">Long</span>, </span><br><span class="line">           largestTimestamp: <span class="type">Long</span>, </span><br><span class="line">           shallowOffsetOfMaxTimestamp: <span class="type">Long</span>, </span><br><span class="line">           records: <span class="type">MemoryRecords</span>): <span class="type">Unit</span> = &#123; </span><br><span class="line">  <span class="keyword">if</span> (records.sizeInBytes &gt; <span class="number">0</span>) &#123; </span><br><span class="line">    trace(<span class="string">s&quot;Inserting <span class="subst">$&#123;records.sizeInBytes&#125;</span> bytes at end offset <span class="subst">$largestOffset</span> at position <span class="subst">$&#123;log.sizeInBytes&#125;</span> &quot;</span></span><br><span class="line">          + <span class="string">s&quot;with largest timestamp <span class="subst">$largestTimestamp</span> at shallow offset <span class="subst">$shallowOffsetOfMaxTimestamp</span>&quot;</span>) </span><br><span class="line">    <span class="keyword">val</span> physicalPosition = log.sizeInBytes() </span><br><span class="line">    <span class="keyword">if</span> (physicalPosition == <span class="number">0</span>) </span><br><span class="line">    rollingBasedTimestamp = <span class="type">Some</span>(largestTimestamp) ensureOffsetInRange(largestOffset) <span class="comment">// append the messages </span></span><br><span class="line">    <span class="keyword">val</span> appendedBytes = log.append(records) trace(<span class="string">s&quot;Appended <span class="subst">$appendedBytes</span> to <span class="subst">$&#123;log.file&#125;</span> at end offset <span class="subst">$largestOffset</span>&quot;</span>) <span class="comment">// Update the in memory max timestamp and corresponding offset. </span></span><br><span class="line">    <span class="keyword">if</span> (largestTimestamp &gt; maxTimestampSoFar) &#123; </span><br><span class="line">      maxTimestampSoFar = largestTimestamp </span><br><span class="line">      offsetOfMaxTimestampSoFar = shallowOffsetOfMaxTimestamp </span><br><span class="line">    &#125; <span class="comment">// append an entry to</span></span><br></pre></td></tr></table></figure><p><strong>第一步：</strong></p><p>在源码中，首先调用 <code>log.sizeInBytes</code> 方法判断该日志段是否为空，如果是空的话， Kafka 需要记录要写入消息集合的最大时间戳，并将其作为后面新增日志段倒计时的依据。</p><p><strong>第二步：</strong>代码调用 <code>ensureOffsetInRange</code> 方法确保输入参数最大位移值是合法的。</p><p>标准就是看它与日志段起始位移的差值是否在整数范围内，即 <code>largestOffset - baseOffset</code> 的值是不是介于 [0，Int.MAXVALUE] 之间。在极个别的情况下，这个差值可能会越界，这时，append 方法就会抛出异常，阻止后续的消息写入。</p><blockquote><p>一旦你碰到这个问题，你需要做的是升级你的 Kafka 版本，因为这是由已知的 Bug 导致的。</p></blockquote><p><strong>第三步：</strong></p><p>append 方法调用 FileRecords 的 append 方法执行真正的写入。</p><p><strong>第四步：</strong>更新日志段的最大时间戳以及最大时间戳所属消息的位移值属性。</p><p>每个日志段都要保存当前最大时间戳信息和所属消息的位移信息。还记得 Broker 端提供定期删除日志的功能吗？比如我只想保留最近 7 天的日志，没错，当前最大时间戳这个值就是判断的依据；而最大时间戳对应的消息的位移值则用于时间戳索引项。虽然后面我会详细介绍，这里我还是稍微提一下：时间戳索引项保存时间戳与消息位移的对应关系。在这步操作中，Kafka 会更新并保存这组对应关系。</p><p><strong>第五步：</strong>更新索引项和写入的字节数</p><p>日志段默认每写入 4KB 数据就要写入一个索引项。当已写入字节数超过了 4KB 之后，append 方法会调用索引对象的 append 方法新增索引项，同时清空已写入字节数，以备下次重新累积计算。</p><h2 id="2-3-read-方法"><a href="#2-3-read-方法" class="headerlink" title="2.3. read 方法"></a>2.3. read 方法</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(startOffset: <span class="type">Long</span>,</span><br><span class="line">           maxSize: <span class="type">Int</span>,</span><br><span class="line">           maxPosition: <span class="type">Long</span> = size,</span><br><span class="line">           minOneMessage: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">FetchDataInfo</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (maxSize &lt; <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s&quot;Invalid max size <span class="subst">$maxSize</span> for log read from segment <span class="subst">$log</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> startOffsetAndSize = translateOffset(startOffset)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// if the start position is already off the end of the log, return null</span></span><br><span class="line">    <span class="keyword">if</span> (startOffsetAndSize == <span class="literal">null</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">null</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> startPosition = startOffsetAndSize.position</span><br><span class="line">    <span class="keyword">val</span> offsetMetadata = <span class="type">LogOffsetMetadata</span>(startOffset, <span class="keyword">this</span>.baseOffset, startPosition)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> adjustedMaxSize =</span><br><span class="line">      <span class="keyword">if</span> (minOneMessage) math.max(maxSize, startOffsetAndSize.size)</span><br><span class="line">      <span class="keyword">else</span> maxSize</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// return a log segment but with zero size in the case below</span></span><br><span class="line">    <span class="keyword">if</span> (adjustedMaxSize == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="type">FetchDataInfo</span>(offsetMetadata, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// calculate the length of the message set to read based on whether or not they gave us a maxOffset</span></span><br><span class="line">    <span class="keyword">val</span> fetchSize: <span class="type">Int</span> = min((maxPosition - startPosition).toInt, adjustedMaxSize)</span><br><span class="line">    </span><br><span class="line">    <span class="type">FetchDataInfo</span>(offsetMetadata, log.slice(startPosition, fetchSize),</span><br><span class="line">      firstEntryIncomplete = adjustedMaxSize &lt; startOffsetAndSize.size)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>read 方法接收 4 个输入参数。</p><ol><li>startOffset: 要读取的第一条消息的位移</li><li>maxSize: 能读取的最大字节数</li><li>maxPosition: 能读到的最大文件位置</li><li>minOneMessage: 是否允许在消息体过大时至少返回第一条消息。</li></ol><h3 id="2-4-recover-方法"><a href="#2-4-recover-方法" class="headerlink" title="2.4. recover 方法"></a>2.4. recover 方法</h3><p>recover 方法，用于恢复日志段。</p><p>recover 方法，用于恢复日志段。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97(3)/"/>
      <url>2021/03/04/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97(3)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>日志是 Kafka 服务器端代码的重要组件之一，很多其他的核心组件都是以日志为基础的</p><a id="more"></a><h2 id="1-索引类图及源文件组织架构"><a href="#1-索引类图及源文件组织架构" class="headerlink" title="1. 索引类图及源文件组织架构"></a>1. 索引类图及源文件组织架构</h2><p>在 Kafka 源码中，跟索引相关的源码文件有 5 个，它们都位于 core 包的 /src/main/scala/kafka/log 路径下</p><ol><li><p>AbstractIndex.scala</p><p>定义了最顶层的抽象类，这个类封装了所有索引类型的公共操作。</p></li><li><p>LazyIndex.scala</p><p>定义 AbstractIndex 上的一个包装类，实现索引项延迟加载。这个类主要是为了提高性能。</p></li><li><p>OffsetIndex.scala</p><p>定义位移索引，保存 <strong><code>&lt;位移值，文件磁盘物理位置&gt;</code></strong> 对。</p></li><li><p>TimeIndex.scala</p><p>定义时间戳索引，保存 **<code>&lt;时间戳，位移值&gt; </code>**对。</p></li><li><p>TransactionIndex.scala</p><p>定义事务索引，为已中止事务(Aborted Transcation)保存重要的元数据信息。只有启用 Kafka 事务后，这个索引才有可能出现。</p></li></ol><p>其中，OffsetIndex、TimeIndex 和 TransactionIndex 都继承了 AbstractIndex 类，而上层的 LazyIndex 仅仅是包装了一个 AbstractIndex 的实现类，作用是为了提升性能，并没有什么功能上的改进。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97(4)_%E6%97%A5%E5%BF%97%E5%88%A0%E9%99%A4/"/>
      <url>2021/03/04/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97(4)_%E6%97%A5%E5%BF%97%E5%88%A0%E9%99%A4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>日志是 Kafka 服务器端代码的重要组件之一，很多其他的核心组件都是以日志为基础的</p><p>kafka 消息是通过主题来进行组织和区分的，每个主题有分为零个或多个分区，分区数量可以在创建时指定也可以后期修改，不过修改只能增加不能删除，每个分区又有一个或多个副本，副本中会有一个副本被选做 Leader 副本，该副本对外提供读写操作，其他副本则是Follower。</p><p>分区的每个副本对应到一个 Log 对象，每个 Log 有划分为多个 LogSegment，每个 LogSegment 包括一个日志文件和两个索引文件，其中两个索引文件分别是偏移量索引文件和时间戳索引文件。</p><a id="more"></a><h2 id="1-Kafka-日志结构概览"><a href="#1-Kafka-日志结构概览" class="headerlink" title="1. Kafka 日志结构概览"></a>1. Kafka 日志结构概览</h2><p>Kafka 日志对象由多个日志段对象组成，而每个日志段对象会在磁盘上创建一组文件，包括消息日志文件（.log）、位移索引文件（.index）、时间戳索引文件（.timeindex）以及已中止（Aborted）事务的索引文件（.txnindex）。当然，如果你没有使用 Kafka 事务，已中止事务的索引文件是不会被创建出来的。图中的一串数字 0 是该日志段的起始位移值（Base Offset），也就是该日志段中所存的第一条消息的位移值。一般情况下，一个 Kafka 主题有很多分区，每个分区就对应一个 Log 对象，在物理磁盘上则对应于一个子目录。比如你创建了一个双分区的主题 test-topic，那么，Kafka 在磁盘上会创建两个子目录：test-topic-0 和 test-topic-1。而在服务器端，这就是两个 Log 对象。每个子目录下存在多组日志段，也就是多组.log、.index、.timeindex 文件组合，只不过文件名不同，因为每个日志段的起始位移不同。</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@chen-bigdata-master hai_kou_order_topic-0]<span class="comment"># ls</span></span><br><span class="line">00000000000000000000.index  00000000000000000000.timeindex  leader-epoch-checkpoint</span><br><span class="line">00000000000000000000.log    00000000000000000764.snapshot</span><br></pre></td></tr></table></figure><h2 id="2-日志段代码解析"><a href="#2-日志段代码解析" class="headerlink" title="2. 日志段代码解析"></a>2. 日志段代码解析</h2><p>日志段源码位于 Kafka 的 core 工程下，具体文件位置是 <code>core/src/main/scala/kafka/log/LogSegment.scala</code>。实际上，所有日志结构部分的源码都在 core 的 kafka.log 包下。</p><p>该文件下定义了三个 Scala 对象：</p><ol><li>LogSegment class</li><li>LogSegment object</li><li>LogFlushStats object</li></ol><p>LogFlushStats 结尾有个 Stats，它是做统计用的，主要负责为日志落盘进行计时。</p><h3 id="2-1-日志段类声明"><a href="#2-1-日志段类声明" class="headerlink" title="2.1. 日志段类声明"></a>2.1. 日志段类声明</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogSegment</span> <span class="title">private</span>[log] (<span class="params">val log: <span class="type">FileRecords</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val lazyOffsetIndex: <span class="type">LazyIndex</span>[<span class="type">OffsetIndex</span>], </span></span></span><br><span class="line"><span class="class"><span class="params">                               val lazyTimeIndex: <span class="type">LazyIndex</span>[<span class="type">TimeIndex</span>], </span></span></span><br><span class="line"><span class="class"><span class="params">                               val txnIndex: <span class="type">TransactionIndex</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val baseOffset: <span class="type">Long</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val indexIntervalBytes: <span class="type">Int</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val rollJitterMs: <span class="type">Long</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val time: <span class="type">Time</span></span>) </span></span><br><span class="line"><span class="class"><span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123; … &#125;</span><br></pre></td></tr></table></figure><ol><li><p><strong>lazyOffsetIndex</strong></p><p>位移索引文件</p></li><li><p><strong>lazyTimeIndex</strong></p><p>时间戳索引文件</p></li><li><p><strong>txnIndex</strong></p><p>已中止事务索引文件</p></li><li><p><strong>baseOffset</strong></p><p>每个日志段对象保存自己的起始位移 baseOffset, 磁盘上日志文件名就是 baseOffset 的值。每个 LogSegment 对象实例一旦被创建，它的起始位移已经固定，不能再被更改。</p></li><li><p><strong>indexIntervalBytes</strong></p><p>Broker 端参数 log.index.interval.bytes 值，它控制了日志段对象新增索引项的频率。默认情况下，日志段至少新写入 4KB 的消息数据才会新增一条索引项。</p></li><li><p><strong>rollJitterMs</strong> </p><p>日志段对象新增倒计时的 “扰动值”。因为目前 Broker 端日志段新增倒计时是全局设置，这就是说，在未来的某个时刻可能同时创建多个日志段对象，这将极大地增加物理磁盘 I/O 压力。有了 rollJitterMs 值的干扰，每个新增日志段在创建时会彼此岔开一小段时间，这样可以缓解物理磁盘的 I/O 负载瓶颈。</p></li><li><p><strong>time</strong></p><p>它就是用于统计计时的一个实现类</p></li></ol><h2 id="2-2-append-方法"><a href="#2-2-append-方法" class="headerlink" title="2.2. append 方法"></a>2.2. append 方法</h2><p>append 方法接收 4 个参数，分别表示待写入消息批次中消息的<code>最大位移值</code>、<code>最大时间戳</code>、<code>最大时间戳对应消息的位移</code>以<code>及真正要写入的消息集合</code>。下面这张图展示了 append 方法的完整执行流程：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append</span></span>(largestOffset: <span class="type">Long</span>, </span><br><span class="line">           largestTimestamp: <span class="type">Long</span>, </span><br><span class="line">           shallowOffsetOfMaxTimestamp: <span class="type">Long</span>, </span><br><span class="line">           records: <span class="type">MemoryRecords</span>): <span class="type">Unit</span> = &#123; </span><br><span class="line">  <span class="keyword">if</span> (records.sizeInBytes &gt; <span class="number">0</span>) &#123; </span><br><span class="line">    trace(<span class="string">s&quot;Inserting <span class="subst">$&#123;records.sizeInBytes&#125;</span> bytes at end offset <span class="subst">$largestOffset</span> at position <span class="subst">$&#123;log.sizeInBytes&#125;</span> &quot;</span></span><br><span class="line">          + <span class="string">s&quot;with largest timestamp <span class="subst">$largestTimestamp</span> at shallow offset <span class="subst">$shallowOffsetOfMaxTimestamp</span>&quot;</span>) </span><br><span class="line">    <span class="keyword">val</span> physicalPosition = log.sizeInBytes() </span><br><span class="line">    <span class="keyword">if</span> (physicalPosition == <span class="number">0</span>) </span><br><span class="line">    rollingBasedTimestamp = <span class="type">Some</span>(largestTimestamp) ensureOffsetInRange(largestOffset) <span class="comment">// append the messages </span></span><br><span class="line">    <span class="keyword">val</span> appendedBytes = log.append(records) trace(<span class="string">s&quot;Appended <span class="subst">$appendedBytes</span> to <span class="subst">$&#123;log.file&#125;</span> at end offset <span class="subst">$largestOffset</span>&quot;</span>) <span class="comment">// Update the in memory max timestamp and corresponding offset. </span></span><br><span class="line">    <span class="keyword">if</span> (largestTimestamp &gt; maxTimestampSoFar) &#123; </span><br><span class="line">      maxTimestampSoFar = largestTimestamp </span><br><span class="line">      offsetOfMaxTimestampSoFar = shallowOffsetOfMaxTimestamp </span><br><span class="line">    &#125; <span class="comment">// append an entry to</span></span><br></pre></td></tr></table></figure><p><strong>第一步：</strong></p><p>在源码中，首先调用 <code>log.sizeInBytes</code> 方法判断该日志段是否为空，如果是空的话， Kafka 需要记录要写入消息集合的最大时间戳，并将其作为后面新增日志段倒计时的依据。</p><p><strong>第二步：</strong>代码调用 <code>ensureOffsetInRange</code> 方法确保输入参数最大位移值是合法的。</p><p>标准就是看它与日志段起始位移的差值是否在整数范围内，即 <code>largestOffset - baseOffset</code> 的值是不是介于 [0，Int.MAXVALUE] 之间。在极个别的情况下，这个差值可能会越界，这时，append 方法就会抛出异常，阻止后续的消息写入。</p><blockquote><p>一旦你碰到这个问题，你需要做的是升级你的 Kafka 版本，因为这是由已知的 Bug 导致的。</p></blockquote><p><strong>第三步：</strong></p><p>append 方法调用 FileRecords 的 append 方法执行真正的写入。</p><p><strong>第四步：</strong>更新日志段的最大时间戳以及最大时间戳所属消息的位移值属性。</p><p>每个日志段都要保存当前最大时间戳信息和所属消息的位移信息。还记得 Broker 端提供定期删除日志的功能吗？比如我只想保留最近 7 天的日志，没错，当前最大时间戳这个值就是判断的依据；而最大时间戳对应的消息的位移值则用于时间戳索引项。虽然后面我会详细介绍，这里我还是稍微提一下：时间戳索引项保存时间戳与消息位移的对应关系。在这步操作中，Kafka 会更新并保存这组对应关系。</p><p><strong>第五步：</strong>更新索引项和写入的字节数</p><p>日志段默认每写入 4KB 数据就要写入一个索引项。当已写入字节数超过了 4KB 之后，append 方法会调用索引对象的 append 方法新增索引项，同时清空已写入字节数，以备下次重新累积计算。</p><h2 id="2-3-read-方法"><a href="#2-3-read-方法" class="headerlink" title="2.3. read 方法"></a>2.3. read 方法</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(startOffset: <span class="type">Long</span>,</span><br><span class="line">           maxSize: <span class="type">Int</span>,</span><br><span class="line">           maxPosition: <span class="type">Long</span> = size,</span><br><span class="line">           minOneMessage: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">FetchDataInfo</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (maxSize &lt; <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s&quot;Invalid max size <span class="subst">$maxSize</span> for log read from segment <span class="subst">$log</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> startOffsetAndSize = translateOffset(startOffset)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// if the start position is already off the end of the log, return null</span></span><br><span class="line">    <span class="keyword">if</span> (startOffsetAndSize == <span class="literal">null</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">null</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> startPosition = startOffsetAndSize.position</span><br><span class="line">    <span class="keyword">val</span> offsetMetadata = <span class="type">LogOffsetMetadata</span>(startOffset, <span class="keyword">this</span>.baseOffset, startPosition)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> adjustedMaxSize =</span><br><span class="line">      <span class="keyword">if</span> (minOneMessage) math.max(maxSize, startOffsetAndSize.size)</span><br><span class="line">      <span class="keyword">else</span> maxSize</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// return a log segment but with zero size in the case below</span></span><br><span class="line">    <span class="keyword">if</span> (adjustedMaxSize == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="type">FetchDataInfo</span>(offsetMetadata, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// calculate the length of the message set to read based on whether or not they gave us a maxOffset</span></span><br><span class="line">    <span class="keyword">val</span> fetchSize: <span class="type">Int</span> = min((maxPosition - startPosition).toInt, adjustedMaxSize)</span><br><span class="line">    </span><br><span class="line">    <span class="type">FetchDataInfo</span>(offsetMetadata, log.slice(startPosition, fetchSize),</span><br><span class="line">      firstEntryIncomplete = adjustedMaxSize &lt; startOffsetAndSize.size)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>read 方法接收 4 个输入参数。</p><ol><li>startOffset: 要读取的第一条消息的位移</li><li>maxSize: 能读取的最大字节数</li><li>maxPosition: 能读到的最大文件位置</li><li>minOneMessage: 是否允许在消息体过大时至少返回第一条消息。</li></ol><h3 id="2-4-recover-方法"><a href="#2-4-recover-方法" class="headerlink" title="2.4. recover 方法"></a>2.4. recover 方法</h3><p>recover 方法，用于恢复日志段。</p><p>recover 方法，用于恢复日志段。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/03/04/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97(5)_%E7%A3%81%E7%9B%98%E5%AD%98%E5%82%A8/"/>
      <url>2021/03/04/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97(5)_%E7%A3%81%E7%9B%98%E5%AD%98%E5%82%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>日志是 Kafka 服务器端代码的重要组件之一，很多其他的核心组件都是以日志为基础的</p><p>kafka 消息是通过主题来进行组织和区分的，每个主题有分为零个或多个分区，分区数量可以在创建时指定也可以后期修改，不过修改只能增加不能删除，每个分区又有一个或多个副本，副本中会有一个副本被选做 Leader 副本，该副本对外提供读写操作，其他副本则是Follower。</p><p>分区的每个副本对应到一个 Log 对象，每个 Log 有划分为多个 LogSegment，每个 LogSegment 包括一个日志文件和两个索引文件，其中两个索引文件分别是偏移量索引文件和时间戳索引文件。</p><a id="more"></a><h2 id="1-顺序写盘"><a href="#1-顺序写盘" class="headerlink" title="1. 顺序写盘"></a>1. 顺序写盘</h2><p>Kafka 日志对象由多个日志段对象组成，而每个日志段对象会在磁盘上创建一组文件，包括消息日志文件（.log）、位移索引文件（.index）、时间戳索引文件（.timeindex）以及已中止（Aborted）事务的索引文件（.txnindex）。当然，如果你没有使用 Kafka 事务，已中止事务的索引文件是不会被创建出来的。图中的一串数字 0 是该日志段的起始位移值（Base Offset），也就是该日志段中所存的第一条消息的位移值。一般情况下，一个 Kafka 主题有很多分区，每个分区就对应一个 Log 对象，在物理磁盘上则对应于一个子目录。比如你创建了一个双分区的主题 test-topic，那么，Kafka 在磁盘上会创建两个子目录：test-topic-0 和 test-topic-1。而在服务器端，这就是两个 Log 对象。每个子目录下存在多组日志段，也就是多组.log、.index、.timeindex 文件组合，只不过文件名不同，因为每个日志段的起始位移不同。</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@chen-bigdata-master hai_kou_order_topic-0]<span class="comment"># ls</span></span><br><span class="line">00000000000000000000.index  00000000000000000000.timeindex  leader-epoch-checkpoint</span><br><span class="line">00000000000000000000.log    00000000000000000764.snapshot</span><br></pre></td></tr></table></figure><h2 id="2-页缓存"><a href="#2-页缓存" class="headerlink" title="2. 页缓存"></a>2. 页缓存</h2><h2 id="3-零拷贝"><a href="#3-零拷贝" class="headerlink" title="3. 零拷贝"></a>3. 零拷贝</h2><p>append 方法接收 4 个参数，分别表示待写入消息批次中消息的<code>最大位移值</code>、<code>最大时间戳</code>、<code>最大时间戳对应消息的位移</code>以<code>及真正要写入的消息集合</code>。下面这张图展示了 append 方法的完整执行流程：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append</span></span>(largestOffset: <span class="type">Long</span>, </span><br><span class="line">           largestTimestamp: <span class="type">Long</span>, </span><br><span class="line">           shallowOffsetOfMaxTimestamp: <span class="type">Long</span>, </span><br><span class="line">           records: <span class="type">MemoryRecords</span>): <span class="type">Unit</span> = &#123; </span><br><span class="line">  <span class="keyword">if</span> (records.sizeInBytes &gt; <span class="number">0</span>) &#123; </span><br><span class="line">    trace(<span class="string">s&quot;Inserting <span class="subst">$&#123;records.sizeInBytes&#125;</span> bytes at end offset <span class="subst">$largestOffset</span> at position <span class="subst">$&#123;log.sizeInBytes&#125;</span> &quot;</span></span><br><span class="line">          + <span class="string">s&quot;with largest timestamp <span class="subst">$largestTimestamp</span> at shallow offset <span class="subst">$shallowOffsetOfMaxTimestamp</span>&quot;</span>) </span><br><span class="line">    <span class="keyword">val</span> physicalPosition = log.sizeInBytes() </span><br><span class="line">    <span class="keyword">if</span> (physicalPosition == <span class="number">0</span>) </span><br><span class="line">    rollingBasedTimestamp = <span class="type">Some</span>(largestTimestamp) ensureOffsetInRange(largestOffset) <span class="comment">// append the messages </span></span><br><span class="line">    <span class="keyword">val</span> appendedBytes = log.append(records) trace(<span class="string">s&quot;Appended <span class="subst">$appendedBytes</span> to <span class="subst">$&#123;log.file&#125;</span> at end offset <span class="subst">$largestOffset</span>&quot;</span>) <span class="comment">// Update the in memory max timestamp and corresponding offset. </span></span><br><span class="line">    <span class="keyword">if</span> (largestTimestamp &gt; maxTimestampSoFar) &#123; </span><br><span class="line">      maxTimestampSoFar = largestTimestamp </span><br><span class="line">      offsetOfMaxTimestampSoFar = shallowOffsetOfMaxTimestamp </span><br><span class="line">    &#125; <span class="comment">// append an entry to</span></span><br></pre></td></tr></table></figure><p><strong>第一步：</strong></p><p>在源码中，首先调用 <code>log.sizeInBytes</code> 方法判断该日志段是否为空，如果是空的话， Kafka 需要记录要写入消息集合的最大时间戳，并将其作为后面新增日志段倒计时的依据。</p><p><strong>第二步：</strong>代码调用 <code>ensureOffsetInRange</code> 方法确保输入参数最大位移值是合法的。</p><p>标准就是看它与日志段起始位移的差值是否在整数范围内，即 <code>largestOffset - baseOffset</code> 的值是不是介于 [0，Int.MAXVALUE] 之间。在极个别的情况下，这个差值可能会越界，这时，append 方法就会抛出异常，阻止后续的消息写入。</p><blockquote><p>一旦你碰到这个问题，你需要做的是升级你的 Kafka 版本，因为这是由已知的 Bug 导致的。</p></blockquote><p><strong>第三步：</strong></p><p>append 方法调用 FileRecords 的 append 方法执行真正的写入。</p><p><strong>第四步：</strong>更新日志段的最大时间戳以及最大时间戳所属消息的位移值属性。</p><p>每个日志段都要保存当前最大时间戳信息和所属消息的位移信息。还记得 Broker 端提供定期删除日志的功能吗？比如我只想保留最近 7 天的日志，没错，当前最大时间戳这个值就是判断的依据；而最大时间戳对应的消息的位移值则用于时间戳索引项。虽然后面我会详细介绍，这里我还是稍微提一下：时间戳索引项保存时间戳与消息位移的对应关系。在这步操作中，Kafka 会更新并保存这组对应关系。</p><p><strong>第五步：</strong>更新索引项和写入的字节数</p><p>日志段默认每写入 4KB 数据就要写入一个索引项。当已写入字节数超过了 4KB 之后，append 方法会调用索引对象的 append 方法新增索引项，同时清空已写入字节数，以备下次重新累积计算。</p><h2 id="2-3-read-方法"><a href="#2-3-read-方法" class="headerlink" title="2.3. read 方法"></a>2.3. read 方法</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(startOffset: <span class="type">Long</span>,</span><br><span class="line">           maxSize: <span class="type">Int</span>,</span><br><span class="line">           maxPosition: <span class="type">Long</span> = size,</span><br><span class="line">           minOneMessage: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">FetchDataInfo</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (maxSize &lt; <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s&quot;Invalid max size <span class="subst">$maxSize</span> for log read from segment <span class="subst">$log</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> startOffsetAndSize = translateOffset(startOffset)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// if the start position is already off the end of the log, return null</span></span><br><span class="line">    <span class="keyword">if</span> (startOffsetAndSize == <span class="literal">null</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">null</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> startPosition = startOffsetAndSize.position</span><br><span class="line">    <span class="keyword">val</span> offsetMetadata = <span class="type">LogOffsetMetadata</span>(startOffset, <span class="keyword">this</span>.baseOffset, startPosition)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> adjustedMaxSize =</span><br><span class="line">      <span class="keyword">if</span> (minOneMessage) math.max(maxSize, startOffsetAndSize.size)</span><br><span class="line">      <span class="keyword">else</span> maxSize</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// return a log segment but with zero size in the case below</span></span><br><span class="line">    <span class="keyword">if</span> (adjustedMaxSize == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="type">FetchDataInfo</span>(offsetMetadata, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// calculate the length of the message set to read based on whether or not they gave us a maxOffset</span></span><br><span class="line">    <span class="keyword">val</span> fetchSize: <span class="type">Int</span> = min((maxPosition - startPosition).toInt, adjustedMaxSize)</span><br><span class="line">    </span><br><span class="line">    <span class="type">FetchDataInfo</span>(offsetMetadata, log.slice(startPosition, fetchSize),</span><br><span class="line">      firstEntryIncomplete = adjustedMaxSize &lt; startOffsetAndSize.size)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>read 方法接收 4 个输入参数。</p><ol><li>startOffset: 要读取的第一条消息的位移</li><li>maxSize: 能读取的最大字节数</li><li>maxPosition: 能读到的最大文件位置</li><li>minOneMessage: 是否允许在消息体过大时至少返回第一条消息。</li></ol><h3 id="2-4-recover-方法"><a href="#2-4-recover-方法" class="headerlink" title="2.4. recover 方法"></a>2.4. recover 方法</h3><p>recover 方法，用于恢复日志段。</p><p>recover 方法，用于恢复日志段。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/02/23/binlog%E8%A7%A3%E6%9E%90maxwell/"/>
      <url>2021/02/23/binlog%E8%A7%A3%E6%9E%90maxwell/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Maxwell 是一个能实时读取 MySQL 二进制日志 binlog，并生成 JSON 格式的消息，作为生产者发送给 Kafka，Kinesis、RabbitMQ、Redis、Google Cloud Pub/Sub、文件或其它平台的应用程序。它的常见应用场景有ETL、维护缓存、收集表级别的dml指标、增量到搜索引擎、数据分区迁移、切库binlog回滚方案等。</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Maxwell 是一个读取 MySQL binlogs 并将修改字段的更新写入 Kafka, Kinesis, RabbitMQ, Google Cloud Pub/Sub 或 Redis (Pub/Sub or LPUSH) 以作为 JSON 的应用程序。</p><p>Maxwell 拥有可对底层进行操作的操作栏(operational bar)，可生成一致、易于获取的更新流，可以轻松“固定”流处理系统的一些优点，而无需通过整个代码库来添加（不可靠）检测点。 </p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/02/20/%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93&amp;%E8%A1%A8/"/>
      <url>2021/02/20/%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93&amp;%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 下午6.35.06.png" alt="截屏2021-02-20 下午6.35.06" style="zoom:50%;" /><h4 id="创建表的时候显式申明存储引擎"><a href="#创建表的时候显式申明存储引擎" class="headerlink" title="创建表的时候显式申明存储引擎"></a>创建表的时候显式申明存储引擎</h4><h4 id="创建表的时候显式申明字符集"><a href="#创建表的时候显式申明字符集" class="headerlink" title="创建表的时候显式申明字符集"></a>创建表的时候显式申明字符集</h4><h4 id="创建表的时候不添加-drop-操作"><a href="#创建表的时候不添加-drop-操作" class="headerlink" title="创建表的时候不添加 drop 操作"></a>创建表的时候不添加 drop 操作</h4><p><code>DROP TABLE IF EXISTS TABLE XXXX</code>; 然后再来个<code>CREATE  TABLE XXXX</code>，</p><p>修改为: <code>CREATE TABLE IF NOT EXISTS TABLE XXX; </code></p><h4 id="创建表的时候，字段尽量不要为-NULL"><a href="#创建表的时候，字段尽量不要为-NULL" class="headerlink" title="创建表的时候，字段尽量不要为 NULL"></a>创建表的时候，字段尽量不要为 NULL</h4><p>解决办法就是设置字段为NOT NULL，并设置字段的默认值。字段尽量不要为NULL的原因如下：</p><ol><li>NULL 需要占用额外的空间存储；</li><li>进行比较的时候会更复杂，还会导致 select (column) 不准确</li><li>含有 NULL 值的列，会对 SQL 优化产生影响，尤其是组合索引中</li></ol><p>具体 NULL 会带来的问题大家可以查阅：<a href="https://dev.mysql.com/doc/refman/5.7/en/problems-with-null.html">https://dev.mysql.com/doc/refman/5.7/en/problems-with-null.html</a></p><p>正确招式：NOT NULL DEFAULT ‘xxxxx’；</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/02/19/MySQL%E5%A4%87%E4%BB%BD/"/>
      <url>2021/02/19/MySQL%E5%A4%87%E4%BB%BD/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>生产环境中，为了防止硬件故障、软件故障、自然灾害、误操作等各种原因导致的数据库数据丢失后能恢复到事故之前的状态，需要对数据库进行备份和恢复操作。</p><a id="more"></a><h2 id="1-备份类型"><a href="#1-备份类型" class="headerlink" title="1. 备份类型"></a>1. 备份类型</h2><p>在运维中需定期备份 MySQL，为崩溃后的恢复数据做准备。一般分为冷备和热备，冷备就是停掉 MySQL 服务，直接复制文件，但是在生产环境中，很少有机会这样，一般都是在 MySQL 提供服务的时候就进行备份，因此这牵扯到数据一致性的问题。</p><ol><li><p>热备</p><blockquote><p>在数据库正常业务时,备份数据,并且能够一致性恢复(只能是 innodb)<br>对业务影响非常小<br>热备会备份开始前及备份过程中产生的新数据。</p></blockquote></li><li><p>温备</p><blockquote><p>锁表备份,只能查询不能修改(myisam)<br>影响到写入操作</p></blockquote></li><li><p>冷备</p><blockquote><p>关闭数据库业务,数据库没有任何变更的情况下,进行备份数据.<br>业务停止</p></blockquote></li></ol><h2 id="2-备份方式和工具介绍"><a href="#2-备份方式和工具介绍" class="headerlink" title="2. 备份方式和工具介绍"></a>2. 备份方式和工具介绍</h2><h3 id="2-1-逻辑备份工具"><a href="#2-1-逻辑备份工具" class="headerlink" title="2.1. 逻辑备份工具"></a>2.1. 逻辑备份工具</h3><p>基于 SQL 语句进行备份</p><h4 id="2-1-1-mysqldump"><a href="#2-1-1-mysqldump" class="headerlink" title="2.1.1. mysqldump"></a>2.1.1. mysqldump</h4><p>mysql 服务自带的备份工具。mysqldump 是一个逻辑备份工具，它的本质是将数据库转为可执行 SQL 脚本。可以用来做完全备份和部分备份，支持 InnoDB 存储引擎的热备功能，MyISAM 存储引擎的温备功能。</p><p>mysqlbinlog  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">优点：</span><br><span class="line">1.不需要下载安装</span><br><span class="line">2.备份出来的是 SQL，文本格式，可读性高,便于备份处理</span><br><span class="line">3.压缩比较高，节省备份的磁盘空间</span><br><span class="line">缺点</span><br><span class="line">依赖于数据库引擎，需要从磁盘把数据读出然后转换成 SQL 进行转储，比较耗费资源，数据量大的话效率较低  </span><br></pre></td></tr></table></figure><h3 id="2-2-物理备份工具"><a href="#2-2-物理备份工具" class="headerlink" title="2.2. 物理备份工具"></a>2.2. 物理备份工具</h3><p>基于磁盘数据文件备份</p><h4 id="2-2-1-cp"><a href="#2-2-1-cp" class="headerlink" title="2.2.1. cp"></a>2.2.1. cp</h4><p>这是一种物理备份，这种备份的原理是基于快照实现的，快照（请求一个全局锁），之后立即释放锁，达到几乎热备的效果。需要注意的是不能仅仅只备份数据，要同时备份事务日志，并且要求数据和日志在同一逻辑卷。</p><h4 id="2-2-2-xtrabackup-XBK-percona-第三方"><a href="#2-2-2-xtrabackup-XBK-percona-第三方" class="headerlink" title="2.2.2. xtrabackup(XBK) percona 第三方"></a>2.2.2. xtrabackup(XBK) percona 第三方</h4><p>由 Percona 开发的很强大的开源工具，支持对 InnoDB 做热备，物理备份工具。 </p><h4 id="2-2-3-MySQL-Enterprise-Backup-MEB"><a href="#2-2-3-MySQL-Enterprise-Backup-MEB" class="headerlink" title="2.2.3. MySQL Enterprise Backup(MEB)"></a>2.2.3. MySQL Enterprise Backup(MEB)</h4><h4 id="2-2-4-总结"><a href="#2-2-4-总结" class="headerlink" title="2.2.4. 总结"></a>2.2.4. 总结</h4><p>优点</p><ul><li>类似于直接 cp 数据文件，不需要管逻辑结构，相对来说性能较高</li></ul><p>缺点：</p><ul><li>可读性差</li><li>压缩比低，需要更多磁盘空间</li></ul><h2 id="3-备份工具使用"><a href="#3-备份工具使用" class="headerlink" title="3. 备份工具使用"></a>3. 备份工具使用</h2><h3 id="3-1-mysqldump-逻辑备份的客户端工具"><a href="#3-1-mysqldump-逻辑备份的客户端工具" class="headerlink" title="3.1. mysqldump (逻辑备份的客户端工具)"></a>3.1. mysqldump (逻辑备份的客户端工具)</h3><h4 id="3-1-1-客户端通用参数"><a href="#3-1-1-客户端通用参数" class="headerlink" title="3.1.1 客户端通用参数"></a>3.1.1 客户端通用参数</h4><p>本地备份</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  mysqldump -uroot -pchen3494269 -S &#x2F;data&#x2F;tmp&#x2F;bak.sql</span><br></pre></td></tr></table></figure><p>远程备份</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  mysqldump -uroot -pchen3494269  -h 10.0.0.51 -P3306 -S &#x2F;data&#x2F;tmp&#x2F;bak.sql</span><br></pre></td></tr></table></figure><h4 id="3-1-2-备份专用基本参数"><a href="#3-1-2-备份专用基本参数" class="headerlink" title="3.1.2 备份专用基本参数"></a>3.1.2 备份专用基本参数</h4><h4 id="A-全备参数"><a href="#A-全备参数" class="headerlink" title="[-A 全备参数]"></a>[-A 全备参数]</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  mysqldump -uroot -pchen3494269 -A &gt; .&#x2F;backup&#x2F;full.sql</span><br></pre></td></tr></table></figure><ul><li><p>常规备份时要加 –set-gtid-purged=OFF,解决备份时的警告</p><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -uroot -p123 -A  --set-gtid-purged&#x3D;OFF  &gt;&#x2F;backup&#x2F;full.sql</span><br></pre></td></tr></table></figure></blockquote></li><li><p>构建主从时,做的备份,不需要加这个参数</p><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -uroot -p123 -A  --set-gtid-purged&#x3D;ON &gt;&#x2F;backup&#x2F;full.sql</span><br></pre></td></tr></table></figure></blockquote></li></ul><h4 id="B-db1-db2-db3-备份多个单库"><a href="#B-db1-db2-db3-备份多个单库" class="headerlink" title="[-B db1 db2 db3 备份多个单库]"></a>[-B db1 db2 db3 备份多个单库]</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">说明：生产中需要备份，生产相关的库和 MySQL 库</span><br><span class="line">➜  mysqldump -uroot -pchen3494269 -B attack siros &gt; .&#x2F;siros_attack.sql</span><br><span class="line">mysqldump: [Warning] Using a password on the command line interface can be insecure.</span><br><span class="line">mysqldump -uroot -pchen3494269 -B attack siros &gt; .&#x2F;siros_attack.sql  0.32s user 0.18s system 38% cpu 1.308 total</span><br></pre></td></tr></table></figure><h4 id="3-1-3-高级参数应用"><a href="#3-1-3-高级参数应用" class="headerlink" title="3.1.3 高级参数应用"></a>3.1.3 高级参数应用</h4><h4 id="特殊参数1使用（必须要加）"><a href="#特殊参数1使用（必须要加）" class="headerlink" title="特殊参数1使用（必须要加）"></a>特殊参数1使用（必须要加）</h4><ul><li><code>-R</code>            备份存储过程及函数</li><li><code>--triggers</code>    备份触发器</li><li><code>-E</code>            备份事件</li></ul><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -uroot -pchen3494269 siros satcat tle -R --triggers &gt; tle_satcat_of_siroswithtriggers.sql</span><br></pre></td></tr></table></figure><h4 id="F"><a href="#F" class="headerlink" title="-F"></a>-F</h4><p>在备份开始时,刷新一个新 binlog 日志</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -uroot -pchen3494269 siros satcat tle -F -R --triggers &gt; tle_satcat_of_siroswithtriggers2.sql</span><br></pre></td></tr></table></figure><h4 id="–master-data-2"><a href="#–master-data-2" class="headerlink" title="–master-data=2"></a>–master-data=2</h4><p>以注释的形式,保存备份开始时间点的 binlog 的状态信息(记录 position 开始号和 gtid 的所有号)<br>不论是何种引擎, 都会锁表，除非配合 <code>--single-transaction</code> 参数使用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜ mysqldump -uroot -pchen3494269 siros satcat tle -R --triggers --master-data&#x3D;2 --single-transaction &gt; tle_satcat_of_siroswithtrigger_masterdata.sql</span><br></pre></td></tr></table></figure><p>功能：</p><ol><li><p>在备份时，会自动记录，二进制日志文件名和位置号</p><ul><li><p>0: 默认值</p></li><li><p>1: 以 change master to 命令形式，可以用作主从复制</p></li><li><p>2: 以注释的形式记录，备份时刻的文件名 +postion 号</p></li></ul><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-19 下午9.21.58.png" alt="截屏2021-02-19 下午9.21.58" style="zoom:50%;" /></li><li><p>自动锁表</p><ul><li><p>不使用 <code>--single-transaction</code> 时，实现的是温备，何种引擎都会锁表。配合 <code>--single-transaction</code> 只对非 InnoDB 表进行锁表备份。</p></li><li><p>InnoDB 表进行 “热备”(实际上是实现快照备份), 非真正热备，只备份备份开始时刻数据， 备份过程中产生的新数据不会备份。</p></li><li><p>使用该参数后记录有备份开始时刻的 position,配合 mysqlbinlog 恢复数据时，需要找出备份开始到数据库异常时刻的所有 binlog 信息，然后配合全备即可恢复所有</p></li></ul></li></ol><h2 id="4-备份策略"><a href="#4-备份策略" class="headerlink" title="4. 备份策略"></a>4. 备份策略</h2><p>备份策略一般都是[全量+差异+binlogs]或者[全量+增量+binlogs]。需要注意到的是，如果需要更完整的备份数据，还需要依靠binlogs（二进制日志）。binlogs是MySQL中最重要的日志之一，它记录了所有的 DDL和 DML (除了数据查询语句)语句，以事件形式记录。这里强烈建议在生产环境中，将数据与二进制日志分开存放并对二进制日志也做备份。</p><p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-19 下午9.27.49.png" alt="截屏2021-02-19 下午9.27.49" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 上午8.50.29.png" alt="截屏2021-02-20 上午8.50.29" style="zoom:50%;" /></p><p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 上午8.56.25.png" alt="截屏2021-02-20 上午8.56.25" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 上午8.59.24.png" alt="截屏2021-02-20 上午8.59.24" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 上午9.07.51.png" alt="截屏2021-02-20 上午9.07.51" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 上午9.10.25.png" alt="截屏2021-02-20 上午9.10.25" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 上午9.20.39.png" alt="截屏2021-02-20 上午9.12.54" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 上午9.40.32.png" alt="截屏2021-02-20 上午9.40.32" style="zoom:50%;" /></p><ol start="3"><li></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/02/19/hello_binlog/"/>
      <url>2021/02/19/hello_binlog/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>MySQL 的二进制日志 binlog 可以说是 MySQL 最重要的日志，它记录了所有的 <code>DDL</code> 和 <code>DML</code> 语句（除了数据查询语句select、show等），<strong>以事件形式记录</strong>，还包含语句所执行的消耗的时间，MySQL的二进制日志是事务安全型的。binlog 的主要目的是<strong>复制和恢复</strong></p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h2><p>binlog 是记录所有数据库表结构变更(例如 CREATE、ALTER TABLE…)以及表数据修改(INSERT、UPDATE、DELETE…)的二进制日志。</p><p>binlog 不会记录 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改，可以通过查询通用日志来查看 MySQL执行过的所有语句。</p><p>二进制日志包括两类文件：</p><ul><li>二进制日志索引文件（文件名后缀为.index）用于记录所有的二进制文件，</li><li>二进制日志文件（文件名后缀为.00000*）记录数据库所有的 DDL 和 DML (除了数据查询语句)语句事件。</li></ul><h2 id="2-binlog-模式"><a href="#2-binlog-模式" class="headerlink" title="2. binlog 模式"></a>2. binlog 模式</h2><p>binlog模式分三种（row，statement，mixed）</p><ol><li>ROW 记录包括了是 EVENT TYPE，且是基于每行的,即执行一个 DML 操作，binlog 中记录的并不是具体的 sql，而是针对该语句的每一行或者多行记录各自生成记录，这样能有效避免主从下针对同一条sql而产生不同的结果这种方式无疑是最安全的，但是效率和空间上消耗是最大的。</li><li>STATAMENT 是基于sql执行语句的，相对于row占用的存储空间要少。用于数据同步的话还是要谨慎，需要保证主从机器之间的一致性（variables参数，Binlog日志格式参数，表引擎，数据，索引等等），如果不能保证，用于恢复数据的情景还是要慎用（可以参考下面<code>update where limit</code>语句的例子）</li><li>MIXED格式是自动判断并自动切换行和语句的策略，既然是自动，就不能保证完全符合每个业务场景，除非Server层面能做到绝对安全。</li></ol><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-19 下午2.44.45.png" alt="截屏2021-02-19 下午2.44.45" style="zoom:30%;" /><img src="/Users/joker/Desktop/截屏2021-02-04 上午11.35.48.png" alt="截屏2021-02-04 上午11.35.48" style="zoom:50%;" /><img src="/Users/joker/Desktop/截屏2021-02-19 下午2.54.13.png" alt="截屏2021-02-19 下午2.54.13" style="zoom:50%;" /><h2 id="3-binlog-文件解析"><a href="#3-binlog-文件解析" class="headerlink" title="3.binlog 文件解析"></a>3.binlog 文件解析</h2><h4 id="binlog-日志包括两类文件"><a href="#binlog-日志包括两类文件" class="headerlink" title="binlog 日志包括两类文件"></a>binlog 日志包括两类文件</h4><ol><li>二进制日志索引文件(文件名后缀为.index)用于记录所有有效的的二进制文件</li><li>二进制日志文件(文件名后缀为.00000*)记录数据库所有的 DDL 和 DML 语句事件</li></ol><h4 id="Events"><a href="#Events" class="headerlink" title="Events"></a>Events</h4><p>binlog 是一个二进制文件集合，每个 binlog 文件以一个4字节的魔数开头，接着是一组</p><ul><li><p>魔数：0xfe62696e 对应的是 0xfebin；</p></li><li><p>Event：每个 Event 包含 header 和 data 两个部分</p><p>header 提供了 Event 的创建时间，哪个服务器等信息，</p><p>data 部分提供的是针对该 Event 的具体信息，如具体数据的修改；</p></li><li><p>第一个 Event 用于描述 binlog 文件的格式版本，这个格式就是event写入binlog文件的格式；</p></li><li><p>其余的 Event 按照第一个 Event 的格式版本写入；</p></li><li><p>最后一个 Event 用于说明下一个binlog文件；</p></li><li><p>binlog 的索引文件是一个文本文件，其中内容为当前的 binlog 文件列表</p></li></ul><h4 id="binlog-文件序号递增"><a href="#binlog-文件序号递增" class="headerlink" title="binlog 文件序号递增"></a>binlog 文件序号递增</h4><p>当遇到以下3种情况时，MySQL 会重新生成一个新的日志文件，</p><ol><li>MySQL 服务器停止或重启时</li><li>使用 <code>flush logs</code> 命令；</li><li>当 binlog 文件大小超过 <code>max_binlog_size</code> 变量的值时；</li></ol><blockquote><p><code>max_binlog_size</code> 的最小值是4096字节，最大值和默认值是 1GB (1073741824字节)。事务被写入到binlog的一个块中，所以它不会在几个二进制日志之间被拆分。因此，如果你有很大的事务，为了保证事务的完整性，不可能做切换日志的动作，只能将该事务的日志都记录到当前日志文件中，直到事务结束，你可能会看到binlog文件大于 max_binlog_size 的情况。</p></blockquote><h2 id="4-binlog-常用命令"><a href="#4-binlog-常用命令" class="headerlink" title="4. binlog 常用命令"></a>4. binlog 常用命令</h2><h4 id="查看是否开启-binlog"><a href="#查看是否开启-binlog" class="headerlink" title="查看是否开启 binlog"></a>查看是否开启 binlog</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;log_bin&#39;;</span><br><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| log_bin       | ON    |</span><br><span class="line">+---------------+-------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><h4 id="查看-binlog-格式"><a href="#查看-binlog-格式" class="headerlink" title="查看 binlog 格式"></a>查看 binlog 格式</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;binlog_format&#39;;</span><br><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| binlog_format | ROW   |</span><br><span class="line">+---------------+-------+</span><br><span class="line">1 row in set (0.01 sec)</span><br></pre></td></tr></table></figure><h4 id="查看数据库-binlog-文件"><a href="#查看数据库-binlog-文件" class="headerlink" title="查看数据库 binlog 文件"></a>查看数据库 binlog 文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show binary logs;</span><br><span class="line">+---------------+-----------+-----------+</span><br><span class="line">| Log_name      | File_size | Encrypted |</span><br><span class="line">+---------------+-----------+-----------+</span><br><span class="line">| binlog.000065 |       156 | No        |</span><br><span class="line">| binlog.000066 |       179 | No        |</span><br><span class="line">| binlog.000067 |       179 | No        |</span><br><span class="line">| binlog.000068 |       179 | No        |</span><br><span class="line">| binlog.000069 |     61704 | No        |</span><br><span class="line">| binlog.000070 |       179 | No        |</span><br><span class="line">| binlog.000071 |       179 | No        |</span><br><span class="line">| binlog.000072 |       179 | No        |</span><br><span class="line">| binlog.000073 |       156 | No        |</span><br><span class="line">+---------------+-----------+-----------+</span><br><span class="line">9 rows in set (0.02 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure><h4 id="查看最新一个-binlog-日志文件名称和-Position"><a href="#查看最新一个-binlog-日志文件名称和-Position" class="headerlink" title="查看最新一个 binlog 日志文件名称和 Position"></a>查看最新一个 binlog 日志文件名称和 Position</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show master status;</span><br><span class="line">+---------------+----------+--------------+------------------+-------------------+</span><br><span class="line">| File          | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |</span><br><span class="line">+---------------+----------+--------------+------------------+-------------------+</span><br><span class="line">| binlog.000073 |      156 |              |                  |                   |</span><br><span class="line">+---------------+----------+--------------+------------------+-------------------+</span><br><span class="line">1 row in set (0.01 sec)</span><br></pre></td></tr></table></figure><h3 id="4-3-binlog-事件"><a href="#4-3-binlog-事件" class="headerlink" title="4.3. binlog 事件"></a>4.3. binlog 事件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show binlog events in &#39;binlog.000073&#39;;</span><br><span class="line">+---------------+-----+----------------+-----------+-------------+-------------------------------------+</span><br><span class="line">| Log_name      | Pos | Event_type     | Server_id | End_log_pos | Info                                  |</span><br><span class="line">+---------------+-----+----------------+-----------+-------------+-------------------------------------+</span><br><span class="line">| binlog.000073 |   4 | Format_desc    |         1 |         125 | Server ver: 8.0.21, Binlog ver: 4     |</span><br><span class="line">| binlog.000073 | 125 | Previous_gtids |         1 |         156 |                                       |</span><br><span class="line">| binlog.000073 | 156 | Anonymous_Gtid |         1 |         233 | SET @@SESSION.GTID_NEXT&#x3D; &#39;ANONYMOUS&#39;  |</span><br><span class="line">| binlog.000073 | 233 | Query          |         1 |         353 | create database test_bin &#x2F;* xid&#x3D;16 *&#x2F; |</span><br><span class="line">+---------------+-----+----------------+-----------+-------------+-------------------------------------+</span><br><span class="line">4 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-19 下午3.17.21.png" alt="截屏2021-02-19 下午3.17.21" style="zoom:50%;" /><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use test_bin;</span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; create table t1(id int);</span><br><span class="line">Query OK, 0 rows affected (0.07 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; insert into t1 values (1);</span><br><span class="line">Query OK, 1 row affected (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; commit;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show binlog events in &#39;binlog.000073&#39;;</span><br><span class="line">+---------------+-----+----------------+-----------+-------------+-------------------------------------+</span><br><span class="line">| Log_name      | Pos | Event_type     | Server_id | End_log_pos | Info                                                 |</span><br><span class="line">+---------------+-----+----------------+-----------+-------------+-------------------------------------+</span><br><span class="line">| binlog.000073 |   4 | Format_desc    |         1 |         125 | Server ver: 8.0.21, Binlog ver: 4                    |</span><br><span class="line">| binlog.000073 | 125 | Previous_gtids |         1 |         156 |                                                      |</span><br><span class="line">| binlog.000073 | 156 | Anonymous_Gtid |         1 |         233 | SET @@SESSION.GTID_NEXT&#x3D; &#39;ANONYMOUS&#39;                 |</span><br><span class="line">| binlog.000073 | 233 | Query          |         1 |         353 | create database test_bin &#x2F;* xid&#x3D;16 *&#x2F;                |</span><br><span class="line">| binlog.000073 | 353 | Anonymous_Gtid |         1 |         430 | SET @@SESSION.GTID_NEXT&#x3D; &#39;ANONYMOUS&#39;                 |</span><br><span class="line">| binlog.000073 | 430 | Query          |         1 |         549 | use &#96;test_bin&#96;; create table t1(id int) &#x2F;* xid&#x3D;25 *&#x2F; |</span><br><span class="line">| binlog.000073 | 549 | Anonymous_Gtid |         1 |         628 | SET @@SESSION.GTID_NEXT&#x3D; &#39;ANONYMOUS&#39;                 |</span><br><span class="line">| binlog.000073 | 628 | Query          |         1 |         707 | BEGIN                                                |</span><br><span class="line">| binlog.000073 | 707 | Table_map      |         1 |         759 | table_id: 88 (test_bin.t1)                           |</span><br><span class="line">| binlog.000073 | 759 | Write_rows     |         1 |         799 | table_id: 88 flags: STMT_END_F                       |</span><br><span class="line">| binlog.000073 | 799 | Xid            |         1 |         830 | COMMIT &#x2F;* xid&#x3D;26 *&#x2F;                                  |</span><br><span class="line">+---------------+-----+----------------+-----------+-------------+-------------------------------------+</span><br><span class="line">11 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  mysql-8.0.21-macos10.15-x86_64 mysqlbinlog --base64-output=decode-rows -vv ./data/binlog.000073</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">➜  mysql-8.0.21-macos10.15-x86_64 mysqlbinlog -d test_bin --base64-output&#x3D;decode-rows -vv .&#x2F;data&#x2F;binlog.000073</span><br></pre></td></tr></table></figure><h2 id="5-mysqlbinlog"><a href="#5-mysqlbinlog" class="headerlink" title="5. mysqlbinlog"></a>5. mysqlbinlog</h2><h2 id="日志截取"><a href="#日志截取" class="headerlink" title="日志截取"></a>日志截取</h2><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">➜  mysql-8.0.21-macos10.15-x86_64 mysqlbinlog --start-position=759 --stop-position=799 --base64-output=decode-rows -vv ./data/binlog.000073</span><br><span class="line">/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;</span><br><span class="line">/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;</span><br><span class="line">DELIMITER /*!*/;</span><br><span class="line"></span><br><span class="line"><span class="comment"># at 156</span></span><br><span class="line"><span class="comment">#210212 14:18:35 server id 1  end_log_pos 125 CRC32 0x78458f7f Start: binlog v 4, server v 8.0.21 created 210212 14:18:35 at startup</span></span><br><span class="line"><span class="comment"># Warning: this binlog is either in use or was not closed properly.</span></span><br><span class="line">ROLLBACK/*!*/;</span><br><span class="line"><span class="comment"># at 759</span></span><br><span class="line"><span class="comment">#210219 15:19:40 server id 1  end_log_pos 799 CRC32 0x306febe1 Write_rows: table id 88 flags: STMT_END_F</span></span><br><span class="line"><span class="comment">### Row event for unknown table #88SET @@SESSION.GTID_NEXT= &#x27;AUTOMATIC&#x27; /* added by mysqlbinlog */ /*!*/;</span></span><br><span class="line">DELIMITER ;</span><br><span class="line"><span class="comment"># End of log file</span></span><br><span class="line">/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;</span><br><span class="line">/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;</span><br></pre></td></tr></table></figure><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-19 下午3.48.15.png" alt="截屏2021-02-19 下午3.48.15" style="zoom:50%;" /><img src="/Users/joker/Desktop/截屏2021-02-19 下午4.03.09.png" alt="截屏2021-02-19 下午4.03.09" style="zoom:50%;" /><img src="/Users/joker/Desktop/截屏2021-02-19 下午4.44.53.png" alt="截屏2021-02-19 下午4.44.53" style="zoom:50%;" /><p><img src="/Users/joker/Desktop/截屏2021-02-19 下午4.44.53.png" alt="截屏2021-02-19 下午4.44.53" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-19 下午5.01.51.png" alt="截屏2021-02-19 下午5.01.51" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-19 下午7.21.17.png" alt="截屏2021-02-19 下午7.21.17" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-19 下午5.08.04.png" alt="截屏2021-02-19 下午5.08.04" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-19 下午7.29.12.png" alt="截屏2021-02-19 下午7.29.12" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-19 下午7.42.13.png" alt="截屏2021-02-19 下午7.42.13" style="zoom:50%;" /></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/02/05/%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8D%E5%8A%A0%E9%94%81%E7%9A%84SQL/"/>
      <url>2021/02/05/%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8D%E5%8A%A0%E9%94%81%E7%9A%84SQL/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/01/12/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"/>
      <url>2021/01/12/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>日志段及其相关代码是 Kafka 服务器源码中最为重要的组件代码之一。你可能会非常关心，在 Kafka 中，消息是如何被保存和组织在一起的。毕竟，不管是学习任何消息引擎，弄明白消息建模方式都是首要的问题。因此，你非常有必要学习日志段这个重要的子模块的源码实现。除此之外，了解日志段也有很多实际意义，比如说，你一定对 Kafka 底层日志文件 00000000000000012345.log 的命名感到很好奇。学过日志段之后，我相信这个问题一定会迎刃而解的。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/01/06/Http1.1/"/>
      <url>2021/01/06/Http1.1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在：</p><ol><li><p><strong>长连接</strong></p><p>HTTP 1.0 规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个 TCP 连接，服务器完成请求处理后立即断开 TCP 连接，服务器不跟踪每个客户也不记录过去的请求。</p></li></ol><p>   HTTP1.1 增加了一个 Connection 字段，通过设置 Keep-Alive 可以保持 HTTP 连接不断开，避免了每次客户端与服务器请求都要重复建立释放建立 TCP 连接，提高了网络的利用率。如果客户端想关闭 HTTP 连接，可以在请求头中携带 Connection: false 来告知服务器关闭请求。</p><p>   HTTP 1.1 则支持永久连接, 并且默认使用永久连接. 在同一个 tcp 的连接中可以传送多个 HTTP 请求和响应. 多个请求和响应可以重叠，多个请求和响应可以同时进行. 更加多的请求头和响应头(比如HTTP1.0没有host的字段).</p><ol start="2"><li><p><strong>错误状态响应码</strong></p><p>在 HTTP1.1 中新增了24个错误状态响应码</p><ul><li><p>409（Conflict）表示请求的资源与资源的当前状态发生冲突</p></li><li><p>410（Gone）表示服务器上的某个资源被永久性的删除。</p></li><li><p>100 Continue 初始的请求已经接受，客户应当继续发送请求的其余部分</p></li><li><p>101 Switching Protocols 服务器将遵从客户的请求转换到另外一种协议</p></li></ul></li><li><p><strong>缓存处理</strong></p><p>在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP 1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。</p></li><li><p><strong>带宽优化及网络连接的使用</strong></p><p>HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。</p></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/01/06/Http2.0/"/>
      <url>2021/01/06/Http2.0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HTTP/2引入二进制数据帧和流的概念，其中帧对数据进行顺序标识，浏览器收到数据之后，就可以按照序列对数据进行合并，而不会出现合并后数据错乱的情况。同样是因为有了序列，服务器就可以并行的传输数据，这就是流所做的事情。</p><a id="more"></a><h2 id="新特性"><a href="#新特性" class="headerlink" title="新特性"></a>新特性</h2><p>HTTP2.0 的新特性大致如下：</p><h3 id="二进制分帧"><a href="#二进制分帧" class="headerlink" title="二进制分帧"></a><strong>二进制分帧</strong></h3><p>HTTP2.0 通过在应用层和传输层之间增加一个二进制分帧层，突破了 HTTP1.1 的性能限制、改进传输性能。</p><p><img src="/Users/zxc/Documents/big_data/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/Http2.0.assets/2.png" alt="2"></p><h3 id="头部压缩"><a href="#头部压缩" class="headerlink" title="头部压缩"></a><strong>头部压缩</strong></h3><p>在HTTP1.x中，头部元数据都是以纯文本的形式发送的，通常会给每个请求增加500~800字节的负荷。</p><p>比如说 cookie，默认情况下，浏览器会在每次请求的时候，把 cookie 附在 header 上面发送给服务器。（由于cookie比较大且每次都重复发送，一般不存储信息，只是用来做状态记录和身份认证）</p><p>HTTP2.0 使用 encoder 来减少需要传输的 header 大小，通讯双方各自 cache 一份 header fields表，既避免了重复 header 的传输，又减小了需要传输的大小。高效的压缩算法可以很大的压缩 header，减少发送包的数量从而降低延迟。</p><h3 id="多路复用（连接共享）"><a href="#多路复用（连接共享）" class="headerlink" title="多路复用（连接共享）"></a><strong>多路复用（连接共享）</strong></h3><p>所有的HTTP2.0通信都在一个TCP连接上完成，这个连接可以承载任意数量的双向数据流。</p><img src="/Users/zxc/Documents/big_data/计算机网络/Http2.0.assets/3.png" alt="3" style="zoom:80%;" /><p>每个数据流以消息的形式发送，而消息由一或多个帧组成。这些帧可以乱序发送，然后再根据每个帧头部的流标识符（stream id）重新组装。</p><p>举个例子，每个请求是一个数据流，数据流以消息的方式发送，而消息又分为多个帧，帧头部记录着stream id用来标识所属的数据流，不同属的帧可以在连接中随机混杂在一起。接收方可以根据stream id将帧再归属到各自不同的请求当中去。</p><p>另外，多路复用（连接共享）可能会导致关键请求被阻塞。HTTP2.0里每个数据流都可以设置优先级和依赖，优先级高的数据流会被服务器优先处理和返回给客户端，数据流还可以依赖其他的子数据流。</p><p>可见，HTTP2.0实现了真正的并行传输，它能够在一个TCP上进行任意数量HTTP请求。而这个强大的功能则是基于“二进制分帧”的特性。</p><h3 id="服务器推送"><a href="#服务器推送" class="headerlink" title="服务器推送"></a><strong>服务器推送</strong></h3><p>服务器除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，而无需客户端明确的请求。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/01/06/Http3.0/"/>
      <url>2021/01/06/Http3.0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HTTP/2引入二进制数据帧和流的概念，其中帧对数据进行顺序标识，浏览器收到数据之后，就可以按照序列对数据进行合并，而不会出现合并后数据错乱的情况。同样是因为有了序列，服务器就可以并行的传输数据，这就是流所做的事情。</p><a id="more"></a><h2 id="新特性"><a href="#新特性" class="headerlink" title="新特性"></a>新特性</h2><p>HTTP2.0 的新特性大致如下：</p><h3 id="二进制分帧"><a href="#二进制分帧" class="headerlink" title="二进制分帧"></a><strong>二进制分帧</strong></h3><p>HTTP2.0 通过在应用层和传输层之间增加一个二进制分帧层，突破了 HTTP1.1 的性能限制、改进传输性能。</p><p><img src="/Users/zxc/Documents/big_data/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/Http2.0.assets/2.png" alt="2"></p><h3 id="头部压缩"><a href="#头部压缩" class="headerlink" title="头部压缩"></a><strong>头部压缩</strong></h3><p>在HTTP1.x中，头部元数据都是以纯文本的形式发送的，通常会给每个请求增加500~800字节的负荷。</p><p>比如说 cookie，默认情况下，浏览器会在每次请求的时候，把 cookie 附在 header 上面发送给服务器。（由于cookie比较大且每次都重复发送，一般不存储信息，只是用来做状态记录和身份认证）</p><p>HTTP2.0 使用 encoder 来减少需要传输的 header 大小，通讯双方各自 cache 一份 header fields表，既避免了重复 header 的传输，又减小了需要传输的大小。高效的压缩算法可以很大的压缩 header，减少发送包的数量从而降低延迟。</p><h3 id="多路复用（连接共享）"><a href="#多路复用（连接共享）" class="headerlink" title="多路复用（连接共享）"></a><strong>多路复用（连接共享）</strong></h3><p>所有的HTTP2.0通信都在一个TCP连接上完成，这个连接可以承载任意数量的双向数据流。</p><img src="/Users/zxc/Documents/big_data/计算机网络/Http2.0.assets/3.png" alt="3" style="zoom:80%;" /><p>每个数据流以消息的形式发送，而消息由一或多个帧组成。这些帧可以乱序发送，然后再根据每个帧头部的流标识符（stream id）重新组装。</p><p>举个例子，每个请求是一个数据流，数据流以消息的方式发送，而消息又分为多个帧，帧头部记录着stream id用来标识所属的数据流，不同属的帧可以在连接中随机混杂在一起。接收方可以根据stream id将帧再归属到各自不同的请求当中去。</p><p>另外，多路复用（连接共享）可能会导致关键请求被阻塞。HTTP2.0里每个数据流都可以设置优先级和依赖，优先级高的数据流会被服务器优先处理和返回给客户端，数据流还可以依赖其他的子数据流。</p><p>可见，HTTP2.0实现了真正的并行传输，它能够在一个TCP上进行任意数量HTTP请求。而这个强大的功能则是基于“二进制分帧”的特性。</p><h3 id="服务器推送"><a href="#服务器推送" class="headerlink" title="服务器推送"></a><strong>服务器推送</strong></h3><p>服务器除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，而无需客户端明确的请求。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2021/01/06/Https/"/>
      <url>2021/01/06/Https/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HTTPS 是身披 SSL 外壳的 HTTP。HTTPS 是一种通过计算机网络进行安全通信的传输协议，经由 HTTP 进行通信，利用 SSL/TLS 建立全信道，加密数据包。HTTPS 使用的主要目的是提供对网站服务器的身份认证，同时保护交换数据的隐私与完整性。<br>TLS 使用<strong>非对称加密保护下的对称加密</strong>在保证了通信效率的同时防止窃听，使用证书体系防止信息篡改和身份冒认。</p><a id="more"></a><h2 id="1-为什么需要-HTTPS"><a href="#1-为什么需要-HTTPS" class="headerlink" title="1. 为什么需要 HTTPS"></a>1. 为什么需要 <code>HTTPS</code></h2><p>在 HTTP 协议中有可能存在信息窃取或身份伪装等安全问题。使用 HTTPS 通信机制可以有效地防止这些问题，接下来，我们先来了解下 HTTP 协议存在的哪些问题？</p><ol><li><p><strong><font color='blue'>通信使用明文，不加密，内容可能被窃听</font></strong></p><p>由于 HTTP 本身不具备加密的功能，所以也无法做到对通信整体进行加密。即，<strong>HTTP 报文使用明文（指未经过加密的报文）方式发送</strong>。</p><p>HTTP 明文协议的缺陷是导致<strong>数据泄露、数据篡改、流量劫持、钓鱼攻击</strong>等安全问题的重要原因。HTTP 协议无法加密数据，所有通信数据都在网络中明文“裸奔”。通过网络的嗅探设备及一些技术手段，就可还原HTTP报文内容。</p></li></ol><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-14 下午8.02.54.png" alt="截屏2021-05-14 下午8.02.54" style="zoom:50%;" /><ol start="2"><li><strong><font color='blue'>无法证明报文的完整性，所以可能遭篡改</font></strong></li></ol><p>所谓完整性是指<strong>信息的准确度</strong>。若无法证明其完整性，通常也就意味着无法判断信息是否准确。由于 HTTP 协议无法证明通信的报文完整性，因此，在请求或响应送出之后直到对方接收之前的这段时间内，即使请求或响应的内容遭到篡改，也没有办法获悉。<br>换句话说，<strong>没有任何办法确认，发出的请求/响应和接收到的请求/响应是前后相同的</strong>。</p><ol start="3"><li><strong><font color='blue'>不验证通信方的身份，因此有可能遭遇伪装</font></strong></li></ol><p><strong>HTTP 协议中的请求和响应不会对通信方进行确认</strong>。在 HTTP 协议通信时，由于不存在确认通信方的处理步骤，任何人都可以发起请求。另外，服务器只要接收到请求，不管对方是谁都会返回一个响应（但也仅限于发送端的IP地址和端口号没有被Web服务器设定限制访问的前提下）</p><p>HTTP协议无法验证通信方身份，任何人都可以伪造虚假服务器欺骗用户，实现“钓鱼欺诈”，用户无法察觉。</p><h2 id="2-HTTPS-如何解决-HTTP-上述问题"><a href="#2-HTTPS-如何解决-HTTP-上述问题" class="headerlink" title="2. HTTPS 如何解决 HTTP 上述问题?"></a>2. <code>HTTPS</code> 如何解决 <code>HTTP</code> 上述问题?</h2><p>HTTPS 并非是应用层的一种新协议。只是 HTTP 通信接口部分用 SSL 和 TLS 协议代替而已。</p><p>通常，HTTP 直接和 TCP 通信。当使用 SSL 时，则演变成先和 SSL 通信，再由 SSL 和 TCP 通信了。简言之，<strong>所谓 HTTPS，其实就是身披 SSL 协议这层外壳的 HTTP</strong>。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-14 下午8.04.50.png" alt="截屏2021-05-14 下午8.04.50" style="zoom:50%;" /><p>HTTPS 协议的主要功能基本都依赖于 TLS/SSL 协议，TLS/SSL 的功能实现主要依赖于三类基本算法：散列函数 、对称加密和非对称加密，<strong>其利用非对称加密实现身份认证和密钥协商，对称加密算法采用协商的密钥对数据加密，基于散列函数验证信息的完整性</strong>。</p><h3 id="2-1-解决内容可能被窃听的问题——加密"><a href="#2-1-解决内容可能被窃听的问题——加密" class="headerlink" title="2.1. 解决内容可能被窃听的问题——加密"></a>2.1. <font color='blue'>解决内容可能被窃听的问题——加密</font></h3><h4 id="2-1-1-对称加密"><a href="#2-1-1-对称加密" class="headerlink" title="2.1.1. 对称加密"></a>2.1.1. 对称加密</h4><p><strong>加密和解密时使用的密钥都是同样的密钥</strong>。只要保证了密钥的安全性，那么整个通信过程也就是具有了机密性</p><p>对称加密的加密方和解密方都使用同一个<code>密钥</code>，也就是说，加密方必须对原始数据进行加密，然后再把密钥交给解密方进行解密，然后才能解密数据，对称加密存在风险。</p><h4 id="2-1-2-非对称加密"><a href="#2-1-2-非对称加密" class="headerlink" title="2.1.2. 非对称加密"></a>2.1.2. 非对称加密</h4><h5 id="非对称加密-Asymmetrical-Encryption-也被称为-公钥加密，相对于对称加密来说，非对称加密是一种新的改良加密方式。密钥通过网络传输交换，它能够确保及时密钥被拦截，也不会暴露数据信息。非对称加密中有两个密钥，一个是公钥，一个是私钥，公钥进行加密，私钥进行解密。公开密钥可供任何人使用，私钥只有自己能够知道。"><a href="#非对称加密-Asymmetrical-Encryption-也被称为-公钥加密，相对于对称加密来说，非对称加密是一种新的改良加密方式。密钥通过网络传输交换，它能够确保及时密钥被拦截，也不会暴露数据信息。非对称加密中有两个密钥，一个是公钥，一个是私钥，公钥进行加密，私钥进行解密。公开密钥可供任何人使用，私钥只有自己能够知道。" class="headerlink" title="非对称加密(Asymmetrical Encryption) 也被称为 公钥加密，相对于对称加密来说，非对称加密是一种新的改良加密方式。密钥通过网络传输交换，它能够确保及时密钥被拦截，也不会暴露数据信息。非对称加密中有两个密钥，一个是公钥，一个是私钥，公钥进行加密，私钥进行解密。公开密钥可供任何人使用，私钥只有自己能够知道。"></a><strong>非对称加密(Asymmetrical Encryption)</strong> 也被称为 <strong>公钥加密</strong>，相对于对称加密来说，非对称加密是一种新的改良加密方式。密钥通过网络传输交换，它能够确保及时密钥被拦截，也不会暴露数据信息。非对称加密中有两个密钥，一个是公钥，一个是私钥，公钥进行加密，私钥进行解密。公开密钥可供任何人使用，私钥只有自己能够知道。</h5><p>使用公钥加密的文本只能使用私钥解密，同时，使用私钥加密的文本也可以使用公钥解密。公钥不需要具有安全性，因为公钥需要在网络间进行传输，非对称加密可以解决<code>密钥交换</code>的问题。网站保管私钥，在网上任意分发公钥，密文只能由私钥持有者才能解密。没有私钥，就无法破解密文。</p><h4 id="2-1-3-对称加密-非对称加密-HTTPS-采用这种方式"><a href="#2-1-3-对称加密-非对称加密-HTTPS-采用这种方式" class="headerlink" title="2.1.3. 对称加密+非对称加密 (HTTPS 采用这种方式)"></a>2.1.3. 对称加密+非对称加密 (HTTPS 采用这种方式)</h4><p>使用对称密钥的好处是解密的效率比较快，使用非对称密钥的好处是可以使得传输的内容不能被破解，因为就算你拦截到了数据，但是没有对应的私钥，也是不能破解内容的。就将对称加密与非对称加密结合起来,充分利用两者各自的优势，<strong>在交换密钥环节使用非对称加密方式，之后的建立通信交换报文阶段则使用对称加密方式</strong>。具体做法是：<strong>发送密文的一方使用对方的公钥进行加密处理“对称的密钥”，然后对方用自己的私钥解密拿到“对称的密钥”，这样可以确保交换的密钥是安全的前提下，使用对称加密方式进行通信</strong>。所以，HTTPS 采用对称加密和非对称加密两者并用的混合加密机制。</p>   <img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-14 下午8.21.31.png" alt="截屏2021-05-14 下午8.21.31" style="zoom:35%;" /><h3 id="2-2-解决报文的完整性——摘要算法"><a href="#2-2-解决报文的完整性——摘要算法" class="headerlink" title="2.2. 解决报文的完整性——摘要算法"></a>2.2. <font color='blue'>解决报文的完整性——摘要算法</font></h3><p>实现完整性的手段主要是 <code>摘要算法(Digest Algorithm)</code></p><p>摘要算法理解成一种特殊的压缩算法，它能够把任意长度的数据<code>压缩</code>成一种固定长度的字符串，这就好像是给数据加了一把锁</p><p>除了常用的 MD5 是加密算法外，<code>SHA-1(Secure Hash Algorithm 1)</code> 也是一种常用的加密算法，不过 SHA-1 也是不安全的加密算法，在 TLS 里面被禁止使用。目前 TLS 推荐使用的是 SHA-1 的后继者：<code>SHA-2</code>。</p><p>MD5 的全称是 <code>Message Digest Algorithm 5</code>，它是属于<code>密码哈希算法(cryptographic hash algorithm)</code>的一种，MD5 可用于从任意长度的字符串创建 128 位字符串值。尽管 MD5 存在不安全因素，但是仍然沿用至今。MD5 最常用于<code>验证文件</code>的完整性。但是，它还用于其他安全协议和应用程序中，例如 SSH、SSL 和 IPSec。一些应用程序通过向明文加盐值或多次应用哈希函数来增强 MD5 算法</p><p>SHA-2 的全称是<code>Secure Hash Algorithm 2</code> , SHA-2 系列包含六个哈希函数，其摘要(哈希值) 分别为 224、256、384 或 512 位: <strong>SHA-224, SHA-256, SHA-384, SHA-512</strong>。分别能够生成 28 字节、32 字节、48 字节、64 字节的摘要。</p><p>SHA-2 能够实现数据的完整性，哪怕在文件中改变一个标点符号，增加一个空格，生成的文件摘要也会完全不同，不过 SHA-2 是基于明文的加密方式，还是不够安全</p><p>安全性更高的加密方式是使用 <code>HMAC</code></p><p>MAC 的全称是 <code>message authentication code</code>，它通过 MAC 算法从消息和密钥生成，MAC 值允许验证者（也拥有秘密密钥）检测到消息内容的任何更改，从而保护了消息的数据完整性。</p><p>HMAC 是 MAC 更进一步的拓展，它是使用 MAC 值 + Hash 值的组合方式，HMAC 的计算中可以使用任何加密哈希函数，例如 SHA-256 等。</p><h3 id="2-3-解决通信方身份可能被伪装的问题——数字证书"><a href="#2-3-解决通信方身份可能被伪装的问题——数字证书" class="headerlink" title="2.3. 解决通信方身份可能被伪装的问题——数字证书"></a>2.3. <font color='blue'>解决通信方身份可能被伪装的问题——数字证书</font></h3><p>私钥加密，公钥解密。使用私钥再加上摘要算法，就能够实现<code>数字签名</code>，从而实现认证。</p><p>CA 的全称是 <code>Certificate Authority</code>，证书认证机构，CA 颁布具有认证过的公钥，才能解决公钥的信任问题。</p><h4 id="2-3-1-数字证书认证机构的业务流程"><a href="#2-3-1-数字证书认证机构的业务流程" class="headerlink" title="2.3.1. 数字证书认证机构的业务流程"></a>2.3.1. <strong>数字证书认证机构的业务流程</strong></h4><ol><li><p>服务器的运营人员向第三方机构 CA 提交公钥、组织信息、个人信息(域名)等信息并申请认证</p></li><li><p>CA 通过线上、线下等多种手段验证申请者提供信息的真实性，如组织是否存在、企业是否合法，是否拥有域名的所有权等</p></li><li><p>如信息审核通过，CA 会向申请者签发认证文件-证书。</p><p>证书包含以下信息：申请者公钥、申请者的组织信息和个人信息、签发机构 CA 的信息、有效时间、证书序列号等信息的明文，同时包含一个签名。 </p><p>其中签名的产生算法：首先，使用散列函数计算公开的明文信息的信息摘要，然后，采用 CA 的私钥对信息摘要进行加密，密文即签名</p></li><li><p>客户端 Client 向服务器 Server 发出请求时，Server 返回证书文件;</p></li><li><p>客户端 Client 读取证书中的相关的明文信息，采用相同的散列函数计算得到信息摘要，然后，利用对应 CA 的公钥解密签名数据，对比证书的信息摘要，如果一致，则可以确认证书的合法性，即服务器的公开密钥是值得信赖的。</p></li><li><p>客户端还会验证证书相关的域名信息、有效时间等信息; 客户端会内置信任 CA 的证书信息(包含公钥)，如果CA 不被信任，则找不到对应 CA 的证书，证书也会被判定非法。</p></li></ol><h2 id="3-HTTPS-传输过程"><a href="#3-HTTPS-传输过程" class="headerlink" title="3. HTTPS 传输过程"></a><strong>3. HTTPS 传输过程</strong></h2><p><strong><font color='blue' size='4'>HTTPS 在传输的过程中会涉及到三个密钥</font></strong></p><ol><li>服务器端的公钥和私钥，用来进行非对称加密</li><li>客户端生成的随机密钥，用来进行对称加密</li></ol><p><strong>流程</strong></p><ol><li><p><strong>客户端浏览器发送信息到服务器，包括随机数 R1、支持的加密算法类型、协议版本、压缩算法等。注意该过程为明文</strong></p><ul><li><p>支持的协议版本，比如 <code>TLS 1.0</code> 版</p></li><li><p>一个客户端生成的随机数<code>R1</code>，稍后用于生成”对话密钥”</p></li><li><p>支持的加密方法，比如 <code>RSA</code> 公钥加密</p></li><li><p>支持的压缩方法</p></li></ul></li><li><p><strong>服务端返回信息，包括随机数R2、选定加密算法类型、协议版本以及服务器证书。注意该过程为明文。</strong></p><ul><li>确认使用的加密通信协议版本，比如 <code>TLS 1.0</code> 版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信</li><li>一个服务器生成的随机数，稍后用于生成”对话密钥” <code>R2</code></li><li>确认使用的加密方法，比如 <code>RSA</code> 公钥加密，此时带有公钥信息</li><li>服务器证书</li></ul></li><li><p>客户端收到服务器端的服务器证书之后，会对服务器证书进行检查，验证其合法性，该证书需要由第三方 <code>CA</code> 来签发，浏览器和操作系统会预置权威 <code>CA</code> 的根证书。如果证书被篡改作假[中间人攻击]，很容易通过 <code>CA</code> 的证书验证出来。如果发现发现公钥有问题，那么 <code>HTTPS</code> 传输就无法继续。严格的说，这里应该是验证服务器发送的数字证书的合法性。</p><ul><li><p>验证证书的合法性</p></li><li><p>如果证书受信任，一个随机数 <code>pre-master key</code>。该随机数用服务器公钥加密，防止被窃听。</p></li><li><p>使用约定好的 HASH 计算握手消息</p><ul><li>非对称加密算法：RSA，DSA/DSS，用于在握手过程中加密生成的密码。</li><li>对称加密算法：AES，RC4，3DES，用于对真正传输的数据进行加密。</li><li>HASH算法：MD5，SHA1，SHA256，验证数据的完整性。</li></ul></li><li><p>使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。</p></li></ul><p>如果证书没问题，则客户端用服务端证书中的公钥加密随机数 <code>R3</code>（又叫Pre-MasterSecret），发送给服务器。此时，只有客户端和服务器都拥有 <code>R1</code>、<code>R2</code> 和 <code>R3</code> 信息，基于随机数 <code>R1</code>、<code>R2</code> 和 <code>R3</code>，双方通过伪随机数函数来生成共同的对称会话密钥 <code>MasterSecret</code>。</p></li><li><p>网站接收浏览器发来的数据之后要做以下的操作</p><ul><li><p>使用自己的私钥将信息解密取出密码</p></li><li><p>使用密码解密浏览器发来的握手消息，并验证 HASH 是否与浏览器发来的一致。</p></li><li><p>使用密码加密一段握手消息，发送给浏览器</p></li></ul></li><li><p>浏览器解密并计算握手消息的 HASH，如果与服务端发来的 HASH一致，此时握手结束。</p></li><li><p>使用随机密码和对称加密算法对传输的数据加密，传输。</p></li></ol><p><strong><font color='blue' size='4'>客户端在接受到服务端发来的 SSL 证书时，会对证书的真伪进行校验，以浏览器为例说明如下</font></strong></p><ol><li>首先浏览器读取证书中的证书所有者、有效期等信息进行一一校验</li><li>浏览器开始查找操作系统中已内置的受信任的证书发布机构 CA，与服务器发来的证书中的颁发者CA比对，用于校验证书是否为合法机构颁发</li><li>如果找不到，浏览器就会报错，说明服务器发来的证书是不可信任的。</li><li>如果找到，那么浏览器就会从操作系统中取出 颁发者CA 的公钥，然后对服务器发来的证书里面的签名进行解密</li><li>浏览器使用相同的 hash 算法计算出服务器发来的证书的 hash 值，将这个计算的 hash 值与证书中签名做对比</li><li>对比结果一致，则证明服务器发来的证书合法，没有被冒充</li><li>此时浏览器就可以读取证书中的公钥，用于后续加密了</li></ol><h2 id="HTTP-与-HTTPS-的区别"><a href="#HTTP-与-HTTPS-的区别" class="headerlink" title="HTTP 与 HTTPS 的区别"></a><code>HTTP</code> 与 <code>HTTPS</code> 的区别</h2><ol><li>HTTP 是明文传输协议，HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。</li><li>https 协议需要到 CA 申请证书，一般免费证书较少，因而需要一定费用。</li><li>http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后者是 443。</li><li>http的连接很简单，是无状态的；HTTPS 协议是由 SSL/TLS+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 http 协议安全。</li></ol><h2 id="如何优化-HTTPS-的速度"><a href="#如何优化-HTTPS-的速度" class="headerlink" title="如何优化 HTTPS 的速度"></a>如何优化 <code>HTTPS</code> 的速度</h2><ol><li><p><strong><font color='blue' size='4'>HSTS 重定向技术</font></strong></p><p>HSTS（HTTP Strict Transport Security）技术，启用HSTS后，将保证浏览器始终连接到网站的 HTTPS 加密版本。</p><ul><li><p>用户在浏览器里输入 HTTP 协议进行访问时，浏览器会自动将 HTTP 转换为 HTTPS 进行访问，确保用户访问安全；</p></li><li><p>省去301跳转的出现，缩短访问时间；</p></li><li><p>能阻止基于 SSL Strip 的中间人攻击，万一证书有错误，则显示错误，用户不能回避警告，从而能够更加有效安全的保障用户的访问。</p></li></ul></li><li><p><strong><font color='blue' size='4'>TLS 握手优化</font></strong></p></li></ol><ol start="3"><li><p><strong><font color='blue' size='4'>Session Identifier（会话标识符）复用</font></strong></p></li><li><p><strong><font color='blue' size='4'>开启OSCP Stapling，提高TLS握手效率</font></strong></p></li><li><p><strong><font color='blue' size='4'>完全前向加密PFS，保护用户数据，预防私钥泄漏</font></strong></p></li></ol><h2 id="HTTPS-涉及的计算环节"><a href="#HTTPS-涉及的计算环节" class="headerlink" title="HTTPS 涉及的计算环节"></a><strong>HTTPS</strong> 涉及的计算环节</h2><ol><li><strong>非对称密钥交换</strong>。比如 <code>RSA</code>, <code>Diffie-Hellman</code>, <code>ECDHE</code>.这类算法的主要作用就是根据客户端和服务端不对称的信息，经过高强度的密钥生成算法，生成对称密钥，用于加解密后续应用消息。</li><li><strong>对称加解密</strong>。服务端使用密钥 A 对响应内容进行加密，客户端使用相同的密钥A对加密内容进行解密，反之亦然。</li><li><strong>消息一致性验证</strong>。每一段加密的内容都会附加一个 MAC 消息，即消息认证码。简单地说就是对内容进行的安全哈希计算，接收方需要校验 MAC 码。</li><li><strong>证书签名校验</strong>。这个阶段主要发生在客户端校验服务端证书身份时，需要对证书签名进行校验，确保证书的真实性。</li></ol><h2 id="为何不所有的网站都使用-HTTPS-？"><a href="#为何不所有的网站都使用-HTTPS-？" class="headerlink" title="为何不所有的网站都使用 HTTPS ？"></a>为何不所有的网站都使用 <code>HTTPS</code> ？</h2><ol><li>Https 协议握手阶段比较费时，会使页面的加载时间延长。</li><li>Https 连接缓存不如 Http 高效，会增加数据开销，甚至已有的安全措施也会因此而受到影响；</li><li>SSL 证书通常需要绑定 IP，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗。</li><li>Https 协议的加密范围也比较有限。最关键的，SSL 证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>HDFS 擦除编码</title>
      <link href="2020/12/12/HDFS%E6%93%A6%E9%99%A4%E7%BC%96%E7%A0%81/"/>
      <url>2020/12/12/HDFS%E6%93%A6%E9%99%A4%E7%BC%96%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-目的"><a href="#1-目的" class="headerlink" title="1.目的"></a>1.目的</h1><p>复制很昂贵 HDFS 中的默认3x复制方案在存储空间和其他资源（例如，网络带宽）中具有200％的开销。但是，对于I/O活动相对较低的暖和冷数据集，在正常操作期间很少访问其他块副本，但仍会消耗与第一个副本相同的资源量。</p><p>因此，自然的改进是使用擦除编码（EC）代替复制，其提供相同级别的容错并且具有更少的存储空间。在典型的擦除编码（EC）设置中，存储开销不超过50％。EC文件的复制因子没有意义。它始终为1，无法通过-setrep命令进行更改。</p><p>在存储系统中，EC最值得注意的用途是廉价磁盘冗余阵列（RAID）。RAID通过条带化实现EC，条带化将逻辑顺序数据（例如文件）划分为更小的单元（例如位，字节或块），并将连续单元存储在不同的磁盘上。在本指南的其余部分中，这个条带分布单元称为条带化单元（或单元）。对于每个原始数据单元条带，计算并存储一定数量的奇偶校验单元 - 其过程称为编码。可以通过基于幸存数据和奇偶校验单元的解码计算来恢复任何条带化单元上的错误。</p><p>将EC与HDFS集成可以提高存储效率，同时仍然提供与传统的基于复制的HDFS部署类似的数据持久性。例如，具有6个块的3x复制文件将消耗6 * 3 = 18个磁盘空间块。但是使用EC（6数据，3奇偶校验）部署，它将只消耗9块磁盘空间。</p><h1 id="2-架构"><a href="#2-架构" class="headerlink" title="2.架构"></a>2.架构</h1><p>在 EC 的背景下，条带化具有几个关键优势。首先，它启用在线EC（以EC格式立即写入数据），避免转换阶段并立即节省存储空间。在线EC还通过并行利用多个磁盘轴来增强顺序I / O性能; 这在具有高端网络的集群中尤其可取。其次，它自然地将一个小文件分发到多个DataNode，并且无需将多个文件捆绑到一个编码组中。这极大地简化了文件操作，例如删除，配额报告和联合命名空间之间的迁移。</p><p>在典型的HDFS群集中，小文件占总存储消耗的3/4以上。为了更好地支持小文件，在第一阶段的工作中，HDFS支持使用条带化的EC。在未来，HDFS还将支持连续的EC布局。有关详细信息，请参阅设计文档和有关 <a href="https://issues.apache.org/jira/browse/HDFS-7285">HDFS-7285 的</a>讨论。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="群集和硬件配置"><a href="#群集和硬件配置" class="headerlink" title="群集和硬件配置"></a><strong>群集和硬件配置</strong></h3><p>擦除编码在 CPU 和网络方面对集群提出了额外的要求。</p><p>编码和解码工作在 HDFS 客户端和 DataNode 上消耗额外的 CPU。</p><p>擦除编码要求群集中的数据节点数与配置的 EC 条带宽度相同。对于 EC 策略 RS（6,3），这意味着至少9个DataNode。</p><p><strong><em>*</em>*擦除编码文件也分布在机架上，用于机架容错。这意味着在读取和写入条带文件时，大多数操作都是在机架外。因此，网络二分带宽非常重要。*\</strong>***</p><p><strong><em>*</em>*对于机架容错，拥有足够数量的机架也很重要，因此平均而言，每个机架保持的块数不超过EC奇偶校验块的数量。计算它的公式将是（数据块+奇偶校验块）/奇偶校验块，向上舍入。对于EC政策RS（6,3），这意味着最少3个机架（由（6 + 3）/ 3 = 3计算），理想情况下9个或更多来处理计划内和计划外中断。对于机架数量少于奇偶校验单元数量的群集，HDFS无法保持机架容错，但仍会尝试跨多个节点分布条带文件以保留节点级别的容错。因此，建议设置具有相似数量的DataNode的机架。*\</strong>***</p>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka：Kafka 副本管理器</title>
      <link href="2020/10/15/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka_%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8/"/>
      <url>2020/10/15/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka_%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>所谓的副本写入，是指向副本底层日志写入消息。在 ReplicaManager 类中，实现副本写入的方法叫 appendRecords。</p><a id="more"></a><h2 id="1-分区及副本管理"><a href="#1-分区及副本管理" class="headerlink" title="1. 分区及副本管理"></a>1. 分区及副本管理</h2><p>除了对副本进行读写之外，副本管理器还有一个重要的功能，就是管理副本和对应的分区。ReplicaManager 管理它们的方式，是通过字段 allPartitions 来实现的。</p><p>每个 ReplicaManager 实例都维护了所在 Broker 上保存的所有分区对象，而每个分区对象 Partition 下面又定义了一组副本对象 Replica。通过这样的层级关系，副本管理器实现了对于分区的直接管理和对副本对象的间接管理。应该这样说，ReplicaManager 通过直接操作分区对象来间接管理下属的副本对象。</p><h2 id="2-becomeLeaderOrFollower"><a href="#2-becomeLeaderOrFollower" class="headerlink" title="2. becomeLeaderOrFollower"></a>2. becomeLeaderOrFollower</h2><p>becomeLeaderOrFollower 方法具体处理 LeaderAndIsrRequest 请求，同时也是副becomeLeaderOrFollower 方法，就是具体处理 LeaderAndIsrRequest 请求的地方，同时也是副本管理器添加分区的地方。本管理器添加分区的地方。</p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka：Kafka副本管理模块_AbstractFetcherThread</title>
      <link href="2020/10/15/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka_%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97_AbstractFetcherThread/"/>
      <url>2020/10/15/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka_%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97_AbstractFetcherThread/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>副本机制是 Kafka 实现数据高可靠性的基础。同一个分区下的多个副本分散在不同的 Broker 机器上，它们保存相同的消息数据以实现高可靠性。对于分布式系统而言，一个必须要解决的问题，就是如何确保所有副本上的数据是一致的。</p><a id="more"></a><p>AbstractFetcherThread 类是副本获取线程 ReplicaFetcherThread 的抽象基类。它里面定义和实现了很多重要的字段和方法</p><h2 id="1-类定义及字段"><a href="#1-类定义及字段" class="headerlink" title="1.类定义及字段"></a>1.类定义及字段</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractFetcherThread</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  name: <span class="type">String</span>,  // 线程名称</span></span></span><br><span class="line"><span class="class"><span class="params">  clientId: <span class="type">String</span>,  // <span class="type">Client</span> <span class="type">Id</span>，用于日志输出</span></span></span><br><span class="line"><span class="class"><span class="params">  val sourceBroker: <span class="type">BrokerEndPoint</span>,  // 数据源 <span class="type">Broker</span> 地址, 是指此线程要从哪个 <span class="type">Broker</span> 上读取数据。</span></span></span><br><span class="line"><span class="class"><span class="params">  failedPartitions: <span class="type">FailedPartitions</span>,  // 处理过程中出现失败的分区</span></span></span><br><span class="line"><span class="class"><span class="params">  fetchBackOffMs: <span class="type">Int</span> = 0,  // 获取操作重试间隔</span></span></span><br><span class="line"><span class="class"><span class="params">  isInterruptible: <span class="type">Boolean</span> = true,  // 线程是否允许被中断</span></span></span><br><span class="line"><span class="class"><span class="params">  val brokerTopicStats: <span class="type">BrokerTopicStats</span></span>) <span class="title">//</span> <span class="title">Broker端主题监控指标</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">ShutdownableThread</span>(<span class="params">name, isInterruptible</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// 定义 FetchData 类型表示获取的消息数据</span></span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">FetchData</span> </span>= <span class="type">FetchResponse</span>.<span class="type">PartitionData</span>[<span class="type">Records</span>]</span><br><span class="line">  <span class="comment">// 定义 EpochData 类型表示 Leader Epoch 数据</span></span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">EpochData</span> </span>= <span class="type">OffsetsForLeaderEpochRequest</span>.<span class="type">PartitionData</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> partitionStates = <span class="keyword">new</span> <span class="type">PartitionStates</span>[<span class="type">PartitionFetchState</span>]</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="../images/kafka/截屏2021-05-10 上午10.31.46.png" alt="截屏2021-05-10 上午10.31.46" style="zoom:50%;" /><p>FetchData 定义里的 PartitionData 类型，是客户端 clients 工程中 FetchResponse 类定义的嵌套类。FetchResponse 类封装的是 FETCH 请求的 Response 对象，而里面的 PartitionData 类是一个 POJO 类，保存的是 Response 中单个分区数据拉取的各项数据，包括从该分区的 Leader 副本拉取回来的消息、该分区的高水位值和日志起始位移值等。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public static <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionData&lt;T</span> <span class="keyword">extends</span> <span class="title">BaseRecords&gt;</span> </span>&#123;</span><br><span class="line">    public <span class="keyword">final</span> <span class="type">Errors</span> error;           <span class="comment">// 错误码</span></span><br><span class="line">    public <span class="keyword">final</span> long highWatermark;     <span class="comment">// 高水位值</span></span><br><span class="line">    public <span class="keyword">final</span> long lastStableOffset;  <span class="comment">// 最新LSO值 </span></span><br><span class="line">    public <span class="keyword">final</span> long logStartOffset;    <span class="comment">// 最新Log Start Offset值</span></span><br><span class="line">    <span class="comment">// 期望的 Read Replica, 用于指定可对外提供读服务的 Follower 副本</span></span><br><span class="line">    <span class="comment">// KAFKA 2.4 之后支持部分 Follower 副本可以对外提供读服务</span></span><br><span class="line">    public <span class="keyword">final</span> <span class="type">Optional</span>&lt;<span class="type">Integer</span>&gt; preferredReadReplica;</span><br><span class="line">    <span class="comment">// 该分区对应的已终止事务列表</span></span><br><span class="line">    public <span class="keyword">final</span> <span class="type">List</span>&lt;<span class="type">AbortedTransaction</span>&gt; abortedTransactions;</span><br><span class="line">    <span class="comment">// 消息集合，最重要的字段！</span></span><br><span class="line">    public <span class="keyword">final</span> <span class="type">T</span> records;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>![截屏2021-05-10 上午10.47.49](../images/kafka/截屏2021-05-10 上午10.47.49.png)</p><h2 id="2-分区读取状态类"><a href="#2-分区读取状态类" class="headerlink" title="2.分区读取状态类"></a>2.分区读取状态类</h2><p>AbstractFetcherThread 类构造函数中，封装了一个名为 PartitionStates[PartitionFetchState]类型的字段,表征 <font color='blue'>分区读取状态</font>的，保存的是分区的<font color='green'>已读取位移值 </font>和 **<font color='green'>对应的副本状态</font>**。</p><p>分区读取状态有 3 个，</p><ol><li>可获取，表明副本获取线程当前能够读取数据。</li><li>截断中，表明分区副本正在执行截断操作(比如该副本刚刚成为 Follower 副本)。</li><li>被推迟，表明副本获取线程获取数据时出现错误，需要等待一段时间后重试。</li></ol><blockquote><p>这里的状态有两个，一个是分区读取状态，一个是副本读取状态。副本读取状态由 ReplicaState 接口表示，</p><p>如下所示：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sealed</span> <span class="class"><span class="keyword">trait</span> <span class="title">ReplicaState</span></span></span><br><span class="line"><span class="class"><span class="title">//</span> <span class="title">截断中</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">object</span> <span class="title">Truncating</span> <span class="keyword">extends</span> <span class="title">ReplicaState</span></span></span><br><span class="line"><span class="class"><span class="title">//</span> <span class="title">获取中</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">object</span> <span class="title">Fetching</span> <span class="keyword">extends</span> <span class="title">ReplicaState</span></span></span><br></pre></td></tr></table></figure><p>可见，副本读取状态有截断中和获取中两个：当副本执行截断操作时，副本状态被设置成 Truncating；当副本被读取时，副本状态被设置成 Fetching。</p></blockquote><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">PartitionFetchState</span>(<span class="params">fetchOffset: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  lag: <span class="type">Option</span>[<span class="type">Long</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">  currentLeaderEpoch: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  delay: <span class="type">Option</span>[<span class="type">DelayedItem</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">  state: <span class="type">ReplicaState</span></span>) </span>&#123;</span><br><span class="line">  <span class="comment">// 分区可获取的条件是副本处于Fetching且未被推迟执行</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isReadyForFetch</span></span>: <span class="type">Boolean</span> = state == <span class="type">Fetching</span> &amp;&amp; !isDelayed</span><br><span class="line">  <span class="comment">// 副本处于ISR的条件：没有lag</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isReplicaInSync</span></span>: <span class="type">Boolean</span> = lag.isDefined &amp;&amp; lag.get &lt;= <span class="number">0</span></span><br><span class="line">  <span class="comment">// 分区处于截断中状态的条件：副本处于Truncating状态且未被推迟执行</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isTruncating</span></span>: <span class="type">Boolean</span> = state == <span class="type">Truncating</span> &amp;&amp; !isDelayed</span><br><span class="line">  <span class="comment">// 分区被推迟获取数据的条件：存在未过期的延迟任务</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isDelayed</span></span>: <span class="type">Boolean</span> = </span><br><span class="line">    delay.exists(_.getDelay(<span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>) &gt; <span class="number">0</span>)</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-processPartitionData"><a href="#3-processPartitionData" class="headerlink" title="3. processPartitionData"></a>3. processPartitionData</h2><p>用于处理读取回来的消息集合。它是一个抽象方法，因此需要子类实现它的逻辑。具体到 Follower 副本而言， 是由 ReplicaFetcherThread 类实现的</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">processPartitionData</span></span>(</span><br><span class="line">  topicPartition: <span class="type">TopicPartition</span>,  <span class="comment">// 读取哪个分区的数据</span></span><br><span class="line">  fetchOffset: <span class="type">Long</span>,               <span class="comment">// 读取到的最新位移值</span></span><br><span class="line">  partitionData: <span class="type">FetchData</span>         <span class="comment">// 读取到的分区消息数据</span></span><br><span class="line">): <span class="type">Option</span>[<span class="type">LogAppendInfo</span>]           <span class="comment">// 写入已读取消息数据前的元数据</span></span><br></pre></td></tr></table></figure><h2 id="4-truncate"><a href="#4-truncate" class="headerlink" title="4. truncate"></a>4. truncate</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">truncate</span></span>(</span><br><span class="line">  topicPartition: <span class="type">TopicPartition</span>, <span class="comment">// 要对哪个分区下副本执行截断操作</span></span><br><span class="line">  truncationState: <span class="type">OffsetTruncationState</span>  <span class="comment">// Offset + 截断状态</span></span><br><span class="line">): <span class="type">Unit</span></span><br></pre></td></tr></table></figure><h2 id="5-buildFetch"><a href="#5-buildFetch" class="headerlink" title="5. buildFetch"></a>5. buildFetch</h2><p>buildFetch 的本质就是，为指定分区构建对应的 FetchRequest.Builder 对象，而该对象是构建 FetchRequest 的核心组件。Kafka 中任何类型的消息读取，都是通过给指定 Broker 发送 FetchRequest 请求来完成的。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">buildFetch</span></span>(</span><br><span class="line">  <span class="comment">// 一组要读取的分区列表</span></span><br><span class="line">  <span class="comment">// 分区是否可读取取决于PartitionFetchState中的状态</span></span><br><span class="line">  partitionMap: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionFetchState</span>]): </span><br><span class="line"><span class="comment">// 封装FetchRequest.Builder对象</span></span><br><span class="line"><span class="type">ResultWithPartitions</span>[<span class="type">Option</span>[<span class="type">ReplicaFetch</span>]]</span><br></pre></td></tr></table></figure><h2 id="6-doWork"><a href="#6-doWork" class="headerlink" title="6. doWork"></a>6. doWork</h2><p>doWork 方法是 AbstractFetcherThread 类的核心方法，是线程的主逻辑运行方法</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doWork</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  maybeTruncate()   <span class="comment">// 执行副本截断操作</span></span><br><span class="line">  maybeFetch()      <span class="comment">// 执行消息获取操作</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>AbstractFetcherThread 线程只要一直处于运行状态，就是会不断地重复这两个操作</p><p>分区的 Leader 可能会发生变化。每当有新 Leader 产生时，Follower 副本就必须主动执行截断操作，将自己的本地日志裁剪成与 Leader 一样的消息序列，甚至，Leader 副本本身也需要执行截断操作，将 LEO 调整到分区高水位处。</p><h3 id="maybeTruncate"><a href="#maybeTruncate" class="headerlink" title="maybeTruncate()"></a>maybeTruncate()</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeTruncate</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 将所有处于截断中状态的分区依据有无Leader Epoch值进行分组</span></span><br><span class="line">  <span class="keyword">val</span> (partitionsWithEpochs, partitionsWithoutEpochs) = fetchTruncatingPartitions()</span><br><span class="line">  <span class="comment">// 对于有Leader Epoch值的分区，将日志截断到Leader Epoch值对应的位移值处</span></span><br><span class="line">  <span class="keyword">if</span> (partitionsWithEpochs.nonEmpty) &#123;</span><br><span class="line">    truncateToEpochEndOffsets(partitionsWithEpochs)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 对于没有Leader Epoch值的分区，将日志截断到高水位值处</span></span><br><span class="line">  <span class="keyword">if</span> (partitionsWithoutEpochs.nonEmpty) &#123;</span><br><span class="line">    truncateToHighWatermark(partitionsWithoutEpochs)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><img src="../images/kafka/截屏2021-05-10 上午10.26.39.png" alt="截屏2021-05-10 上午10.26.39" style="zoom:50%;" />]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka：Kafka副本读写流程</title>
      <link href="2020/10/14/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka_%E5%89%AF%E6%9C%AC%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/"/>
      <url>2020/10/14/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka_%E5%89%AF%E6%9C%AC%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>所谓的副本写入</strong>，是指向副本底层日志写入消息。在 ReplicaManager 类中，实现副本写入的方法叫 appendRecords。</p><a id="more"></a><h2 id="1-副本写入场景"><a href="#1-副本写入场景" class="headerlink" title="1. 副本写入场景"></a>1. 副本写入场景</h2><ol><li>生产者向 Leader 副本写入消息</li><li>Follower 副本拉取消息后写入副本</li><li>消费者组写入组信息</li><li>事务管理器写入事务信息（包括事务标记、事务元数据等）</li></ol><p>除了第二个场景是直接调用 Partition 对象的方法实现之外，其他 3 个都是调用 appendRecords 来完成的。该方法将给定一组分区的消息写入到对应的 Leader 副本中，并且根据 PRODUCE 请求中 acks 设置的不同，有选择地等待其他副本写入完成。然后，调用指定的回调逻辑。</p><h2 id="2-appendRecords"><a href="#2-appendRecords" class="headerlink" title="2. appendRecords"></a>2. appendRecords</h2><h3 id="2-1-输入参数"><a href="#2-1-输入参数" class="headerlink" title="2.1. 输入参数"></a>2.1. 输入参数</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecords</span></span>(</span><br><span class="line">  timeout: <span class="type">Long</span>,  <span class="comment">// 请求处理超时时间</span></span><br><span class="line">  requiredAcks: <span class="type">Short</span>,  <span class="comment">// 请求acks设置</span></span><br><span class="line">  internalTopicsAllowed: <span class="type">Boolean</span>,  <span class="comment">// 是否允许写入内部主题</span></span><br><span class="line">  origin: <span class="type">AppendOrigin</span>,  <span class="comment">// 写入方来源</span></span><br><span class="line">  entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>], <span class="comment">// 待写入消息</span></span><br><span class="line">  <span class="comment">// 回调逻辑 </span></span><br><span class="line">  responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span><br><span class="line">  delayedProduceLock: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span>,</span><br><span class="line">  recordConversionStatsCallback: </span><br><span class="line">    <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">RecordConversionStats</span>] =&gt; <span class="type">Unit</span> = _ =&gt; ())</span><br><span class="line">  : <span class="type">Unit</span> = &#123;</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><p>timeout</p><p>请求处理超时时间。对于生产者来说，它就是 request.timeout.ms 参数值。</p></li><li><p>requiredAcks</p><p>是否需要等待其他副本写入。对于生产者而言，它就是 acks 参数的值。而在其他场景中，Kafka 默认使用 -1，表示等待其他副本全部写入成功再返回。</p></li><li><p>internalTopicsAllowed</p><p>是否允许向内部主题写入消息。对于普通的生产者而言，该字段是 False，即不允许写入内部主题。对于 Coordinator 组件，特别是消费者组 GroupCoordinator 组件来说，它的职责之一就是向内部位移主题写入消息，因此，此时，该字段值是 True。</p></li><li><p>origin</p><p>AppendOrigin 是一个接口，表示写入方来源。当前，它定义了 3 类写入方，分别是 Replication、Coordinator 和 Client。</p><ul><li><p>Replication 表示写入请求是由 Follower 副本发出的，它要将从 Leader 副本获取到的消息写入到底层的消息日志中。</p></li><li><p>Coordinator 表示这些写入由 Coordinator 发起，它既可以是管理消费者组的 GroupCooridnator，也可以是管理事务的 TransactionCoordinator。</p></li></ul></li></ol><blockquote><p>注: Client 表示本次写入由客户端发起。Follower 副本同步过程不调用 appendRecords 方法，因此，这里的 origin 值只可能是 Replication 或 Coordinator。</p></blockquote><h3 id="2-2-方法体"><a href="#2-2-方法体" class="headerlink" title="2.2. 方法体"></a>2.2. 方法体</h3><p>isValidRequiredAcks(requiredAcks)</p><p>判断 requiredAcks 的取值是否在合理范围内，”是否是 -1、0、1 这 3 个数值中的一个”。如果不是合理取值，代码就进入到外层的 else 分支，构造名为 INVALID_REQUIRED_ACKS 的异常，并将其封装进回调函数中执行，然后返回结果。否则的话，代码进入到外层的 if 分支下。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> localProduceResults = appendToLocalLog(internalTopicsAllowed = internalTopicsAllowed,</span><br><span class="line">    origin, entriesPerPartition, requiredAcks)</span><br></pre></td></tr></table></figure><p>进入到 if 分支后，代码调用 appendToLocalLog 方法，将要写入的消息集合保存到副本的本地日志上。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> produceStatus = localProduceResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</span><br><span class="line">    topicPartition -&gt;</span><br><span class="line">            <span class="type">ProducePartitionStatus</span>(</span><br><span class="line">              result.info.lastOffset + <span class="number">1</span>, <span class="comment">// 设置下一条待写入消息的位移值</span></span><br><span class="line">              <span class="comment">// 构建PartitionResponse封装写入结果</span></span><br><span class="line">              <span class="keyword">new</span> <span class="type">PartitionResponse</span>(result.error, result.info.firstOffset.getOrElse(<span class="number">-1</span>), result.info.logAppendTime,</span><br><span class="line">                result.info.logStartOffset, result.info.recordErrors.asJava, result.info.errorMessage))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后构造 PartitionResponse 对象实例，来封装写入结果以及一些重要的元数据信息，比如本次写入有没有错误(errorMessage)、下一条待写入消息的位移值、本次写入消息集合首条消息的位移值</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 需要等待其他副本完成写入</span></span><br><span class="line"><span class="keyword">if</span> (delayedProduceRequestRequired(</span><br><span class="line">  requiredAcks, entriesPerPartition, localProduceResults)) &#123;</span><br><span class="line">  <span class="keyword">val</span> produceMetadata = <span class="type">ProduceMetadata</span>(requiredAcks, produceStatus)</span><br><span class="line">  <span class="comment">// 创建DelayedProduce延时请求对象</span></span><br><span class="line">  <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback, delayedProduceLock)</span><br><span class="line">  <span class="keyword">val</span> producerRequestKeys = entriesPerPartition.keys.map(<span class="type">TopicPartitionOperationKey</span>(_)).toSeq</span><br><span class="line">  <span class="comment">// 再一次尝试完成该延时请求</span></span><br><span class="line">  <span class="comment">// 如果暂时无法完成，则将对象放入到相应的Purgatory中等待后续处理</span></span><br><span class="line">  delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123; <span class="comment">// 无需等待其他副本写入完成，可以立即发送Response </span></span><br><span class="line">  <span class="keyword">val</span> produceResponseStatus = produceStatus.map &#123; <span class="keyword">case</span> (k, status) =&gt; k -&gt; status.responseStatus &#125;</span><br><span class="line">  <span class="comment">// 调用回调逻辑然后返回即可</span></span><br><span class="line">  responseCallback(produceResponseStatus)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果还需要等待其他副本同步完成消息写入，那么就不能立即返回，代码要创建 DelayedProduce 延时请求对象，并把该对象交由 Purgatory 来管理。DelayedProduce 是生产者端的延时发送请求，对应的 Purgatory 就是 ReplicaManager 类构造函数中的 delayedProducePurgatory。所谓的 Purgatory 管理，主要是调用 tryCompleteElseWatch 方法尝试完成延时发送请求。如果暂时无法完成，就将对象放入到相应的 Purgatory 中，等待后续处理。如果无需等待其他副本同步完成消息写入，那么，appendRecords 方法会构造响应的 Response，并调用回调逻辑函数，至此，方法结束。</p><h2 id="3-appendToLocalLog"><a href="#3-appendToLocalLog" class="headerlink" title="3. appendToLocalLog"></a>3. appendToLocalLog</h2><p>实现消息写入</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取分区对象 </span></span><br><span class="line"><span class="keyword">val</span> partition = getPartitionOrException(topicPartition, expectLeader = <span class="literal">true</span>)</span><br><span class="line"><span class="comment">// 向该分区对象写入消息集合 </span></span><br><span class="line"><span class="keyword">val</span> info = partition.appendRecordsToLeader(records, origin, requiredAcks)</span><br></pre></td></tr></table></figure><h2 id="4-delayedProduceRequestRequired"><a href="#4-delayedProduceRequestRequired" class="headerlink" title="4. delayedProduceRequestRequired"></a>4. delayedProduceRequestRequired</h2><p>delayedProduceRequestRequired 方法的源码。它用于判断消息集合被写入到日志之后，是否需要等待其他副本也写入成功。</p><h2 id="5-副本读取-fetchMessages"><a href="#5-副本读取-fetchMessages" class="headerlink" title="5. 副本读取: fetchMessages"></a>5. 副本读取: fetchMessages</h2><p>在 ReplicaManager 类中，负责读取副本数据的方法是 fetchMessages。不论是 Java 消费者 API，还是 Follower 副本，它们拉取消息的主要途径都是向 Broker 发送 FETCH 请求，Broker 端接收到该请求后，调用 fetchMessages 方法从底层的 Leader 副本取出消息。</p><p>和 appendRecords 方法类似，fetchMessages 方法也可能会延时处理 FETCH 请求，因为 Broker 端必须要累积足够多的数据之后，才会返回 Response 给请求发送方。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetchMessages</span></span>(timeout: <span class="type">Long</span>,</span><br><span class="line">                  replicaId: <span class="type">Int</span>,</span><br><span class="line">                  fetchMinBytes: <span class="type">Int</span>,</span><br><span class="line">                  fetchMaxBytes: <span class="type">Int</span>,</span><br><span class="line">                  hardMaxBytesLimit: <span class="type">Boolean</span>,</span><br><span class="line">                  fetchInfos: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PartitionData</span>)],</span><br><span class="line">                  quota: <span class="type">ReplicaQuota</span>,</span><br><span class="line">                  responseCallback: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">FetchPartitionData</span>)] =&gt; <span class="type">Unit</span>,</span><br><span class="line">                  isolationLevel: <span class="type">IsolationLevel</span>,</span><br><span class="line">                  clientMetadata: <span class="type">Option</span>[<span class="type">ClientMetadata</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka：Kafka 副本简介</title>
      <link href="2020/10/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka_%E5%89%AF%E6%9C%AC/"/>
      <url>2020/10/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka_%E5%89%AF%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>所谓的副本写入</strong>，是指向副本底层日志写入消息。在 ReplicaManager 类中，实现副本写入的方法叫 appendRecords。</p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>副本(Replica)是分布式系统中常见的概念之一，指的是分布式系统对数据和提供的一种冗余方式。在常见的分布式系统<br>中，为了对外提供可用的服务，对数据和服务进行副本处理。</p><p>数据副本是指在不同的节点上持久化同一份数据，当某一点上存储的数据丢失时，可以从副本上读取该数据</p><p>服务副本，指多个节点提供同样的服务，每个节点都有能力接收来自外部的请求并进行相应的处理。<br>Kafka 从 0.8 版本开始为分区引入了多副本机制，通过增加副本数量来提升数据容灾能力。同时，Kafka 通过多副本机制实现故障自动转移，在 Kafka 集群中某个 broker 节点失效的情况下仍然保证服务可用。<br>副本是相对于分区而言的，即副本是特定分区的副本。</p><ol><li>一个分区中包含一个或多个副本，其中一个为 leader 副本，其余为 follower 副本，各个副本位于不同的 broker 节点中。只有 leader 副本对外提供服务，follower 副本只负责数据同步。</li><li>分区中的所有副本统称为 AR,而 ISR 是指与 leoder 副本保持同步状态的副本集合，当然leader副本本身也是这个集合中的一员。</li><li>LEO 标识每个分区中最后一条消息的下一个位置，分区的每个副本都有自己的 LEO,ISR 中最小的 LEO 即为 HW,俗称高水位，消费者只能拉取到 HW 之前的消息。</li><li>从生产者发出的一条消息首先会被写入分区的leader副本，不过还需要等待 ISR 集合中的所有 follower 副本都同步完之后才能被认为已经提交，之后才会更新分区的 HW,进而消费者可以消费到这条消息。</li></ol><h2 id="2-失效副本"><a href="#2-失效副本" class="headerlink" title="2. 失效副本"></a>2. 失效副本</h2><h2 id="1-副本写入场景"><a href="#1-副本写入场景" class="headerlink" title="1. 副本写入场景"></a>1. 副本写入场景</h2><ol><li>生产者向 Leader 副本写入消息</li><li>Follower 副本拉取消息后写入副本</li><li>消费者组写入组信息</li><li>事务管理器写入事务信息（包括事务标记、事务元数据等）</li></ol><p>除了第二个场景是直接调用 Partition 对象的方法实现之外，其他 3 个都是调用 appendRecords 来完成的。该方法将给定一组分区的消息写入到对应的 Leader 副本中，并且根据 PRODUCE 请求中 acks 设置的不同，有选择地等待其他副本写入完成。然后，调用指定的回调逻辑。</p><h2 id="2-appendRecords"><a href="#2-appendRecords" class="headerlink" title="2. appendRecords"></a>2. appendRecords</h2><h3 id="2-1-输入参数"><a href="#2-1-输入参数" class="headerlink" title="2.1. 输入参数"></a>2.1. 输入参数</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">appendRecords</span></span>(</span><br><span class="line">  timeout: <span class="type">Long</span>,  <span class="comment">// 请求处理超时时间</span></span><br><span class="line">  requiredAcks: <span class="type">Short</span>,  <span class="comment">// 请求acks设置</span></span><br><span class="line">  internalTopicsAllowed: <span class="type">Boolean</span>,  <span class="comment">// 是否允许写入内部主题</span></span><br><span class="line">  origin: <span class="type">AppendOrigin</span>,  <span class="comment">// 写入方来源</span></span><br><span class="line">  entriesPerPartition: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">MemoryRecords</span>], <span class="comment">// 待写入消息</span></span><br><span class="line">  <span class="comment">// 回调逻辑 </span></span><br><span class="line">  responseCallback: <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">PartitionResponse</span>] =&gt; <span class="type">Unit</span>,</span><br><span class="line">  delayedProduceLock: <span class="type">Option</span>[<span class="type">Lock</span>] = <span class="type">None</span>,</span><br><span class="line">  recordConversionStatsCallback: </span><br><span class="line">    <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">RecordConversionStats</span>] =&gt; <span class="type">Unit</span> = _ =&gt; ())</span><br><span class="line">  : <span class="type">Unit</span> = &#123;</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><p>timeout</p><p>请求处理超时时间。对于生产者来说，它就是 request.timeout.ms 参数值。</p></li><li><p>requiredAcks</p><p>是否需要等待其他副本写入。对于生产者而言，它就是 acks 参数的值。而在其他场景中，Kafka 默认使用 -1，表示等待其他副本全部写入成功再返回。</p></li><li><p>internalTopicsAllowed</p><p>是否允许向内部主题写入消息。对于普通的生产者而言，该字段是 False，即不允许写入内部主题。对于 Coordinator 组件，特别是消费者组 GroupCoordinator 组件来说，它的职责之一就是向内部位移主题写入消息，因此，此时，该字段值是 True。</p></li><li><p>origin</p><p>AppendOrigin 是一个接口，表示写入方来源。当前，它定义了 3 类写入方，分别是 Replication、Coordinator 和 Client。</p><ul><li><p>Replication 表示写入请求是由 Follower 副本发出的，它要将从 Leader 副本获取到的消息写入到底层的消息日志中。</p></li><li><p>Coordinator 表示这些写入由 Coordinator 发起，它既可以是管理消费者组的 GroupCooridnator，也可以是管理事务的 TransactionCoordinator。</p></li></ul></li></ol><blockquote><p>注: Client 表示本次写入由客户端发起。Follower 副本同步过程不调用 appendRecords 方法，因此，这里的 origin 值只可能是 Replication 或 Coordinator。</p></blockquote><h3 id="2-2-方法体"><a href="#2-2-方法体" class="headerlink" title="2.2. 方法体"></a>2.2. 方法体</h3><p>isValidRequiredAcks(requiredAcks)</p><p>判断 requiredAcks 的取值是否在合理范围内，”是否是 -1、0、1 这 3 个数值中的一个”。如果不是合理取值，代码就进入到外层的 else 分支，构造名为 INVALID_REQUIRED_ACKS 的异常，并将其封装进回调函数中执行，然后返回结果。否则的话，代码进入到外层的 if 分支下。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> localProduceResults = appendToLocalLog(internalTopicsAllowed = internalTopicsAllowed,</span><br><span class="line">    origin, entriesPerPartition, requiredAcks)</span><br></pre></td></tr></table></figure><p>进入到 if 分支后，代码调用 appendToLocalLog 方法，将要写入的消息集合保存到副本的本地日志上。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> produceStatus = localProduceResults.map &#123; <span class="keyword">case</span> (topicPartition, result) =&gt;</span><br><span class="line">    topicPartition -&gt;</span><br><span class="line">            <span class="type">ProducePartitionStatus</span>(</span><br><span class="line">              result.info.lastOffset + <span class="number">1</span>, <span class="comment">// 设置下一条待写入消息的位移值</span></span><br><span class="line">              <span class="comment">// 构建PartitionResponse封装写入结果</span></span><br><span class="line">              <span class="keyword">new</span> <span class="type">PartitionResponse</span>(result.error, result.info.firstOffset.getOrElse(<span class="number">-1</span>), result.info.logAppendTime,</span><br><span class="line">                result.info.logStartOffset, result.info.recordErrors.asJava, result.info.errorMessage))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后构造 PartitionResponse 对象实例，来封装写入结果以及一些重要的元数据信息，比如本次写入有没有错误(errorMessage)、下一条待写入消息的位移值、本次写入消息集合首条消息的位移值</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 需要等待其他副本完成写入</span></span><br><span class="line"><span class="keyword">if</span> (delayedProduceRequestRequired(</span><br><span class="line">  requiredAcks, entriesPerPartition, localProduceResults)) &#123;</span><br><span class="line">  <span class="keyword">val</span> produceMetadata = <span class="type">ProduceMetadata</span>(requiredAcks, produceStatus)</span><br><span class="line">  <span class="comment">// 创建DelayedProduce延时请求对象</span></span><br><span class="line">  <span class="keyword">val</span> delayedProduce = <span class="keyword">new</span> <span class="type">DelayedProduce</span>(timeout, produceMetadata, <span class="keyword">this</span>, responseCallback, delayedProduceLock)</span><br><span class="line">  <span class="keyword">val</span> producerRequestKeys = entriesPerPartition.keys.map(<span class="type">TopicPartitionOperationKey</span>(_)).toSeq</span><br><span class="line">  <span class="comment">// 再一次尝试完成该延时请求</span></span><br><span class="line">  <span class="comment">// 如果暂时无法完成，则将对象放入到相应的Purgatory中等待后续处理</span></span><br><span class="line">  delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123; <span class="comment">// 无需等待其他副本写入完成，可以立即发送Response </span></span><br><span class="line">  <span class="keyword">val</span> produceResponseStatus = produceStatus.map &#123; <span class="keyword">case</span> (k, status) =&gt; k -&gt; status.responseStatus &#125;</span><br><span class="line">  <span class="comment">// 调用回调逻辑然后返回即可</span></span><br><span class="line">  responseCallback(produceResponseStatus)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果还需要等待其他副本同步完成消息写入，那么就不能立即返回，代码要创建 DelayedProduce 延时请求对象，并把该对象交由 Purgatory 来管理。DelayedProduce 是生产者端的延时发送请求，对应的 Purgatory 就是 ReplicaManager 类构造函数中的 delayedProducePurgatory。所谓的 Purgatory 管理，主要是调用 tryCompleteElseWatch 方法尝试完成延时发送请求。如果暂时无法完成，就将对象放入到相应的 Purgatory 中，等待后续处理。如果无需等待其他副本同步完成消息写入，那么，appendRecords 方法会构造响应的 Response，并调用回调逻辑函数，至此，方法结束。</p><h2 id="3-appendToLocalLog"><a href="#3-appendToLocalLog" class="headerlink" title="3. appendToLocalLog"></a>3. appendToLocalLog</h2><p>实现消息写入</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取分区对象 </span></span><br><span class="line"><span class="keyword">val</span> partition = getPartitionOrException(topicPartition, expectLeader = <span class="literal">true</span>)</span><br><span class="line"><span class="comment">// 向该分区对象写入消息集合 </span></span><br><span class="line"><span class="keyword">val</span> info = partition.appendRecordsToLeader(records, origin, requiredAcks)</span><br></pre></td></tr></table></figure><h2 id="4-delayedProduceRequestRequired"><a href="#4-delayedProduceRequestRequired" class="headerlink" title="4. delayedProduceRequestRequired"></a>4. delayedProduceRequestRequired</h2><p>delayedProduceRequestRequired 方法的源码。它用于判断消息集合被写入到日志之后，是否需要等待其他副本也写入成功。</p><h2 id="5-副本读取-fetchMessages"><a href="#5-副本读取-fetchMessages" class="headerlink" title="5. 副本读取: fetchMessages"></a>5. 副本读取: fetchMessages</h2><p>在 ReplicaManager 类中，负责读取副本数据的方法是 fetchMessages。不论是 Java 消费者 API，还是 Follower 副本，它们拉取消息的主要途径都是向 Broker 发送 FETCH 请求，Broker 端接收到该请求后，调用 fetchMessages 方法从底层的 Leader 副本取出消息。</p><p>和 appendRecords 方法类似，fetchMessages 方法也可能会延时处理 FETCH 请求，因为 Broker 端必须要累积足够多的数据之后，才会返回 Response 给请求发送方。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetchMessages</span></span>(timeout: <span class="type">Long</span>,</span><br><span class="line">                  replicaId: <span class="type">Int</span>,</span><br><span class="line">                  fetchMinBytes: <span class="type">Int</span>,</span><br><span class="line">                  fetchMaxBytes: <span class="type">Int</span>,</span><br><span class="line">                  hardMaxBytesLimit: <span class="type">Boolean</span>,</span><br><span class="line">                  fetchInfos: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">PartitionData</span>)],</span><br><span class="line">                  quota: <span class="type">ReplicaQuota</span>,</span><br><span class="line">                  responseCallback: <span class="type">Seq</span>[(<span class="type">TopicPartition</span>, <span class="type">FetchPartitionData</span>)] =&gt; <span class="type">Unit</span>,</span><br><span class="line">                  isolationLevel: <span class="type">IsolationLevel</span>,</span><br><span class="line">                  clientMetadata: <span class="type">Option</span>[<span class="type">ClientMetadata</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka：为什么不支持读写分离？</title>
      <link href="2020/10/12/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%94%AF%E6%8C%81%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%EF%BC%9F/"/>
      <url>2020/10/12/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%94%AF%E6%8C%81%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与leader副本进行交互的，从而实现的是一种主写主读的生产消费模型</p><a id="more"></a><p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从而实现的是一种主写主读的生产消费模型。数据库、Redis等都具备主写主读的功能，与此同时还支持主写从读的功能，主写从读也就是读写分离。</p><p>主写从读可以让从节点去分担主节点的负载压力，预防主节点负载过重而从节点却空闲的情况发生。但主写从读也<br>有 2 个很明显的缺点</p><ol><li><p>数据一致性问题。</p><p>数据从主节点转到从节点有一个延时的时间窗口，这个时间窗口会导致主从节点之间的数据不一致。</p></li><li><p>延时问题。</p><p>类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历<code>[网络→主节点内存→网络→从节点内存]</code>这几个阶段，而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历 <code>[网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘]</code>这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</p></li></ol><p>主读从写可以均摊一定的负载却不能做到完全的负载均衡,对于数据写压力很大而读压力很小的情况，从节点只能分摊很少的<br>负载压力，而绝大多数压力还是在主节点上。而在 Kafka 中却可以达到很大程度上的负载均衡，而且这种均衡是在主写主读的架构上实现的</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-11 下午4.42.33.png" alt="截屏2021-03-11 下午4.42.33" style="zoom:50%;" /><p>在 Kafka 集群中有 3 个分区，每个分区有 3 个副本，正好均匀地分布在 3 个 broker 上，每个 broker 都有消息从生产者流入; 当消费者读取消息的叫候也是从 leader 副本中读取的，每个 broker 都有消息流出到消费者。每个 broker 上的读写负载都是一样的，这就说明 Kafka 可以通过主写主读实现负载均衡。</p><p>上图展示是一种理想的部署情况，有以下几种情况会造成一定程度上的负载不均衡</p><ol><li><p>broker 端的分区分配不均。</p><blockquote><p>当创建主题的时候可能会出现某些 broker 分配到的分区数多而其他 broker 分配到的分区少，分配到的 leader 副本也就不均。</p></blockquote></li><li><p>生产者写入消息不均。</p><blockquote><p>生产者可能只对某些 broker 中的 leader 副本进行大量的写入操作，而对其他 broker 中的 leader 副本不闻不问。</p></blockquote></li><li><p>消费者消费消息不均。</p><blockquote><p>消费者可能只对某些 broker 中的 leader 副本进行大量的拉取操作，而对其他 broker 中的leader 副本不闻不问。</p></blockquote></li><li><p>leader 副本的切换不均。</p><blockquote><p>在实际应用中可能会由于 broker 宕机而造成主从副本的切换，或者分区副本的重分配等，这些动作都有可能造成各个 broker 中 leader 副本的分配不均。</p></blockquote></li></ol><p>针对第一种情况，在主题创建的时候尽可能使分区分配得均衡，Kafka 中相应的分配算法也是地追求这一目标，如果是自定义的分配，则需要注意这方面的内容。对于第二和第三种情况，主写从读也无法解决。对于第四种情况，Kafka 提供了优先副本的选举来达到 leader 副本的均衡，与此同时，也可以配合相应的监控、告警和运维平台来实现均衡的优化。</p><p>Kafka 只支持主写主读有几个优点</p><ol><li>可以简化代码的实现逻辑，减少出错的可能</li><li>将负载粒度细化均摊，与主写从读相比，不仅负载效能更好，而且对用户可控</li><li>没有延时的影响</li><li>在副本稳定的情况下，不会出现数据不一致的情况</li></ol>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2020/06/30/Redis%20%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/"/>
      <url>2020/06/30/Redis%20%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Redis 支持的常用 5 种数据类型指的是 value 类型，分别为：<strong>字符串 String、列表 List、哈希Hash、集合 Set、有序集合 Zset</strong>，但是 Redis 后续又丰富了几种数据类型分别是 Bitmaps、HyperLogLogs、GEO。</p><a id="more"></a><p>由于 Redis 是基于标准C写的，只有最基础的数据类型，因此 Redis 为了满足对外使用的5种数据类型，开发了属于自己<strong>独有的一套基础数据结构</strong>，使用这些数据结构来实现5种数据类型。</p><p>Redis 底层的数据结构包括：<strong>简单动态数组SDS、链表、字典、跳跃链表、整数集合、压缩列表、对象。</strong></p><p>Redis 为了平衡空间和时间效率，针对 value 的具体类型在底层会采用不同的数据结构来实现，其中哈希表和压缩列表是复用比较多的数据结构，如下图展示了对外数据类型和底层数据结构之间的映射关系：</p><img src="/Users/joker/Documents/redis/images/1.png" alt="1" style="zoom:50%;" /><h3 id="Redis-的-SDS-和-C-中字符串相比有什么优势？"><a href="#Redis-的-SDS-和-C-中字符串相比有什么优势？" class="headerlink" title="Redis 的 SDS 和 C 中字符串相比有什么优势？"></a>Redis 的 SDS 和 C 中字符串相比有什么优势？</h3><p>SDS 本质分为三部分：<strong>header、buf、null 结尾符</strong>，其中 header 可以认为是整个 SDS 的指引部分，给定了使用的空间大小、最大分配大小等信息，</p><img src="/Users/zxc/Documents/hexo/source/_posts/Redis 常用数据结构及其实现.assets/屏幕快照 2020-04-04 上午9.48.07.png" alt="屏幕快照 2020-04-04 上午9.48.07" style="zoom:80%;" /><img src="/Users/zxc/Desktop/屏幕快照 2020-04-04 上午9.49.33.png" alt="屏幕快照 2020-04-04 上午9.49.33" style="zoom:80%;" /><ol><li><strong>O(1)获取长度</strong>: C字符串需要遍历而sds中有len可以直接获得；</li><li><strong>防止缓冲区溢出 bufferoverflow</strong>: 当sds需要对字符串进行修改时，首先借助于len和alloc检查空间是否满足修改所需的要求，如果空间不够的话，SDS会自动扩展空间，避免了像C字符串操作中的覆盖情况；</li><li><strong>有效降低内存分配次数</strong>: C字符串在涉及增加或者清除操作时会改变底层数组的大小造成重新分配、sds使用了空间预分配和惰性空间释放机制，说白了就是每次在扩展时是成倍的多分配的，在缩容是也是先留着并不正式归还给OS，这两个机制也是比较好理解的；</li><li><strong>二进制安全</strong>：C语言字符串只能保存ascii码，对于图片、音频等信息无法保存，sds是二进制安全的，写入什么读取就是什么，不做任何过滤和限制；</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2020/05/19/Redis%20%E7%BC%93%E5%86%B2%E8%AE%BE%E8%AE%A1/"/>
      <url>2020/05/19/Redis%20%E7%BC%93%E5%86%B2%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-缓存击穿"><a href="#1-缓存击穿" class="headerlink" title="1.缓存击穿"></a>1.缓存击穿</h1><p>缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="缓存中无值"><a href="#缓存中无值" class="headerlink" title="缓存中无值"></a>缓存中无值</h3><p>加锁获取缓存。也就是当获取的 value 值为空时（<code>这里的空表示缓存过期</code>），先加锁，然后从数据库加载并放入缓存，最后释放锁。如果其他线程获取锁失败，则睡眠一段时间后重试。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">String <span class="title">get</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">    String value = redis.get(key);  </span><br><span class="line">    <span class="keyword">if</span> (value  == <span class="keyword">null</span>) &#123;  </span><br><span class="line">        <span class="keyword">if</span> (redis.setnx(key_mutex, <span class="string">&quot;1&quot;</span>)) &#123;  </span><br><span class="line">            <span class="comment">// 3 min timeout to avoid mutex holder crash  </span></span><br><span class="line">            redis.expire(key_mutex, <span class="number">3</span> * <span class="number">60</span>)  </span><br><span class="line">            value = db.get(key);  </span><br><span class="line">            redis.set(key, value);  </span><br><span class="line">            redis.delete(key_mutex);  </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">            <span class="comment">//其他线程休息50毫秒后重试  </span></span><br><span class="line">            Thread.sleep(<span class="number">50</span>);</span><br><span class="line">            get(key);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="缓存不过期"><a href="#缓存不过期" class="headerlink" title="缓存不过期"></a>缓存不过期</h3><p>真正的缓存过期时间不有 Redis 控制，而是由程序代码控制。当获取数据时发现数据超时时，就需要发起一个异步请求去加载数据。这种策略的有点就是不会产生死锁等现象，但是有可能会造成缓存不一致的现象</p><h3 id="白名单"><a href="#白名单" class="headerlink" title="白名单"></a>白名单</h3><h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。</p><h1 id="2-缓存穿透"><a href="#2-缓存穿透" class="headerlink" title="2.缓存穿透"></a>2.缓存穿透</h1><p>缓存穿透访问了不存在的数据，跳过了合法数据的 redis 数据缓存阶段，每次访问数据库，对服务器造成压力。通常此类数据的出现量是一个较低的值，并及时报警。</p><a id="more"></a><h2 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h2><ol><li><p><strong>缓存 null</strong></p><p>对查询结果为 null 的数据进行缓存（长期使用，定期清理），设定短时限，例如30-60秒，最高5分钟</p></li><li><p><strong>白名单策略</strong></p></li><li><p><strong>实时监控 redis 命中率（业务正常范围时，通常会有一个波动值）与 null 数据的占比</strong></p><p>非活动时段波动：通常检测3-5倍，超过5倍纳入重点排查对象</p><p>活动时段波动：通常检测10-50倍，超过50倍纳入重点排查对象</p><p>根据倍数不同，启动不同的排查流程。然后使用黑名单进行防控（运营）</p></li><li><p><strong>key 加密</strong><br>问题出现后，临时启动防灾业务key,对key进行业务层传输加嘧服务，设定校验程序，过来的key校验<br>例如每天随机分配60个加密串，挑选2到3个，混淆到页面数据id中，发现访问key不满足规则，驳回数据访问P</p></li></ol><h1 id="3-缓存雪崩"><a href="#3-缓存雪崩" class="headerlink" title="3.缓存雪崩"></a>3.缓存雪崩</h1><p>缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至 down 机。和缓存击穿不同的是，    缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p><h2 id="3-1-解决方案"><a href="#3-1-解决方案" class="headerlink" title="3.1.解决方案"></a>3.1.解决方案</h2><ol><li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li><li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。</li><li>设置热点数据永远不过期。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2020/05/19/Redis%20%E5%8D%95%E7%BA%BF%E7%A8%8B%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/"/>
      <url>2020/05/19/Redis%20%E5%8D%95%E7%BA%BF%E7%A8%8B%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>本质上 Redis 并不是单纯的单线程服务模型，一些辅助工作比如持久化刷盘、惰性删除等任务是由 BIO 线程来完成的，这里说的单线程主要是说与客户端交互完成命令请求和回复的工作线程。</p><a id="more"></a><h3 id="单线程模式的考量"><a href="#单线程模式的考量" class="headerlink" title="单线程模式的考量"></a>单线程模式的考量</h3><ol><li><p><strong>CPU 并非瓶颈</strong></p><p>多线程模型主要是为了充分利用多核 CPU，让线程在 IO 阻塞时被挂起让出 CPU 使用权交给其他线程，充分提高 CPU 的使用率，但是这个场景在 Redis 并不明显，因为 CPU 并不是 Redis 的瓶颈，Redis 的绝大部分操作操作都是基于内存的，处理事件极快，因此使用多线程来切换线程提高 CPU 利用率的需求并不强烈</p></li><li><p><strong>内存才是瓶颈</strong></p><p>单个 Redis 实例对单核的利用已经很好了，但是Redis的瓶颈在于内存，设想64核的机器假如内存只有16GB，那么多线程Redis有什么用武之地？</p></li><li><p><strong>复杂的 Value 类型</strong></p><p>Redis 有丰富的数据结构，并不是简单的 Key-Value 型的 NoSQL，其中常用的 Hash、Zset、List 等结构在 value 很大时，CURD 的操作会很复杂，如果采用多线程模式在进行相同 key 操作时就需要加锁来进行同步，这样就可能造成死锁问题。</p><p>这时候你会问：将 key 做 hash 分配给相同的线程来处理就可以解决呀，确实是这样的，这样的话就需要在Redis 中增加 key 的 hash 处理以及多线程负载均衡的处理，从而 Redis 的实现就成为多线程模式了，好像确实也没有什么问题，但是Antirez并没有这么做，大神这么做肯定是有原因的，果不其然，我们见到了集群化的Redis；</p></li><li><p><strong>集群化扩展</strong></p><p>目前的机器都是多核的，但是内存一般 128GB/64GB 算是比较普遍了，但是 Redis 在使用内存60%以上稳定性就不如50%的性能了，因此在数据较大时，当 Redis 作为主存，就必须使用多台机器构建集群化的 Redis 数据库系统，这样以来 Redis 的单线程模式又被集群化的处理所扩展了；</p></li><li><p><strong>软件工程角度</strong></p><p>单线程无论从开发和维护都比多线程要容易非常多，并且也能提高服务的稳定性，无锁化处理让单线程的Redis 在开发和维护上都具备相当大的优势；</p></li></ol><h2 id="单线程-Redis-为什么那么快？"><a href="#单线程-Redis-为什么那么快？" class="headerlink" title="单线程 Redis 为什么那么快？"></a>单线程 Redis 为什么那么快？</h2><p>Redis 的大部分操作在内存上完成，再加上采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。</p><h3 id="多路复用机制"><a href="#多路复用机制" class="headerlink" title="多路复用机制"></a>多路复用机制</h3><h3 id="基于多路复用的高性能-I-O-模型"><a href="#基于多路复用的高性能-I-O-模型" class="headerlink" title="基于多路复用的高性能 I/O 模型"></a>基于多路复用的高性能 I/O 模型</h3><p>Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</p><p><img src="../images/hello.jpg" alt="hello"></p><p>如图就是基于多路复用的 Redis IO 模型。图中的多个 FD 就是刚才所说的多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。</p><p>为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。</p><p>select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。</p><h3 id="Redis-的文件事件和时间事件"><a href="#Redis-的文件事件和时间事件" class="headerlink" title="Redis 的文件事件和时间事件"></a>Redis 的文件事件和时间事件</h3><h2 id="从单线程处理网络请求到多线程处理"><a href="#从单线程处理网络请求到多线程处理" class="headerlink" title="从单线程处理网络请求到多线程处理"></a>从单线程处理网络请求到多线程处理</h2><p>在 Redis 6.0 中，非常受关注的第一个新特性就是多线程。采用多个 IO 线程来处理网络请求，提高网络请求处理的并行度但是，Redis 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。这是因为，Redis 处理请求时，网络处理经常是瓶颈，通过多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Topic 是如何删除的？</title>
      <link href="2020/05/16/Topic%E6%98%AF%E6%80%8E%E4%B9%88%E8%A2%AB%E5%88%A0%E9%99%A4%E7%9A%84%EF%BC%9F/"/>
      <url>2020/05/16/Topic%E6%98%AF%E6%80%8E%E4%B9%88%E8%A2%AB%E5%88%A0%E9%99%A4%E7%9A%84%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>Kafka 中有一些状态机和管理器具有相对独立的功能框架，不严重依赖使用方，TopicDeletionManager (主题删除管理器)、ReplicaStateMachine(副本状态机)和 PartitionStateMachine(分区状态机)。TopicDeletionManager 负责对指定 Kafka 主题执行删除操作，清除待删除主题在集群上的各类”痕迹”。无论是主题、分区，还是副本，它们在 Kafka 中的生命周期通常都有多个状态。</p><h2 id="2-TopicDeletionManager-结构"><a href="#2-TopicDeletionManager-结构" class="headerlink" title="2. TopicDeletionManager 结构"></a>2. TopicDeletionManager 结构</h2><p>TopicDeletionManager.scala 这个源文件，包括 3 个部分。</p><p>![截屏2021-05-10 上午11.45.15](/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-10 上午11.45.15.png)</p><h3 id="2-1-DeletionClient-接口"><a href="#2-1-DeletionClient-接口" class="headerlink" title="2.1. DeletionClient 接口"></a>2.1. DeletionClient 接口</h3><p>负责实现删除主题以及后续的动作，比如更新元数据等。这个接口里定义了 4 个方法。DeletionClient 接口定义的方法用于删除主题，并将删除主题这件事儿同步给其他 Broker。</p><ol><li>deleteTopic</li><li>deleteTopicDeletions</li><li>mutePartitionModifications</li><li>sendMetadataUpdate</li></ol><h3 id="2-2-ControllerDeletionClient-类"><a href="#2-2-ControllerDeletionClient-类" class="headerlink" title="2.2. ControllerDeletionClient 类"></a>2.2. ControllerDeletionClient 类</h3><p>目前，DeletionClient 这个接口只有一个实现类，即 ControllerDeletionClient</p><h4 id="2-2-1-构造函数"><a href="#2-2-1-构造函数" class="headerlink" title="2.2.1. 构造函数"></a>2.2.1. 构造函数</h4><ol><li>KafkaController: Controller 组件对象</li><li>KafkaZkClient: Kafka 与 ZooKeeper 交互的客户端对象</li></ol><h4 id="2-2-2-deleteTopic"><a href="#2-2-2-deleteTopic" class="headerlink" title="2.2.2. deleteTopic"></a>2.2.2. deleteTopic</h4><p>删除主题在 ZooKeeper 上的所有”痕迹”。调用 <code>KafkaZkClient</code> 的 3 个方法去删除 ZooKeeper 下 /brokers/topics/节点、/config/topics/节点和 /admin/delete_topics/节点。</p><h4 id="2-2-3-deleteTopicDeletions"><a href="#2-2-3-deleteTopicDeletions" class="headerlink" title="2.2.3. deleteTopicDeletions"></a>2.2.3. deleteTopicDeletions</h4><p>用于删除 ZooKeeper 下待删除主题的标记节点。调用 KafkaZkClient 的 deleteTopicDeletions 方法，批量删除一组主题在 /admin/delete_topics 下的子节点。</p><blockquote><p>deleteTopic 是删除主题，deleteTopicDeletions 是删除 /admin/delete_topics 下的对应子节点。</p></blockquote><blockquote><p>两个方法里都有一个 epochZkVersion 的字段，代表期望的 Controller Epoch 版本号。使用旧 Epoch 版本号执行这些方法，ZooKeeper 会拒绝，因为和它自己保存的版本号不匹配。如果一个 Controller 的 Epoch 值小于 ZooKeeper 中保存的，那么这个 Controller 很可能是已经过期的 Controller。这种 Controller 就被称为 Zombie Controller。epochZkVersion 字段的作用，就是隔离 Zombie Controller 发送的操作。</p></blockquote><h4 id="2-2-4-mutePartitionModifications"><a href="#2-2-4-mutePartitionModifications" class="headerlink" title="2.2.4. mutePartitionModifications"></a>2.2.4. mutePartitionModifications</h4><p>屏蔽主题分区数据变更监听器，具体实现原理其实就是取消 /brokers/topics/节点数据变更的监听。这样当该主题的分区数据发生变更后，由于对应的 ZooKeeper 监听器已经被取消了，因此不会触发 Controller 相应的处理逻辑。</p><h4 id="2-2-5-sendMetadataUpdate"><a href="#2-2-5-sendMetadataUpdate" class="headerlink" title="2.2.5. sendMetadataUpdate"></a>2.2.5. sendMetadataUpdate</h4><p>调用 KafkaController 的 sendUpdateMetadataRequest 方法，给集群所有 Broker 发送更新请求，告诉它们不要再为已删除主题的分区提供服务</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">sendMetadataUpdate</span></span>(partitions: <span class="type">Set</span>[<span class="type">TopicPartition</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 给集群所有Broker发送UpdateMetadataRequest</span></span><br><span class="line">  <span class="comment">// 通知它们给定partitions的状态变化</span></span><br><span class="line">  controller.sendUpdateMetadataRequest(</span><br><span class="line">    controller.controllerContext.liveOrShuttingDownBrokerIds.toSeq, partitions)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-TopicDeletionManager"><a href="#2-3-TopicDeletionManager" class="headerlink" title="2.3. TopicDeletionManager"></a>2.3. TopicDeletionManager</h3><p>主题删除管理器类，定义了若干个方法维护主题删除前后集群状态的正确性。比如，什么时候才能删除主题、什么时候主题不能被删除、主题删除过程中要规避哪些操作</p><h4 id="2-3-1-定义及初始化"><a href="#2-3-1-定义及初始化" class="headerlink" title="2.3.1. 定义及初始化"></a>2.3.1. 定义及初始化</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TopicDeletionManager</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  // <span class="type">KafkaConfig</span>类，保存<span class="type">Broker</span>端参数</span></span></span><br><span class="line"><span class="class"><span class="params">  config: <span class="type">KafkaConfig</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">  // 集群元数据</span></span></span><br><span class="line"><span class="class"><span class="params">  controllerContext: <span class="type">ControllerContext</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  // 副本状态机，用于设置副本状态</span></span></span><br><span class="line"><span class="class"><span class="params">  replicaStateMachine: <span class="type">ReplicaStateMachine</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  // 分区状态机，用于设置分区状态</span></span></span><br><span class="line"><span class="class"><span class="params">  partitionStateMachine: <span class="type">PartitionStateMachine</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  // <span class="type">DeletionClient</span>接口，实现主题删除</span></span></span><br><span class="line"><span class="class"><span class="params">  client: <span class="type">DeletionClient</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.logIdent = <span class="string">s&quot;[Topic Deletion Manager <span class="subst">$&#123;config.brokerId&#125;</span>] &quot;</span></span><br><span class="line">  <span class="comment">// 是否允许删除主题</span></span><br><span class="line">  <span class="keyword">val</span> isDeleteTopicEnabled: <span class="type">Boolean</span> = config.deleteTopicEnable</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-10 下午2.07.59.png" alt="截屏2021-05-10 下午2.07.59" style="zoom:50%;" /><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> topicDeletionManager = <span class="keyword">new</span> <span class="type">TopicDeletionManager</span>(config, controllerContext, replicaStateMachine,</span><br><span class="line">  partitionStateMachine, <span class="keyword">new</span> <span class="type">ControllerDeletionClient</span>(<span class="keyword">this</span>, zkClient))</span><br></pre></td></tr></table></figure><p>实例化一个 ControllerDeletionClient 对象，然后利用这个对象实例和 replicaStateMachine、partitionStateMachine，一起创建 TopicDeletionManager 实例。</p><h4 id="2-3-2-重要方法"><a href="#2-3-2-重要方法" class="headerlink" title="2.3.2. 重要方法"></a>2.3.2. 重要方法</h4><h4 id="resumeDeletions"><a href="#resumeDeletions" class="headerlink" title="resumeDeletions()"></a>resumeDeletions()</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">resumeDeletions</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 从元数据缓存中获取要删除的主题列表</span></span><br><span class="line">  <span class="keyword">val</span> topicsQueuedForDeletion = <span class="type">Set</span>.empty[<span class="type">String</span>] ++ controllerContext.topicsToBeDeleted</span><br><span class="line">  <span class="comment">// 待重试主题列表</span></span><br><span class="line">  <span class="keyword">val</span> topicsEligibleForRetry = mutable.<span class="type">Set</span>.empty[<span class="type">String</span>]</span><br><span class="line">  <span class="comment">// 待删除主题列表</span></span><br><span class="line">  <span class="keyword">val</span> topicsEligibleForDeletion = mutable.<span class="type">Set</span>.empty[<span class="type">String</span>]</span><br><span class="line">  <span class="keyword">if</span> (topicsQueuedForDeletion.nonEmpty)</span><br><span class="line">    info(<span class="string">s&quot;Handling deletion for topics <span class="subst">$&#123;topicsQueuedForDeletion.mkString(&quot;,&quot;)&#125;</span>&quot;</span>)</span><br><span class="line">  <span class="comment">// 遍历每个待删除主题</span></span><br><span class="line">  topicsQueuedForDeletion.foreach &#123; topic =&gt;</span><br><span class="line">    <span class="comment">// 如果该主题所有副本已经是ReplicaDeletionSuccessful状态</span></span><br><span class="line">    <span class="comment">// 即该主题已经被删除  </span></span><br><span class="line">    <span class="keyword">if</span> (controllerContext.areAllReplicasInState(topic, <span class="type">ReplicaDeletionSuccessful</span>)) &#123;</span><br><span class="line">      <span class="comment">// 调用completeDeleteTopic方法完成后续操作即可</span></span><br><span class="line">      completeDeleteTopic(topic)</span><br><span class="line">      info(<span class="string">s&quot;Deletion of topic <span class="subst">$topic</span> successfully completed&quot;</span>)</span><br><span class="line">     <span class="comment">// 如果主题删除尚未开始并且主题当前无法执行删除的话</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!controllerContext.isAnyReplicaInState(topic, <span class="type">ReplicaDeletionStarted</span>)) &#123;</span><br><span class="line">      <span class="keyword">if</span> (controllerContext.isAnyReplicaInState(topic, <span class="type">ReplicaDeletionIneligible</span>)) &#123;</span><br><span class="line">        <span class="comment">// 把该主题加到待重试主题列表中用于后续重试</span></span><br><span class="line">        topicsEligibleForRetry += topic</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果该主题能够被删除</span></span><br><span class="line">    <span class="keyword">if</span> (isTopicEligibleForDeletion(topic)) &#123;</span><br><span class="line">      info(<span class="string">s&quot;Deletion of topic <span class="subst">$topic</span> (re)started&quot;</span>)</span><br><span class="line">      topicsEligibleForDeletion += topic</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 重试待重试主题列表中的主题删除操作</span></span><br><span class="line">  <span class="keyword">if</span> (topicsEligibleForRetry.nonEmpty) &#123;</span><br><span class="line">    retryDeletionForIneligibleReplicas(topicsEligibleForRetry)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 调用onTopicDeletion方法，对待删除主题列表中的主题执行删除操作</span></span><br><span class="line">  <span class="keyword">if</span> (topicsEligibleForDeletion.nonEmpty) &#123;</span><br><span class="line">    onTopicDeletion(topicsEligibleForDeletion)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><p>resumeDeletions() 方法首先从元数据缓存中获取要删除的主题列表，之后定义了两个空的主题列表，分别保存待重试删除主题和待删除主题。</p></li><li><p>遍历每个要删除的主题，去看它所有副本的状态。</p><blockquote><p>如果副本状态都是 ReplicaDeletionSuccessful，就表明该主题已经被成功删除，此时，再调用 completeDeleteTopic 方法，完成后续的操作就可以了。对于那些删除操作尚未开始，并且暂时无法执行删除的主题，源码会把这类主题加到待重试主题列表中，用于后续重试；如果主题是能够被删除的，就将其加入到待删除列表中。</p></blockquote></li><li><p>用 retryDeletionForIneligibleReplicas 方法，来重试待重试主题列表中的主题删除操作。对于待删除主题列表中的主题则调用 onTopicDeletion 删除之。</p></li></ol><h4 id="completeDeleteTopic"><a href="#completeDeleteTopic" class="headerlink" title="completeDeleteTopic()"></a>completeDeleteTopic()</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">completeDeleteTopic</span></span>(topic: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 第1步：注销分区变更监听器，防止删除过程中因分区数据变更</span></span><br><span class="line">  <span class="comment">// 导致监听器被触发，引起状态不一致</span></span><br><span class="line">  client.mutePartitionModifications(topic)</span><br><span class="line">  <span class="comment">// 第2步：获取该主题下处于ReplicaDeletionSuccessful状态的所有副本对象，</span></span><br><span class="line">  <span class="comment">// 即所有已经被成功删除的副本对象</span></span><br><span class="line">  <span class="keyword">val</span> replicasForDeletedTopic = controllerContext.replicasInState(topic, <span class="type">ReplicaDeletionSuccessful</span>)</span><br><span class="line">  <span class="comment">// 第3步：利用副本状态机将这些副本对象转换成NonExistentReplica状态。</span></span><br><span class="line">  <span class="comment">// 等同于在状态机中删除这些副本</span></span><br><span class="line">  replicaStateMachine.handleStateChanges(</span><br><span class="line">    replicasForDeletedTopic.toSeq, <span class="type">NonExistentReplica</span>)</span><br><span class="line">  <span class="comment">// 第4步：更新元数据缓存中的待删除主题列表和已开始删除的主题列表</span></span><br><span class="line">  <span class="comment">// 因为主题已经成功删除了，没有必要出现在这两个列表中了</span></span><br><span class="line">  controllerContext.topicsToBeDeleted -= topic</span><br><span class="line">  controllerContext.topicsWithDeletionStarted -= topic</span><br><span class="line">  <span class="comment">// 第5步：移除ZooKeeper上关于该主题的一切“痕迹”</span></span><br><span class="line">  client.deleteTopic(topic, controllerContext.epochZkVersion)</span><br><span class="line">  <span class="comment">// 第6步：移除元数据缓存中关于该主题的一切“痕迹”</span></span><br><span class="line">  controllerContext.removeTopic(topic)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka：日志结构概览</title>
      <link href="2020/03/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97(1)/"/>
      <url>2020/03/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>日志是 Kafka 服务器端代码的重要组件之一，很多其他的核心组件都是以日志为基础的</p><p>kafka 分区的每个副本对应到一个 Log 对象，每个 Log 有划分为多个 LogSegment，每个 LogSegment 包括一个日志文件和两个索引文件，其中两个索引文件分别是偏移量索引文件和时间戳索引文件。</p><a id="more"></a><h2 id="1-Kafka-日志结构概览"><a href="#1-Kafka-日志结构概览" class="headerlink" title="1. Kafka 日志结构概览"></a>1. Kafka 日志结构概览</h2><p>Kafka 日志对象由多个日志段对象组成，而每个日志段对象会在磁盘上创建一组文件，包括消息日志文件（.log）、位移索引文件（.index）、时间戳索引文件（.timeindex）以及已中止（Aborted）事务的索引文件（.txnindex）。当然，如果你没有使用 Kafka 事务，已中止事务的索引文件是不会被创建出来的。图中的一串数字 0 是该日志段的起始位移值（Base Offset），也就是该日志段中所存的第一条消息的位移值。一般情况下，一个 Kafka 主题有很多分区，每个分区就对应一个 Log 对象，在物理磁盘上则对应于一个子目录。比如你创建了一个双分区的主题 test-topic，那么，Kafka 在磁盘上会创建两个子目录：test-topic-0 和 test-topic-1。而在服务器端，这就是两个 Log 对象。每个子目录下存在多组日志段，也就是多组.log、.index、.timeindex 文件组合，只不过文件名不同，因为每个日志段的起始位移不同。</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@chen-bigdata-master hai_kou_order_topic-0]<span class="comment"># ls</span></span><br><span class="line">00000000000000000000.index  00000000000000000000.timeindex  leader-epoch-checkpoint</span><br><span class="line">00000000000000000000.log    00000000000000000764.snapshot</span><br></pre></td></tr></table></figure><img src="../images/kafka/截屏2021-05-12 上午10.56.42.png" alt="截屏2021-05-12 上午10.56.42" style="zoom:50%;" /><h2 id="2-日志段代码解析"><a href="#2-日志段代码解析" class="headerlink" title="2. 日志段代码解析"></a>2. 日志段代码解析</h2><p>日志段源码位于 Kafka 的 core 工程下，具体文件位置是 <code>core/src/main/scala/kafka/log/LogSegment.scala</code>。实际上，所有日志结构部分的源码都在 core 的 kafka.log 包下。</p><p>该文件下定义了三个 Scala 对象：</p><ol><li>LogSegment class</li><li>LogSegment object</li><li>LogFlushStats object</li></ol><p>LogFlushStats 结尾有个 Stats，它是做统计用的，主要负责为日志落盘进行计时。</p><h3 id="2-1-日志段类声明"><a href="#2-1-日志段类声明" class="headerlink" title="2.1. 日志段类声明"></a>2.1. 日志段类声明</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogSegment</span> <span class="title">private</span>[log] (<span class="params">val log: <span class="type">FileRecords</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val lazyOffsetIndex: <span class="type">LazyIndex</span>[<span class="type">OffsetIndex</span>], </span></span></span><br><span class="line"><span class="class"><span class="params">                               val lazyTimeIndex: <span class="type">LazyIndex</span>[<span class="type">TimeIndex</span>], </span></span></span><br><span class="line"><span class="class"><span class="params">                               val txnIndex: <span class="type">TransactionIndex</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val baseOffset: <span class="type">Long</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val indexIntervalBytes: <span class="type">Int</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val rollJitterMs: <span class="type">Long</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">                               val time: <span class="type">Time</span></span>) </span></span><br><span class="line"><span class="class"><span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123; … &#125;</span><br></pre></td></tr></table></figure><ol><li><p><strong>lazyOffsetIndex</strong></p><p>位移索引文件</p></li><li><p><strong>lazyTimeIndex</strong></p><p>时间戳索引文件</p></li><li><p><strong>txnIndex</strong></p><p>已中止事务索引文件</p></li><li><p><strong>baseOffset</strong></p><p>每个日志段对象保存自己的起始位移 baseOffset, 磁盘上日志文件名就是 baseOffset 的值。每个 LogSegment 对象实例一旦被创建，它的起始位移已经固定，不能再被更改。</p></li><li><p><strong>indexIntervalBytes</strong></p><p>Broker 端参数 log.index.interval.bytes 值，它控制了日志段对象新增索引项的频率。默认情况下，日志段至少新写入 4KB 的消息数据才会新增一条索引项。</p></li><li><p><strong>rollJitterMs</strong> </p><p>日志段对象新增倒计时的 “扰动值”。因为目前 Broker 端日志段新增倒计时是全局设置，这就是说，在未来的某个时刻可能同时创建多个日志段对象，这将极大地增加物理磁盘 I/O 压力。有了 rollJitterMs 值的干扰，每个新增日志段在创建时会彼此岔开一小段时间，这样可以缓解物理磁盘的 I/O 负载瓶颈。</p></li><li><p><strong>time</strong></p><p>它就是用于统计计时的一个实现类</p></li></ol><h2 id="2-2-append-方法"><a href="#2-2-append-方法" class="headerlink" title="2.2. append 方法"></a>2.2. append 方法</h2><p>append 方法接收 4 个参数，分别表示待写入消息批次中消息的<code>最大位移值</code>、<code>最大时间戳</code>、<code>最大时间戳对应消息的位移</code>以<code>及真正要写入的消息集合</code>。下面这张图展示了 append 方法的完整执行流程：</p><p>![截屏2021-05-12 上午11.21.54](../images/kafka/截屏2021-05-12 上午11.21.54.png)</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append</span></span>(largestOffset: <span class="type">Long</span>, </span><br><span class="line">           largestTimestamp: <span class="type">Long</span>, </span><br><span class="line">           shallowOffsetOfMaxTimestamp: <span class="type">Long</span>, </span><br><span class="line">           records: <span class="type">MemoryRecords</span>): <span class="type">Unit</span> = &#123; </span><br><span class="line">  <span class="keyword">if</span> (records.sizeInBytes &gt; <span class="number">0</span>) &#123; </span><br><span class="line">    trace(<span class="string">s&quot;Inserting <span class="subst">$&#123;records.sizeInBytes&#125;</span> bytes at end offset <span class="subst">$largestOffset</span> at position <span class="subst">$&#123;log.sizeInBytes&#125;</span> &quot;</span></span><br><span class="line">          + <span class="string">s&quot;with largest timestamp <span class="subst">$largestTimestamp</span> at shallow offset <span class="subst">$shallowOffsetOfMaxTimestamp</span>&quot;</span>) </span><br><span class="line">    <span class="keyword">val</span> physicalPosition = log.sizeInBytes() </span><br><span class="line">    <span class="keyword">if</span> (physicalPosition == <span class="number">0</span>) </span><br><span class="line">    rollingBasedTimestamp = <span class="type">Some</span>(largestTimestamp) ensureOffsetInRange(largestOffset) <span class="comment">// append the messages </span></span><br><span class="line">    <span class="keyword">val</span> appendedBytes = log.append(records) trace(<span class="string">s&quot;Appended <span class="subst">$appendedBytes</span> to <span class="subst">$&#123;log.file&#125;</span> at end offset <span class="subst">$largestOffset</span>&quot;</span>) <span class="comment">// Update the in memory max timestamp and corresponding offset. </span></span><br><span class="line">    <span class="keyword">if</span> (largestTimestamp &gt; maxTimestampSoFar) &#123; </span><br><span class="line">      maxTimestampSoFar = largestTimestamp </span><br><span class="line">      offsetOfMaxTimestampSoFar = shallowOffsetOfMaxTimestamp </span><br><span class="line">    &#125; <span class="comment">// append an entry to</span></span><br></pre></td></tr></table></figure><img src="../images/kafka/截屏2021-05-12 上午11.29.25.png" alt="截屏2021-05-12 上午11.29.25" style="zoom:50%;" /><p><strong>第一步：</strong></p><p>在源码中，首先调用 <code>log.sizeInBytes</code> 方法判断该日志段是否为空，如果是空的话， Kafka 需要记录要写入消息集合的最大时间戳，并将其作为后面新增日志段倒计时的依据。</p><p><strong>第二步：</strong>代码调用 <code>ensureOffsetInRange</code> 方法确保输入参数最大位移值是合法的。</p><p>标准就是看它与日志段起始位移的差值是否在整数范围内，即 <code>largestOffset - baseOffset</code> 的值是不是介于 [0，Int.MAXVALUE] 之间。在极个别的情况下，这个差值可能会越界，这时，append 方法就会抛出异常，阻止后续的消息写入。</p><blockquote><p>一旦你碰到这个问题，你需要做的是升级你的 Kafka 版本，因为这是由已知的 Bug 导致的。</p></blockquote><p><strong>第三步：</strong></p><p>append 方法调用 FileRecords 的 append 方法执行真正的写入。</p><p><strong>第四步：</strong>更新日志段的最大时间戳以及最大时间戳所属消息的位移值属性。</p><blockquote><p>每个日志段都要保存当前最大时间戳信息和所属消息的位移信息。还记得 Broker 端提供定期删除日志的功能吗？比如我只想保留最近 7 天的日志，没错，当前最大时间戳这个值就是判断的依据；而最大时间戳对应的消息的位移值则用于时间戳索引项。虽然后面我会详细介绍，这里我还是稍微提一下：时间戳索引项保存时间戳与消息位移的对应关系。在这步操作中，Kafka 会更新并保存这组对应关系。</p></blockquote><p><strong>第五步：</strong>更新索引项和写入的字节数</p><p>日志段默认每写入 4KB 数据就要写入一个索引项。当已写入字节数超过了 4KB 之后，append 方法会调用索引对象的 append 方法新增索引项，同时清空已写入字节数，以备下次重新累积计算。</p><h2 id="2-3-read-方法"><a href="#2-3-read-方法" class="headerlink" title="2.3. read 方法"></a>2.3. read 方法</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(startOffset: <span class="type">Long</span>,</span><br><span class="line">           maxSize: <span class="type">Int</span>,</span><br><span class="line">           maxPosition: <span class="type">Long</span> = size,</span><br><span class="line">           minOneMessage: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">FetchDataInfo</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (maxSize &lt; <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s&quot;Invalid max size <span class="subst">$maxSize</span> for log read from segment <span class="subst">$log</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> startOffsetAndSize = translateOffset(startOffset)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// if the start position is already off the end of the log, return null</span></span><br><span class="line">    <span class="keyword">if</span> (startOffsetAndSize == <span class="literal">null</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">null</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> startPosition = startOffsetAndSize.position</span><br><span class="line">    <span class="keyword">val</span> offsetMetadata = <span class="type">LogOffsetMetadata</span>(startOffset, <span class="keyword">this</span>.baseOffset, startPosition)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> adjustedMaxSize =</span><br><span class="line">      <span class="keyword">if</span> (minOneMessage) math.max(maxSize, startOffsetAndSize.size)</span><br><span class="line">      <span class="keyword">else</span> maxSize</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// return a log segment but with zero size in the case below</span></span><br><span class="line">    <span class="keyword">if</span> (adjustedMaxSize == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="type">FetchDataInfo</span>(offsetMetadata, <span class="type">MemoryRecords</span>.<span class="type">EMPTY</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// calculate the length of the message set to read based on whether or not they gave us a maxOffset</span></span><br><span class="line">    <span class="keyword">val</span> fetchSize: <span class="type">Int</span> = min((maxPosition - startPosition).toInt, adjustedMaxSize)</span><br><span class="line">    </span><br><span class="line">    <span class="type">FetchDataInfo</span>(offsetMetadata, log.slice(startPosition, fetchSize),</span><br><span class="line">      firstEntryIncomplete = adjustedMaxSize &lt; startOffsetAndSize.size)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>read 方法接收 4 个输入参数。</p><ol><li>startOffset: 要读取的第一条消息的位移</li><li>maxSize: 能读取的最大字节数</li><li>maxPosition: 能读到的最大文件位置</li><li>minOneMessage: 是否允许在消息体过大时至少返回第一条消息。</li></ol><h3 id="2-4-recover-方法"><a href="#2-4-recover-方法" class="headerlink" title="2.4. recover 方法"></a>2.4. recover 方法</h3><p>recover 方法，用于恢复日志段。 Broker 在启动时会从磁盘上加载所有日志段信息到内存中，并创建相应的 LogSegment 对象实例。在这个过程中，它需要执行一系列的操作。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recover</span></span>(producerStateManager: <span class="type">ProducerStateManager</span>, </span><br><span class="line">            leaderEpochCache: <span class="type">Option</span>[<span class="type">LeaderEpochFileCache</span>] = <span class="type">None</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    offsetIndex.reset()</span><br><span class="line">    timeIndex.reset()</span><br><span class="line">    txnIndex.reset()</span><br><span class="line">    <span class="keyword">var</span> validBytes = <span class="number">0</span></span><br><span class="line">    <span class="keyword">var</span> lastIndexEntry = <span class="number">0</span></span><br><span class="line">    maxTimestampSoFar = <span class="type">RecordBatch</span>.<span class="type">NO_TIMESTAMP</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">for</span> (batch &lt;- log.batches.asScala) &#123;</span><br><span class="line">        batch.ensureValid()</span><br><span class="line">        ensureOffsetInRange(batch.lastOffset)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// The max timestamp is exposed at the batch level, so no need to iterate the records</span></span><br><span class="line">        <span class="keyword">if</span> (batch.maxTimestamp &gt; maxTimestampSoFar) &#123;</span><br><span class="line">          maxTimestampSoFar = batch.maxTimestamp</span><br><span class="line">          offsetOfMaxTimestampSoFar = batch.lastOffset</span><br><span class="line">        &#125;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// Build offset index</span></span><br><span class="line">        <span class="keyword">if</span> (validBytes - lastIndexEntry &gt; indexIntervalBytes) &#123;</span><br><span class="line">          offsetIndex.append(batch.lastOffset, validBytes)</span><br><span class="line">          timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestampSoFar)</span><br><span class="line">          lastIndexEntry = validBytes</span><br><span class="line">        &#125;</span><br><span class="line">        validBytes += batch.sizeInBytes()</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> (batch.magic &gt;= <span class="type">RecordBatch</span>.<span class="type">MAGIC_VALUE_V2</span>) &#123;</span><br><span class="line">          leaderEpochCache.foreach &#123; cache =&gt;</span><br><span class="line">            <span class="keyword">if</span> (batch.partitionLeaderEpoch &gt; <span class="number">0</span> &amp;&amp; </span><br><span class="line">                cache.latestEpoch.forall(batch.partitionLeaderEpoch &gt; _))</span><br><span class="line">              cache.assign(batch.partitionLeaderEpoch, batch.baseOffset)</span><br><span class="line">          &#125;</span><br><span class="line">          updateProducerState(producerStateManager, batch)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e@ (_: <span class="type">CorruptRecordException</span> | _: <span class="type">InvalidRecordException</span>) =&gt;</span><br><span class="line">        warn(<span class="string">&quot;Found invalid messages in log segment %s at byte offset %d: %s. %s&quot;</span></span><br><span class="line">          .format(log.file.getAbsolutePath, validBytes, e.getMessage, e.getCause))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> truncated = log.sizeInBytes - validBytes</span><br><span class="line">    <span class="keyword">if</span> (truncated &gt; <span class="number">0</span>)</span><br><span class="line">      debug(<span class="string">s&quot;Truncated <span class="subst">$truncated</span> invalid bytes at the end of segment <span class="subst">$&#123;log.file.getAbsoluteFile&#125;</span> during recovery&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    log.truncateTo(validBytes)</span><br><span class="line">    offsetIndex.trimToValidSize()</span><br><span class="line">    <span class="comment">// A normally closed segment always appends the biggest timestamp ever seen into log segment, we do this as well.</span></span><br><span class="line">    timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestampSoFar, skipFullCheck = <span class="literal">true</span>)</span><br><span class="line">    timeIndex.trimToValidSize()</span><br><span class="line">    truncated</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>recover 开始时，代码依次调用索引对象的 reset 方法清空所有的索引文件，之后会开始遍历日志段中的所有消息集合或消息批次（RecordBatch）。对于读取到的每个消息集合，日志段必须要确保它们是合法的，这主要体现在两个方面：该集合中的消息必须要符合 Kafka 定义的二进制格式；该集合中最后一条消息的位移值不能越界，即它与日志段起始位移的差值必须是一个正整数值。</p><p>校验完消息集合之后，代码会更新遍历过程中观测到的最大时间戳以及所属消息的位移值。同样，这两个数据用于后续构建索引项。再之后就是不断累加当前已读取的消息字节数，并根据该值有条件地写入索引项。最后是更新事务型 Producer 的状态以及 Leader Epoch 缓存。不过，这两个并不是理解 Kafka 日志结构所必需的组件，因此，我们可以忽略它们。遍历执行完成后，Kafka 会将日志段当前总字节数和刚刚累加的已读取字节数进行比较，如果发现前者比后者大，说明日志段写入了一些非法消息，需要执行截断操作，将日志段大小调整回合法的数值。同时， Kafka 还必须相应地调整索引文件的大小。把这些都做完之后，日志段恢复的操作也就宣告结束了。</p><img src="../images/kafka/截屏2021-03-12 下午4.33.23.png" alt="截屏2021-03-12 下午4.33.23" style="zoom:50%;" /><img src="/Users/joker/Documents/chen_blog/source/images/kafka/截屏2021-05-12 下午3.45.16.png" alt="截屏2021-05-12 下午3.45.16" style="zoom:50%;" />]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka 消息系统源码深度剖析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(1)：Controller元数据</title>
      <link href="2020/03/12/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(1)%EF%BC%9AController%E5%85%83%E6%95%B0%E6%8D%AE/"/>
      <url>2020/03/12/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(1)%EF%BC%9AController%E5%85%83%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Kafka 中的 Controller 组件是 Kafka 核心组件之一。一方面，它要为集群中的所有主题分区选举领导者副本；另一方面，它还承载着集群的全部元数据信息，并负责将这些元数据信息同步到其他 Broker 上。</p><a id="more"></a><h1 id="集群元数据"><a href="#集群元数据" class="headerlink" title="集群元数据"></a>集群元数据</h1><p>集群 Broker 不会与 ZooKeeper 直接交互去获取元数据的。相反地，它们总是与 Controller 进行通信，获取和更新最新的集群数据。</p><h2 id="什么是集群的元数据"><a href="#什么是集群的元数据" class="headerlink" title="什么是集群的元数据"></a>什么是集群的元数据</h2><p>目前，Controller 定义的元数据有 17 项之多。不过，并非所有的元数据都同等重要，重点关注那些最重要的元数据，并结合源代码来了解下这些元数据都是用来做什么的。</p><p>Kafka 元数据信息全部封装在 ControllerContext 类里，是 Controller 组件的数据容器类。</p><img src="/Users/joker/Documents/Kafka/未命名文件夹/截屏2021-01-26 上午10.50.47.png" alt="截屏2021-01-26 上午10.50.47" style="zoom:50%;" /><h2 id="ControllerContext"><a href="#ControllerContext" class="headerlink" title="ControllerContext"></a>ControllerContext</h2><p>Controller 组件的源代码位于 core 包的 src/main/scala/kafka/controller 路径下，ControllerContext 类就位于这个路径下的 KafkaController.scala 文件中。其中，最重要的数据结构就是 ControllerContext 类。它定义了前面提到的所有元数据信息，以及许多实用的工具方法。比如，获取集群上所有主题分区对象的 allPartitions 方法、获取某主题分区副本列表的 partitionReplicaAssignment 方法，等等。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">ControllerContext</span> </span>&#123;   </span><br><span class="line">   <span class="keyword">val</span> stats = <span class="keyword">new</span> <span class="type">ControllerStats</span> <span class="comment">// Controller统计信息类    </span></span><br><span class="line">   <span class="keyword">var</span> offlinePartitionCount = <span class="number">0</span>   <span class="comment">// 离线分区计数器   </span></span><br><span class="line">   <span class="keyword">val</span> shuttingDownBrokerIds = mutable.<span class="type">Set</span>.empty[<span class="type">Int</span>]  <span class="comment">// 关闭中Broker的Id列表   </span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">val</span> liveBrokers = mutable.<span class="type">Set</span>.empty[<span class="type">Broker</span>] <span class="comment">// 当前运行中Broker对象列表   </span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">val</span> liveBrokerEpochs = mutable.<span class="type">Map</span>.empty[<span class="type">Int</span>, <span class="type">Long</span>]   <span class="comment">// 运行中Broker Epoch列表   </span></span><br><span class="line">   <span class="keyword">var</span> epoch: <span class="type">Int</span> = <span class="type">KafkaController</span>.<span class="type">InitialControllerEpoch</span>   <span class="comment">// Controller当前Epoch值</span></span><br><span class="line">   <span class="comment">// Controller对应ZooKeeper节点的Epoch值</span></span><br><span class="line">   <span class="keyword">var</span> epochZkVersion: <span class="type">Int</span> = <span class="type">KafkaController</span>.<span class="type">InitialControllerEpochZkVersion</span>     </span><br><span class="line">   <span class="keyword">val</span> allTopics = mutable.<span class="type">Set</span>.empty[<span class="type">String</span>]  <span class="comment">// 集群主题列表   </span></span><br><span class="line">   <span class="comment">// 主题分区的副本列表</span></span><br><span class="line">   <span class="keyword">val</span> partitionAssignments = mutable.<span class="type">Map</span>.empty[<span class="type">String</span>, mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">ReplicaAssignment</span>]]</span><br><span class="line">   <span class="comment">// 主题分区的Leader/ISR副本信息</span></span><br><span class="line">   <span class="keyword">val</span> partitionLeadershipInfo = mutable.<span class="type">Map</span>.empty[<span class="type">TopicPartition</span>, <span class="type">LeaderIsrAndControllerEpoch</span>]     </span><br><span class="line">   <span class="keyword">val</span> partitionsBeingReassigned = mutable.<span class="type">Set</span>.empty[<span class="type">TopicPartition</span>]  <span class="comment">// 正处于副本重分配过程的主题分区列表   </span></span><br><span class="line">   <span class="keyword">val</span> partitionStates = mutable.<span class="type">Map</span>.empty[<span class="type">TopicPartition</span>, <span class="type">PartitionState</span>] <span class="comment">// 主题分区状态列表    </span></span><br><span class="line">   <span class="keyword">val</span> replicaStates = mutable.<span class="type">Map</span>.empty[<span class="type">PartitionAndReplica</span>, <span class="type">ReplicaState</span>]  <span class="comment">// 主题分区的副本状态列表   </span></span><br><span class="line">   <span class="keyword">val</span> replicasOnOfflineDirs = mutable.<span class="type">Map</span>.empty[<span class="type">Int</span>, <span class="type">Set</span>[<span class="type">TopicPartition</span>]]  <span class="comment">// 不可用磁盘路径上的副本列表    </span></span><br><span class="line">   <span class="keyword">val</span> topicsToBeDeleted = mutable.<span class="type">Set</span>.empty[<span class="type">String</span>]  <span class="comment">// 待删除主题列表   </span></span><br><span class="line">   <span class="keyword">val</span> topicsWithDeletionStarted = mutable.<span class="type">Set</span>.empty[<span class="type">String</span>]  <span class="comment">// 已开启删除的主题列表   </span></span><br><span class="line">   <span class="keyword">val</span> topicsIneligibleForDeletion = mutable.<span class="type">Set</span>.empty[<span class="type">String</span>]  <span class="comment">// 暂时无法执行删除的主题列表   ......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ControllerStats"><a href="#ControllerStats" class="headerlink" title="ControllerStats"></a>ControllerStats</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ControllerStats</span> <span class="keyword">extends</span> <span class="title">KafkaMetricsGroup</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> _uncleanLeaderElectionRate = newMeter(<span class="string">&quot;UncleanLeaderElectionsPerSec&quot;</span>, <span class="string">&quot;elections&quot;</span>, <span class="type">TimeUnit</span>.<span class="type">SECONDS</span>)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> _leaderElectionTimer = <span class="keyword">new</span> <span class="type">KafkaTimer</span>(newTimer(<span class="string">&quot;LeaderElectionRateAndTimeMs&quot;</span>, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>, <span class="type">TimeUnit</span>.<span class="type">SECONDS</span>))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// KafkaServer needs to initialize controller metrics during startup. We perform initialization</span></span><br><span class="line">  <span class="comment">// through method calls to avoid Scala compiler warnings.</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">uncleanLeaderElectionRate</span></span>: <span class="type">Meter</span> = _uncleanLeaderElectionRate</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">leaderElectionTimer</span></span>: <span class="type">KafkaTimer</span> = _leaderElectionTimer</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="offlinePartitionCount"><a href="#offlinePartitionCount" class="headerlink" title="offlinePartitionCount"></a>offlinePartitionCount</h3><p>该字段统计集群中所有离线或处于不可用状态的主题分区数量</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 更新offlinePartitionCount元数据</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">updatePartitionStateMetrics</span></span>(</span><br><span class="line">  partition: <span class="type">TopicPartition</span>, </span><br><span class="line">  currentState: <span class="type">PartitionState</span>,</span><br><span class="line">  targetState: <span class="type">PartitionState</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 如果该主题当前并未处于删除中状态</span></span><br><span class="line">  <span class="keyword">if</span> (!isTopicDeletionInProgress(partition.topic)) &#123;</span><br><span class="line">    <span class="comment">// targetState表示该分区要变更到的状态</span></span><br><span class="line">    <span class="comment">// 如果当前状态不是OfflinePartition，即离线状态并且目标状态是离线状态</span></span><br><span class="line">    <span class="comment">// 这个if语句判断是否要将该主题分区状态转换到离线状态</span></span><br><span class="line">    <span class="keyword">if</span> (currentState != <span class="type">OfflinePartition</span> &amp;&amp; targetState == <span class="type">OfflinePartition</span>) &#123;</span><br><span class="line">      offlinePartitionCount = offlinePartitionCount + <span class="number">1</span></span><br><span class="line">    <span class="comment">// 如果当前状态已经是离线状态，但targetState不是</span></span><br><span class="line">    <span class="comment">// 这个else if语句判断是否要将该主题分区状态转换到非离线状态</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (currentState == <span class="type">OfflinePartition</span> &amp;&amp; targetState != <span class="type">OfflinePartition</span>) &#123;</span><br><span class="line">      offlinePartitionCount = offlinePartitionCount - <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="shuttingDownBrokerIds"><a href="#shuttingDownBrokerIds" class="headerlink" title="shuttingDownBrokerIds"></a>shuttingDownBrokerIds</h3><p><strong>该字段保存所有正在关闭中的 Broker ID 列表。</strong></p><p>当 Controller 在管理集群 Broker 时，它要依靠这个字段来甄别 Broker 当前是否已关闭，因为处于关闭状态的 Broker 是不适合执行某些操作的，如分区重分配（Reassignment）以及主题删除等。</p><h3 id="liveBrokers"><a href="#liveBrokers" class="headerlink" title="liveBrokers"></a>liveBrokers</h3><p>该字段保存当前所有运行中的 Broker 对象。每个 Broker 对象就是一个 的三元组。</p><h3 id="liveBrokerEpochs"><a href="#liveBrokerEpochs" class="headerlink" title="liveBrokerEpochs"></a>liveBrokerEpochs</h3><p>该字段保存所有运行中 Broker 的 Epoch 信息。Kafka 使用 Epoch 数据防止 Zombie Broker，即一个非常老的 Broker 被选举成为 Controller。</p><h3 id="epoch"><a href="#epoch" class="headerlink" title="epoch"></a>epoch</h3><p>epoch 是 ZooKeeper 中 /controller_epoch 节点的值，是 Controller 在整个 Kafka 集群的版本号</p><h3 id="allTopics"><a href="#allTopics" class="headerlink" title="allTopics"></a>allTopics</h3><p>该字段保存集群上所有的主题名称。每当有主题的增减，Controller 就要更新该字段的值。</p><h3 id="partitionAssignments"><a href="#partitionAssignments" class="headerlink" title="partitionAssignments"></a>partitionAssignments</h3><p>该字段保存所有主题分区的副本分配情况。</p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka 消息系统源码深度剖析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(17)_垃圾回收算法[2]_清除阶段</title>
      <link href="2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(17)_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%5B2%5D:%E6%B8%85%E9%99%A4%E9%98%B6%E6%AE%B5%20/"/>
      <url>2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(17)_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%5B2%5D:%E6%B8%85%E9%99%A4%E9%98%B6%E6%AE%B5%20/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>当成功区分出内存中存活对象和死亡对象后，GC接下来的任务就是执行垃圾回收，释放掉无用对象所占用的内存空间，以便有足够的可用内存空间为新对象分配内存。</p><a id="more"></a><p>当成功区分出内存中存活对象和死亡对象后，GC 接下来的任务就是执行垃圾回收，释放掉无用对象所占用的内存空间，以便有足够的可用内存空间为新对象分配内存。目前在 JVM 中比较常见的三种垃圾收集算法是<font color=red><strong>标记-清除算法（Mark-Sweep）、复制算法（Copying）、标记-压缩算法（Mark-Compact）</strong></font>。</p><h2 id="1-标记-清除算法"><a href="#1-标记-清除算法" class="headerlink" title="1. 标记-清除算法"></a>1. 标记-清除算法</h2><p>标记-清除（Mark-Sweep）算法是一种非常基础和常见的垃圾收集算法，该算法被 J.McCarthy 等人在 1960 年提出并应用于 Lisp 语言。</p><h3 id="1-1-执行过程"><a href="#1-1-执行过程" class="headerlink" title="1.1. 执行过程"></a>1.1. 执行过程</h3><p>当 JVM 中的有效内存空间（avaiable memory）被耗尽的时候，就会停止整个程序(stop the world)，然后进行两项工作，第一项是标记，第二项是清除。</p><ul><li><font color=blue><strong>标记</strong></font>：Collector 从引用根节点开始标记所有被引用的对象。一般是在对象的 Header 中记录为可达对象。</li><li><font color=blue><strong>清除</strong></font>：Collector 对堆内存从头到尾进行线性的遍历，如果发现某个对象在 Header 中没有标记为可达对象，则将其回收。</li></ul><img src="/images/jvm/289.png" alt="img" style="zoom:50%;" /><h3 id="1-2-缺点"><a href="#1-2-缺点" class="headerlink" title="1.2. 缺点"></a>1.2. 缺点</h3><ul><li><p>效率不算高</p></li><li><p>在进行 GC 的时候，需要停止整个应用程序，导致用户体验差</p></li><li><p>这种方式清理出来的空闲内存是不连续的，产生内存碎片。需要维护一个空闲列表，大对象可能放不下</p></li><li><p>注意：何为清除？</p><ul><li>这里所谓的清除并不是真的置空，而是把需要清除的对象地址保存在空闲的地址列表中。下次有新对象需要加载时，判断垃圾的位置空间是否够，如果够，就存放。</li></ul></li></ul><h2 id="2-复制算法"><a href="#2-复制算法" class="headerlink" title="2. 复制算法"></a>2. 复制算法</h2><p>为了解决标记-清除算法在垃圾收集效率方面的缺陷，M.L.Minsky 于1963年发表了著名的论文，核心思想：将活着的内存空间分为两块，每次使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，最后完成垃圾回收。</p><img src="/images/jvm/290.png" alt="img" style="zoom:50%;" /><h3 id="2-1-优点："><a href="#2-1-优点：" class="headerlink" title="2.1. 优点："></a>2.1. 优点：</h3><ul><li>实现简单，运行高效</li><li>复制过去后保证了空间的连续性，不会出现 <code>碎片</code>问题</li></ul><h3 id="2-2-缺点："><a href="#2-2-缺点：" class="headerlink" title="2.2. 缺点："></a>2.2. 缺点：</h3><ul><li>此算法的缺点也是非常明显的，就是需要两倍的内存空间。</li><li>对于 G1 这种分拆称为大量 region 的GC，赋值而不是移动，意味着 GC 需要维护 region 之间对象引用关系，不管内存占用还是时间，开销也不小。</li></ul><h2 id="3-标记-压缩算法"><a href="#3-标记-压缩算法" class="headerlink" title="3. 标记-压缩算法"></a>3. 标记-压缩算法</h2><p>复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代进程发生，但是在老年代，更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活对象较多，复制的成本也将很高。因此，<font color=red><strong>基于老年代垃圾回收的特性，需要使用其他的算法</strong></font>。</p><p>标记-清除算法的确可以应用在老年代中，但是该算法不仅执行效率低下，而且在执行完内存回收后还会产生碎片，所以 JVM 的设计者需要在此基础之上进行改进。标记-压缩（Mark-Compact）算法由此诞生。</p><p>1970年前后，G.L.Steele、C.J.Chene和D.S.Wise等研究者发布标记-压缩算法。在许多现代的垃圾收集器中，人们都是用了标记-压缩算法或其他改进版本。</p><img src="/images/jvm/292.png" alt="img" style="zoom:50%;" /><p>标记-压缩算法的最终效果等同于标记-清除算法执行完成后，再进行一次内存碎片整理，因此，也可以把它称为<font color=red><strong>标记-清除-压缩（Mark-Sweep-Compact）算法</strong></font>。</p><p>标记-压缩算法 和 标记-清除算法本质区别: 标记-压缩算法是<font color=blue><strong>移动式的</strong></font>,标记-清除算法是一种<font color=blue><strong>非移动式的回收算法</strong></font>。</p><p>标记的存活对象将会被整理，按照内存地址一次排列，而未被标记的内存会被清理掉。如此以来，当需要给新对象分配内存时，JVM 只需要持有一个内存的起始地址即可, 比维护一个空闲列表显然少了许多开销。</p><h3 id="3-1-优点"><a href="#3-1-优点" class="headerlink" title="3.1. 优点"></a>3.1. 优点</h3><ul><li>消除了标记-清除算法中，内存区域分散的缺点，需要给新对象分配内存时，JVM 只需要持有一个内存的起始地址即可。</li><li>消除了赋值算法当中，内存减半的高额代价。</li></ul><h3 id="3-2-缺点"><a href="#3-2-缺点" class="headerlink" title="3.2. 缺点"></a>3.2. 缺点</h3><ul><li>从效率上来说，标记-整理算法要低于另外两种算法（标记-清除算法、复制算法）</li><li>移动对象的同时，如果对象被其他对象引用，则还需调整引用的地址</li><li>移动的过程中，需要全称暂停用户应用程序。即STW。（其他两种算法也有这个问题）</li></ul><h2 id="4-小节"><a href="#4-小节" class="headerlink" title="4 小节"></a>4 小节</h2><img src="/images/jvm/293.png" alt="img" style="zoom:50%;" /><p>效率上来说，复制算法是当之无愧的老大，但是却浪费了太多内存。</p><p>而为了尽量兼顾上面的三个指标，标记-整理算法相对来说更平滑一些，但是效率上不尽如人意，它比复制算法多了一个标记的阶段，比标记-清除算法多了一个整理内存的阶段。</p><h2 id="5-分代收集算法"><a href="#5-分代收集算法" class="headerlink" title="5 分代收集算法"></a>5 分代收集算法</h2><p>前面所有这些算法中，并没有一种算法可以完全替代其他算法，他们都具有自己独特的优势和特点。分代收集算法应运而生。</p><p>分代收集算法，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，<font color=blue><strong>不同生命周期的对象可以采取不同的收集方式，一遍提高回收效率</strong></font>。一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率。</p><p>在 Java 程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关，比如 <font color=blue><strong>Http 请求中的 Session 对象、线程、Socket 连接</strong></font>，这类对象跟业务直接挂钩，因此生命周期比较长。但是还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期比较短，比如：<font color=blue><strong>String对象</strong></font>，由于其不变性的特性，系统会产生大量这些对象，有些对象甚至只用一次即可回收。</p><p><font color=red><strong>目前几乎所有的 GC 都是采用分代收集（Generational Collecting）算法执行垃圾回收的</strong></font>。</p><p>在 Hotspot 中，基于分代的概念，GC 所使用的内存回收算法必须结合年轻代和老年代各自的特点。</p><h3 id="5-1-年轻代-Young-Gen"><a href="#5-1-年轻代-Young-Gen" class="headerlink" title="5.1. 年轻代(Young Gen)"></a>5.1. 年轻代(Young Gen)</h3><p>年轻代特点：区域相对于老年代较小，对象声明周期短、存活率低，回收频繁。这种情况<font color=blue><strong>复制算法</strong></font>是回收整理速度最快的。赋值算法的效率之和当前存活对象大小有关，因此很适用于年轻代的回收。而赋值算法内存利用率不高的问题，通过hotspot中的两个 survivor 的设计得到缓解。</p><h3 id="5-2-老年代-Tenured-Gen"><a href="#5-2-老年代-Tenured-Gen" class="headerlink" title="5.2. 老年代(Tenured Gen)"></a>5.2. 老年代(Tenured Gen)</h3><p>老年代特点：区域较大，对象生命周期长、存活率高，回收不及年轻代频繁。这种情况下存在大量存活率高的对象，赋值算法变得明显不合适。一般是由<font color=blue><strong>标记-清除算法 与 标记-压缩算法</strong></font>的混合实现。</p><p>以 Hotspot 中的 CMS 回收器为例，CMS 是基于 Mark-Sweep 实现的，对于对象的回收效率很高。而对于碎片问题，CMS采用基于Mark-Compact算法的Serial Old回收器作为补偿措施：当内存回收不佳(碎片导致Concurrent Mode Failure时)，将采用 Serial Old 执行 Full GC 以达到对老年代内存的整理。</p><h2 id="6-增量收集算法、分区算法"><a href="#6-增量收集算法、分区算法" class="headerlink" title="6. 增量收集算法、分区算法"></a>6. 增量收集算法、分区算法</h2><p>这两种算法都是为了解决 STW 的问题</p><h3 id="6-1-增量收集算法-从时间角度提高低延迟"><a href="#6-1-增量收集算法-从时间角度提高低延迟" class="headerlink" title="6.1. 增量收集算法(从时间角度提高低延迟)"></a>6.1. 增量收集算法(从时间角度提高低延迟)</h3><p>上述现有的算法，在垃圾回收过程中，应用软件将处于一种 Stop the World 的状态。在 <font color=blue><strong>Stop the World</strong></font> 状态下，应用程序所有的线程都会挂起，暂停一切正常的工作，等待垃圾回收的完成。如果垃圾回收时间过长，应用程序会被挂起很久，<font color=blue><strong>将严重影响用户体验或者系统的稳定性</strong></font>。为了解决这个问题，即对实时垃圾收集算法的研究导致了增量收集（Incremental Collecting）算法的诞生。</p><ul><li><p>基本思想</p><p>如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序交替执行。每次，<font color=blue><strong>垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成</strong></font>。</p></li><li><p>增量收集算法的基础仍然是传统的标记-清除算法和复制算法。增量收集算法通过<font color=red><strong>对线程间冲突的妥善处理，允许垃圾线程以分阶段的方式完成标记、清理或复制工作</strong></font>。</p></li><li><p>缺点</p><p>使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总成本上升，<font color=blue><strong>造成系统吞吐量的下降</strong></font>。</p></li></ul><h3 id="6-2-分区算法-从空间角度提高低延迟"><a href="#6-2-分区算法-从空间角度提高低延迟" class="headerlink" title="6.2. 分区算法(从空间角度提高低延迟)"></a>6.2. 分区算法(从空间角度提高低延迟)</h3><p>一般来说，在相同条件下，堆空间越大，一次 GC 所需要的时间越长，有关 GC 产生的停顿也越长。为了更好地控制 GC 产生的停顿时间，将一块大的内存区域分割成多个小块，格局目标的停顿时间，每次合理地回收若干小区间，而不是整个堆空间，从而减少一次GC锁产生的停顿。</p><p>分代算法将按照对象的生命周期长短划分为两个部分，分区算法将整个堆空间划分成连续的不同小区间 region。</p><p>每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少峰小区间。</p><img src="/images/jvm/294.png" alt="img" style="zoom:67%;" />]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(16)_垃圾回收算法[1]_标记阶段</title>
      <link href="2020/03/02/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(16)_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%5B1%5D:%E6%A0%87%E8%AE%B0%E9%98%B6%E6%AE%B5/"/>
      <url>2020/03/02/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(16)_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%5B1%5D:%E6%A0%87%E8%AE%B0%E9%98%B6%E6%AE%B5/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在堆里存放着几乎所有的 Java 对象实例，在 GC 执行垃圾回收之前，首先<font color=blue><strong>需要区分出内存中哪些是存活对象，哪些是死亡的对象</strong></font>。只有被标记为已经死亡的对象，GC 才会在执行垃圾回收时，释放掉其所占的内存空间，因此这个过程我们可以称为<font color=blue><strong>垃圾标记阶段</strong></font>。</p><a id="more"></a><p>当一个对象已经不再被任何存活对象继续引用时，就可以判为已经死亡。判断对象存活一般由两种方式：<font color=red><strong>引用计数算法</strong></font>和<font color=red><strong>可达性分析算法</strong></font>。</p><h2 id="1-引用计数算法"><a href="#1-引用计数算法" class="headerlink" title="1. 引用计数算法"></a>1. 引用计数算法</h2><p>引用计数算法（Reference Counting）对每个对象保存一个整形的<font color=red><strong>引用计数器属性。用于记录对象被引用的情况</strong></font>。</p><p>对于一个对象 A，只要有任何一个对象引用了A，则 A 的引用计数器就加1；当引用失效时，引用计数器就减1.只要对象A的引用计数器的值为0，即表示对象 A 不可能再被使用，可进行回收。</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p><font color=blue><strong>实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性</strong></font>。</p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>它需要单独的字段存储计数器，这样的做法增加了<font color=blue><strong>存储空间的开销</strong></font>。</li><li>没每次赋值都需要更新计数器，伴随着加法和减法的操作，这增加了<font color=blue><strong>时间开销</strong></font>。</li><li>引用计数器有一个严重的问题，即无法处理<font color=blue><strong>循环引用</strong></font>的情况。这是一条致命缺陷，导致在 Java 的垃圾回收器中没有使用这类算法。</li></ul><img src="/images/jvm/270.png" alt="img" style="zoom:67%;" /><ul><li><p>代码示例</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * -XX:+PrintGCDetails</span></span><br><span class="line"><span class="comment"> * 证明：java使用的不是引用计数算法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RefCountGC</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 这个成员属性唯一的作用就是占用一点内存</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">byte</span>[] bigSize = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">5</span> * <span class="number">1024</span> * <span class="number">1024</span>];  <span class="comment">// 5MB</span></span><br><span class="line"></span><br><span class="line">    Object reference = <span class="keyword">null</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        RefCountGC obj1 = <span class="keyword">new</span> RefCountGC();</span><br><span class="line">        RefCountGC obj2 = <span class="keyword">new</span> RefCountGC();</span><br><span class="line"></span><br><span class="line">        obj1.reference = obj2;</span><br><span class="line">        obj2.reference = obj1;</span><br><span class="line"></span><br><span class="line">        obj1 = <span class="keyword">null</span>;</span><br><span class="line">        obj2 = <span class="keyword">null</span>;</span><br><span class="line">        <span class="comment">// 显式的执行垃圾回收行为</span></span><br><span class="line">        <span class="comment">// 这里发生GC，obj1和obj2能否被回收？</span></span><br><span class="line">        System.gc();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>如果采用循环引用会出现问题，如下图：</p><img src="/images/jvm/271.png" alt="img" style="zoom:67%;" /><p><strong>如果 System.gc();被注释掉，输出结果如下</strong></p><img src="/images/jvm/272.png" alt="img" style="zoom:100%;" /><p><strong>如果System.gc();没被注释掉，输出结果如下</strong></p><img src="/images/jvm/273.png" alt="img" style="zoom:100%;" /><hr><h3 id="小节"><a href="#小节" class="headerlink" title="小节"></a>小节</h3><ul><li>引用计数算法，是很多语言的资源回收选择，例如 Python，它更是同时支持引用计数和垃圾收集机制。</li><li>具体哪种最优是要看场景的，业界有大规模时间中仅保留引用技术机制，以提高吞吐量的尝试。</li><li>Java 并没有选择引用计数，是因为其存在一个基本难题，也就是很难处理循环引用关系。</li><li>Python如何解决循环引用<ul><li>手动解除</li><li>使用弱引用 weakref，weakref 是 Python 提供的标准，只在解决循环引用。</li></ul></li></ul><h2 id="2-可达性分析算法"><a href="#2-可达性分析算法" class="headerlink" title="2. 可达性分析算法"></a>2. 可达性分析算法</h2><p>相对于引用计数算法而言，可达性分析算法不仅同样具备实现简单和执行高效等特点，更重要的是该算法可以有效地<font color=blue><strong>解决在引用计数算法中循环引用的问题，防止内存泄露的发生</strong></font>。</p><p>相对于引用计数算法，这里的可达性分析就是<font color=red><strong>Java、C#</strong></font>选择的。这种类型的垃圾收集通常也叫做<font color=blue><strong>追踪性垃圾收集</strong></font>（Tracing Garbage Collection）。</p><p>所谓“GC Roots”根集合就是一组必须活跃的引用。</p><h3 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h3><ol><li>可达性分析算法是以根集合（GC Roots）为起始点，按照从上至下的方式<font color=blue><strong>搜索被根对象集合所连接的目标是否可达</strong></font>。</li><li>使用可达性分析算法后，内存中存活对象都会被根对象集合直接或间接连接着，搜索走过的路径称为<font color=red><strong>引用链（Reference Chain）</strong></font>。</li><li>如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象已经死亡，可以标记为垃圾对象。</li><li>在可达性分析算法中，只有能被根对象集合直接或者间接连接的对象才是存活对象。</li></ol><hr><h3 id="GC-Roots"><a href="#GC-Roots" class="headerlink" title="GC Roots"></a>GC Roots</h3><ol><li>虚拟机栈中引用的对象<ul><li>比如：各个线程被调用的方法中使用到的参数、局部变量等。</li></ul></li><li>本地方法栈 JNI 引用的对象</li><li>方法区中静态属性引用的对象<ul><li>比如：Java 类的引用类型静态变量</li></ul></li><li>方法区中常量引用的对象<ul><li>比如：字符串常量池（StringTable）里的引用</li></ul></li><li>所有被同步锁synchronized持有的对象</li><li>Java虚拟机内部的引用。<ul><li>基本数据类型对应的Class对象，一些常驻的异常对象（如：NullPointerException、OutOfMemoryError），系统类加载器。</li></ul></li><li>反应java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。</li><li>除了这些固定的GC Roots集合以外，根据用户选择的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整GC Roots集合，比如：分代收集和局部回收（Partial GC）。如果只针对Java堆中某一块区域进行垃圾回收（比如：典型的只针对新生代），必须考虑到内存区域是虚拟机字节的实现细节，更不是鼓励封闭的，这个区域的对象完全有可能被其他区域对象的对象所引用，这时候就需要一并将关联的区域对象也加入GC Roots集合中去考虑，才能保证可达性分析的准确定。</li></ol><p>由于 Root 采用栈方式存放变量和指针，所以如果一个指针，它保存了堆内存里面的对象，但是自己又不存放在堆内存里面，那么它就是一个Root。</p><hr><p>如果要使用可达性分析算法来判断内存是否可回收，那么分析工作必须在一个能保证一致性的快照中进行。这点不满足的话分析结果的准确性就无法保证。</p><p>这点也是导致GC进行时必须“Stop The World”的一个重要原因。</p><p>即使是号称（几乎）不会发生停顿的CMS收集器中，<font color=red><strong>枚举根节点时也是必须要停顿的</strong></font>。</p><h2 id="3-finalization-机制"><a href="#3-finalization-机制" class="headerlink" title="3. finalization 机制"></a>3. finalization 机制</h2><p>Java 语言提供了对象终止（finalization）机制来允许开发人员提供能<font color=blue><strong>自定义对象被销毁之前的处理逻辑</strong></font>。当垃圾回收器发现没有引用指向一个对象，即：垃圾回收此对象之前，总会先调用这个对象的 finalize()方法。finalize() 方法允许在子类中被重写，<font color=blue><strong>用于在对象被回收之前进行资源释放</strong></font>。通常在这个方法中进行一些资源释放和清理工作，比如关闭文件、套接字和数据库连接等。</p><blockquote><p>不要主动调用某个对象的finalize()方法，应该交给垃圾回收机制调用。理由包括下面三点：</p><p>(1) 在finalize() 时可能会导致对象复活。</p><p>(2) finalize() 方法的执行时没有时间保障的，它完全由 GC 线程决定，极端情况下，若不发生 GC，则 finalize() 方法将没有执行机会。</p><p>(3) 一个糟糕的 finalize() 会严重影响GC的性能。</p></blockquote><hr><h3 id="3-1-对象状态"><a href="#3-1-对象状态" class="headerlink" title="3.1. 对象状态"></a>3.1. 对象状态</h3><p>由于finalize()方法的存在，<font color=blue><strong>虚拟机中的对象一般处于三种可能的状态</strong></font>。</p><p>如果从所有的根节点都无法访问到某个对象，说明对象已经不再使用了。一般来说，此对象需要被回收，但事实上，<font color=red><strong>一个无法触及的对象有可能在某一个条件下 “复活” 自己</strong></font>，如果这样，那么对它的回收就是不合理的，为此，定义虚拟机中的对象可能的三种状态。如下：</p><ol><li><font color=red><strong>可触及的</strong></font>：从根节点开始，可以到达这个对象。</li><li><font color=red><strong>可复活的</strong></font>：对象的所有引用都被释放，但是对象有可能在 finalize() 中复活。</li><li><font color=red><strong>不可触及的</strong></font>：对象的 finalize() 被调用，并且没有复活，那么就会进入不可触及状态。不可触及的对象不可能被复活，因为<font color=blue><strong>finalize()只会被调用一次</strong></font>。</li></ol><p>以上三种状态中，是由于finalize()方法的存在，进行的区分。只有在对象不可触及是才可能被回收。</p><h3 id="3-2-对象回收过程"><a href="#3-2-对象回收过程" class="headerlink" title="3.2. 对象回收过程"></a>3.2. 对象回收过程</h3><p>回收对象的具体过程：判断一个对象objA是否可回收，至少要经历两次标记过程：</p><ol><li><p>如果对象 objA 到 GC Roots 没有引用链，则进行第一次标记。</p></li><li><p>进行筛选，判断次对象是否有必要执行 finalize() 方法</p><ul><li><p>如果对象 objA 没有重写 finalize() 方法，或者 finalize() 方法已经被虚拟机调用过，则虚拟机将会把finalize() 方法视为 **<code>没有必要执行</code>**，objA 被判定为不可触及的。</p></li><li><p>如果对象 objA 重写了 finalize() 方法，且还未执行过，那么 objA 会被插入队列中，由一个虚拟机自动创建的、低优先级的 Finalizer 线程触发 finalize() 方法执行。</p><img src="/images/jvm/276.png" alt="img" style="zoom:100%;" /></li><li><p><font color=red><strong>finalize()方法是对象逃脱死亡的最后机会</strong></font>，稍后 GC 会对 F-Queue 队列中的对象进行第二次标记。<font color=blue><strong>如果 objA 在 finalize() 方法中与引用链上的任何一个对象建立了联系</strong></font>，那么在第二次标记时，objA 会被移出 <strong><code>即将回收</code></strong> 集合。</p></li><li><p>当对象再次出现没有引用的情况。这种情况下，finalize() 方法不会再次被调用，对象会直接编程不可触及的状态，也就是说，一个对象的 finalize() 方法只会被调用一次。</p></li></ul></li></ol><h4 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 测试Object类中finalize()方法，即对象的finalization机制。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CanReliveObj</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> CanReliveObj obj;  <span class="comment">// 类变量，属于 GC Root</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 此方法只能被调用一次</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">finalize</span><span class="params">()</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.finalize();</span><br><span class="line">        System.out.println(<span class="string">&quot;调用当前类重写的finalize()方法&quot;</span>);</span><br><span class="line">        obj = <span class="keyword">this</span>;  <span class="comment">// 当前待回收的对象在finalize()方法中与引用链上的一个对象obj建立了联系</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            obj = <span class="keyword">new</span> CanReliveObj();</span><br><span class="line">            <span class="comment">// 对象第一次成功拯救自己</span></span><br><span class="line">            obj = <span class="keyword">null</span>;</span><br><span class="line">            System.gc();  <span class="comment">// 调用垃圾回收器</span></span><br><span class="line">            System.out.println(<span class="string">&quot;第1次 gc&quot;</span>);</span><br><span class="line">            <span class="comment">// 因为Finalizer线程优先级很低，暂停2秒，以等待它</span></span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            <span class="keyword">if</span> (obj == <span class="keyword">null</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;obj is dead&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;obj is still alive&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;第2次 gc&quot;</span>);</span><br><span class="line">            <span class="comment">// 下面这段代码与上面的完全相同，但是这次自救却失败了</span></span><br><span class="line">            obj = <span class="keyword">null</span>;</span><br><span class="line">            System.gc();</span><br><span class="line">            <span class="comment">// 因为Finalizer线程优先级很低，暂停2秒，以等待它</span></span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            <span class="keyword">if</span> (obj == <span class="keyword">null</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;obj is dead&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;obj is still alive&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">第一次 GC</span><br><span class="line">调用当前类重写的 finalize() 方法</span><br><span class="line">obj is still alive</span><br><span class="line">第二次 GC</span><br><span class="line">obj is dead</span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop源码学习[5]-Edits 双缓冲机制</title>
      <link href="2020/02/23/Hadoop%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%5B3%5D-Edits%E5%8F%8C%E7%BC%93%E5%86%B2%E6%9C%BA%E5%88%B6/"/>
      <url>2020/02/23/Hadoop%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%5B3%5D-Edits%E5%8F%8C%E7%BC%93%E5%86%B2%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="单缓冲机制"><a href="#单缓冲机制" class="headerlink" title="单缓冲机制"></a>单缓冲机制</h3><p>在存储系统写数据的过程中，出于性能上的考虑，新写的数据并不是每次都 flush 到目标存储中的，而是先放入到一个 buffer 空间里，等到 buffer 空间满了，再做一次 flush 出去的动作。这种情况和人们等车的例子极为类似，一辆车等人都上满了再开，才能保证更高的效率。但是这种缓冲设计模式还是存有一个主要弊端的，当缓冲数据满后将会阻塞住后面的数据操作直到缓冲数据完全flush出去。 </p><a id="more"></a><h3 id="双缓冲机制"><a href="#双缓冲机制" class="headerlink" title="双缓冲机制"></a>双缓冲机制</h3><p>如果说增大缓冲区长度属于纵向扩展的话，那么这里所说的双缓冲则是横向上的扩展。</p><p>它的运作原理如下:<br>‌将缓冲区分为 2 份，1份为当前缓冲区 buf current，另外 1 份为预写入分区 buf ready，两个缓冲区空间大小一致。current 区负责当前的写操作存放，当我们达到缓冲处罚条件时，执行一次双缓冲的调换操作。然后由另外的程序执行 ready 区的 flush 操作。被交换变为空缓冲区的 current 区重新用于这的数据写入。<br>‌<br>‌以上的执行模式有以下2大优势:</p><ol><li>‌程序无需反复进行创建新缓冲的操作</li><li>程序的写请求不会被阻塞住，除非current缓冲区已经满了同时ready缓冲区数据还没有全部flush出去</li></ol><p>如果说增大缓冲区长度属于纵向扩展的话，那么这里所说的双缓冲则是横向上的扩展。</p><p>它的运作原理如下:<br>‌将缓冲区分为2份，1份为当前缓冲区buf current，另外1份为预写入分区buf<br>ready，两个缓冲区空间大小一致。current区负责当前的写操作存放，当我们达到缓冲处罚条件时，执行一次双缓冲的调换操作。然后由另外的程序执行ready区的flush操作。被交换变为空缓冲区的current区重新用于这的数据写入。<br>‌<br>‌以上的执行模式有以下2大优势:<br>‌1）程序无需反复进行创建新缓冲的操作<br>‌2）程序的写请求不会被阻塞住，除非current缓冲区已经满了同时ready缓冲区数据还没有全部flush出去</p><p>在使用双缓冲区模式时，因为缓冲区是可能存在 concurrent 使用的情况，所以这里需要有 thread<br>safe 的处理，以此保证每个操作是原子的更新。比如双缓冲在swap的时候就不应该发生 add 缓冲的动作，再比如还应该有一个线程可先性的变量来告诉程序，ready 缓冲区是否已完全 flush 出去。</p><h2 id="手写双缓冲"><a href="#手写双缓冲" class="headerlink" title="手写双缓冲"></a>手写双缓冲</h2><h2 id="HDFS-双缓冲机制"><a href="#HDFS-双缓冲机制" class="headerlink" title="HDFS 双缓冲机制"></a>HDFS 双缓冲机制</h2>]]></content>
      
      
      <categories>
          
          <category> Hadoop 源码阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> Hadoop 源码阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(15)_垃圾回收概述</title>
      <link href="2020/02/20/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(15)_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%A6%82%E8%BF%B0/"/>
      <url>2020/02/20/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(15)_%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>垃圾是指<font color=red><strong>在运行程序中没有任何指针指向的对象</strong></font>，这个对象就是需要被回收的垃圾。</p><a id="more"></a><h2 id="什么是垃圾？"><a href="#什么是垃圾？" class="headerlink" title="什么是垃圾？"></a>什么是垃圾？</h2><p>垃圾是指<font color=red><strong>在运行程序中没有任何指针指向的对象</strong></font>，这个对象就是需要被回收的垃圾。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">An object is considered garbage when it can no longer be reached from any pointer in the running program.</span><br></pre></td></tr></table></figure><p>垃圾收集，不是 Java 语言的伴生产物。早在1960年，第一门开始使用内存动态分配和垃圾收集技术的Lisp语言诞生。</p><p>关于垃圾收集有三个经典问题：</p><ol><li>哪些内存需要收集？</li><li>什么时候回收垃圾？</li><li>如何回收垃圾？</li></ol><p>垃圾回收机制是 Java 的招牌能力，<font color=blue><strong>极大地提高了开发效率</strong></font>。如今，垃圾收集几乎成为现代语言的标配，即使经过如此长时间的发展，Java 的垃圾收集机制仍然在不断的演进中，不同大小的设备、不同特征的应用场景，对垃圾收集提出了新的挑战</p><p>如果不及时对内存中的垃圾进行清理，那么，这些垃圾对象所占的内存空间会一直保留到应用程序结束，被保留的空间无法被其他对象使用。甚至可能导致内存溢出。</p><h2 id="为什么需要-GC-？"><a href="#为什么需要-GC-？" class="headerlink" title="为什么需要 GC ？"></a>为什么需要 GC ？</h2><ol><li>对于高级语言来说，一个基本认知是如果不进行垃圾回收，<font color=blue><strong>内存迟早都会被消耗完</strong></font>，因为不断地分配内存空间而不进行回收。</li><li>处理释放没用的对象，垃圾回收也可以清除内存里的记录碎片。碎片整理将所占用的堆内存一道堆的一端，一遍<font color=blue><strong>JVM将整理出的内存分给新的对象</strong></font>。</li><li>随着应用程序所应付的业务越来越庞大、复杂，用户越来越多，<font color=blue><strong>没有GC就不能保证应用程序的正常进行</strong></font>。而经常造成 STW的GC又跟不上实际的需求，所以才会不断地尝试对 GC 优化。</li></ol><h2 id="早期垃圾回收"><a href="#早期垃圾回收" class="headerlink" title="早期垃圾回收"></a>早期垃圾回收</h2><p>在早期的 C/C++ 时代，垃圾回收基本上是手工进行的。开发人员可以使用 new 关键字进行申请，并使用 delete 关键字进行内存释放。比如以下代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MibBridge *pBridge = <span class="keyword">new</span> cmBaseGroupBridge();</span><br><span class="line"><span class="comment">// 如果注册失败，使用delete释放该对象所占内存区域</span></span><br><span class="line"><span class="keyword">if</span> (pBridge-&gt;Register(kDestroy) != NO_ERROR)</span><br><span class="line">    <span class="keyword">delete</span> pBridge;</span><br></pre></td></tr></table></figure><p>这种方式可以灵活控制内存释放的时间，但是会给开发人员带来<font color=blue><strong>频繁申请和释放内存的管理负担</strong></font>。倘若有一处内存区间由于程序员编码的问题忘记被回收，那么就会产生<font color=blue><strong>内存泄露</strong></font>，垃圾对象永远无法被清除，随着系统运行时间的不断增长，垃圾对象所耗内存可能持续上升，直到出现内存溢出并造成<font color=blue><strong>应用程序崩溃</strong></font>。</p><p>有了垃圾回收机制后，上述代码极有可能变成这样：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MibBridge *pBridge = <span class="keyword">new</span> cmBaseGroupBridge();</span><br><span class="line">pBridge-&gt;Register(kDestroy</span><br></pre></td></tr></table></figure><p>现在，处理 Java 以外，C#、Python、Ruby 等语言都是用了自动垃圾回收的思想，也是未来发展趋势。可以说，这种自动化的内存分配和垃圾回收的方式已经成为现代语言必备的标准。</p><h2 id="Java垃圾回收机制"><a href="#Java垃圾回收机制" class="headerlink" title="Java垃圾回收机制"></a>Java垃圾回收机制</h2><p>自动内存管理，无需开发人员手动参与内存分配与回收，这样<font color=red><strong>降低内存泄露和内存溢出的风险</strong></font>。</p><p>oracle 官网关于垃圾回收的介绍：<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/toc.html">https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/toc.html</a></p><p>对于Java开发人员而言，自动内存管理就像是一个黑匣子，如果过度依赖于“自动”，那么这将会是异常灾难，最严重的就会<font color=blue><strong>弱化Java开发人员在程序出现内存溢出时定位问题和解决问题的能力</strong></font>。</p><p>此时，了解JVM的自动内存分配和内存回收原理就显得非常重要，只有在真正了解JVM是如何管理内存后，我们才能够在遇见OutOfMemoryError时，快速地根据错误日志定位问题和解决问题。</p><p>当需要排查各种内存溢出、内存泄露问题时，当垃圾收集称为系统达到更高并发量的瓶颈时，我们就必须对这些“自动化”的技术<font color=blue><strong>实施比亚的监控和调节</strong></font>。</p><h3 id="应该关心哪些区域的回收？"><a href="#应该关心哪些区域的回收？" class="headerlink" title="应该关心哪些区域的回收？"></a>应该关心哪些区域的回收？</h3><p>垃圾回收器可以对年轻代回收，也可以对老年代回收，甚至是全堆和方法区（Java虚拟机规范没有规定必须对方法区进行回收）的回收。其中，<font color=red><strong>Java堆是垃圾回收器的工作重点</strong></font>。</p><ul><li><font color=red><strong>频繁收集新生代</strong></font></li><li><font color=red><strong>较少收集老年代</strong></font></li><li><font color=red><strong>基本不动方法区</strong></font></li></ul>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>数据传输过程</title>
      <link href="2020/02/12/%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%BF%87%E7%A8%8B/"/>
      <url>2020/02/12/%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在需要传输数据的源主机和目标主机之间，它们通过若干路由器或交换机连接。</p><a id="more"></a><img src="../images/计算机网络/1.png" alt="截屏2021-05-13 下午11.37.42" style="zoom:50%;" /><img src="./images/计算机网络/1.png" alt="截屏2021-05-13 下午11.37.42" style="zoom:50%;" /><img src="/images/计算机网络/1.png" alt="截屏2021-05-13 下午11.37.42" style="zoom:50%;" /><h2 id=""><a href="#" class="headerlink" title=""></a></h2><img src="../../images/计算机网络/1.png" alt="截屏2021-05-13 下午11.37.42" style="zoom:50%;" /><h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><h2 id="1-源主机和目标主机在同一个局域网"><a href="#1-源主机和目标主机在同一个局域网" class="headerlink" title="1. 源主机和目标主机在同一个局域网"></a>1. 源主机和目标主机在同一个局域网</h2><p>源主机和目标主机在同一个局域网内，中间通过交换机连接，采用了最常见的以太网协议</p><p>通讯开始时，源主机只有目标主机的 IP 地址，</p><p>并没有 MAC 地址。以太网通讯需要 MAC 地址，源主机会发起一个 ARP 请求去获得目标 IP 对应的 MAC 地址。</p><blockquote><p>源主机会缓存这个对应关系。第二次继续给相同 IP 发信息的时候，不需重新发起 ARP 请求。</p></blockquote><blockquote><p>无论是 ARP 请求，还是普通的数据包，都会先到达交换机。ARP 是一个广播请求，所以交换机会转发给所有其他主机，目标主机发现这个 IP 地址是自己的，于是返回自己的 MAC 地址。有了目标主机的 MAC 地址，源主机就可以发数据了。同样的，所有数据包都发给了交换机。</p></blockquote><p>交换机是性能极高的网络数据交换设备。它通常工作在网络协议的第二层，也就是数据链路层。这一层只认 MAC 地址，不认 IP 地址。</p><p>交换机在工作的过程中，会不断地收集资料去创建一个地址映射表：<code>MAC 地址 =&gt; 交换机端口</code>。这个表记录了某个 MAC 地址是在哪个端口上被发现的。</p><p>交换机收到一个数据包后，首先会进行学习，把源 MAC 地址和收到数据包的交换机端口对应起来。然后交换机查看数据包的目标 MAC 地址，并在地址映射表中找，如果找到对应的端口，那么就往这个端口转发数据包。</p><p>如果没找到，交换机可能会把这个数据包 “扩散” 出去，就好像收到广播数据包一样。这时如果目标主机收到广播过来的数据包后，回复了这个数据包，那么它的 MAC 地址和交换机端口的映射关系就也会被学习到。</p><p>当交换机初次加入网络时，由于地址映射表是空的，所以，所有的数据包将发往局域网内的全部端口，直到交换机 “学习” 到各个 MAC 地址为止。交换机刚刚启动时与传统的共享式集线器类似，直到地址映射表比较完整地建立起来后，它才真正发挥高性能。</p><h3 id="2-2-源主机和目标主机都有公网-IP-地址"><a href="#2-2-源主机和目标主机都有公网-IP-地址" class="headerlink" title="2.2. 源主机和目标主机都有公网 IP 地址"></a>2.2. 源主机和目标主机都有公网 IP 地址</h3><p>源主机和目标主机都有公网 IP 地址，它们中间经过若干交换机和路由器相连</p><p>路由器工作在网络协议的网络层。网络层看到的是 IP 协议，能够知道数据传输的源 IP 地址和目标 IP 地址。</p><p>路由器可以拥有一部分交换机的能力，比如，如果发现请求是局域网内的话，也可以引入类似交换机那样的基于 MAC 地址的映射表实现高速通讯。但总体来说，路由器要考虑的问题复杂很多，涉及 “最佳路由路径” 的问题。</p><ol><li>源主机发送的数据包，经由交换机（可选），到达本局域网的公网网关（路由器）。这个过程属于局域网内通讯。</li><li>路由器收到了数据包，发现目标主机是 Internet 上的某个远端的目标主机，于是对数据包进行拆包重组，形成新的数据包。</li><li>循着自身的路由表，把这个新数据包层层转发，最后到达目标主机对应的公网网关（路由器）上。</li><li>路由器发现是发给本局域网内的目标主机，于是再拆包重组，形成新的数据包。</li><li>新数据包转到局域网内，经由交换机（可选），并最终到达目标主机。如此，整个数据传输过程就结束了。</li></ol><h3 id="2-3-源主机和目标主机至少有一方在局域网内且只有私有-IP-地址"><a href="#2-3-源主机和目标主机至少有一方在局域网内且只有私有-IP-地址" class="headerlink" title="2.3. 源主机和目标主机至少有一方在局域网内且只有私有 IP 地址"></a>2.3. 源主机和目标主机至少有一方在局域网内且只有私有 IP 地址</h3><p>源主机和目标主机至少有一方在局域网内且只有私有 IP 地址，它们中间经过若干交换机和路由器相连。</p><blockquote><p>在 IPv4 地址区间中，有一些区段，比如 10.0.0.0 ~ 10.255.255.255、172.16.0.0 ~ 172.31.255.255、192.168.0.0 ~ 192.168.255.255 ，这几个 IP 地址区间都是私有 IP 地址，只用于局域网内通讯。</p></blockquote><p>NAT（Network Address Translation，网络地址转换）技术。源主机用的 IP+ 端口为 <code>iAddr:port1</code>，经过 NAT 网关后，NAT 将源主机的 IP 换成自己的公网 IP (eAddr)，端口随机分配(port2)。从目标主机看来，这个数据包是来自于 <code>eAddr:port2</code>。</p><p>然后，目标主机把数据包回复到 <code>eAddr:port2</code>，NAT 网关再把它转发给 <code>iAddr:port1</code>。也就是说，NAT 网关临时建立了一个双向的映射表 <code>iAddr:port1 &lt;=&gt; eAddr:port2</code>，一旦完成映射关系的建立，在映射关系删除前，eAddr:port2 就变成了 iAddr:port1 的 “替身”。这样，内网主机也就能够上网了。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(13)_直接内存</title>
      <link href="2020/02/10/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(13)_%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98/"/>
      <url>2020/02/10/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(13)_%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。直接内存是在Java堆外的、直接向系统申请的内存空间。来源于NIO，通过存在堆中的 DirectByteBuffer 操作 Native 内存。</p><a id="more"></a><h1 id="直接内存（Direct-Memory）"><a href="#直接内存（Direct-Memory）" class="headerlink" title="直接内存（Direct Memory）"></a>直接内存（Direct Memory）</h1><ul><li><p>不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。</p></li><li><p>直接内存是在Java堆外的、直接向系统申请的内存空间。</p></li><li><p>来源于NIO，通过存在堆中的DirectByteBuffer操作Native内存。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  IO                  NIO (New IO / Non-Blocking IO)</span></span><br><span class="line"><span class="comment"> *  byte[] / char[]     Buffer</span></span><br><span class="line"><span class="comment"> *  Stream              Channel</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 查看直接内存的占用与释放</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BufferTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> BUFFER = <span class="number">1024</span> * <span class="number">1024</span> * <span class="number">1024</span>;<span class="comment">//1GB</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="comment">// 直接分配本地内存空间</span></span><br><span class="line">        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(BUFFER);</span><br><span class="line">        System.out.println(<span class="string">&quot;直接内存分配完毕，请求指示！&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        scanner.next();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;直接内存开始释放！&quot;</span>);</span><br><span class="line">        byteBuffer = <span class="keyword">null</span>;</span><br><span class="line">        System.gc();</span><br><span class="line">        scanner.next();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="images/221.png" alt="img" style="zoom:100%;" /></li><li><p>通常，访问直接内存的速度会优于Java堆。即读写性能高。</p><ul><li>因此出于性能考虑，读写频繁的场合可能会考虑使用直接内存。</li><li>Java的NIO库允许Java程序使用直接内存，用于数据缓存区</li></ul><img src="images/222.png" alt="img" style="zoom:70%;" /><img src="images/223.png" alt="img" style="zoom:70%;" /></li></ul><hr><ul><li><p>也可能导致OutOfMemoryError异常</p></li><li><p>由于直接内存在Java堆外，因此它的大小不会直接受限于-Xmx指定的最大堆大小，但是系统内存是优先的，Java堆和直接内存的总和依然受限于操作系统能给的最大内存。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 本地内存的OOM:  OutOfMemoryError: Direct buffer memory</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BufferTest2</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> BUFFER = <span class="number">1024</span> * <span class="number">1024</span> * <span class="number">20</span>;<span class="comment">//20MB</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ArrayList&lt;ByteBuffer&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">                ByteBuffer byteBuffer = ByteBuffer.allocateDirect(BUFFER);</span><br><span class="line">                list.add(byteBuffer);</span><br><span class="line">                count++;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            System.out.println(count);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="images/224.png" alt="img" style="zoom:90%;" /></li><li><p>缺点</p><ul><li>分配回收成本高</li><li>不受JVM内存回收管理</li></ul></li><li><p>直接内存大小可以通过MaxDirectMemorySize设置</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 绕过DirectByteBuffer，直接分配本地内存</span></span><br><span class="line"><span class="comment"> * -Xmx20m -XX:MaxDirectMemorySize=10m</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> shkstart  shkstart@126.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span> 2020  0:36</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxDirectMemorySizeTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> _1MB = <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IllegalAccessException </span>&#123;</span><br><span class="line">        Field unsafeField = Unsafe.class.getDeclaredFields()[<span class="number">0</span>];</span><br><span class="line">        unsafeField.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">        Unsafe unsafe = (Unsafe) unsafeField.get(<span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            unsafe.allocateMemory(_1MB);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="images/225.png" alt="img" style="zoom:90%;" /></li><li><p>如果不指定，默认与堆的最大值-Xmx参数值一致</p></li></ul><hr><img src="images/226.png" alt="img" style="zoom:90%;" /><p>简单理解：<font color=red><strong>java process memory = java heap + native memory</strong></font></p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2020/02/07/MySQL%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96(3)%EF%BC%9A%E5%AD%90%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
      <url>2020/02/07/MySQL%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96(3)%EF%BC%9A%E5%AD%90%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2020/02/07/MySQL%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96(2)%EF%BC%9A%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0/"/>
      <url>2020/02/07/MySQL%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96(2)%EF%BC%9A%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-查询优化算法"><a href="#1-查询优化算法" class="headerlink" title="1. 查询优化算法"></a>1. 查询优化算法</h1>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2020/02/07/MySQL%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96(1)%EF%BC%9A%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"/>
      <url>2020/02/07/MySQL%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96(1)%EF%BC%9A%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><h2 id="1-1-SQL-执行时间长的原因"><a href="#1-1-SQL-执行时间长的原因" class="headerlink" title="1.1. SQL 执行时间长的原因"></a>1.1. <code>SQL</code> 执行时间长的原因</h2><ul><li>查询语句写的烂</li><li>索引失效</li><li>关联查询有太多 <code>Join</code></li><li>服务器调优及各个参数设置，如缓冲、线程数等</li></ul><h2 id="1-2-SQL-执行顺序"><a href="#1-2-SQL-执行顺序" class="headerlink" title="1.2. SQL 执行顺序"></a>1.2. <code>SQL</code> 执行顺序</h2><ul><li><p><strong><code>FROM</code></strong> <left_table></p><blockquote><p><code>sql</code> 首先执行 <code>from</code> 将数据从硬盘加载到数据缓冲区中，以便对这些数据进行操作。如果有多个表则求所有表的笛卡尔积。<br><code>[ table1的记录条数 * table2的记录条数 * tableN的记录条数）这时第一个虚拟表产生VT1]</code></p></blockquote></li><li><p><strong><code>ON</code></strong> <join_condition></p><blockquote><p>其次执行<code>on</code>，从 <code>VT1</code> 中取出匹配 <code>on</code> 条件的行, 产生 <code>VT2</code>。</p></blockquote></li><li><p><strong><code>JOIN</code></strong> </p><blockquote><p><code>left join</code>，<code>right join</code> 外部连接就是在这个时候执行的，在 <code>VT2</code> 的基础上添加符合条件的外部的行，产生 <code>VT3</code>。</p></blockquote></li><li><p><strong><code>WHERE</code></strong> <where_condition></p><blockquote><p>执行 <code>where</code> 过滤，产生 <code>VT4</code><br>由于这个时候 <code>select</code> 没有执行，所以 <code>select</code> 中的别名不可以用于 <code>where</code></p></blockquote></li><li><p><strong><code>GROUP BY</code></strong> <group_by_list></p><blockquote><p>在 <code>VT4</code> 的基础上执行 <code>group by</code> 分组数据，产生 <code>VT5</code>。</p></blockquote></li><li><p><strong><code>HAVING</code></strong>  <having_condition></p><blockquote><p>在 <code>VT5</code> 的基础上执行 <code>having</code> 过滤，产生 <code>VT6</code>。</p></blockquote></li><li><p><strong><code>SELECT</code></strong> </p><blockquote><p>查出我们要的字段，产生 <code>VT7</code></p></blockquote></li><li><p><strong><code>DISTINCT</code></strong> <select_list></p></li><li><p><strong><code>ORDER BY</code></strong> <order_by_condition></p><blockquote><p>排序 产生 <code>VT8</code></p></blockquote></li><li><p><strong><code>LIMIT</code></strong> <limit_number></p><blockquote><p>限制返回行数</p></blockquote></li></ul><h1 id="2-SQL-性能分析"><a href="#2-SQL-性能分析" class="headerlink" title="2. SQL 性能分析"></a>2. <code>SQL</code> 性能分析</h1><h1 id="3-Explain"><a href="#3-Explain" class="headerlink" title="3. Explain"></a>3. <code>Explain</code></h1><blockquote><p><code>Explain</code> 命令，可以用显示 <code>MySQL</code> 如何使用索引来处理 <code>select</code> 语句以及连接表</p></blockquote><h2 id="3-1-字段"><a href="#3-1-字段" class="headerlink" title="3.1. 字段"></a>3.1. 字段</h2><h3 id="3-1-1-id"><a href="#3-1-1-id" class="headerlink" title="3.1.1. id"></a>3.1.1. <code>id</code></h3><ul><li><p>概述</p><blockquote><p>查询序号，表示查询中 <code>select</code> 语句执行顺序</p></blockquote></li><li><p>说明</p><ul><li><code>id</code> 相同时，执行顺序由上至下</li><li>子查询 <code>id</code> 的序号会递增，<code>id</code> 值越大优先级越高，越先被执行</li><li><code>id</code> 相同，可以视为一组，从上往下顺序执行</li></ul></li></ul><h3 id="3-2-2-select-type"><a href="#3-2-2-select-type" class="headerlink" title="3.2.2. select_type"></a>3.2.2. <code>select_type</code></h3><ul><li><p>概述</p><blockquote><p>查询类型，主要是用于区别普通查询、联合查询、字查询等复杂查询</p></blockquote></li><li><p>说明</p><ul><li><code>SIMPLE </code>表示简单的 <code>select</code>，没有 <code>union</code> 和子查询</li><li><code>PRIMARY </code> 子查询的语句中，最外面的 <code>select</code> 查询就是 <code>primary</code></li><li><code>UNION</code>：<code>union</code> 语句的第二个或者说是后面那一个</li><li><code>DERIVED</code>在 <code>from</code> 列表中的子查询被标记为 <code>DERIVED</code>[衍生]，<code>MySQL</code>会递归执行这些子查询，并把结果放在临时表中。</li></ul></li></ul><h3 id="3-2-3-table"><a href="#3-2-3-table" class="headerlink" title="3.2.3. table"></a>3.2.3. <code>table</code></h3><blockquote><p>显示这一步所访问数据库中表名称[显示这一行的数据是关于哪张表的]，有时不是真实的表名字，可能是简称</p></blockquote><h3 id="3-2-4-type"><a href="#3-2-4-type" class="headerlink" title="3.2.4. type"></a>3.2.4. <code>type</code></h3><blockquote><p>表示 <code>MySQL</code> 在表中找到所需行的方式，又称**”访问类型”**</p><p>常用的类型有:<strong><code>ALL</code>,<code> index</code>,<code> range</code>,<code> ref</code>,<code> eq_ref</code>,<code> const</code>,<code> system</code></strong>   <strong>[从左到右，性能从差到好]</strong></p></blockquote><ul><li><p><code>ALL</code></p><blockquote><p><code>Full Table Scan</code>， <code>MySQL</code> 将遍历全表以找到匹配的行</p></blockquote></li><li><p><code>index</code></p><blockquote><p><code>Full Index Scan</code>，遍历所有的索引树，比 <code>ALL</code> 要快的多，因为索引文件要比数据文件小的多</p></blockquote></li><li><p><code>range</code></p><blockquote><p>查找某个索引的部分索引，一般在 <code>where</code>子句中使用 <code>&lt;</code> 、<code>&gt;</code>、<code>in</code>、<code>between</code> 等关键词。只检索给定范围的行，属于范围查找</p></blockquote></li><li><p><code>ref</code></p><blockquote><p><strong><u>查找非唯一性索引</u>**，</strong>返回匹配某一条件的多条数据**。属于精确查找、数据返回可能是多条</p></blockquote></li><li><p><code>eq_ref</code></p><blockquote><p><u><strong>查找唯一性索引</strong></u>，<strong>返回的数据至多一条</strong>。属于精确查找</p></blockquote></li><li><p><code>const</code></p><blockquote><p><u><strong>查找主键索引</strong></u>，<strong>返回的数据至多一条（0或者1条）</strong>。属于精确查找（id为主键）</p></blockquote></li><li><p><code>system</code></p><blockquote><p>查找主键索引，<strong>返回的数据至多一条（0或者1条）</strong>。属于精确查找</p></blockquote></li></ul><h3 id="3-2-5-possible-keys"><a href="#3-2-5-possible-keys" class="headerlink" title="3.2.5. possible_keys"></a>3.2.5. <code>possible_keys</code></h3><blockquote><p>显示可能应用在这张表中的索引，一个或多个</p><p>查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用。</p></blockquote><h3 id="3-2-6-key"><a href="#3-2-6-key" class="headerlink" title="3.2.6. key"></a>3.2.6. <code>key</code></h3><blockquote><p>显示 <code>MySQL</code> 实际决定使用的索引</p><p>如果没有选择索引，键是 <code>NULL</code>。</p><p>要想强制 <code>MySQL</code> 使用或忽视 <code>possible_keys</code> 列中的索引，在查询中使用 <code>FORCE INDEX</code>、<code>USE INDEX</code> 或者<code>IGNORE INDEX</code></p></blockquote><h3 id="3-2-7-key-len"><a href="#3-2-7-key-len" class="headerlink" title="3.2.7. key_len"></a>3.2.7. <code>key_len</code></h3><blockquote><p>表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即 <code>key_len</code> 是根据表定义计算而得，不是通过表内检索出的）</p></blockquote><blockquote><p><code>key_len</code>公式</p><ul><li><p><code>varchar(10)</code> 变长字段并且允许<code>null</code> </p><blockquote><p><code>key_len</code> = 10 * (<strong>character set</strong>: <code>utf8=3</code>, <code>gbk=3</code>, <code>latin=1</code>)  + 1 [null] + 2 [变长字段]</p></blockquote></li><li><p><code>varchar(10)</code> 变长字段不允许<code>null</code> </p><blockquote><p><code>key_len</code> = 10 * (<strong>character set</strong>: <code>utf8=3</code>, <code>gbk=3</code>, <code>latin=1</code>)  + 2 [变长字段]</p></blockquote></li><li><p><code>char(10)</code> 固定字段并且允许<code>null</code> </p><blockquote><p><code>key_len</code> = 10 * (<strong>character set</strong>: <code>utf8=3</code>, <code>gbk=3</code>, <code>latin=1</code>)  + 1 [null]</p></blockquote></li><li><p><code>char(10)</code> 固定字段不允许<code>null</code> </p><blockquote><p><code>key_len</code> = 10 * (<strong>character set</strong>: <code>utf8=3</code>, <code>gbk=3</code>, <code>latin=1</code>)</p></blockquote></li></ul></blockquote><h3 id="3-2-8-ref"><a href="#3-2-8-ref" class="headerlink" title="3.2.8. ref"></a>3.2.8. <code>ref</code></h3><h3 id="3-2-9-rows"><a href="#3-2-9-rows" class="headerlink" title="3.2.9. rows"></a>3.2.9. <code>rows</code></h3><blockquote><p><code>MySQL</code> 估计为了找到所需的行而要读取的行，<code>rows</code> 值很重要，它决定采用哪个索引以及是否放弃索引改为全表。它是一个平均数，用来估算查找需要行而必须读取的平均值。</p></blockquote><h3 id="3-2-10-6-extra"><a href="#3-2-10-6-extra" class="headerlink" title="3.2.10. 6.extra"></a>3.2.10. <code>6.extra</code></h3><ul><li><p><code>Using filesort</code></p><blockquote><p>说明 <code>MySQL</code>会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取</p></blockquote></li><li><p><code>Using temporary</code></p></li><li><p><code>Using index</code></p><blockquote><p> 出现这个说明 <code>MySQL</code> 使用了覆盖索引，避免访问了表的数据行，效率不错！通俗的说也就是查询的列不需要回表，在索引树上就能拿到结果</p></blockquote></li><li><p><code>Using where</code></p><blockquote><p> 说明服务器在存储引擎收到行后将进行过滤。有些where中的条件会有属于索引的列，当它读取使用索引的时候，就会被过滤，所以会出现有些where语句并没有在extra列中出现using where这么一个说明。</p></blockquote></li><li><p><code>Using join buffer</code></p></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>TCP 重传机制</title>
      <link href="2020/02/06/TCP%20%E9%87%8D%E4%BC%A0%E6%9C%BA%E5%88%B6/"/>
      <url>2020/02/06/TCP%20%E9%87%8D%E4%BC%A0%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>重传是保证 TCP 可靠性的重要手段之一，因为数据包可能因为网络等问题导致数据包丢失，甚至是接收方发送的 ACK 包本身丢失，它们都会导致发送方重新发送数据包。TCP使用两套独立的机制来完成重传，一是基于时间，二是基于确认信息的构成。</p><a id="more"></a><h2 id="1-超时重传"><a href="#1-超时重传" class="headerlink" title="1. 超时重传"></a>1. 超时重传</h2><p>发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 <code>ACK</code> 确认应答报文，就会重发该数据</p><p>检测丢失 segment 的方法，每一次开始发送一个 TCP segment 的时候，就启动重传定时器，定时器的时间一开始是一个预设的值（Linux 规定为1s）,如果在 ACK 收到之前，定时器到期，协议栈就会认为这个片段被丢失，重新传送数据。</p><h2 id="2-快速重传"><a href="#2-快速重传" class="headerlink" title="2. 快速重传"></a>2. 快速重传</h2><p>TCP 还有另外一种<strong>快速重传（Fast Retransmit）机制</strong>，它<strong>不以时间为驱动，而是以数据驱动重传</strong>。</p><p>快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。</p><h2 id="3-SACK"><a href="#3-SACK" class="headerlink" title="3. SACK"></a>3. SACK</h2><p>由于采用累积 ACK 确认，因此 TCP 有时候并不能正确地确认之前已经接收的数据。</p><p>SACK 信息保存于 SACK 选项中，包含了接收方已经接收的数据块的序列号范围，每个范围被称作一个SACK块，由一对32位的序列号表示。因此，一个 SACK 选项包含了 n 个SACK块，长度为（8n+2）个字节，增加的2个字节用于保存SACK选项的种类与长度。由于TCP头部选项的空间有限，因此一个报文段中发送的最大的 SACK 块数目为 3（假设使用了时间戳选项）。虽然只用SYN报文段才能包含“选择确认”选项，但是只要发送方已经发送了该选项，SACK 块就能通过任何报文段发送出去。<br><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-15 下午11.51.52.png" alt="截屏2021-05-15 下午11.51.52" style="zoom:50%;" /></p><h2 id="4-Duplicate-SACK"><a href="#4-Duplicate-SACK" class="headerlink" title="4. Duplicate SACK"></a>4. Duplicate SACK</h2><p>Duplicate SACK又称D-SACK，<strong>其主要使用了SACK来告诉发送方有哪些数据被重复接收了</strong></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>POP3&amp;IMAP 协议</title>
      <link href="2020/02/06/POP3&amp;IMAP%20%E5%8D%8F%E8%AE%AE/"/>
      <url>2020/02/06/POP3&amp;IMAP%20%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>邮箱的收发信协议主要有SMTP、POP3、IMAP三个，此外与邮件传输相关的还有安全协议SSL。</strong></p><a id="more"></a><h2 id="1-POP3-简介"><a href="#1-POP3-简介" class="headerlink" title="1. POP3 简介"></a>1. POP3 简介</h2><p>POP3 全称为 Post Office Protocol version3, 即邮局协议第3版。它被用户代理用来邮件服务器取得邮件。POP3 采用的也是 C/S 通信模型</p><h2 id="2-POP3-通信过程"><a href="#2-POP3-通信过程" class="headerlink" title="2. POP3 通信过程"></a>2. POP3 通信过程</h2><ol><li>用户运行用户代理(如Foxmail, Outlook Express)</li><li>用户代理(客户端)与邮件服务器的 110 端口建立 TCP 连接</li><li>客户端向服务器端发出各种命令，来请求各种服务(如查询邮箱信息，下载某封邮件等)</li><li>服务端解析用户的命令，做出相应动作并返回给客户端一个响应</li><li>(3) 和 (4)交替进行，直到接收完所有邮件转到步骤6)，或两者的连接被意外中断而直接退出。</li><li>用户代理解析从服务器端获得的邮件，以适当地形式（如可读）的形式呈现给用户</li></ol><h2 id="3-IMAP-简介"><a href="#3-IMAP-简介" class="headerlink" title="3. IMAP 简介"></a>3. IMAP 简介</h2><p>IMAP 协议相对于 POP3 协议而言，它定了更为强大的邮件接收功能</p><ol><li>IMAP 具有摘要浏览功能，可以让用户在读完所有邮件的主题、发件人、大小等信息后，再由用户做出是否下载或直接在服务器上删除的决定。</li><li>IMAP 可以让用户有选择性地下载邮件附件。例如一封邮件包含3个附件，如果用户确定其中只有2个附件对自已有用，就可只下载这2个附件，而不必下载整封邮件，从而节省了下载时间。</li><li>IMAP 可以让用户在邮件服务器上创建自己的邮件夹，分类保存各个邮件。</li></ol><h2 id="4-MIME"><a href="#4-MIME" class="headerlink" title="4. MIME"></a>4. MIME</h2><p>早期人们在使用电子邮件时，都是使用普通文本内容的电子邮件内容进行交流，由于互联网的迅猛发展，人们希望在邮件中嵌入图片、声音、动画和附件等二进制数据。但在以往的邮件只能发送文本信息，无法发送非文本的邮件，针对这个问题，专门为此定义了 MIME (Multipurpose Internet Mail Extension，多用途 Internet 邮件扩展)协议。</p><p>一封 MIME 邮件中的 MIME 消息可以有三种组合关系：混合、关联、选择，它们对应 MIME 类型 <code>multipart/mixed</code>, <code>multipart/related</code>, <code>multipart/alternative</code></p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-14 上午11.27.05.png" alt="截屏2021-05-14 上午11.27.05" style="zoom:80%;" /><p>邮件中只有普通文本内容与 HTML 文本内容，那么整封邮件的 MIME 类型则应定义为 <code>multipart/alternative</code> 如果整封邮件中包含有 HTML 文本内容和内嵌资源，但不包含附件，那么整封邮件的 MIME 类型则应该定义为 <code>multipart/related</code></p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h2><p>POP3 相对于因特网报文存取协议 IMAP(Internet Message Access Protocol) 的最大的不足是只是一个脱机协议，客户与服务器的交互性不是特别好。例如不能直接在邮箱中创建文件夹，不太好选择性地下载邮件的某部分等。然而，它也有自己的优势，那就是协议简单，容易实现，成本低，这是 POP3 用得很广泛而 IMAP 几近淘汰的最重要的原因。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2020/02/06/MySQL%20%E9%94%81/"/>
      <url>2020/02/06/MySQL%20%E9%94%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><h2 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1. 简介"></a>1.1. 简介</h2><blockquote><p>数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。加锁是实现数据库并发控制的一个非常重要的技术。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。<br>相对其他数据库而言，<code>MySQL</code> 的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。</p></blockquote><h2 id="1-2-分类"><a href="#1-2-分类" class="headerlink" title="1.2. 分类"></a>1.2. 分类</h2><h3 id="1-2-1-读锁-amp-写锁"><a href="#1-2-1-读锁-amp-写锁" class="headerlink" title="1.2.1. 读锁 &amp; 写锁"></a>1.2.1. 读锁 <code>&amp;</code> 写锁</h3><h3 id="1-2-2-表锁-amp-行锁"><a href="#1-2-2-表锁-amp-行锁" class="headerlink" title="1.2.2. 表锁 &amp; 行锁"></a>1.2.2. 表锁 <code>&amp;</code> 行锁</h3><blockquote><p> <code>MySQL</code>大致可归纳为以下 <code>3</code> 种锁：</p></blockquote><ul><li><p>表级锁：</p><blockquote><p>偏向 <code>MyISAM</code> 存储引擎，开销小，加锁快<br>不会出现死锁<br>锁定粒度大，发生锁冲突的概率最高，并发度最低。</p></blockquote></li><li><p>行级锁</p><blockquote><p>开销大，加锁慢</p><p>会出现死锁 </p><p>锁定粒度最小，发生锁冲突的概率最低，并发度也最高</p></blockquote></li><li><p>页面锁</p><blockquote><p>开销和加锁时间界于表锁和行锁之间 </p><p>会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</p></blockquote></li></ul><h2 id="1-表锁"><a href="#1-表锁" class="headerlink" title="1. 表锁"></a>1. 表锁</h2><h2 id="1-1-简介-1"><a href="#1-1-简介-1" class="headerlink" title="1.1. 简介"></a>1.1. 简介</h2><ul><li><code>MySQL</code> 的表级锁有两种模式<ul><li>表共享读锁 <code>Table Read Lock</code></li><li>写独占写锁 <code>Table Write Lock</code></li></ul></li></ul><h2 id="1-2-相关-SQL-语句"><a href="#1-2-相关-SQL-语句" class="headerlink" title="1.2. 相关 SQL 语句"></a>1.2. 相关 <code>SQL</code> 语句</h2><ul><li><p>手动增加表锁</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lock table 表名字 read(write)，表名字read(write)，...;</span><br></pre></td></tr></table></figure></li><li><p>查看表上加过的锁</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show open tables;</span><br></pre></td></tr></table></figure></li><li><p>释放表锁</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unlock tables;</span><br></pre></td></tr></table></figure><h2 id="1-3-实验数据"><a href="#1-3-实验数据" class="headerlink" title="1.3. 实验数据"></a>1.3. 实验数据</h2></li><li><p>创建 <code>Person</code> 数据表，其存储引擎为 <code>MyISAM</code></p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE person (</span><br><span class="line">  id int primary key, </span><br><span class="line">  name varchar(30), </span><br><span class="line">  Age int</span><br><span class="line">)ENGINE&#x3D;MyISAM DEFAULT CHARSET&#x3D;utf8;</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from person;</span><br><span class="line">+----+-------+------+</span><br><span class="line">| id | name  | Age  |</span><br><span class="line">+----+-------+------+</span><br><span class="line">|  6 | go    |   11 |</span><br><span class="line">|  5 | hello |   11 |</span><br><span class="line">|  4 | jack  |   11 |</span><br><span class="line">|  3 | chen  |   12 |</span><br><span class="line">|  2 | tom   |   10 |</span><br><span class="line">|  1 | jerry |   16 |</span><br><span class="line">+----+-------+------+</span><br><span class="line">6 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></li></ul><h3 id="1-1-读锁"><a href="#1-1-读锁" class="headerlink" title="1.1. 读锁"></a>1.1. 读锁</h3><h4 id="1-1-1-简介"><a href="#1-1-1-简介" class="headerlink" title="1.1.1. 简介"></a>1.1.1. 简介</h4><p>对 <code>MyISAM</code> 表加读锁，不会阻塞其他进程对同一表的读请求，但会阻塞对同一表的写请求，只有当读锁释放后，才会执行其他进程的写操作。</p><h4 id="1-1-2-学习示例"><a href="#1-1-2-学习示例" class="headerlink" title="1.1.2. 学习示例"></a>1.1.2. 学习示例</h4><p>在客户端 [1]中，为 <code>person</code> 表添加读锁</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; lock table person read;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">mysql&gt; show open tables;</span><br><span class="line">+--------------------+---------------------------------------------+--------+-------------+</span><br><span class="line">| Database           | Table                                       | In_use | Name_locked |</span><br><span class="line">+--------------------+---------------------------------------------+--------+-------------+</span><br><span class="line">| performance_schema | events_statements_current                   |      0 |           0 |</span><br><span class="line">| performance_schema | events_stages_current                       |      0 |           0 |</span><br><span class="line">| performance_schema | events_waits_summary_by_instance            |      0 |           0 |</span><br><span class="line">| test               | person                                      |      1 |           0 |</span><br></pre></td></tr></table></figure><blockquote><p>对 <code>MyISAM</code> 表加读锁，不会阻塞其他进程对同一表的读请求</p></blockquote><p>在客户端 [2] 中，可以正常读取数据表 <code>person</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from person;</span><br><span class="line">+<span class="comment">----+-------+------+</span></span><br><span class="line">| id | name  | Age  |</span><br><span class="line">+<span class="comment">----+-------+------+</span></span><br><span class="line">|  6 | go    |   11 |</span><br><span class="line">|  5 | hello |   11 |</span><br><span class="line">|  4 | jack  |   11 |</span><br><span class="line">|  3 | chen  |   12 |</span><br><span class="line">|  2 | tom   |   10 |</span><br><span class="line">|  1 | jerry |   16 |</span><br><span class="line">+<span class="comment">----+-------+------+</span></span><br><span class="line">6 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><blockquote><p>对 <code>MyISAM</code> 表加读锁，会阻塞其他进程对同一表的写请求</p></blockquote><p>在客户端 [2] 中，无法正常修改数据表 <code>person</code>,会一直处于阻塞状态。直至客户端 [1] 释放表锁。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into person (id, name, Age) values (7, &#x27;zxc&#x27;, 11);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><font color='red'><strong>注意:</strong></font> 在客户端 [1] 中，无法正常查看其他数据表数据。直至客户端 [1] 释放表锁。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from book;</span><br><span class="line">ERROR 1100 (HY000): Table &#x27;book&#x27; was not locked <span class="keyword">with</span> <span class="keyword">LOCK</span> <span class="keyword">TABLES</span></span><br></pre></td></tr></table></figure><h3 id="1-2-写锁"><a href="#1-2-写锁" class="headerlink" title="1.2. 写锁"></a>1.2. 写锁</h3><h4 id="1-2-1-简介"><a href="#1-2-1-简介" class="headerlink" title="1.2.1. 简介"></a>1.2.1. 简介</h4><blockquote><p>对 <code>MyISAM</code> 表加写锁，会阻塞其他进程对同一表的读和写操作，只有当写锁释放后，才会执行其他进程的写操作。</p></blockquote><h4 id="1-2-2-学习示例"><a href="#1-2-2-学习示例" class="headerlink" title="1.2.2. 学习示例"></a>1.2.2. 学习示例</h4><blockquote><p>在客户端 <code>[1]</code>中，为 <code>person</code> 表添加读锁</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; lock table person write;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">mysql&gt; show open tables;</span><br><span class="line">+--------------------+--------------------------------------------+--------+-------------+</span><br><span class="line">| Database           | Table                                      | In_use | Name_locked |</span><br><span class="line">+--------------------+--------------------------------------------+--------+-------------+</span><br><span class="line">| performance_schema | events_statements_current                  |      0 |           0 |</span><br><span class="line">| performance_schema | events_stages_current                      |      0 |           0 |</span><br><span class="line">| performance_schema | events_waits_summary_by_instance           |      0 |           0 |</span><br><span class="line">| test               | person                                     |      1 |           0 |</span><br></pre></td></tr></table></figure><blockquote><p>对 <code>MyISAM</code> 表加写锁，会阻塞其他进程对同一表的读请求，直至客户端 [1]释放锁</p></blockquote><p>在客户端 [2] 中，读取数据表 <code>person</code>出现阻塞</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from person;</span><br><span class="line">mysql&gt;</span><br><span class="line">mysql&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>对 <code>MyISAM</code> 表加读锁，会阻塞其他进程对同一表的写请求</p></blockquote><p>在客户端 [2] 中，无法正常修改数据表 <code>person</code>,会一直处于阻塞状态。直至客户端 [1] 释放表锁。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into person (id, name, Age) values (9, &#x27;chener&#x27;, 11);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="1-3-分析表锁定"><a href="#1-3-分析表锁定" class="headerlink" title="1.3. 分析表锁定"></a>1.3. 分析表锁定</h3><blockquote><p> 可以通过 <code>show status like &#39;table%&#39;</code> 检查 <code>table_locks_waited</code> 和 <code>table_locks_immediate</code> 状态变量来分析系统上的表锁定</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show status like &#39;table%&#39;;</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">| Variable_name              | Value |</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">| Table_locks_immediate      | 142   |</span><br><span class="line">| Table_locks_waited         | 0     |</span><br><span class="line">| Table_open_cache_hits      | 4     | &#96;</span><br><span class="line">| Table_open_cache_misses    | 4     |</span><br><span class="line">| Table_open_cache_overflows | 0     |</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">5 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><ul><li><p><code>Table_locks_immediate</code></p><blockquote><p>产生表级锁定的次数，表示可以立即获取锁的查询次数，每次立即获取锁加1</p></blockquote></li><li><p><code>Table_locks_waited</code></p><blockquote><p>出现表级锁定争用发生等待的次数(不能立即获取锁的次数，每等待一次锁值加1)，此值高则 说明存在着较严重的表级锁争用情况。</p></blockquote></li></ul><p>此外，<code>MyISAM</code> 的读写锁调度是写优先，这也是 <code>MyISAM</code> 不适合做以数据写如为主的表引擎，因为在写锁后，其他线程不能做任何操作，大量的更新操作会使查询很难得到锁，从而造成永远阻塞。</p><h2 id="2-行锁"><a href="#2-行锁" class="headerlink" title="2. 行锁"></a>2. 行锁</h2><h2 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1. 概述"></a>2.1. 概述</h2><blockquote><p>单条索引记录上加锁，<code>record lock</code> 锁住的永远是索引，而非记录本身，即使该表上没有任何索引，那么<code>innodb</code> 会在后台创建一个隐藏的聚集主键索引，那么锁住的就是这个隐藏的聚集主键索引。所以说当一条<code>sql</code> 没有任何索引时，那么将会在每一条聚集索引后面加 <code>X</code> 锁，这个类似于表锁，但原理上和表锁应该是完全不同的。</p></blockquote><blockquote><p> 在 <code>InnoDB</code> 中，除单个 <code>SQL</code> 组成的事务外，锁是逐步获得的，这就决定了在 <code>InnoDB</code> 中发生死锁是可能的。<br> 行级锁只在存储引擎层实现，而 <code>MySQL</code> 服务器层没有实现。 行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理<code>OLTP</code>系统。</p><p> 行锁开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。最大程度的支持并发，同时也带来了最大的锁开销。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set autocommit &#x3D; 0;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update staffs set age&#x3D;&#39;16&#39; where id&#x3D;&#39;2&#39;;</span><br><span class="line">Query OK, 1 row affected (0.12 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from staffs;</span><br><span class="line">+----+------+-----+---------+---------------------+</span><br><span class="line">| id | name | age | pos     | add_time            |</span><br><span class="line">+----+------+-----+---------+---------------------+</span><br><span class="line">|  1 | Z3   |  22 | manager | 2019-11-24 05:36:40 |</span><br><span class="line">|  2 | July |  16 | dev     | 2019-11-24 05:36:40 |</span><br><span class="line">|  3 | 2000 |  22 | dev     | 2019-11-24 05:36:40 |</span><br><span class="line">+----+------+-----+---------+---------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from staffs;</span><br><span class="line">+----+------+-----+---------+---------------------+</span><br><span class="line">| id | name | age | pos     | add_time            |</span><br><span class="line">+----+------+-----+---------+---------------------+</span><br><span class="line">|  1 | Z3   |  22 | manager | 2019-11-24 05:36:40 |</span><br><span class="line">|  2 | July |  22 | dev     | 2019-11-24 05:36:40 |</span><br><span class="line">|  3 | 2000 |  22 | dev     | 2019-11-24 05:36:40 |</span><br><span class="line">+----+------+-----+---------+---------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><h3 id="2-2-行锁演示案例"><a href="#2-2-行锁演示案例" class="headerlink" title="2.2. 行锁演示案例"></a>2.2. 行锁演示案例</h3><p><img src="https://img-blog.csdnimg.cn/20200111100156168.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update staffs <span class="built_in">set</span> age=<span class="string">&#x27;3&#x27;</span> <span class="built_in">where</span> id=<span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">Query OK, 1 row affected (0.01 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 阻塞</span></span><br><span class="line">mysql&gt; update staffs <span class="built_in">set</span> age=<span class="string">&#x27;10&#x27;</span> <span class="built_in">where</span> id=<span class="string">&#x27;1&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; commit;</span><br><span class="line">Query OK, 0 rows affected (0.13 sec)</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update staffs <span class="built_in">set</span> age=<span class="string">&#x27;10&#x27;</span> <span class="built_in">where</span> id=<span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">Query OK, 1 row affected (43.86 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; commit ;</span><br><span class="line">Query OK, 0 rows affected (0.05 sec)</span><br></pre></td></tr></table></figure><blockquote><p>不同行不阻塞</p></blockquote><h3 id="2-3-行锁升级为表锁"><a href="#2-3-行锁升级为表锁" class="headerlink" title="2.3. 行锁升级为表锁"></a>2.3. 行锁升级为表锁</h3><p>varchar必须用 ‘’</p><h3 id="2-5-锁定一行"><a href="#2-5-锁定一行" class="headerlink" title="2.5. 锁定一行"></a>2.5. 锁定一行</h3><p><img src="https://img-blog.csdnimg.cn/20200111103106459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200111103446655.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200111131714835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2020011113173370.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200111131817318.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="3-间隙锁"><a href="#3-间隙锁" class="headerlink" title="3. 间隙锁"></a>3. 间隙锁</h2><h2 id="3-1-简介"><a href="#3-1-简介" class="headerlink" title="3.1. 简介"></a>3.1. 简介</h2><blockquote><p>编程的思想源于生活，生活中的例子能帮助我们更好的理解一些编程中的思想。<br>生活中排队的场景，小明，小红，小花三个人依次站成一排，此时，如何让新来的小刚不能站在小红旁边，这时候只要将小红和她前面的小明之间的空隙封锁，将小红和她后面的小花之间的空隙封锁，那么小刚就不能站到小红的旁边。这里的小红，小明，小花，小刚就是数据库的一条条记录。<br>他们之间的空隙也就是间隙，而封锁他们之间距离的锁，叫做间隙锁。</p></blockquote><blockquote><p>当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，<code>InnoDB</code> 会给符合条件的已有数据记录的索引项加锁，对于键值在条件范围内但并不存在的记录，叫做  <strong>间隙 <code>GAP</code></strong></p><p><code>InnoDB</code> 也会对这个 <strong>间隙 <code>GAP</code></strong> 加锁，这种锁机制就是所谓的  <strong>间隙锁 <code>Next-Key</code> 锁</strong></p></blockquote><h2 id="3-2-innodb-使用间隙锁的条件"><a href="#3-2-innodb-使用间隙锁的条件" class="headerlink" title="3.2. innodb 使用间隙锁的条件"></a>3.2. <code>innodb</code> 使用间隙锁的条件</h2><ul><li>必须在 <code>REPEATABLE READ</code> 级别下</li><li>检索条件必须有索引，如果没有索引，<code>MySQL</code> 会全表扫描，那样会锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加。</li></ul><h3 id="3-2-危害"><a href="#3-2-危害" class="headerlink" title="3.2. 危害"></a>3.2. 危害</h3><blockquote><p> 执行查询过程中通过范围查找会锁定整个范围内的所有索引键值，即使这个键值并不存在，造成锁定的时候无法插入键值范围内的任何数据，在某些场景下可能对性能造成很大的危害。</p></blockquote><h3 id="3-3-示例"><a href="#3-3-示例" class="headerlink" title="3.3. 示例"></a>3.3. 示例</h3><h2 id="4-死锁"><a href="#4-死锁" class="headerlink" title="4. 死锁"></a>4. 死锁</h2><p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。</p><p>如下图所示，事务 <code>A</code> 在等待事务 <code>B</code> 释放 <code>id = 2</code> 的行锁，而事务 <code>B</code> 在等待 事务 <code>A</code> 释放 <code>id = 1</code> 的行锁，事务 <code>A</code>  和事务 <code>B</code>  在互相等待对方的资源释放，就是进入了死锁状态。</p><p>当出现死锁以后，有两种策略</p><p>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 <code>innodb_lock_wait_timeout</code> 来设置。</p><blockquote><p>在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间是无法接受的。但是，如果把这个时间设置成一个很小的值，比如 1s。出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待会出现很多误伤。</p></blockquote><p>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 <code>innodb_deadlock_detect</code> 设置为 <code>on</code>，表示开启这个逻辑。</p><p>每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。</p><blockquote><p>innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。</p></blockquote><h4 id="热点行更新导致的性能问题"><a href="#热点行更新导致的性能问题" class="headerlink" title="热点行更新导致的性能问题"></a>热点行更新导致的性能问题</h4><p>每个新来的被堵住的线程，都需要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。CPU 利用率很高，但是每秒却执行不了几个事务。</p><ol><li><p>临时把死锁检测关掉。</p><blockquote><p>这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。</p></blockquote></li><li><p>控制并发度。</p><p>同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。</p><ul><li><p>修改 MySQL 源码</p><blockquote><p>对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。</p></blockquote></li><li><p>通过将一行改成逻辑上的多行来减少锁冲突。</p><blockquote><p>以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。</p></blockquote></li></ul></li></ol><h2 id="5-二阶段锁"><a href="#5-二阶段锁" class="headerlink" title="5. 二阶段锁"></a>5. 二阶段锁</h2><h2 id="5-1-概述"><a href="#5-1-概述" class="headerlink" title="5.1. 概述"></a>5.1. 概述</h2><blockquote><p>因为有大量的并发访问，为了预防死锁，一般应用中推荐使用一次封锁法，就是在方法的开始阶段，已经预先知道会用到哪些数据，然后全部锁住，在方法运行之后，再全部解锁。这种方式可以有效的避免循环死锁，但在数据库中却不适用，因为在事务开始阶段，数据库并不知道会用到哪些数据。</p><p>数据库遵循的是<strong>两段锁协议</strong>，将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁）。</p></blockquote><h2 id="5-2-加锁阶段"><a href="#5-2-加锁阶段" class="headerlink" title="5.2. 加锁阶段"></a>5.2. 加锁阶段</h2><blockquote><p>加锁阶段：在该阶段可以进行加锁操作。在对任何数据进行读操作之前要申请并获得S锁（共享锁，其它事务可以继续加共享锁，但不能加排它锁），在进行写操作之前要申请并获得X锁（排它锁，其它事务不能再获得任何锁）。加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。</p></blockquote><h2 id="5-3-解锁阶段"><a href="#5-3-解锁阶段" class="headerlink" title="5.3. 解锁阶段"></a>5.3. 解锁阶段</h2><blockquote><p>当事务释放了一个封锁以后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。</p><p>数据库的两段锁协议是指所有事务必须分两个阶段对数据项进行加锁和解锁在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，需要等事务结束时才释放，这就是两阶段锁协议，分为加锁阶段和解锁阶段，所有的 <code>lock</code> 操作都在 <code>unlock</code> 操作之后。</p></blockquote><h1 id="6-意向锁"><a href="#6-意向锁" class="headerlink" title="6. 意向锁"></a>6. 意向锁</h1><h2 id="6-1-概述"><a href="#6-1-概述" class="headerlink" title="6.1. 概述"></a>6.1. 概述</h2><blockquote><p><code>innodb</code> 的意向锁主要用户多粒度的锁并存的情况。比如事务 <code>A</code> 要在一个表上加 <code>S</code> 锁，如果表中的一行已被事务<code>B</code> 加了 <code>X</code> 锁，那么该锁的申请也应被阻塞。如果表中的数据很多，逐行检查锁标志的开销将很大，系统的性能将会受到影响。为了解决这个问题，可以在表级上引入新的锁类型来表示其所属行的加锁情况，这就引出了 <strong>“意向锁”</strong> 的概念。</p><p>如果表中记录1亿，事务 <code>A</code> 把其中有几条记录上了行锁了，这时事务 <code>B</code> 需要给这个表加表级锁，如果没有意向锁的话，那就要去表中查找这一亿条记录是否上锁了。如果存在意向锁，那么假如事务<code>Ａ</code>在更新一条记录之前，先加意向锁，再加<code>Ｘ</code>锁，事务 <code>B</code> 先检查该表上是否存在意向锁，存在的意向锁是否与自己准备加的锁冲突，如果有冲突，则等待直到事务<code>Ａ</code>释放，而无须逐条记录去检测。事务<code>Ｂ</code>更新表时，其实无须知道到底哪一行被锁了，它只要知道反正有一行被锁了就行了。</p></blockquote><h2 id="6-2-作用"><a href="#6-2-作用" class="headerlink" title="6.2. 作用"></a>6.2. 作用</h2><blockquote><p>意向锁的主要作用是处理行锁和表锁之间的矛盾，能够显示“某个事务正在某一行上持有了锁，或者准备去持有锁”</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>TCP 长连接&amp;KeepAlive</title>
      <link href="2020/02/05/TCP%20%E9%95%BF%E8%BF%9E%E6%8E%A5&amp;%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6/"/>
      <url>2020/02/05/TCP%20%E9%95%BF%E8%BF%9E%E6%8E%A5&amp;%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>TCP协议中有长连接和短连接之分。短连接环境下，数据交互完毕后，主动释放连接</p><a id="more"></a><p>长连接的环境下，进行一次数据交互后，很长一段时间内无数据交互时，客户端可能意外断电、死机、崩溃、重启，还是中间路由网络无故断开，这些 TCP 连接并未来得及正常释放，连接的另一方并不知道对端的情况，会一直维护这个连接，长时间的积累会导致非常多的半打开连接，造成端系统资源的消耗和浪费，且有可能导致在一个无效的数据链路层面发送业务数据，结果就是发送失败。所以服务器端要做到快速感知失败，减少无效链接操作，这就有了 TCP 的 Keepalive(保活探测)机制。</p><h2 id="1-TCP-Keepalive-工作原理"><a href="#1-TCP-Keepalive-工作原理" class="headerlink" title="1. TCP Keepalive 工作原理"></a>1. TCP Keepalive 工作原理</h2><p>当一个 TCP 连接建立之后，启用 TCP Keepalive 的一端便会启动一个计时器，当这个计时器数值到达 0 之后(也就是经过 <code>tcp_keep-alive_time</code> 时间后)，一个 TCP 探测包便会被发出。这个 TCP 探测包是一个纯 ACK 包, 其 Seq 号与上一个包是重复的，所以其实探测保活报文不在窗口控制范围内。</p><p>如果一个给定的连接在两小时内（默认时长）没有任何的动作，则服务器就向客户发一个探测报文段，客户主机必须处于以下4个状态之一</p><ol><li>客户主机依然正常运行，并从服务器可达。客户的 TCP 响应正常，而服务器也知道对方是正常的，服务器在两小时后将保活定时器复位。</li><li>客户主机已经崩溃，并且关闭或者正在重新启动。客户的 TCP 没有响应。服务端将不能收到对探测的响应，并在 75 秒后超时。服务器总共发送10个这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。</li><li>客户主机崩溃并已经重新启动。服务器将收到一个对其保活探测的响应，这个响应是一个复位，使得服务器终止这个连接</li><li>客户机正常运行，但是服务器不可达，这种情况与2类似，TCP能发现的就是没有收到探测的响应。</li></ol><h2 id="2-TCP-Keepalive-作用"><a href="#2-TCP-Keepalive-作用" class="headerlink" title="2. TCP Keepalive 作用"></a>2. TCP Keepalive 作用</h2><ol><li><p>探测连接的对端是否存活</p><blockquote><p>在应用交互的过程中，可能存在以下几种情况</p></blockquote><ul><li>客户端或服务器意外断电，死机，崩溃，重启</li><li>中间网络已经中断</li></ul><blockquote><p>利用保活探测功能，可以探知这种对端的意外情况，从而保证在意外发生时，可以释放半打开的 TCP 连接</p></blockquote></li><li><p>防止中间设备因超时删除连接相关的连接表</p><blockquote><p>中间设备如防火墙等，会为经过它的数据报文建立相关的连接信息表，并为其设置一个超时时间的定时器，如果超出预定时间，某连接无任何报文交互的话，中间设备会将该连接信息从表中删除，在删除后，再有应用报文过来时，中间设备将丢弃该报文，从而导致应用出现异常</p></blockquote></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP 阻塞控制</title>
      <link href="2020/02/05/TCP%20%E9%98%BB%E5%A1%9E%E6%8E%A7%E5%88%B6/"/>
      <url>2020/02/05/TCP%20%E9%98%BB%E5%A1%9E%E6%8E%A7%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>TCP 让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率。</p><a id="more"></a><p>运行在发送方的 TCP 拥塞控制机制会跟踪一个额外的变量，即<strong>拥塞窗口cwnd</strong>（congestion window）。它对一个TCP发送方能向网络中发送流量的速率进行了限制。</p><h2 id="1-TCP-发送方如何感知网络拥塞？"><a href="#1-TCP-发送方如何感知网络拥塞？" class="headerlink" title="1. TCP 发送方如何感知网络拥塞？"></a>1. TCP 发送方如何感知网络拥塞？</h2><p><strong>冗余 ACK（duplicate ACK）</strong>：就是再次确认某个报文段的 ACK，而发送方先前已经收到对该报文段的确认。</p><p>当出现过度的拥塞时，路由器的缓存会溢出，导致一个数据报被丢弃。丢弃的数据报接着会引起发送方的<code>丢包事件</code>。那么此时，发送方就认为在发送方到接收方的路径上出现了<code>网络拥塞</code>。</p><h2 id="2-发送方感知到网络拥塞时，采用何种算法来改变其发送速率？"><a href="#2-发送方感知到网络拥塞时，采用何种算法来改变其发送速率？" class="headerlink" title="2. 发送方感知到网络拥塞时，采用何种算法来改变其发送速率？"></a>2. 发送方感知到网络拥塞时，采用何种算法来改变其发送速率？</h2><p><strong>TCP 拥塞控制算法（TCP congestion control algorithm）</strong>包括三个主要部分：<strong>慢启动、拥塞避免、快速恢复</strong>，其中快速恢复并非是发送方必须的，慢启动和拥塞避免则是TCP强制要求的</p><h3 id="2-1-慢启动-amp-拥塞控制"><a href="#2-1-慢启动-amp-拥塞控制" class="headerlink" title="2.1. 慢启动&amp;拥塞控制"></a>2.1. 慢启动&amp;拥塞控制</h3><p>当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。</p><h4 id="2-1-1-慢启动流程"><a href="#2-1-1-慢启动流程" class="headerlink" title="2.1.1. 慢启动流程"></a>2.1.1. 慢启动流程</h4><p>通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段 MSS 的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个 MSS 的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。</p><blockquote><p>MSS(Maximum Segment Size)最大报文段长度。在连接建立的时候，即在发送 SYN 段的时候，同时会将 MSS 发送给对方（MSS 选项只能出现在 SYN 段中！！！），告诉对端他期望接收的 TCP 报文段数据部分最大长度。</p></blockquote><p>每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间 RTT。不过“传输轮次”更加强调：把拥塞窗口 cwnd 所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。 另，慢开始的“慢”并不是指 cwnd 的增长速率慢，而是指在 TCP 开始发送报文段时先设置 cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大 cwnd。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-15 下午11.16.10.png" alt="截屏2021-05-15 下午11.16.10" style="zoom:50%;" /><h4 id="2-1-2-慢启动门限-ssthresh"><a href="#2-1-2-慢启动门限-ssthresh" class="headerlink" title="2.1.2. 慢启动门限 ssthresh"></a>2.1.2. 慢启动门限 ssthresh</h4><p>为了防止拥塞窗口 cwnd 增长过大引起网络拥塞，还需要设置一个慢开始门限 ssthresh 状态变量。慢开始门限 ssthresh 的用法如下： 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法</p><p>让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍。这样拥塞窗口 cwnd 按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-15 下午11.22.20.png" alt="截屏2021-05-15 下午11.22.20" style="zoom:50%;" /><p>无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限 ssthresh 设置为出现拥塞时的发送方窗口值的一半（但不能小于 2）。然后把拥塞窗口 cwnd 重新设置为 1，执行慢开始算法。 这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。</p><h4 id="2-1-3-图解拥塞控制的过程"><a href="#2-1-3-图解拥塞控制的过程" class="headerlink" title="2.1.3. 图解拥塞控制的过程"></a>2.1.3. 图解拥塞控制的过程</h4><ol><li>在标号为 1 的箭头处，TCP 初始连接进行数据交换，开始慢启动，初始 cwnd=I，W=1，ssthresh=16，在传输轮次 0-4 阶段进行慢启动过程，cwnd 按照 1-2-4-8-16 的顺序进行指数增长</li><li>在标号为 2 的箭头处，cwnd=16=ssthresh，此时触发拥塞避免过程，开始线性增长，在传输轮次 4-12 阶段，cwnd 按照 16-17-18-19-20-21-22-23-24 进行线性增长。</li><li>在标号为 3 的箭头处，TCP 发生了 RTO 重传，认为网络发生拥塞，于是设置 ssthresh=cwnd/2=12，cwnd=1 重新进行慢启动过程</li><li>在标号为 4 的箭头处，TCP 从 cwnd=1 开始重新开始慢启动过程</li><li>在标号为 5 的箭头处，当 cwnd = 12 时改为执行拥塞避免算法，拥塞窗口按按线性规律增长，每经过一个往返时延就增加一个 MSS 的大小。</li></ol><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-15 下午11.25.26.png" alt="截屏2021-05-15 下午11.25.26" style="zoom:50%;" /><h3 id="2-2-快速重传"><a href="#2-2-快速重传" class="headerlink" title="2.2. 快速重传"></a>2.2. 快速重传</h3><p>如果发送方设置的超时计时器时限已到但还没有收到确认，那么很可能是网络出现了拥塞，致使报文段在网络中的某处被丢弃。这时，TCP马上把拥塞窗口 cwnd 减小到1，并执行慢开始算法，同时把慢开始门限值 ssthresh 减半。这是不使用快重传的情况。</p><p>快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。</p><h3 id="2-3-快恢复"><a href="#2-3-快恢复" class="headerlink" title="2.3. 快恢复"></a>2.3. <strong>快恢复</strong></h3><p>与快重传配合使用的还有快恢复算法，其过程有以下两个要点：</p><p>送方知道现在只是丢失了个别的报文段，于是不启动慢开始，执行<strong>快恢复</strong>算法。此时，发送方调整门限值</p><ol><li>ssthresh=cwnd/2</li><li>cwnd=ssthresh</li></ol><p>并开始执行拥塞避免算法</p><p>当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。这是为了预防网络发生拥塞。请注意：接下去不执行慢开始算法。</p><p>由于发送方现在认为网络很可能没有发生拥塞，因此与慢开始不同之处是现在不执行慢开始算法(即拥塞窗口cwnd现在不设置为1)，而是把 cwnd 值设置为慢开始门限 ssthresh 减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。</p><blockquote><p>也有的快重传实现是把开始时的拥塞窗口 cwnd 值再增大一点，等于 ssthresh + 3 * MSS 。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不再消耗网络的资源而是停留在接收方的缓存中。可见现在网络中并不是堆积了分组而是减少了三个分组。因此可以适当把拥塞窗口扩大了些。</p></blockquote><p>使用了快恢复算法后，慢开始算法就只会在建立tcp连接和出现超时的时候才会执行</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(12)_对象的实例化内存布局与访问定位</title>
      <link href="2020/02/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(12)_%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%AE%9E%E4%BE%8B%E5%8C%96%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%E4%B8%8E%E8%AE%BF%E9%97%AE%E5%AE%9A%E4%BD%8D/"/>
      <url>2020/02/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(12)_%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%AE%9E%E4%BE%8B%E5%8C%96%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%E4%B8%8E%E8%AE%BF%E9%97%AE%E5%AE%9A%E4%BD%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>虚拟机遇到一条new指令，首先去检查这个指令的参数能否在Metaspace的常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载、解析和初始化。（即判断类元信息是否存在）。如果没有，那么在双亲委派模式下，使用当前类加载器以ClassLoader+包名+类名 为Key进行查找对应的.class文件。如果没有找到文件，则抛出ClassNotFoundException异常，如果找到，则进行类加载，并生成对应的Classs对象</p><a id="more"></a><h1 id="对象的实例化内存布局与访问定位"><a href="#对象的实例化内存布局与访问定位" class="headerlink" title="对象的实例化内存布局与访问定位"></a>对象的实例化内存布局与访问定位</h1><h2 id="1-对象的实例化"><a href="#1-对象的实例化" class="headerlink" title="1 对象的实例化"></a>1 对象的实例化</h2><ul><li>面试题<ul><li><font color=red><strong>美团</strong></font><ul><li>对象在JVM中是怎么存储的？</li><li>对象头信息里面有哪些东西？</li></ul></li><li><font color=red><strong>蚂蚁金服</strong></font><ul><li>二面：java对象头里有什么？</li></ul></li></ul></li></ul><hr><img src="images/213.png" alt="img" style="zoom:80%;" /><img src="images/214.png" alt="img" style="zoom:80%;" /><hr><ul><li><p>创建对象的步骤</p><ol><li><p><font color=red><strong>判断对象对应的类是否加载、链接、初始化</strong></font></p><p>虚拟机遇到一条new指令，首先去检查这个指令的参数能否在Metaspace的常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载、解析和初始化。（即判断类元信息是否存在）。如果没有，那么在双亲委派模式下，使用当前类加载器以ClassLoader+包名+类名 为Key进行查找对应的.class文件。如果没有找到文件，则抛出ClassNotFoundException异常，如果找到，则进行类加载，并生成对应的Classs对象</p></li><li><p><font color=red><strong>为对象分配内存</strong></font></p><p>首先计算对象占用空间大小，接着再堆中分配一块内存给新对象。如果实例成员变量是引用变量，仅分配引用变量空间即可，即4个字节大小。</p><ul><li><p>如果内存规整，使用<strong>指针碰撞</strong></p><p>如果内存是规整的，那么虚拟机将采用指针碰撞法（Bump The Pointer）来为对象分配内存。意思是所有用过的内存在一边，空闲的内存在另外一边，中间放着一个指针作为分界点的指示器，分配内存就仅仅是把指针向空闲那边挪动一段与对象大小相等的距离罢了。如果垃圾收集器选择的是Serial、ParNew这种基于标记-压缩算法的，虚拟机采用这种分配方式。一般使用带有compact（整理）过程的收集器时，使用指针碰撞。</p></li><li><p>如果内存不规整，虚拟机需要维护一个列表，使用<strong>空闲列表</strong>分配</p><p>如果内存不是规整的，已使用的内存和未使用的内存相互交错，那么虚拟机将采用的是空闲列表法来为对象分配内存。意思是虚拟机维护一个列表，记录上哪些内存块是可用的，再分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的内容。这种分配方式称为“空闲列表（Free List）”。</p><p><font color=blue><strong>说明</strong></font>：选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾回收器是否带有压缩整理功能决定。</p></li></ul></li><li><p><font color=red><strong>处理并发安全问题</strong></font></p><p>在分配内存空间时，另外一个问题是及时保证new对象时候的线程安全性：创建对象是非常频繁的操作，虚拟机需要解决并发安全问题。虚拟机采用了两种方式解决并发安全问题：</p><ul><li>CAS（Compare And Swap）失败重试、区域加锁：保证指针更新操作的原子性；</li><li>TLAB吧内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为<strong>本地线程分配缓冲区</strong>（TLAB，Thread Local Allocation Buffer），虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来设定。</li></ul></li><li><p><font color=red><strong>初始化分配到的空间</strong></font></p><p>内存分配结束，虚拟机将分配到的内存空间都初始化为零值（不包括对象头）。这一步保证了对象的实例字段在Java代码中可以不用赋初值就可以直接使用，程序能访问到这些字段的数据类型所对应的零值。</p></li><li><p><font color=red><strong>设置对象的对象头</strong></font></p><p>将对象的所属类（即类的元数据信息）、对象的HashCode和对象的GC信息、锁信息等数据存储在对象的对象头中。这个过程的具体设置方式取决于JVM实现。</p></li><li><p><font color=red><strong>执行init方法进行初始化</strong></font></p><p>在Java程序的视角来看，初始化才正式开始。初始化成员变量，执行实例化代码块，调用类的构造方法，并把堆内对象的首地址赋值给引用变量。</p><p>因此一般来说（由字节码中是否跟随有invokespecial指令所决定），new指令之后会接着就是执行方法，吧对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全创建出来。</p></li></ol></li></ul><h2 id="2-对象的内存布局"><a href="#2-对象的内存布局" class="headerlink" title="2 对象的内存布局"></a>2 对象的内存布局</h2><ul><li><p>创建的对象在堆中的含有哪些内容</p><img src="images/215.png" alt="img" style="zoom:80%;" /><p>并不是所有的对象都会保存类型指针</p></li><li><p>例子</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 测试对象实例化的过程</span></span><br><span class="line"><span class="comment"> *  ① 加载类元信息 - ② 为对象分配内存 - ③ 处理并发问题  - ④ 属性的默认初始化（零值初始化）</span></span><br><span class="line"><span class="comment"> *  - ⑤ 设置对象头的信息 - ⑥ 属性的显式初始化、代码块中初始化、构造器中初始化</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  给对象的属性赋值的操作：</span></span><br><span class="line"><span class="comment"> *  ① 属性的默认初始化 - ② 显式初始化 / ③ 代码块中初始化 - ④ 构造器中初始化</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Customer</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> id = <span class="number">1001</span>;  <span class="comment">// ② 显式初始化</span></span><br><span class="line">    String name;</span><br><span class="line">    Account acct;</span><br><span class="line"></span><br><span class="line">    &#123;</span><br><span class="line">        name = <span class="string">&quot;匿名客户&quot;</span>;  <span class="comment">// ③ 代码块中初始化</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Customer</span><span class="params">()</span></span>&#123;</span><br><span class="line">        acct = <span class="keyword">new</span> Account();  <span class="comment">// ④ 构造器中初始化</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Account</span></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomerTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Customer cust = <span class="keyword">new</span> Customer();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="images/216.png" alt="img" style="zoom:80%;" /></li></ul><h2 id="3-对象的访问定位"><a href="#3-对象的访问定位" class="headerlink" title="3 对象的访问定位"></a>3 对象的访问定位</h2><img src="images/217.png" alt="img" style="zoom:80%;" /><ul><li><p>JVM是如何通过栈帧中的对象引用访问到其内部的对象实例的呢？</p><ul><li>通过栈上reference访问</li></ul><img src="images/218.png" alt="img" style="zoom:67%;" /></li><li><p>对象访问的两种方式</p><ul><li><p>句柄访问</p><img src="images/219.png" alt="img" style="zoom:67%;" /><ul><li>优点：GC之后只需要改变句柄池中的地址即可</li><li>缺点：访问效率低，访问实例数据和元数据均需要中转一次</li></ul></li><li><p>直接指针（Hotspot采用）</p><img src="images/220.png" alt="img" style="zoom:67%;" /><p>优点：访问效率高，访问实例数据一步到位</p><p>缺点：GC之后需要更改虚拟机栈中本地变量表中的引用地址</p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello_Http</title>
      <link href="2020/02/01/Hello%20Http/"/>
      <url>2020/02/01/Hello%20Http/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HTTP 协议即超文本传输协议 (HTTP-Hypertext transfer protocol)，是互联网上应用最为广泛的一种网络协议，是一种详细规定了浏览器和万维网服务器之间互相通信的规则，通过因特网传送万维网文档的数据传送协议。用于从 WWW 服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。</p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>在 OSI 七层模型中，HTTP 协议位于最顶层的应用层中。通过浏览器访问网页就直接使用了 HTTP 协议。使用 HTTP 协议时，客户端首先与服务端的 80 端口建立一个 TCP 连接，然后在这个连接的基础上进行请求和应答，以及数据的交换。</p><p>HTTP 有两个常用版本，分别是 1.0 和 1.1。<strong>主要区别在于 HTTP 1.0 中每次请求和应答都会使用一个新的 TCP 连接，而从 HTTP 1.1 开始，运行在一个 TCP 连接上发送多个命令和应答。因此大幅度减少了 TCP 连接的建立和断开，提高了效率。</strong></p><hr><h3 id="1-1-URI-amp-URL"><a href="#1-1-URI-amp-URL" class="headerlink" title="1.1. URI&amp;URL"></a>1.1. URI&amp;URL</h3><h4 id="URL"><a href="#URL" class="headerlink" title="URL"></a>URL</h4><p><strong>统一资源定位符 URL</strong>(Uniform Resources Locator) 用来表示**<font color='blue'>资源在互联网上的位置和访问这些资源的方法</font><strong>，并使每一个资源在整个互联网范围内具有唯一的标识符URL。即 **URL 实际上就是资源在互联网上的地址</strong>。</p><h4 id="URI"><a href="#URI" class="headerlink" title="URI"></a>URI</h4><p><strong>统一资源标识符 URI</strong>（Uniform Recourses Identifier）就是由某个协议方案表示的资源定位标识符。协议方案是指访问资源所使用的协议类型名称。</p><ol><li><p>URI 强调的是给资源标记命名，URL 强调的是给资源定位</p></li><li><p>URL 是 URI 的子集，所有的 URL 都是 URI，但不是每个 URI 都是 URL，还有可能是 URN。让 URI 能成为 URL 的当然就是那个 “访问机制，”网络位置”。</p><p>e.g. <code>http://</code> or <code>ftp://</code></p></li></ol><p>我们在浏览器输入的都是 URL，因为我们输入的目的是为了找到某一个资源</p><hr><h3 id="1-2-HTTP-的特点"><a href="#1-2-HTTP-的特点" class="headerlink" title="1.2.HTTP 的特点"></a>1.2.HTTP 的特点</h3><ol><li><p><strong>HTTP 使用了面向连接的 TCP 作为传输层协议</strong>，保证了数据的可靠传输。HTTP 客户首先发起一个与服务器的 TCP 连接，一旦连接建立。该浏览器和服务器进程就可以通过套接字接口访问 TCP。</p></li><li><p><strong>HTTP 协议本身是无连接的</strong>。</p><p>这就是说，虽然 HTTP 使用了 TCP 连接，但通信的双方在交换 HTTP 报文之间不需要先建立 HTTP 连接</p></li><li><p><strong>HTTP 协议是无状态的</strong>。无状态协议对于事务没有记忆能力，HTTP 服务器并不保存关于客户端的任何信息。同一个客户在短时间内两次请求同一个对象，服务器会对这两次请求作出两次响应，因为服务器并不记得曾经这个客户访问过，也不记得为这个客户服务器过多少次。</p><p><strong><font color='grey'>[HTTP协议设计成无状态的原因]</font></strong></p><blockquote><p>简化了服务器的设计，使服务器更容易支持大量并发的 HTTP 请求。</p></blockquote><blockquote><p>有状态的协议更加复杂，需要维护客户端的状态，并且如果客户或服务器失效，会产生状态不一致，解决这种不一致的代价高。</p></blockquote><blockquote><p>不需保存客户的状态信息可以减少服务器的 CPU 及内存的消耗。</p></blockquote></li></ol><hr><h4 id="1-3-Cookie-amp-Session"><a href="#1-3-Cookie-amp-Session" class="headerlink" title="1.3.Cookie&amp;Session"></a>1.3.<code>Cookie</code>&amp;<code>Session</code></h4><ol><li>cookie 数据存放在客户的浏览器上，session 数据存放在服务器上</li><li>cookie 不是很安全，别人可以分析存放在本地的 cookie 并进行 cookie 欺骗，所以将登陆信息等重要信息存放在 session 中比较好，其他信息如果需要保留，可以存放在 cookie 中</li><li>session 会在一定时间内保存在服务器上，当访问增多，会比较占用服务器性能</li><li>单个 cookie 保存的数据不能超过4k，很多浏览器都限制一个站点最多保存20个 cookie</li><li>http 协议是无状态的，但是很多应用需要服务器掌握客户端的状态，比如网上购物，这时 cookie 和session 就发挥了它们的作用</li></ol><h4 id="1-4-持续连接和非持续连接"><a href="#1-4-持续连接和非持续连接" class="headerlink" title="1.4.持续连接和非持续连接"></a>1.4.持续连接和非持续连接</h4><p>HTTP 协议首先和服务器建立 TCP 连接。这需要三次握手，当建立 TCP 连接的三次报文握手的前两部分后（即经过了一个 RTT 时间后），客户将把 HTTP 请求报文作为建立TCP 连接的第三次握手的第三个报文的数据（前面介绍过三次握手中第三次握手客户端可以携带数据），发送给服务器。服务器收到 HTTP 请求报文后，就把所请求的文档作为响应报文返回给客户。</p><p>从上面的过程可以看出，<strong>从服务器请求一个文档的所需的时间就是该文档传输时间加上两倍的往返时间 RTT</strong>。</p><p><strong>非连续连接</strong>是指当一系列请求到达服务器时，每个请求/响应应对是经过一个单独的 TCP 进行的。如果使用浏览器浏览一个页面，这个页面包含多个链接对象（如图片）那么就需要进行依次链接，每一次链接都导致 2× RTT 的开销。另一个开销就是服务器和客户每一次建立新的 TCP 连接都要分配缓存和变量。特别万维网服务器往往要同时服务器大量客户请求，所以非持续连接会使万维网服务器负担很重。</p><p>下图表示非连续连接的工作方式，对于每一个请求都建立一个TCP连接。</p><p>为了解决非连续连接的问题，HTTP 1.1 使用持续连接（默认），所谓的<strong>持续连接</strong>是指服务器在发送响应后仍然一段时间内保持这条连接，使同一个客户（浏览器）和该服务器可以继续在这条链接上传送后续的 HTTP 请求报文和响应报文。</p><p>持久连接的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器的负载。另外，减少开销的那部分时间，使 HTTP 请求和响应能更早的结束，这样Web页面的显示速度也就提高了。</p><p>HTTP/1.1协议的持续连接有两种工作方式，即<strong>非流水线方式</strong>（without pipelining）和<strong>流水线方式</strong>（with pipelining）。<br><strong>非流水线方式的工作特点</strong>：客户在收到前一个响应后才能发出下一个请求。因此，在 TCP 连接已建立后，客户每访问一次对象都要用去一个往返时间 RTT。这比非持续连接要用去两倍 RTT 的开销，节省了建立 TCP 所需的一个 RTT 时间。上图的持续连接方式就是非流水线方式，这种方式的缺点是服务器在发送完一个对象后，其TCP 连接就处于空闲状态，浪费了服务器资源。</p><p><strong>流水线方式的工作特点</strong>：客户在收到 HTTP 响应报文之前就能够接着发送新的请求报文。于是一个接着一个的请求报文到达服务器后，服务器就可以连续发回响应报文。因此，使用流水线方式时，客户访问所有的对象只需花费一个 RTT 时间。流水线工作方式使 TCP 连接中的空闲时间减少，提高了文档下载效率。</p><h4 id="1-4-Cookie"><a href="#1-4-Cookie" class="headerlink" title="1.4.Cookie"></a>1.4.Cookie</h4><p>前面介绍，HTTP 是无状态协议，即 HTTP 协议自身不对请求和响应之间的通信状态进行保存。但是在狠多情况下需要保存用户状态，例如用户登录到一家购物网站，即使他跳转到该站的其他页面后，也需要能继续保持登录状态。针对这个实例，网站为了能够掌握是谁送出的请求，需要保存用户的状态。</p><p>为了解决上面的问题，目前大多站点使用 <strong>Cookie</strong> 技术。Cookie 是网站为了辨别用户身份，进行会话跟踪而存储在客户端上的数据。</p><blockquote><p>当用户访问某个使用 Cookie 的网站时，该网站的服务器就为用户产生一个唯一的识别码，并以此作为索引在服务器的后端服务器数据库中产生一个表项。</p></blockquote><blockquote><p>服务器在给用户的 HTTP 响应报文中添加一个叫做 Set-Cookie 的首部行。如 Set-Cookie: 1234</p></blockquote><blockquote><p>当用户收到这个响应时，其浏览器就在它管理的特定的 Cookie 文件中添加一行，其中包括这个服务器主机名和 Set-Cookie 后面的给出的识别码。当用户继续浏览这个网站时，每发送一个 HTTP 请求报文，其浏览器就会从 Cookie 文件中取出这个网站的识别码，并放到 HTTP 请求报文的 Cookie 首部行中，即Coolkie: 1234</p></blockquote><h4 id="1-6-HTTP-断点续传"><a href="#1-6-HTTP-断点续传" class="headerlink" title="1.6. HTTP 断点续传"></a>1.6. HTTP 断点续传</h4><p>断点续传就是从文件上次中断的地方开始重新下载或上传,当下载或上传文件的时候,如果没有实现断点续传功能,那么每次出现异常或者用户主动的暂停,都会去重头下载,这样很浪费时间。所以断点续传的功能就应运而生了。要实现断点续传的功能，需要客户端记录下当前的下载或上传进度，并在需要续传的时候通知服务端本次需要下载或上传的内容片段。</p><h2 id="2-HTTP-报文格式"><a href="#2-HTTP-报文格式" class="headerlink" title="2. HTTP 报文格式"></a>2. HTTP 报文格式</h2><h3 id="2-1-请求报文格式"><a href="#2-1-请求报文格式" class="headerlink" title="2.1. 请求报文格式"></a>2.1. 请求报文格式</h3><p><strong>请求报文包含三部分：请求行、请求头部和请求正文三部分组成</strong></p><img src="../images/计算机网络/截屏2021-05-16 上午11.26.01.png" alt="截屏2021-05-16 上午11.26.01" style="zoom:50%;" /><ol><li><p>请求行由3部分组成，分别为：请求方法、URL、协议版本。之间由空格分隔</p><p>请求方法包括 GET，HEAD，PUT，POST，TRACE，OPTIONS，DELET以及扩展方法，当然并不是所有的服务器都实现了所有的方法，部分方法即便支持，处于安全性的考虑也是不可用的</p></li><li><p>请求头部</p><p>HTTP 客户程序(例如浏览器)，向服务器发送请求的时候必须指明请求类型(一般是 GET 或者 POST)。如有必要，客户程序还可以选择发送其他的请求头。对于 POST 请求来说 Content-Length 必须出现。</p></li><li><p>请求正文</p></li></ol><h3 id="2-2-响应报文格式"><a href="#2-2-响应报文格式" class="headerlink" title="2.2. 响应报文格式"></a>2.2. 响应报文格式</h3><p><strong>HTTP 响应报文也由三部分组成：响应行、响应头、响应体</strong></p><img src="../images/计算机网络/截屏2021-05-16 上午11.27.51.png" alt="截屏2021-05-16 上午11.27.51" style="zoom:50%;" /><ol><li><p>响应行</p><p>响应行一般由协议版本、状态码及其描述组成</p></li><li><p>响应头</p></li><li><p>响应体</p><p>响应体就是响应的消息体，如果是纯数据就是返回纯数据，如果请求的是HTML页面，那么返回的就是HTML代码，如果是 JS 就是 JS 代码等。</p></li></ol><h3 id="2-3-请求方法"><a href="#2-3-请求方法" class="headerlink" title="2.3. 请求方法"></a>2.3. 请求方法</h3><p>![截屏2021-05-14 下午4.39.22](../images/计算机网络/截屏2021-05-14 下午4.39.22.png)</p><ol><li><strong>POST</strong>：用于传输信息给服务器，主要功能与 Get 方法类似。</li><li><strong>GET</strong>   用于请求访问已经被 URL 识别的资源，可以通过 URL 传参给服务器。</li><li><strong>PUT</strong>：传输文件，报文主体包含文件内容，保存到对应 URL 位置。</li><li><strong>HEAD</strong>：获取报文首部，与 GET 方法类似，只是不返回报文主体，一般用于验证 URL 是否有效。</li><li><strong>DELET</strong>：删除文件，与 PUT 方法相反，删除对应 URL 位置的文件。</li><li><strong>OPTIONS</strong>： 返回服务器支持的 HTTP 方法。</li><li><strong>CONNECT</strong>: 把请求连接转换到透明的 TCP/IP 通道</li></ol><h3 id="2-4-状态码"><a href="#2-4-状态码" class="headerlink" title="2.4. 状态码"></a>2.4. 状态码</h3><h4 id="2-4-1-2XX-成功"><a href="#2-4-1-2XX-成功" class="headerlink" title="2.4.1. 2XX: 成功"></a>2.4.1. <code>2XX</code>: 成功</h4><ol><li><strong>200：请求被正常处理</strong></li><li><strong>204：请求被受理但没有资源可以返回</strong></li><li>206：客户端只是请求资源的一部分，服务器只对请求的部分资源执行 GET 方法，相应报文中通过Content-Range 指定范围的资源。</li></ol><h4 id="2-4-2-3XX-重定向"><a href="#2-4-2-3XX-重定向" class="headerlink" title="2.4.2. 3XX: 重定向"></a>2.4.2. <code>3XX</code>: 重定向</h4><p>HTTP重定向：服务器无法处理浏览器发送过来的请求，服务器告诉浏览器跳转到可以处理请求的url上。浏览器会自动访问该URL地址。 </p><p>在 HTTP 协议中，重定向操作由服务器通过发送特殊的响应（即 redirects）而触发。HTTP 协议的重定向响应的状态码为 3xx 。浏览器在接收到重定向响应的时候，会采用该响应提供的新的 URL ，并立即进行加载；大多数情况下，除了会有一小部分性能损失之外，重定向操作对于用户来说是不可见的。</p><p>不同类型的重定向映射可以划分为三个类别：永久重定向、临时重定向和特殊重定向。</p><h5 id="永久重定向"><a href="#永久重定向" class="headerlink" title="永久重定向"></a>永久重定向</h5><p>这种重定向操作是永久性的。它表示原 URL 不应再被使用，而应该优先选用新的 URL。搜索引擎机器人会在遇到该状态码时触发更新操作，在其索引库中修改与该资源相关的 URL。</p><table><thead><tr><th align="left">编码</th><th align="left">含义</th><th align="left">处理方法</th><th align="left">典型应用场景</th></tr></thead><tbody><tr><td align="left"><code>301</code></td><td align="left">Moved Permanently</td><td align="left">GET 方法不会发生变更，其他方法有可能会变更为 GET 方法，网站重构。</td><td align="left"></td></tr><tr><td align="left"><code>308</code></td><td align="left">Permanent Redirect</td><td align="left">方法和消息主体都不发生变化。</td><td align="left">***网站重构，用于非 GET 方法。</td></tr></tbody></table><hr><h5 id="特殊重定向"><a href="#特殊重定向" class="headerlink" title="特殊重定向"></a>特殊重定向</h5><p>除了上述两种常见的重定向之外，还有两种特殊的重定向。304（Not Modified，资源未被修改）会使页面跳转到本地陈旧的缓存版本当中（该缓存已过期(?)），而 300（Multiple Choice，多项选择） 则是一种手工重定向：以 Web 页面形式呈现在浏览器中的消息主体包含了一个可能的重定向链接的列表，用户可以从中进行选择。</p><table><thead><tr><th align="left">编码</th><th align="left">含义</th><th align="left">典型应用场景</th></tr></thead><tbody><tr><td align="left">300</td><td align="left">Multiple Choice</td><td align="left">不会太多：所有的选项在消息主体的 HTML 页面中列出。也可以返回 200 OK 状态码。</td></tr><tr><td align="left">304</td><td align="left">Not Modified</td><td align="left">缓存刷新：该状态码表示缓存值依然有效，可以使用。</td></tr></tbody></table><hr><h4 id="2-4-3-4XX-客户端错误"><a href="#2-4-3-4XX-客户端错误" class="headerlink" title="2.4.3. 4XX:客户端错误"></a>2.4.3. <code>4XX</code>:客户端错误</h4><ol><li>400：请求报文语法有误，服务器无法识别</li><li>401：请求需要认证</li><li>403：请求的对应资源禁止被访问</li><li>404：服务器无法找到对应资源</li><li>409（Conflict）表示请求的资源与资源的当前状态发生冲突</li><li>410（Gone）表示服务器上的某个资源被永久性的删除。</li></ol><h4 id="2-4-4-5XX-服务器错误"><a href="#2-4-4-5XX-服务器错误" class="headerlink" title="2.4.4. 5XX:服务器错误"></a>2.4.4. <code>5XX</code>:服务器错误</h4><ol><li>500：服务器内部错误</li><li>503：服务器正忙</li><li>502: 表示错误网关，无效网关。</li><li>504: 表示网关超时，说明服务器作为网关或代理，但是没有及时从上游服务器收到请求。</li></ol><h2 id="3-一次完整的-HTTP-请求所经历的7个步骤"><a href="#3-一次完整的-HTTP-请求所经历的7个步骤" class="headerlink" title="3. 一次完整的 HTTP 请求所经历的7个步骤"></a>3. 一次完整的 HTTP 请求所经历的7个步骤</h2><p>当我们在web浏览器的地址栏中输入：<a href="http://www.baidu.com，具体发生了什么？">www.baidu.com，具体发生了什么？</a></p><ol><li><p><strong>对 <a href="http://www.baidu.com/">www.baidu.com</a> 这个网址进行 DNS 域名解析，得到对应的 IP 地址</strong></p><p>DNS 域名解析采用的是递归查询的方式</p><ul><li><p>首先会搜索浏览器自身的 DNS 缓存</p></li><li><p>如果浏览器自身的缓存里面没有找到，那么浏览器会搜索系统自身的 Host 文件</p><blockquote><p>操作系统也会有一个域名解析的过程</p><p>在 Windows 中可以通过C:\Windows\System32drivers\etc\hosts文件来设置，可以将任何域名解析到任何能够访问的IP地址。</p><p>在 Linux 中这个配置文件是 /etc/hosts, 修改这个文件可以达到同样的目的。</p><p>操作系统会在缓存中缓存这个解析结果</p><p>如果在本机中仍然无法完成域名的解析，就会<strong>真正请求域名服务器来解析这个域名</strong></p></blockquote></li><li><p>在网络配置中都会有 “DNS服务器地址” 这一项，这个地址就用于解决前面两个过程无法解析时要怎么办，操作系统会把这个域名发送给这里设置的 LDNS（Local DNS）,也就是本地区的域名服务器。这个DNS 通常都提供给你本地互联网接入的一个 DNS 解析服务，例如你是在学校接入互联网，那么你的DNS服务器肯定在你的学校，如果你是在一个小区接入互联网的，那这个 DNS 就是提供给你接入互联网的应用提供商，即电信或者联通，也就是通常所说的SPA）</p><p>转发模式</p></li><li><p>如果 LDNS 仍然没有命中，就直接到 <strong>RootServer</strong> 域名服务器请求解析。</p></li><li><p>根域名服务器返回给本地域名服务器一个所查询域的主域名服务器(gTLdServer)地址。</p><blockquote><p>gTLD是国际顶级域名服务器,如.com、 .cn、.org 等</p></blockquote></li><li><p>本地域名服务器(Local DNS Server) 再向上-步返回的主域名服务器发送请求</p></li><li><p>接受请求的主域名服务器查找并返回此域名对应的 Name Server域名服务器的地址</p><blockquote><p>这个Name Server通常就是你注册的域名服务器，例如你在某个域名服务提供商申请的域名，那么这个域名解析任务就由这个域名提供商的服务器来完成。</p></blockquote></li><li><p>NameServer 域名服务器会查询存储的域名和 IP 的映射关系表，在正常情况下都根据域名得到目标IP记录，连同一个 TTL 值返回给 DNS Server 域名服务器。</p></li><li><p>返回该域名对应的 IP 和 TTL 值，Local DNS Server 会缓存这个域名和 IP 的对应关系，缓存的时间由 TTL 值控制。</p></li><li><p>把解析的结果返回给用户，用户根据 TTL 值缓存在本地系统缓存中，城解析过程结束。</p></li></ul></li><li><p>根据 IP，找到对应的服务器，发起 TCP 的三次握手</p></li><li><p>建立 TCP 连接后发起 HTTP 请求</p><p>建立 TCP 连接之后，Web 浏览器就会向服务器发送请求命令。如：GET/hello/index.html HTTP/1.1。浏览器发送其请求命令之后，还要以头信息的形式向服务器发送一些别的信息(例：Accept ,User-Agent 等)，之后浏览器发送一空白行来通知服务器，它已经结束了头信息的发送。</p></li><li><p>服务器响应 HTTP 请求</p><p>浏览器向服务器发出请求后，服务器会浏览器进行应答，应答内容包括：协议的版本号和应答状态码 ：HTTP/1.1 200 OK，响应头信息来记录服务器自己的数据，被请求的文档内容。最后发送一个空白行来表示头信息的发送到此为结束，接着以 Content-Type 响应头信息所描述的格式发送用户所请求的实际数据。</p></li><li><p>浏览器解析网页代码，并请求网页代码中的资源（如js、css、图片等）</p><p>浏览器拿到 html 文件后，就开始解析其中的 html 代码，遇到js/css/image等静态资源时，就向服务器端去请求下载（会使用多线程下载，每个浏览器的线程数不一样），这是时候就用上 keep-alive特性了，建立一次HTTP连接，可以请求多个资源，下载资源的顺序就是按照代码里面的顺序，但是由于每个资源大小不一样，而浏览器又是多线程请求请求资源，所以这里显示的顺序并不一定是代码里面的顺序。</p></li><li><p>浏览器对页面进行渲染呈现给用户</p></li><li><p><strong>Web 服务器关闭 TCP 连接</strong></p><p>一般情况下，一旦 Web 服务器向浏览器发送了请求数据，它就要关闭 TCP 连接，然而如果浏览器或者服务器在其头信息加入了这行代码： Connection:keep-alive</p><p>TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP粘包</title>
      <link href="2020/02/01/TCP%20%E7%B2%98%E5%8C%85/"/>
      <url>2020/02/01/TCP%20%E7%B2%98%E5%8C%85/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>TCP，Transmission Control Protocol</strong>。传输控制协议，是一种面向连接的、可靠的、基于<strong>字节流</strong>的传输层通信协议。应用层传到 TCP 协议的数据，不是以<strong>消息报为单位</strong>向目的主机发送，而是以<strong>字节流</strong>的方式发送到下游，这些数据可能被<strong>切割和组装</strong>成各种数据包，接收端收到这些数据包后没有正确还原原来的消息，因此出现粘包现象。</p><a id="more"></a><h2 id="1-为什么要组装发送的数据"><a href="#1-为什么要组装发送的数据" class="headerlink" title="1. 为什么要组装发送的数据 ?"></a>1. 为什么要组装发送的数据 ?</h2><h3 id="1-1-MTU"><a href="#1-1-MTU" class="headerlink" title="1.1. MTU"></a>1.1. MTU</h3><p><strong>Maximum Transmit Unit</strong>，最大传输单元。 由数据链路层<strong>提供给</strong>网络层<strong>最大一次传输数据的大小；一般 MTU=**1500 Byte</strong>。 假设IP层有 &lt;= 1500 byte 需要发送，只需要一个 IP 包就可以完成发送任务；假设 IP 层有&gt; 1500 byte 数据需要发送，需要分片才能完成发送，分片后的 IP Header ID 相同。</p><h3 id="1-2-MSS"><a href="#1-2-MSS" class="headerlink" title="1.2. MSS"></a>1.2. MSS</h3><p>TCP 提交给 IP 层最大分段大小，不包含 TCP Header 和 TCP Option，只包含 TCP Payload ，MSS 是 TCP 用来限制应用层最大的发送字节数。 假设 MTU= 1500 byte，那么 <strong>MSS = 1500- 20(IP Header) -20 (TCP Header) = 1460 byte</strong>，如果应用层有 <strong>2000 byte</strong> 发送，那么需要两个切片才可以完成发送，第一个 TCP 切片 = 1460，第二个 TCP 切片 = 540。</p><img src="../images/计算机网络/截屏2021-05-15 下午10.06.23.png" alt="截屏2021-05-15 下午10.06.23" style="zoom:50%;" /><h2 id="2-Nagle-算法"><a href="#2-Nagle-算法" class="headerlink" title="2. Nagle 算法"></a>2. <strong>Nagle 算法</strong></h2><p><strong>Nagle 算法</strong>目的是为了避免发送小的数据包</p><p>在 Nagle 算法开启的状态下，数据包在以下两个情况会被发送</p><ul><li>如果包长度达到<code>MSS</code> (或含有 <code>Fin</code> 包)，立刻发送，否则<strong>等待</strong>下一个包到来, 如果下一包到来后两个包的总长度超过<code>MSS</code>的话，就会进行拆分发送；</li><li>等待超时（一般为<code>200ms</code>），第一个包没到 <code>MSS</code> 长度，但是又迟迟等不到第二个包的到来，则立即发送。</li></ul><p><strong>Nagle</strong> 算法诞生于 1984 年对于应用程序一次发送一字节数据的场景，如果没有 Nagle 的优化，会导致网络由于太多的包而过载。</p><p>但是今天网络环境比以前好，Nagle 的延迟发送，有时候还可能导致调用延时变大。</p><p>所以现在<strong>一般也会把它关掉</strong>。</p><p>即使关闭 Nagle 算法，接收数据端的应用层没有及时读取 TCP Recv Buffer 中的数据，还是会发生粘包。</p><img src="../images/计算机网络/截屏2021-05-15 下午8.01.18.png" alt="截屏2021-05-15 下午8.01.18" style="zoom:33%;" /><h2 id="3-怎么处理粘包？"><a href="#3-怎么处理粘包？" class="headerlink" title="3. 怎么处理粘包？"></a>3. 怎么处理粘包？</h2><p>粘包出现的根本原因是不确定<strong>消息的边界</strong>。只要在发送端每次发送消息的时候给消息<strong>带上识别消息边界的信息</strong>，接收端就可以根据这些信息识别出消息的边界，从而区分出每个消息。</p><h3 id="3-1-加入特殊标志"><a href="#3-1-加入特殊标志" class="headerlink" title="3.1. 加入特殊标志"></a>3.1. 加入特殊标志</h3><p>可以通过特殊的标志作为头尾，比如当收到了<code>0xfffffe</code>或者回车符，则认为收到了新消息的头，此时继续取数据，直到收到下一个头标志 <code>0xfffffe</code> 或者尾部标记，才认为是一个完整消息。</p><h3 id="3-2-加入消息长度信息"><a href="#3-2-加入消息长度信息" class="headerlink" title="3.2. 加入消息长度信息"></a>3.2. 加入消息长度信息</h3><p>一般配合特殊标志一起使用，在收到头标志时，里面还可以带上消息长度，表明在这之后多少 byte 都是属于这个消息的。如果在这之后正好有符合长度的 byte，则作为一个完整消息给应用层使用。</p><blockquote><p>在实际场景中，HTTP 中的 <code>Content-Length</code> 就起了类似的作用，当接收端收到的消息长度小于 Content-Length 时，说明还有些消息没收到。那接收端会一直等，直到拿够了消息或超时</p></blockquote><h2 id="4-UDP-会粘包吗"><a href="#4-UDP-会粘包吗" class="headerlink" title="4. UDP 会粘包吗?"></a>4. UDP 会粘包吗?</h2><p>跟 <code>TCP</code> 同为传输层的另一个协议，<strong>UDP，User Datagram Protocol</strong>。用户数据包协议，是面向无连接，不可靠的，基于<strong>数据报</strong>的传输层通信协议。</p><p><strong>基于数据报</strong>和<strong>基于字节流</strong>的差异，<strong>TCP 发送端发 10 次字节流数据，而这时候接收端可以分 100 次去取数据，每次取数据的长度可以根据处理能力作调整；但 UDP 发送端发了 10 次数据报，那接收端就要在 10 次收完，且发了多少，就取多少，确保每次都是一个完整的数据报。</strong></p><p><strong>IP 报头</strong>里面是有一个 16 位的总长度的，意味着 IP 报头里记录了整个 IP 包的总长度。接着我们再看下 <strong>UDP 的报头</strong>。</p><img src="../images/计算机网络/截屏2021-05-15 下午9.53.41.png" alt="截屏2021-05-15 下午9.53.41" style="zoom:50%;" /><p>UDP 报头中有 <code>16bit</code> 用于指示 <strong>UDP 数据报文的长度</strong>，接收端的应用层能清晰地将不同的数据报文区分开，从报头开始取 n 位，就是一个<strong>完整的</strong>数据报，从而避免粘包和拆包的问题。</p><img src="../images/计算机网络/截屏2021-05-15 下午5.39.51.png" alt="截屏2021-05-15 下午5.39.51" style="zoom:70%;" /><blockquote><p>就算没有<strong>16位 UDP 长度</strong>，因为 IP 的头部已经包含了数据的<strong>总长度</strong>信息，此时如果 IP 包里放的数据使用的协议是 UDP，这个<strong>总长度</strong>就包含了 UDP 的头部和 UDP 的数据。</p></blockquote><img src="../images/计算机网络/截屏2021-05-15 下午8.38.57.png" alt="截屏2021-05-15 下午8.38.57" style="zoom:50%;" /><p>TCP 首部里是没有长度这个信息的，</p><img src="../images/计算机网络/截屏2021-05-15 下午2.11.14.png" alt="截屏2021-05-15 下午2.11.14" style="zoom:70%;" /><p>跟 UDP 类似，同样可以通过下面的公式获得当前包的 TCP 数据长度。</p><img src="../images/计算机网络/截屏2021-05-15 下午8.58.32.png" alt="截屏2021-05-15 下午8.58.32" style="zoom:50%;" /><p>跟 UDP 不同在于，TCP 发送端在发的时候就<strong>不保证发的是一个完整的数据报</strong>，仅仅看成一连串无结构的字节流，这串字节流在接收端知道长度也没用，因为它很可能只是某个完整消息的一部分。</p><h2 id="5-IP-层有粘包问题吗"><a href="#5-IP-层有粘包问题吗" class="headerlink" title="5. IP 层有粘包问题吗?"></a>5. IP 层有粘包问题吗?</h2><p>IP 层的切片分包</p><img src="/Users/joker/Documents/chen_blog/source/images/计算机网络/截屏2021-05-15 下午8.17.12.png" alt="截屏2021-05-15 下午8.17.12" style="zoom:60%;" /><ul><li>如果消息过长，<code>IP层</code>会按 <strong>MTU 长度</strong>把消息分成 <strong>N 个切片</strong>，每个切片带有自身在<strong>包里的位置（offset）</strong>和<strong>同样的IP头信息</strong>。</li><li>各个切片在网络中进行传输。每个数据包切片可以在不同的路由中流转，然后<strong>在最后的终点汇合后再组装</strong>。</li><li>在接收端收到第一个切片包时会申请一块新内存，创建IP包的数据结构，等待其他切片分包数据到位。</li><li>等消息全部到位后就把整个消息包给到上层（传输层）进行处理。</li></ul><p><code>IP 层</code>从按长度切片到把切片组装成一个数据包的过程中，都只管运输，都不需要在意消息的边界和内容，都不在意消息内容了，那就不会有粘包一说了</p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><ol><li>TCP 不管发送端要发什么，都基于字节流把数据发到接收端。这个字节流里可能包含上一次想要发的数据的部分信息。接收端根据需要在消息里加上识别消息边界的信息。不加就可能出现粘包问题。</li><li>TCP 粘包跟Nagle算法有关系，但关闭 Nagle 算法并不解决粘包问题。</li><li>UDP 是基于数据报的传输协议，不会有粘包问题。</li><li>IP 层也切片，但是因为不关心消息里有啥，因此有不会有粘包问题。</li><li><code>TCP</code> 发送端可以发 <code>10 次</code>字节流数据，接收端可以分 <code>100 次</code>去取；<code>UDP</code> 发送端发了 <code>10 次</code>数据报，那接收端就要在 <code>10 次</code>收完。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello TCP</title>
      <link href="2020/02/01/Hello%20TCP/"/>
      <url>2020/02/01/Hello%20TCP/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="建立连接-三次握手"><a href="#建立连接-三次握手" class="headerlink" title="建立连接 [三次握手]"></a>建立连接 [三次握手]</h2><p>客户端和服务器通过 TCP 发送数据之前，必须先建立连接。建立连接的过程也被称为 TCP 握手，三次握手的目的是建立可靠的通信信道。确认自己与对方的发送与接收机能正常。</p><ol><li><p><strong>第一次握手</strong></p><blockquote><p>客户端 TCP 首先向服务器端 TCP 发送<strong>连接请求报文段</strong>，这时首部中的同步位 SYN = 1，同时选择一个初始随机序号 seq = x。此时，客户端进程进入<strong>同步已发送（SYN-SENT）</strong>状态</p></blockquote><p>TCP 规定，SYN 报文段（即 SYN = 1的报文段）<strong>不能携带数据</strong>，但是要<strong>消耗掉一个序号</strong>。</p><img src="../images/计算机网络/截屏2021-05-15 下午5.07.01.png" alt="截屏2021-05-15 下午5.07.01" style="zoom:28%;" /></li></ol><img src="../images/计算机网络/截屏2021-05-15 下午5.06.05.png" alt="截屏2021-05-15 下午5.06.05" style="zoom:40%;" /><ol start="2"><li><strong>第二次握手</strong></li></ol><p>服务器收到<strong>连接请求报文段</strong>后，如同意连接，则服务器会为该 TCP 连接<strong>分配缓存和变量</strong>，并向客户端返回<strong>确认报文段</strong>，在确认报文段中同步位 SYN = 1 和 确认位 ACK  = 1，确认号 ack = x + 1，同时也为自己选择一个初始序号 seq = y。这时 TCP 服务器进程进入<strong>同步收到（SYN-RCVD）</strong>状态</p><img src="../images/计算机网络/截屏2021-05-15 下午5.08.56.png" alt="截屏2021-05-15 下午5.08.56" style="zoom:28%;" /><img src="../images/计算机网络/截屏2021-05-15 下午5.10.03.png" alt="截屏2021-05-15 下午5.10.03" style="zoom:40%;" /><p>如果 server 端接到了 client 发的 SYN 后回了 SYN-ACK 后 client 掉线了, server 端没有收到 client 回来的ACK，那么，这个连接处于一个中间状态，即没成功，也没失败。于是，server端如果在一定时间内没有收到的TCP会重发SYN-ACK。</p><p>在 Linux 下，默认重试次数为 5 次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。</p><ol start="3"><li><strong>第三次握手</strong></li></ol><p>客户进程在收到服务器进程的确认报文后，客户端为该 TCP 连接<strong>分配缓存和变量</strong>，并向服务器端返回一个报文段，这个报文段是对服务器确认报文段进行确认，该报文段中 ACK = 1，确认号 ack = y + 1，而自己序号为 x + 1。客户端在发送 ACK 报文段后进入<strong>已建立连接（ESTABLISHED）</strong>状态，这时 TCP 连接已经建立。当服务器收到客户端的确认后，也进入<strong>ESTABLISHED</strong>状态。</p><img src="../images/计算机网络/截屏2021-05-15 下午5.14.28.png" alt="截屏2021-05-15 下午5.14.28" style="zoom:35%;" /><img src="../images/计算机网络/截屏2021-05-15 下午5.15.18.png" alt="截屏2021-05-15 下午5.15.18" style="zoom:40%;" /><p>‘</p><p>完成三次握手，随后客户端与服务器之间可以开始传输数据了。</p><p>![截屏2021-05-15 下午5.29.08](../images/计算机网络/截屏2021-05-15 下午5.29.08.png)</p><hr><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><h5 id="为什么在三次握手的过程中要初始化序列号，为什么要使用随机序号，而不能使用固定的序号？"><a href="#为什么在三次握手的过程中要初始化序列号，为什么要使用随机序号，而不能使用固定的序号？" class="headerlink" title="为什么在三次握手的过程中要初始化序列号，为什么要使用随机序号，而不能使用固定的序号？"></a><font color='blue'>为什么在三次握手的过程中要初始化序列号，为什么要使用随机序号，而不能使用固定的序号？</font></h5><p>这样选择序号的目的是为了<strong>防止由于网络路由 TCP 报文段可能存在延迟抵达与排序混乱的问题，从而而导致某个连接的一方对它作错误的解释</strong>。</p><p>如果客户服务器双方建立连接使用固定的序号，在经过三次握手后建立了一个TCP连接，在传输数据时有网路问题而导致数据未能到达，这个报文段在网络中停留。之后，由于某些原因（如客户端主机故障）导致这个TCP连接被释放，等到客户端主机恢复后，使用相同的序列号重新建立一个连接时，在之后的某个时间段，如果之前由于网络问题的报文段达到服务器端，那么服务器就可能会收下这个报文段，而这个数据是属于之前的旧连接的数据，所以这就会导致数据乱序的问题。</p><p>由于一个TCP连接是被一对端点所表示的，其中包括2个IP地址和2个端口号构成的4元组，因此即便是同一个连接也会出现不同的实例，如果连接由于某个报文段长时间延迟而关闭，然后又以相同的4元组被重新打开，那么可以相信延迟的报文段又会被视为有效据重新进入新连接的数据流中，这就会导致数据乱序问题。</p><p>为了避免上述的问题，<strong>避免连接实例间的序号重叠可以将风险降至最低</strong>。</p><p>一个 TCP 报文段只有同时具备连接的 4 元组与当前活动窗口的序列号，才会在通信过程中被对方认为是正确的。然而，这也反应了 TCP 连接的脆弱性：如果选择合适的序列号、IP地址和端口号，那么任何人都能伪造一个TCP报文段，从而打断 TCP 的正常连接。所以使用初始化序号的方式（通常随机生成序号）使得序列号变得难猜，或者使用加密来避免利用这种缺点被攻击。</p><p><strong><font color='blue'>为什么客户端第一次握手不能携带数据而第三次握手可以携带数据？</font></strong></p><blockquote><p>假如第一次握手可以携带数据的话，如果有人使用伪 TCP 报文段恶意攻击服务器，那么每次都在第一次握手中的 SYN 报文中携带大量的数据，因为它不会理会服务器的发送和接收能力是否正常，不断地给服务器重复发送这样携带大量数据的 SYN 报文，这会导致服务器需要花费大量的时间和内存来接收这些报文数据，这会将导致服务器连接资源和内存消耗殆尽。</p></blockquote><blockquote><p>之所以第一次握手不能携带数据，其中的一个原因就是<strong>避免让服务器受到攻击</strong>。而对于第三次握手，此时客户端已经建立了连接，通过前两次已经知道了服务器的接收正常，并且也知道了服务器的接收能力是多少，所以可以携带数据。</p></blockquote><p><strong><font color='blue'>为什么连接建立需要三次握手，而不是两次握手？</font></strong></p><p>根据前面描述，在第一次握手，客户端向服务发送建立连接请求，第二次握手，服务器同意建立连接，并向客户端返回一个确认报文，至此客户端已经知道了服务器同意建立连接，为什么客户端还需要对服务器的允许连接报文段进行确认？</p><blockquote><p><strong>三次握手的最主要目的是保证连接是双工的，可靠更多的是通过重传机制来保证的。</strong></p></blockquote><blockquote><p><strong>为了保证服务端能收接受到客户端的信息并能做出正确的应答而进行前两次(第一次和第二次)握手，为了保证客户端能够接收到服务端的信息并能做出正确的应答而进行后两次(第二次和第三次)握手。</strong></p></blockquote><p><strong><font color='blue'>SYN 洪泛攻击以及如何解决 SYN 洪泛攻击</font></strong></p><p>在三次握手的过程中，服务器为了响应一个收到的 SYN 报文段，会分配并初始化连接变量和缓存，然后服务器发送一个SYNACK报文段进行响应，并等待客户端的 ACK 报文段。如果客户不发送 ACK 来完成该三次握手的第三步，最终（通常在一分多钟之后）服务器将终止该半开连接并回收资源。</p><p>这种 TCP 连接管理协议的特性就会有这样一个漏洞，攻击者发送大量的 TCP SYN 报文段，而不完成第三次握手的步骤。随着这种 SYN 报文段的不断到来，服务器不断为这些半开连接分配资源，从而导致服务器连接资源被消耗殆尽。这种攻击就是 <strong>SYN 洪泛攻击</strong>。</p><p>为了应对这种攻击，现在有一种有效的防御系统，称为 <strong>SYN cookie</strong>。SYN cookie 的工作方式如下：</p><ol><li><p>当服务器接收到一个 SYN 报文段时，它并不知道该报文段是来自一个合法的用户，还是这种 SYN 洪泛攻击的一部分。因为服务器不会为该报文段生成一个半开的连接。相反，服务器生成一个初始 TCP 序列号，该序列号是 SYN 报文段的源IP地址和目的IP地址，源端口号和目的端口号以及仅有服务器知道的秘密数的复杂函数（散列函数）。这种精心制作的初始序列号称为为”cookie”。服务器则发送具有这种特殊初始序号的SYNACK报文分组。<strong>服务器并不记忆该cookie或任何对应于SYN的其他状态信息。</strong></p></li><li><p>如果该客户是合法的，则它将返回一个 ACK 报文段。当服务器收到该 ACK 报文段，需要验证该ACK是与前面发送的某个SYN相对应。由于服务器并不维护有关SYN报文段的记忆，所以服务器通过使用SYNACK报文段中的源和目的IP地址与端口号以及秘密数运行相同的散列函数。如果这个函数的结果（cookie值）加1和在客户的 ACK 报文段中的确认值相同的话，那么服务器就会认为该 ACK 对应于较早的 SYN 报文段，因此它是合法的。服务器则会生成一个套接字的全开连接。</p></li><li><p>另一方面，如果客户没有返回一个 ACK 报文段，说明之前的 SYN 报文段是洪泛攻击的一部分，但是它并没有对服务器产生危害，因为服务器没有为它分配任何资源。</p></li></ol><h2 id="释放连接-四次挥手"><a href="#释放连接-四次挥手" class="headerlink" title="释放连接 [四次挥手]"></a>释放连接 [四次挥手]</h2><p>数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于 ESTABLISHED 状态，然后客户端主动关闭，服务器被动关闭。由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。</p><ol><li><p><strong>第一次挥手</strong></p><blockquote><p>客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部 FIN = 1，其序列号为seq = u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入 <strong>FIN-WAIT-1</strong> 状态。</p></blockquote><p><font color='grey'>TCP 规定，FIN 报文段即使不携带数据，也要消耗一个序号。</font></p></li><li><p><strong>第二次挥手</strong></p><blockquote><p>服务器收到连接释放报文，发出确认报文，ACK=1，ack number=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了 CLOSE-WAIT (关闭等待）状态。</p></blockquote><p>TCP 服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT 状态持续的时间。</p></li><li><p><strong>第三次挥手</strong></p><blockquote><p>客户端收到服务器的确认请求后，此时，客户端就进入 <strong>FIN-WAIT-2</strong>（终止等待2）状态，等待服务器发送连接释放报文。服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN = 1，ack number= u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。</p></blockquote></li><li><p><strong>第四次挥手</strong></p><blockquote><p>客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack number=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了 <strong>TIME-WAIT</strong>(时间等待)<strong>状态。注意此时 TCP 连接还没有释放，必须经过 2MSL</strong>(最长报文段寿命)的时间后，等待 <strong>2MSL</strong> 后依然没有收到回复，则证明 Server 端已正常关闭,客户端撤销相应的 TCB 后，才进入 CLOSED 状态。</p></blockquote></li></ol><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>对实时性要求高和高速传输的场合下使用 UDP；在可靠性要求低，追求效率的情况下使用 UDP；</p><p>需要传输大量数据且对可靠性要求高的情况下使用 TCP</p><p>注：由于TCP提供可靠交付和有序性的保证，它是最适合需要高可靠并且对传输时间要求不高的应用。UDP 是更适合的应用程序需要快速，高效的传输的应用，如游戏。UDP 是无状态的性质，在服务器端需要对大量客户端产生的少量请求进行应答的应用中是非常有用的。在实践中，TCP 被用于金融领域，如FIX协议是一种基于 TCP 的协议，而 UDP 是大量使用在游戏和娱乐场所。</p><h2 id="TCP-报文段的首部格式"><a href="#TCP-报文段的首部格式" class="headerlink" title="TCP 报文段的首部格式"></a>TCP 报文段的首部格式</h2><p>一个 TCP 报文段分为<strong>首部</strong>和<strong>数据部分</strong>两部分。</p><img src="../images/计算机网络/截屏2021-05-15 下午2.11.14.png" alt="截屏2021-05-15 下午2.11.14" style="zoom:70%;" /><p>TCP 报文段首部的前 20 个字节是固定的，后面有 <code>4n</code> 字节是根据需要而增加的选项。因此 <strong>TCP 首部的最小字节是 20 字节</strong>。</p><p><strong>源端口和目的端口</strong></p><p>各占 2 字节，分别写入源端口号和目的端口号，TCP 的分用功能也是通过端口实现的。</p><p><strong>序号</strong></p><p>占 4 字节，序号范围是[0, 2<sup>32</sup> - 1]，共 2<sup>32</sup> 个序号。首部中的序号字段值则指的是本报文段所发送的数据的<strong>第一个字节的序号</strong>。</p><blockquote><p>序号是可以重用的，当序号增加到 [2<sup>32</sup>-1] 后，下一个序号就又回到了0，所以序号逻辑上可以表示为一个循环数组</p></blockquote><blockquote><p>例如，若一个报文段的序号字段值是 301，而携带的数据共有 100 字节，这就表明：本报文段的数据第一个字节的序号是 301，最后一个字节的序号是400。如果还有下一个报文段，则其序号字段的的值应为401。</p></blockquote><p><strong>确认号</strong></p><p>占 4 字节，是<strong>期望收到对方下一个报文段的第一个数据字节的序号</strong></p><blockquote><p>例如，B正确收到了A发送过来的一个报文段，其序号字段值是501，而该报文段的数据长度是200字节[序号501~700]，这表明B正确收到了A发送的到序号700为止的数据，因此B期望收到A的下一个数据序号是701，TCP是可靠传输，收到数据后需要给发送方回复确认信息，所以B在收到数据后给A发送的确认收到的报文段中就把确认号置为701。</p></blockquote><blockquote><p><strong>若确认号 = N,则表明：到序号N - 1为止的所有数据都已正确收到。</strong></p></blockquote><p><strong>数据偏移</strong></p><p>占 4 位，单位：4B。它指出 TCP 报文段数据起始处距离 TCP 报文段的起始处有多远。这个字段实际上是指出 <strong>TCP 报文段的首部长度</strong>。</p><p><strong>保留</strong></p><p>占 6 位，保留今后使用</p><p><strong>控制位</strong></p><ul><li><p><strong>紧急 URG</strong>（URGent）</p><p>仅当 URG = 1，表明后面的紧急指针字段才有效。它表明系统此<strong>报文段有紧急数据，应尽快传送，而不要按照原来的排队顺序来传送</strong>。</p></li><li><p><strong>确认 ACK</strong>（ACKnowledgment）</p><p>仅当 ACK = 1 时，确认号字段才有效。TCP 规定，<strong>在连接建立后所有传送的报文段都必须把 ACK 置 1。</strong></p></li><li><p><strong>推送 PSH</strong>（PUSH）</p><p>通常如果 TCP 缓存中字节很少，TCP 会等待积累有足够多的字节后再构成报文段发送出去，当发送方将 PSH 置为 1时，并立即创建一个报文段发送出去，接收方 TCP 收到 PSH = 1 的报文段，就尽快地交付接收应用进程，而不再等到整个缓存都填满在向上交付。</p></li><li><p><strong>复位 RST</strong>（ReSeT）</p><p>当 RST = 1 时，表明 TCP 连接中出现了严重差错，必须释放连接，然后再重新建立传输连接。RST置为1还可以用来拒绝一个非法的报文段或拒绝打开一个连接。RST也可称为重建位或重置位。</p></li><li><p><strong>同步 SYN</strong>（SYNchronization）</p><p><strong>在连接建立时用来同步序号。</strong>当SYN = 1而ACK = 0时，表明这是一个连接请求报文段。对方同意建立连接，则应在响应的报文段中使用SYN = 1和ACK = 1.因此，SYN 置为1表示这是一个连接请求或连接接收报文。</p></li><li><p><strong>终止 FIN</strong>（FINis）</p><p>用来释放一个连接。当FIN = 1时，表明此报文段的发送方的数据发送完毕，并要求释放传输连接。</p></li></ul><p><strong>窗口</strong></p><p>占2字节，是指发送本报文段的一方的<strong>接收窗口</strong>。窗口的值表示：从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量。即<strong>窗口值作为接收方让发送方设置其发送窗口的依据</strong>。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。</p><blockquote><p>例如，A是发送方，B是接收方，B给A发送一个确认接收数据的报文，其确认号701（表示701之前的所有数据都已经正确收到，期望A下一个报文段的第一个数据字节序号为701），窗口字段的值是1000，这就是告诉发送方A：从701号算起，我的接收缓存还可以接收1000个字节数据，在你给我发送数据的时候，你需要考虑一下我的接收能力。</p></blockquote><blockquote><p><strong>窗口字段明确指出了现在允许对方发送的数据量。窗口值是经常在动态变化</strong>。</p></blockquote><p><strong>校验和</strong></p><p>占2字节。校验和字段校验的范围包括<strong>首部</strong>和<strong>数据</strong>这两个部分。和UDP用户数据报一样，在计算校验和时，需要在TCP报文段的前面加上12字节的<strong>伪首部</strong>。伪首部的格式和UDP伪首部的格式一样，只是需要将协议字段改为6，TCP协议号是6。</p><p><strong>紧急指针</strong>：紧急指针只有在URG= 1时才有意义，它和URG字段配合使用，它指出了报文段中紧急数据的字节数，因此，紧急指针指出了<strong>紧急数据的末尾在报文段中的位置</strong>。</p><blockquote><p>即使窗口的值为0也可以发送紧急数据。</p></blockquote><p><strong>选项和填充</strong>：长度可变，最长可达40字节。填充字段是为了使整个TCP首部的长度是4字节的整数倍。</p><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><h2 id="TCP-特点"><a href="#TCP-特点" class="headerlink" title="TCP 特点"></a>TCP 特点</h2><ol><li><p>TCP 是<strong>面向连接</strong>的传输层协议</p><blockquote><p>应用程序是使用 TCP 协议之前，必须建立 TCP 连接。在传送数据完毕后，必须释放已建立的 TCP 连接。TCP 连接是一条虚连接（逻辑连接），而不是一条真正的物理连接。</p></blockquote></li><li><p>每一条 TCP 连接只能有两个<strong>端点</strong>，每条TCP连接只能是<strong>点对点</strong>的（一对一）。</p></li><li><p>TCP 提供<strong>可靠交付</strong>的服务。通过 TCP 连接传送的数据，<strong>无差错、不丢失、不重复、并且按序达到</strong>。</p></li><li><p>TCP 提供<strong>全双工通信</strong></p></li><li><p>TCP <strong>面向字节流</strong></p><blockquote><p>虽然应用程序和 TCP 的交互是一次一个数据块（大小可以不等），但是TCP把应用程序交下来的数据块看成仅仅一连串的<strong>无结构的字节流。</strong></p></blockquote></li></ol><h2 id="TCP-的连接"><a href="#TCP-的连接" class="headerlink" title="TCP 的连接"></a>TCP 的连接</h2><p>每条 TCP 连接有两个端点，TCP 连接的端点叫做<strong>套接字</strong>或<strong>插口</strong>，这里的套接字定义为：<strong>端口号拼接到IP地址即构成了套接字</strong>。</p><p>套接字的表示方法是在点分十进制的IP地址后面写上端口号，中间用冒号或逗号隔开。</p><p>套接字 socket=（IP地址 : 端口号）</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello UDP</title>
      <link href="2020/02/01/Hello%20UDP/"/>
      <url>2020/02/01/Hello%20UDP/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>用户数据报协议（UDP，User Datagram Protocol）为应用程序提供了一种无需建立连接就可以发送封装的 IP 数据报的方法。UDP 是一种保留消息边界的简单的面向数据报的协议。UDP不提供差错纠正、队列管理、重复消除、流量控制和拥塞控制，但提供差错检测</p><a id="more"></a><p>UDP协议自身提供最小功能，因此使用它的应用程序要做许多关于数据报如何发送和处理的控制工作。想要保证数据被可靠传递或正确排序，应用程序必须自己实现这些保护功能。一般来说，每个被应用程序请求的 UDP 输出操作只产生一个 UDP 数据报，从而发送一个 IP 数据报。而对于面向数据流的传输层协议（例如TCP），应用程序写入的全部数据与真正在单个IP数据报里传送的或接收方接收的内容可能没有联系。</p><h2 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h2><ol><li><p>UDP 是无连接的，即发送数据之前不需要建立连接，因此减少了开销和发送数据之前的时延。</p></li><li><p>UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的连接状态表。</p></li><li><p>UDP 是面向报文的。发送方的 UDP 对应用程序交下来的报文，在添加首部后就向下交付 IP 层。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。因此，应用程序必须选择合适大小的报文。</p><p>这就是说，应用层交给 UDP 多长的报文，UDP就照样发送，即 <strong>UDP一次交付一个完整的报文</strong>。</p><p>因此，应用程序必须选择合适大小的报文。若报文太长，UDP把它交给IP层后，IP层在传送时可能要进行分片，这会降低IP层的效率。反之，如果报文太短，UDP把它交给IP层后，会使IP数据报的首部相对长度太大，也降低了IP层的效率。</p></li><li><p><strong>UDP 没有拥塞控制，因此网络出现的拥塞不会使源主机的发送速率降低。</strong></p><p>很多的实时应用（如IP电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太多的时延。UDP 正好符合这种要求。</p><p>虽然某些实时应用需要使用没有拥塞控制的 UDP ,但当很多的源主机同时都向网络发送高速率的实时视频流时,网络就有可能发生拥塞,结果大家都无法正常接收。因此,不使用拥塞控制功能的 UDP 有可能会引起网络产生严重的拥塞问题。</p></li><li><p>UDP 支持一对一、一对多、多对一和多对多的交互通信。</p></li><li><p>UDP 的首部开销小，只有8个字节，比 TCP 的 20 个字节的首部要短。</p></li></ol><h2 id="UDP-的首部格式"><a href="#UDP-的首部格式" class="headerlink" title="UDP 的首部格式"></a>UDP 的首部格式</h2><p>UDP 有两个字段：数据字段和首部字段。首部字段很简单，只有8个字节，由4个字段组成，每个字段的长度都是两个字节。各字段意义如下：</p><img src="../images/计算机网络/截屏2021-05-15 下午5.39.51.png" alt="截屏2021-05-15 下午5.39.51" style="zoom:50%;" /><ol><li><p><strong>源端口</strong></p><p>源端口号。在需要对方回信时选用。不需要时可用全0。</p></li><li><p><strong>目的端口</strong></p><p>目的端口号。这在终点交付报文时必须要使用到。</p></li><li><p><strong>长度</strong></p><p>UDP 用户数据报的长度，其最小值是 8（仅有首部），发送一个带 0 字节数据的 UDP 数据报是允许的。</p><p>值得注意的是，UDP 长度字段是冗余的；IPV4 头部包含了数据报的总长度，同时 IPV6 头部包含了负载长度。因此，一个 UDP/IPV4 数据报的长度等于 IPV4 数据报的总长度减去 IPV4 头部的长度。一个 UDP/IPV6 数据报的长度等于包含在 IPV6 头部中的负载长度（payload length）字段的值减去所有扩展头部（除非使用了超长数据报）的长度。这两种情况下，UDP长度字段应该与从IP层提供的信息计算得到的长度是一致的。</p></li><li><p><strong>校验和</strong></p><p>检测 UDP 用户数据报在传输中是否有错。有错就丢弃。</p></li></ol><h2 id="UDP-伪首部和校验和计算"><a href="#UDP-伪首部和校验和计算" class="headerlink" title="UDP 伪首部和校验和计算"></a>UDP 伪首部和校验和计算</h2><p><strong>UDP 检验和提供差错检测功能</strong>。在计算校验和时，要在 UDP 用户数据报之前增加12字节的<strong>伪首部</strong>。</p><blockquote><p>伪首部并不是 UDP 用户数据报真正的首部，只是在计算校验和时，临时添加在 UDP 用户数据报前面，得到一个临时的 UDP 用户数据报。</p></blockquote><p><strong>校验和就是按照这个临时的 UDP 用户数据报计算来的</strong>，伪首部既不向下传送也不向上递交，<strong>仅仅是为了计算校验和</strong>。</p><ol><li><strong>源IP地址和目的IP地址</strong>：和 IP 数据一样，各占4个字节。</li><li><strong>伪首部第3个字段是全零</strong>。</li><li><strong>协议字段</strong>：以前说过，UDP 协议的协议字段值是17。</li><li><strong>UDP长度</strong>：UDP 用户数据报长度，首部长度和数据部分长度之和。</li></ol><h2 id="UDP-amp-TCP"><a href="#UDP-amp-TCP" class="headerlink" title="UDP&amp;TCP"></a>UDP&amp;TCP</h2><p>TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议，是专门为了在不可靠的网络中提供一个可靠的端对端字节流而设计的，面向字节流。</p><p>UDP（用户数据报协议）是ISO参考模型中一种无连接的传输层协议，提供简单不可靠的非连接传输层服务，面向报文</p><ol><li><p>TCP 面向连接，客户端和服务器通过 TCP 发送数据之前，必须先建立连接。建立连接的过程也被称为 TCP握手。UDP 是无连接的，即发送数据之前不需要建立连接</p></li><li><p>TCP 提供可靠的服务。通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP尽最大努力交付，即不保证可靠交付</p></li><li><p>TCP 速度比较慢，而 UDP 速度比较快。</p><p>因为 TCP 必须创建连接，以保证消息的可靠交付和有序性，需要做的 UDP 多的多的事。这就是为什么 UDP 更适用于对速度比较敏感的应用，例如：在线视频媒体，电视广播和多人在线游戏</p></li><li><p>TCP面向字节流，实际上是 TCP 把数据看成一连串无结构的字节流；UDP 面向报文</p></li><li><p>TCP 有流量控、拥塞控制。</p><p>在任何用户数据可以被发送之前，TCP 需要设置一个套接字连接，UDP 不能进行流量控制。</p><p>UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）</p></li><li><p>每一条 TCP 连接只能是点到点的；UDP 支持一对一，一对多，多对一和多对多的交互通信</p></li><li><p>TCP首部开销 20 字节；UDP 的首部开销小，只有 8 个字节</p></li><li><p>TCP 的逻辑通信信道是全双工的可靠信道，UDP 则是不可靠信道</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用 Flink ProcessFunction 处理宕机告警</title>
      <link href="2020/01/28/%E4%BD%BF%E7%94%A8-Flink-ProcessFunction-%E5%A4%84%E7%90%86%E5%AE%95%E6%9C%BA%E5%91%8A%E8%AD%A6/"/>
      <url>2020/01/28/%E4%BD%BF%E7%94%A8-Flink-ProcessFunction-%E5%A4%84%E7%90%86%E5%AE%95%E6%9C%BA%E5%91%8A%E8%AD%A6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Flink 的底层 API 就是 ProcessFunction，它是一个低阶的流处理操作，它可以访问流处理程序的基础构建模块：Event、State、Timer。ProcessFunction 可以被认为是一种提供了对 KeyedState 和定时器访问的 FlatMapFunction。每当数据源中接收到一个事件，就会调用来此函数来处理。对于容错的状态，ProcessFunction 可以通过 RuntimeContext 访问 KeyedState。</p><a id="more"></a><h3 id="ProcessFunction-介绍"><a href="#ProcessFunction-介绍" class="headerlink" title="ProcessFunction 介绍"></a>ProcessFunction 介绍</h3><p>Flink 的底层 API 就是 ProcessFunction，它是一个低阶的流处理操作，它可以访问流处理程序的基础构建模块：Event、State、Timer。ProcessFunction 可以被认为是一种提供了对 KeyedState 和定时器访问的 FlatMapFunction。每当数据源中接收到一个事件，就会调用来此函数来处理。对于容错的状态，ProcessFunction 可以通过 RuntimeContext 访问 KeyedState。</p><p>定时器可以对处理时间和事件时间的变化做一些处理。每次调用 processElement() 都可以获得一个 Context 对象，通过该对象可以访问元素的事件时间戳以及 TimerService。TimerService 可以为尚未发生的事件时间/处理时间实例注册回调。当定时器到达某个时刻时，会调用 onTimer() 方法。在调用期间，所有状态再次限定为定时器创建的 key，允许定时器操作 KeyedState。如果要访问 KeyedState 和定时器，那必须在 KeyedStream 上使用 KeyedProcessFunction，比如在 keyBy 算子之后使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(...).process(<span class="keyword">new</span> KeyedProcessFunction&lt;&gt;()&#123;</span><br><span class="line"></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>KeyedProcessFunction 是 ProcessFunction 函数的一个扩展，它可以在 onTimer 和 processElement 方法中获取到分区的 Key 值，这对于数据传递是很有帮助的，因为经常有这样的需求，经过 keyBy 算子之后可能还需要这个 key 字段，那么在这里直接构建成一个新的对象（新增一个 key 字段），然后下游的算子直接使用这个新对象中的 key 就好了，而不在需要重复的拼一个唯一的 key。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(String value, Context ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    System.out.println(ctx.getCurrentKey());</span><br><span class="line">    out.collect(value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onTimer</span><span class="params">(<span class="keyword">long</span> timestamp, OnTimerContext ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    System.out.println(ctx.getCurrentKey());</span><br><span class="line">    <span class="keyword">super</span>.onTimer(timestamp, ctx, out);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="CoProcessFunction-介绍"><a href="#CoProcessFunction-介绍" class="headerlink" title="CoProcessFunction 介绍"></a>CoProcessFunction 介绍</h3><p>如果要在两个输入流上进行操作，可以使用 CoProcessFunction，这个函数可以传入两个不同的数据流输入，并为来自两个不同数据源的事件分别调用 processElement1() 和 processElement2() 方法。可以按照下面的步骤来实现一个典型的 Join 操作：</p><ul><li>为一个数据源的数据建立一个状态对象</li><li>从数据源处有新数据流过来的时候更新这个状态对象</li><li>在另一个数据源接收到元素时，关联状态对象并对其产生出连接的结果</li></ul><p>比如，将监控的 metric 数据和告警规则数据进行一个连接，在流数据的状态中存储了告警规则数据，当有监控数据过来时，根据监控数据的 metric 名称和一些 tag 去找对应告警规则计算表达式，然后通过规则的表达式对数据进行加工处理，判断是否要告警，如果是要告警则会关联构造成一个新的对象，新对象中不仅有初始的监控 metric 数据，还有含有对应的告警规则数据以及通知策略数据，组装成这样一条数据后，下游就可以根据这个数据进行通知，通知还会在状态中存储这个告警状态，表示它在什么时间告过警了，下次有新数据过来的时候，判断新数据是否是恢复的，如果属于恢复则把该状态清除。</p><h3 id="Timer-介绍"><a href="#Timer-介绍" class="headerlink" title="Timer 介绍"></a>Timer 介绍</h3><p>Timer 提供了一种定时触发器的功能，通过 TimerService 接口注册 timer。TimerService 在内部维护两种类型的定时器（处理时间和事件时间定时器）并排队执行。处理时间定时器的触发依赖于 ProcessingTimeService，它负责管理所有基于处理时间的触发器，内部使用 ScheduledThreadPoolExecutor 调度定时任务；事件时间定时器的触发依赖于系统当前的 Watermark。需要注意的一点就是：<strong>Timer 只能在 KeyedStream 中使用</strong>。</p><p>TimerService 会删除每个 Key 和时间戳重复的定时器，即每个 Key 在同一个时间戳上最多有一个定时器。如果为同一时间戳注册了多个定时器，则只会调用一次 onTimer（） 方法。Flink 会同步调用 onTimer() 和 processElement() 方法，因此不必担心状态的并发修改问题。TimerService 不仅提供了注册和删除 Timer 的功能，还可以通过它来获取当前的系统时间和 Watermark 的值。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-14-160008.png" alt="img"></p><h4 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h4><p>定时器具有容错能力，并且会与应用程序的状态一起进行 Checkpoint，如果发生故障重启会从 Checkpoint／Savepoint 中恢复定时器的状态。如果有处理时间定时器原本是要在恢复起来的那个时间之前触发的，那么在恢复的那一刻会立即触发该定时器。定时器始终是异步的进行 Checkpoint（除 RocksDB 状态后端存储、增量的 Checkpoint、基于堆的定时器外）。因为定时器实际上也是一种特殊状态的状态，在 Checkpoint 时会写入快照中，所以如果有大量的定时器，则无非会增加一次 Checkpoint 所需要的时间，必要的话得根据实际情况合并定时器。</p><h4 id="合并定时器"><a href="#合并定时器" class="headerlink" title="合并定时器"></a>合并定时器</h4><p>由于 Flink 仅为每个 Key 和时间戳维护一个定时器，因此可以通过降低定时器的频率来进行合并以减少定时器的数量。对于频率为 1 秒的定时器（基于事件时间或处理时间），可以将目标时间向下舍入为整秒数，则定时器最多提前 1 秒触发，但不会迟于我们的要求，精确到毫秒。因此，每个键每秒最多有一个定时器。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> coalescedTime = ((ctx.timestamp() + timeout) / <span class="number">1000</span>) * <span class="number">1000</span>;</span><br><span class="line">ctx.timerService().registerProcessingTimeTimer(coalescedTime);</span><br></pre></td></tr></table></figure><p>由于事件时间计时器仅在 Watermark 到达时才触发，因此可以将当前 Watermark 与下一个 Watermark 的定时器一起调度和合并：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> coalescedTime = ctx.timerService().currentWatermark() + <span class="number">1</span>;</span><br><span class="line">ctx.timerService().registerEventTimeTimer(coalescedTime);</span><br></pre></td></tr></table></figure><p>定时器也可以类似下面这样移除：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//删除处理时间定时器</span></span><br><span class="line"><span class="keyword">long</span> timestampOfTimerToStop = ...</span><br><span class="line">ctx.timerService().deleteProcessingTimeTimer(timestampOfTimerToStop);</span><br><span class="line"></span><br><span class="line"><span class="comment">//删除事件时间定时器</span></span><br><span class="line"><span class="keyword">long</span> timestampOfTimerToStop = ...</span><br><span class="line">ctx.timerService().deleteEventTimeTimer(timestampOfTimerToStop);</span><br></pre></td></tr></table></figure><p>如果没有该时间戳的定时器，则删除定时器无效。</p><h3 id="如果利用-ProcessFunction-处理宕机告警？"><a href="#如果利用-ProcessFunction-处理宕机告警？" class="headerlink" title="如果利用 ProcessFunction 处理宕机告警？"></a>如果利用 ProcessFunction 处理宕机告警？</h3><p>前面介绍了 ProcessFunction 和 Timer，那么这里讲下笔者公司生产环境的一个案例 —— 利用 ProcessFunction 处理宕机告警？</p><h4 id="宕机告警需求分析"><a href="#宕机告警需求分析" class="headerlink" title="宕机告警需求分析"></a>宕机告警需求分析</h4><p>首先大家应该知道生产环境的服务器一般都是有部署各种各种的服务或者中间件的，那么如果一台机器突然发生了一些突发情况，比如断电、自然灾害、人为因素、服务把机器跑宕机等，那么机器一宕机，原先跑在该机器的服务都会掉线，导致服务出现短暂不可用（可能应用会调度到其他机器）或者直接不可用（没有调度策略并且是运行的单实例），这对于生产环境来说，就麻烦比较大，可能会出现很大的损失，所以这种紧急情况就特别需要实时性非常高的告警。</p><p>在面对这个需求时首先得想一想怎么去判定一台机器是否处于宕机，因为会在机器上部署采集机器信息的 Agent，如果机器是正常的，每隔一定时间（假设时间间隔为 10 秒） Agent 会将数据进行上传，所有的监控数据上传至消息队列后，接下来就需要对这些监控数据处理。那么当机器处于宕机的状态，则运行在机器的 Agent 就已经停止工作了，则它就不会继续上传监控信息来了，所以这里就可以根据判定是否有这台机器的监控数据上来，如果持续有，那么说明机器在线，如果持续一段时间没有收到该机器的数据，则意味着该机器宕机了，那么可能就有人想问了，这个持续时间设置多少合适呢？这个得根据实际情况去做大量的测试和调优了，如果设置的过短，假设数据在消息队列中堆积了一会，那么也会出现误判的宕机告警；如果设置的过长，那么可能机器中途宕机过然后重启了，但是时间还是在设置的预定时间之内，这种情况就出现了宕机告警漏报，也是不允许的（告警延迟性增大并且可能告警漏报），所以就得根据实际情况两者之间做一个权衡。</p><p>在分析完需求后，接下来就得看如何去实现这种需求，怎么去判断机器是否一直有数据上来？那么这里就利用了 Timer 机制。</p><h4 id="宕机告警实现"><a href="#宕机告警实现" class="headerlink" title="宕机告警实现"></a>宕机告警实现</h4><p>机器监控数据有很多的指标，这里列几种比较常见的比如 Mem、CPU、Load、Swap 等，那么这几种数据采集上来的结构都是 MetricEvent 类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MetricEvent</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指标名</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//数据时间</span></span><br><span class="line">    <span class="keyword">private</span> Long timestamp;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指标具体字段</span></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Object&gt; fields;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指标的标识</span></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, String&gt; tags;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就拿 CPU 来举个例子，它发上来的数据是下面这种的：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;cpu&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;timestamp&quot;</span>: <span class="number">1571108814142</span>,</span><br><span class="line">    <span class="attr">&quot;fields&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;usedPercent&quot;</span>: <span class="number">93.896484375</span>,</span><br><span class="line">        <span class="attr">&quot;max&quot;</span>: <span class="number">2048</span>,</span><br><span class="line">        <span class="attr">&quot;used&quot;</span>: <span class="number">1923</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;tags&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;cluster_name&quot;</span>: <span class="string">&quot;zhisheng&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;host_ip&quot;</span>: <span class="string">&quot;121.12.17.11&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里笔者写了个模拟 Mem、CPU、Load、Swap 监控数据的工具类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BuildMachineMetricDataUtil</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String BROKER_LIST = <span class="string">&quot;localhost:9092&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String METRICS_TOPIC = <span class="string">&quot;zhisheng_metrics&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Random random = <span class="keyword">new</span> Random();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> List&lt;String&gt; hostIps = Arrays.asList(<span class="string">&quot;121.12.17.10&quot;</span>, <span class="string">&quot;121.12.17.11&quot;</span>, <span class="string">&quot;121.12.17.12&quot;</span>, <span class="string">&quot;121.12.17.13&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">writeDataToKafka</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, BROKER_LIST);</span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        KafkaProducer producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">long</span> timestamp = System.currentTimeMillis();</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; hostIps.size(); i++) &#123;</span><br><span class="line">                MetricEvent cpuData = buildCpuData(hostIps.get(i), timestamp);</span><br><span class="line">                MetricEvent loadData = buildLoadData(hostIps.get(i), timestamp);</span><br><span class="line">                MetricEvent memData = buildMemData(hostIps.get(i), timestamp);</span><br><span class="line">                MetricEvent swapData = buildSwapData(hostIps.get(i), timestamp);</span><br><span class="line">                ProducerRecord cpuRecord = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(METRICS_TOPIC, <span class="keyword">null</span>, <span class="keyword">null</span>, GsonUtil.toJson(cpuData));</span><br><span class="line">                ProducerRecord loadRecord = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(METRICS_TOPIC, <span class="keyword">null</span>, <span class="keyword">null</span>, GsonUtil.toJson(loadData));</span><br><span class="line">                ProducerRecord memRecord = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(METRICS_TOPIC, <span class="keyword">null</span>, <span class="keyword">null</span>, GsonUtil.toJson(memData));</span><br><span class="line">                ProducerRecord swapRecord = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(METRICS_TOPIC, <span class="keyword">null</span>, <span class="keyword">null</span>, GsonUtil.toJson(swapData));</span><br><span class="line">                producer.send(cpuRecord);</span><br><span class="line">                producer.send(loadRecord);</span><br><span class="line">                producer.send(memRecord);</span><br><span class="line">                producer.send(swapRecord);</span><br><span class="line">            &#125;</span><br><span class="line">            producer.flush();</span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        writeDataToKafka();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> MetricEvent <span class="title">buildCpuData</span><span class="params">(String hostIp, Long timestamp)</span> </span>&#123;</span><br><span class="line">        MetricEvent metricEvent = <span class="keyword">new</span> MetricEvent();</span><br><span class="line">        Map&lt;String, String&gt; tags = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        Map&lt;String, Object&gt; fields = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> used = random.nextInt(<span class="number">2048</span>);</span><br><span class="line">        <span class="keyword">int</span> max = <span class="number">2048</span>;</span><br><span class="line">        metricEvent.setName(<span class="string">&quot;cpu&quot;</span>);</span><br><span class="line">        metricEvent.setTimestamp(timestamp);</span><br><span class="line">        tags.put(<span class="string">&quot;cluster_name&quot;</span>, <span class="string">&quot;zhisheng&quot;</span>);</span><br><span class="line">        tags.put(<span class="string">&quot;host_ip&quot;</span>, hostIp);</span><br><span class="line">        fields.put(<span class="string">&quot;usedPercent&quot;</span>, (<span class="keyword">double</span>) used / max * <span class="number">100</span>);</span><br><span class="line">        fields.put(<span class="string">&quot;used&quot;</span>, used);</span><br><span class="line">        fields.put(<span class="string">&quot;max&quot;</span>, max);</span><br><span class="line">        metricEvent.setFields(fields);</span><br><span class="line">        metricEvent.setTags(tags);</span><br><span class="line">        <span class="keyword">return</span> metricEvent;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> MetricEvent <span class="title">buildLoadData</span><span class="params">(String hostIp, Long timestamp)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//构建 load 数据，和构建 CPU 数据类似</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> MetricEvent <span class="title">buildSwapData</span><span class="params">(String hostIp, Long timestamp)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//构建swap数据，和构建 CPU 数据类似</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> MetricEvent <span class="title">buildMemData</span><span class="params">(String hostIp, Long timestamp)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//构建内存的数据，和构建 CPU 数据类似</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后 Flink 应用程序实时的去消费 Kafka 中的机器监控数据，先判断数据能够正常消费到。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> ParameterTool parameterTool = ExecutionEnvUtil.createParameterTool(args);</span><br><span class="line">StreamExecutionEnvironment env = ExecutionEnvUtil.prepare(parameterTool);</span><br><span class="line"></span><br><span class="line">Properties properties = KafkaConfigUtil.buildKafkaProps(parameterTool);</span><br><span class="line">FlinkKafkaConsumer011&lt;MetricEvent&gt; consumer = <span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">        parameterTool.get(<span class="string">&quot;metrics.topic&quot;</span>),</span><br><span class="line">        <span class="keyword">new</span> MetricSchema(),</span><br><span class="line">        properties);</span><br><span class="line">env.addSource(consumer)</span><br><span class="line">        .assignTimestampsAndWatermarks(<span class="keyword">new</span> MetricWatermark())</span><br><span class="line">        .print();</span><br></pre></td></tr></table></figure><p>再确定能够消费到机器监控数据之后，接下来需要对数据进行构造成 OutageMetricEvent 对象：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OutageMetricEvent</span> </span>&#123;</span><br><span class="line">    <span class="comment">//机器集群名</span></span><br><span class="line">    <span class="keyword">private</span> String clusterName;</span><br><span class="line">    <span class="comment">//机器 host ip</span></span><br><span class="line">    <span class="keyword">private</span> String hostIp;</span><br><span class="line">    <span class="comment">//事件时间</span></span><br><span class="line">    <span class="keyword">private</span> Long timestamp;</span><br><span class="line">    <span class="comment">//机器告警是否恢复</span></span><br><span class="line">    <span class="keyword">private</span> Boolean recover;</span><br><span class="line">    <span class="comment">//机器告警恢复时间</span></span><br><span class="line">    <span class="keyword">private</span> Long recoverTime;</span><br><span class="line">    <span class="comment">//系统时间</span></span><br><span class="line">    <span class="keyword">private</span> Long systemTimestamp;</span><br><span class="line">    <span class="comment">//机器 CPU 使用率</span></span><br><span class="line">    <span class="keyword">private</span> Double cpuUsePercent;</span><br><span class="line">    <span class="comment">//机器内存使用率</span></span><br><span class="line">    <span class="keyword">private</span> Double memUsedPercent;</span><br><span class="line">    <span class="comment">//机器 SWAP 使用率</span></span><br><span class="line">    <span class="keyword">private</span> Double swapUsedPercent;</span><br><span class="line">    <span class="comment">//机器 load5</span></span><br><span class="line">    <span class="keyword">private</span> Double load5;</span><br><span class="line">    <span class="comment">//告警数量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> counter = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过 FlatMap 算子转换：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> FlatMapFunction&lt;MetricEvent, OutageMetricEvent&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(MetricEvent metricEvent, Collector&lt;OutageMetricEvent&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Map&lt;String, String&gt; tags = metricEvent.getTags();</span><br><span class="line">        <span class="keyword">if</span> (tags.containsKey(CLUSTER_NAME) &amp;&amp; tags.containsKey(HOST_IP)) &#123;</span><br><span class="line">            OutageMetricEvent outageMetricEvent = OutageMetricEvent.buildFromEvent(metricEvent);</span><br><span class="line">            <span class="keyword">if</span> (outageMetricEvent != <span class="keyword">null</span>) &#123;</span><br><span class="line">                collector.collect(outageMetricEvent);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将数据转换后，需要将监控数据按照机器的 IP 进行 KeyBy，因为每台机器可能都会出现错误，所以都要将不同机器的状态都保存着，然后使用 process 算子，在该算子中，使用 ValueState 保存 OutageMetricEvent 和机器告警状态信息，另外还有一个 delay 字段定义的是持续多久没有收到监控数据的时间，alertCountLimit 表示的是告警的次数，如果超多一定的告警次数则会静默。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OutageProcessFunction</span> <span class="keyword">extends</span> <span class="title">KeyedProcessFunction</span>&lt;<span class="title">String</span>, <span class="title">OutageMetricEvent</span>, <span class="title">OutageMetricEvent</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ValueState&lt;OutageMetricEvent&gt; outageMetricState;</span><br><span class="line">    <span class="keyword">private</span> ValueState&lt;Boolean&gt; recover;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> delay;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> alertCountLimit;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">OutageProcessFunction</span><span class="params">(<span class="keyword">int</span> delay, <span class="keyword">int</span> alertCountLimit)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.delay = delay;</span><br><span class="line">        <span class="keyword">this</span>.alertCountLimit = alertCountLimit;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        TypeInformation&lt;OutageMetricEvent&gt; outageInfo = TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;OutageMetricEvent&gt;() &#123;</span><br><span class="line">        &#125;);</span><br><span class="line">        TypeInformation&lt;Boolean&gt; recoverInfo = TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Boolean&gt;() &#123;</span><br><span class="line">        &#125;);</span><br><span class="line">        outageMetricState = getRuntimeContext().getState(<span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(<span class="string">&quot;outage_zhisheng&quot;</span>, outageInfo));</span><br><span class="line">        recover = getRuntimeContext().getState(<span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(<span class="string">&quot;recover_zhisheng&quot;</span>, recoverInfo));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(OutageMetricEvent outageMetricEvent, Context ctx, Collector&lt;OutageMetricEvent&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        OutageMetricEvent current = outageMetricState.value();</span><br><span class="line">        <span class="keyword">if</span> (current == <span class="keyword">null</span>) &#123;</span><br><span class="line">            current = <span class="keyword">new</span> OutageMetricEvent(outageMetricEvent.getClusterName(), outageMetricEvent.getHostIp(),</span><br><span class="line">                    outageMetricEvent.getTimestamp(), outageMetricEvent.getRecover(), System.currentTimeMillis());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (outageMetricEvent.getLoad5() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                current.setLoad5(outageMetricEvent.getLoad5());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (outageMetricEvent.getCpuUsePercent() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                current.setCpuUsePercent(outageMetricEvent.getCpuUsePercent());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (outageMetricEvent.getMemUsedPercent() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                current.setMemUsedPercent(outageMetricEvent.getMemUsedPercent());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (outageMetricEvent.getSwapUsedPercent() != <span class="keyword">null</span>) &#123;</span><br><span class="line">                current.setSwapUsedPercent(outageMetricEvent.getSwapUsedPercent());</span><br><span class="line">            &#125;</span><br><span class="line">            current.setSystemTimestamp(System.currentTimeMillis());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (recover.value() != <span class="keyword">null</span> &amp;&amp; !recover.value() &amp;&amp; outageMetricEvent.getTimestamp() &gt; current.getTimestamp()) &#123;</span><br><span class="line">            OutageMetricEvent recoverEvent = <span class="keyword">new</span> OutageMetricEvent(outageMetricEvent.getClusterName(), outageMetricEvent.getHostIp(),</span><br><span class="line">                    current.getTimestamp(), <span class="keyword">true</span>, System.currentTimeMillis());</span><br><span class="line">            recoverEvent.setRecoverTime(ctx.timestamp());</span><br><span class="line">            log.info(<span class="string">&quot;触发宕机恢复事件:&#123;&#125;&quot;</span>, recoverEvent);</span><br><span class="line">            collector.collect(recoverEvent);</span><br><span class="line">            current.setCounter(<span class="number">0</span>);</span><br><span class="line">            outageMetricState.update(current);</span><br><span class="line">            recover.update(<span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        current.setTimestamp(outageMetricEvent.getTimestamp());</span><br><span class="line">        outageMetricState.update(current);</span><br><span class="line">        ctx.timerService().registerEventTimeTimer(current.getSystemTimestamp() + delay);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onTimer</span><span class="params">(<span class="keyword">long</span> timestamp, OnTimerContext ctx, Collector&lt;OutageMetricEvent&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        OutageMetricEvent result = outageMetricState.value();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (result != <span class="keyword">null</span> &amp;&amp; timestamp &gt;= result.getSystemTimestamp() + delay &amp;&amp; System.currentTimeMillis() - result.getTimestamp() &gt;= delay) &#123;</span><br><span class="line">            <span class="keyword">if</span> (result.getCounter() &gt; alertCountLimit) &#123;</span><br><span class="line">                log.info(<span class="string">&quot;宕机告警次数大于:&#123;&#125; :&#123;&#125;&quot;</span>, alertCountLimit, result);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            log.info(<span class="string">&quot;触发宕机告警事件:timestamp = &#123;&#125;, result = &#123;&#125;&quot;</span>, System.currentTimeMillis(), result);</span><br><span class="line">            result.setRecover(<span class="keyword">false</span>);</span><br><span class="line">            out.collect(result);</span><br><span class="line">            ctx.timerService().registerEventTimeTimer(timestamp + delay);</span><br><span class="line">            result.setCounter(result.getCounter() + <span class="number">1</span>);</span><br><span class="line">            result.setSystemTimestamp(timestamp);</span><br><span class="line">            outageMetricState.update(result);</span><br><span class="line">            recover.update(<span class="keyword">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 processElement 方法中不断的处理数据，在处理的时候会从状态中获取看之前状态是否存在数据，在该方法内部最后通过 <code>ctx.timerService().registerEventTimeTimer(current.getSystemTimestamp() + delay);</code> 去注册一个事件时间的定时器，时间戳是当前的系统时间加上 delay 的时间。</p><p>在 onTimer 方法中就是具体的定时器，在定时器中获取到状态值，然后将状态值中的时间与 delay 的时间差是否满足，如果满足则表示一直没有数据过来，接着对比目前告警的数量与定义的限制数量，如果大于则不告警了，如果小于则表示触发了宕机告警并且打印相关的日志，然后更新状态中的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onTimer</span><span class="params">(<span class="keyword">long</span> timestamp, OnTimerContext ctx, Collector&lt;OutageMetricEvent&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    OutageMetricEvent result = outageMetricState.value();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (result != <span class="keyword">null</span> &amp;&amp; timestamp &gt;= result.getSystemTimestamp() + delay &amp;&amp; System.currentTimeMillis() - result.getTimestamp() &gt;= delay) &#123;</span><br><span class="line">        <span class="keyword">if</span> (result.getCounter() &gt; alertCountLimit) &#123;</span><br><span class="line">            log.info(<span class="string">&quot;宕机告警次数大于:&#123;&#125; :&#123;&#125;&quot;</span>, alertCountLimit, result);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        log.info(<span class="string">&quot;触发宕机告警事件:timestamp = &#123;&#125;, result = &#123;&#125;&quot;</span>, System.currentTimeMillis(), result);</span><br><span class="line">        result.setRecover(<span class="keyword">false</span>);</span><br><span class="line">        out.collect(result);</span><br><span class="line">        ctx.timerService().registerEventTimeTimer(timestamp + delay);</span><br><span class="line">        result.setCounter(result.getCounter() + <span class="number">1</span>);</span><br><span class="line">        result.setSystemTimestamp(timestamp);</span><br><span class="line">        outageMetricState.update(result);</span><br><span class="line">        recover.update(<span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就完成了告警事件的判断了，接下来的算子就可以将告警事件转换成告警消息，然后将告警消息发送到下游去通知。那么就这样可以完成一个机器宕机告警的需求。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka：ReplicaStateMachine 副本状态机</title>
      <link href="2020/01/13/Kafka%E5%89%AF%E6%9C%AC%E7%8A%B6%E6%80%81%E6%9C%BA/"/>
      <url>2020/01/13/Kafka%E5%89%AF%E6%9C%AC%E7%8A%B6%E6%80%81%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>副本状态机代码定义了 Kafka 副本的状态集合，同时控制了这些状态之间的流转规则</p><a id="more"></a><h2 id="1-定义与初始化"><a href="#1-定义与初始化" class="headerlink" title="1. 定义与初始化"></a>1. 定义与初始化</h2><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-11 上午10.09.34.png" alt="截屏2021-05-11 上午10.09.34" style="zoom:50%;" /><h2 id="2-ZKReplicaStateMachine"><a href="#2-ZKReplicaStateMachine" class="headerlink" title="2. ZKReplicaStateMachine"></a>2. ZKReplicaStateMachine</h2><p>ReplicaStateMachine 需要接收一个 ControllerContext 对象实例。ControllerContext 封装了 Controller 端保存的所有集群元数据信息。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ReplicaStateMachine抽象类定义</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">ReplicaStateMachine</span>(<span class="params">controllerContext: <span class="type">ControllerContext</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>构造一个 ZKReplicaStateMachine 实例，除了 ControllerContext 实例，比较重要的属性还有 KafkaZkClient 对象实例和 ControllerBrokerRequestBatch 实例。前者负责与 ZooKeeper 进行交互；后者用于给集群 Broker 发送控制类请求</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ZkReplicaStateMachine具体实现类定义</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZkReplicaStateMachine</span>(<span class="params">config: <span class="type">KafkaConfig</span>, </span></span></span><br><span class="line"><span class="class"><span class="params">  stateChangeLogger: <span class="type">StateChangeLogger</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  controllerContext: <span class="type">ControllerContext</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  zkClient: <span class="type">KafkaZkClient</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  controllerBrokerRequestBatch: <span class="type">ControllerBrokerRequestBatch</span></span>) </span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">ReplicaStateMachine</span>(<span class="params">controllerContext</span>) <span class="keyword">with</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-ReplicaState"><a href="#3-ReplicaState" class="headerlink" title="3. ReplicaState"></a>3. ReplicaState</h2><p>ReplicaState 接口及其实现对象定义了每种状态的序号，以及合法的前置状态。</p><ol><li>NewReplica 副本被创建之后所处的状态</li><li>OnlineReplica 副本正常提供服务时所处的状态</li><li>OfflineReplica 副本服务下线时所处的状态</li><li>ReplicaDeletionStarted 副本被删除时所处的状态。</li><li>ReplicaDeletionSuccessful 副本被成功删除后所处的状态。</li><li>ReplicaDeletionIneligible 开启副本删除，但副本暂时无法被删除时所处的状态。</li><li>NonExistentReplica 副本从副本状态机被移除前所处的状态。</li></ol><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ReplicaState接口</span></span><br><span class="line"><span class="keyword">sealed</span> <span class="class"><span class="keyword">trait</span> <span class="title">ReplicaState</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">state</span></span>: <span class="type">Byte</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">validPreviousStates</span></span>: <span class="type">Set</span>[<span class="type">ReplicaState</span>] <span class="comment">// 定义合法的前置状态</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// OnlineReplica状态</span></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">object</span> <span class="title">OnlineReplica</span> <span class="keyword">extends</span> <span class="title">ReplicaState</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> state: <span class="type">Byte</span> = <span class="number">2</span></span><br><span class="line">  <span class="keyword">val</span> validPreviousStates: <span class="type">Set</span>[<span class="type">ReplicaState</span>] = <span class="type">Set</span>(<span class="type">NewReplica</span>, <span class="type">OnlineReplica</span>, <span class="type">OfflineReplica</span>, <span class="type">ReplicaDeletionIneligible</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>OnlineReplica 的 validPreviousStates 属性是一个集合类型，里面包含 NewReplica、OnlineReplica、OfflineReplica 和 ReplicaDeletionIneligible。这说明，Kafka 只允许副本从刚刚这 4 种状态变更到 OnlineReplica 状态。如果从 ReplicaDeletionStarted 状态跳转到 OnlineReplica 状态，就是非法的状态转换。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-11 上午11.18.32.png" alt="截屏2021-05-11 上午11.18.32" style="zoom:50%;" /><p>当副本对象首次被创建出来后，它会被置于 NewReplica 状态。经过初始化，当副本对象能够对外提供服务之后，状态机会将其调整为 OnlineReplica，并一直以该状态持续工作。</p><p>如果副本所在的 Broker 关闭或者是因为其他原因不能正常工作了，副本需要从 OnlineReplica 变更为 OfflineReplica，表明副本已处于离线状态。</p><p>一旦开启了如删除主题这样的操作，状态机会将副本状态跳转到 ReplicaDeletionStarted，以表明副本删除已然开启。若删除成功，则置为 ReplicaDeletionSuccessful，倘若不满足删除条件（如所在 Broker 处于下线状态），那就设置成 ReplicaDeletionIneligible，以便后面重试。</p><p>当副本对象被删除后，其状态会变更为 NonExistentReplica，副本状态机将移除该副本数据。</p><h2 id="4-ZkReplicaStateMachine"><a href="#4-ZkReplicaStateMachine" class="headerlink" title="4. ZkReplicaStateMachine"></a>4. ZkReplicaStateMachine</h2><h3 id="4-1-状态转换方法定义"><a href="#4-1-状态转换方法定义" class="headerlink" title="4.1. 状态转换方法定义"></a>4.1. 状态转换方法定义</h3><p>![截屏2021-05-11 下午4.44.29](/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-11 下午4.44.29.png)</p><h3 id="4-2-handleStateChanges"><a href="#4-2-handleStateChanges" class="headerlink" title="4.2. handleStateChanges()"></a>4.2. handleStateChanges()</h3><p>handleStateChange 方法的作用是处理状态的变更，是对外提供状态转换操作的入口方法。</p><p>该方法接收两个参数</p><ol><li>replicas 是一组副本对象，每个副本对象都封装了它们各自所属的主题、分区以及副本所在的 Broker ID 数据</li><li>targetState 是这组副本对象要转换成的目标状态</li></ol><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">handleStateChanges</span></span>(</span><br><span class="line">  replicas: <span class="type">Seq</span>[<span class="type">PartitionAndReplica</span>], </span><br><span class="line">  targetState: <span class="type">ReplicaState</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (replicas.nonEmpty) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 清空Controller待发送请求集合</span></span><br><span class="line">      controllerBrokerRequestBatch.newBatch()</span><br><span class="line">      <span class="comment">// 将所有副本对象按照Broker进行分组，依次执行状态转换操作</span></span><br><span class="line">      replicas.groupBy(_.replica).foreach &#123;</span><br><span class="line">        <span class="keyword">case</span> (replicaId, replicas) =&gt;</span><br><span class="line">          doHandleStateChanges(replicaId, replicas, targetState)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 发送对应的Controller请求给Broker</span></span><br><span class="line">      controllerBrokerRequestBatch.sendRequestsToBrokers(</span><br><span class="line">        controllerContext.epoch)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// 如果Controller易主，则记录错误日志然后抛出异常</span></span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">ControllerMovedException</span> =&gt;</span><br><span class="line">        error(<span class="string">s&quot;Controller moved to another broker when moving some replicas to <span class="subst">$targetState</span> state&quot;</span>, e)</span><br><span class="line">        <span class="keyword">throw</span> e</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt; error(<span class="string">s&quot;Error while moving some replicas to <span class="subst">$targetState</span> state&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(11)_方法区</title>
      <link href="2020/01/10/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(11)_%E6%96%B9%E6%B3%95%E5%8C%BA/"/>
      <url>2020/01/10/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(11)_%E6%96%B9%E6%B3%95%E5%8C%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>《Java虚拟机规范》中明确说明：”尽管所有的方法区在逻辑上属于堆的一部分，但一些简单的实现可能不会去进行垃圾收集或者进行压缩” 但是对于HotSpotJVM而言，方法区还有一个别名叫做 Non-Heap（非堆），目的就是要和堆分开。</p><a id="more"></a><h2 id="1-栈、堆、方法区的交互关系"><a href="#1-栈、堆、方法区的交互关系" class="headerlink" title="1 栈、堆、方法区的交互关系"></a>1 栈、堆、方法区的交互关系</h2><ul><li><p>运行时数据区结构图</p><img src="images/168.png" alt="img" style="zoom:67%;" /><img src="images/169.png" alt="img" style="zoom:67%;" /><img src="images/170.png" alt="img" style="zoom:67%;" /></li></ul><h2 id="2-方法区的理解"><a href="#2-方法区的理解" class="headerlink" title="2 方法区的理解"></a>2 方法区的理解</h2><ul><li><p>官方定义</p><img src="images/171.png" alt="img" style="zoom:97%;" /></li><li><p>方法区在哪里？</p><ul><li>《Java虚拟机规范》中明确说明：“尽管所有的方法区在逻辑上属于堆的一部分，但一些简单的实现可能不会去进行垃圾收集或者进行压缩。”但是对于HotSpotJVM而言，方法区还有一个别名叫做Non-Heap（非堆），目的就是要和堆分开。</li><li>所以，<font color=red><strong>方法区看做是一块独立于Java堆的内存空间。</strong></font></li></ul></li><li><p>方法区的基本理解</p><ul><li>方法区（Method Area）与Java堆一样，是各个线程共享的内存区域。</li><li><font color=red><strong>方法区在JDK8之前的落地实现叫做永久代，在JDK8及以后的落地实现叫做元空间</strong></font></li><li>方法区在JVM启动的时候被创建，并且它的实际的物理内存空间和Java堆一样都是可以不连续的。</li><li>方法区的大小，跟堆空间一样，可以选择固定大小或者可扩展。</li><li>方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机同样会抛出内存溢出错误：java.lang.OutOfMemoryError:PermGen space 或者 java.lang.OutOfMemoryError:Metaspace<ul><li>类过多的情况：加载大量的第三方jar包；Tomcat部署的工程过多（30-50个）；大量动态地生成反射类</li></ul></li><li>关闭JVM就会释放这个区域的内存</li></ul></li></ul><hr><ul><li>在JDK7及以前，习惯上把方法区称为永久代。JDK8开始，使用元空间取代了永久代。</li><li>本质上，方法区和永久代并不等价。仅是对hotspot而言的。《Java虚拟机规范》对如何实现方法区，不做统一要求。例如：BEA JRocket / IBM J9中不存在永久代的概念。<ul><li>现在来看，当前使用永久代，不是好的idea。导致Java程序更容易OOM（应为永久代使用的是JVM内存，不是本地内存，当超过-XX:MaxPermSize上限时报OOM）</li></ul></li></ul><img src="images/172.png" alt="img" style="zoom:67%;" /><ul><li><p>到了JDK8，终于完全废弃了永久代的概念，改用与JRocket、J9一样在本地内存中实现的元空间（Metaspace）来代替</p><img src="images/173.png" alt="img" style="zoom:67%;" /></li><li><p>元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代最大的区别在于：<font color=red><strong>元空间不在虚拟机设置的内存中，而是使用本地内存。</strong></font></p></li><li><p>永久代、元空间二者并不只是名字变了，内部结构也调整了。</p></li><li><p>根据《Java虚拟机规范》的规定，如果方法区无法满足新的内存分配需求时，将抛出OOM异常。</p></li></ul><h2 id="3-设置方法区的大小与OOM"><a href="#3-设置方法区的大小与OOM" class="headerlink" title="3 设置方法区的大小与OOM"></a>3 设置方法区的大小与OOM</h2><ul><li><p>方法区的大小不必是固定的，JVM可以根据应用的需求动态调整。</p></li><li><p><font color=red><strong>JDK7及以前：</strong></font></p><ul><li><p><font color=blue><strong>通过-XX:PermSize来设置永久费初始分配空间。默认值是20.75M</strong></font></p></li><li><p><font color=blue><strong>-XX:MaxPermSize来设定永久代最大可分配空间。32位机器默认64M，64位机器模式是82M</strong></font></p></li><li><p>当JVM加载的类信息容量超过了这个值，会报OutOfMemoryError:PermGenspace。</p><img src="images/174.png" alt="img" style="zoom:100%;" /></li></ul></li><li><p><font color=red><strong>JDK8及以后：</strong></font></p><ul><li><p>元数据区大小可以使用参数-XX:MetaspaceSize和-XX:MaxMetaspaceSize指定，替代上述原有的两个参数。</p></li><li><p>默认值依赖于平台。windows下，-XX:MetaspaceSize是21M，-XX:MaxMetaspaceSize的值是-1，即没有限制。</p></li><li><p>与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常OutOfMemoryError:Metaspace</p></li><li><p>-XX:MetaspaceSize：设置初始的元空间大小。对于一个64位的服务器端JVM来说，其默认的-XX:MetaspaceSize为21MB。这就是初始的高水位线，一旦触及这个水位线，Full GC将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放空间不足，那么在不超过MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。</p></li><li><p>如果初始化的高水位线设置过低，上述高水位线调整情况会发生多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁GX，建议将-XX:MetaspaceSize设置为一个相对较高的值。</p><img src="images/175.png" alt="img" style="zoom:100%;" /></li></ul></li></ul><hr><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * jdk6/7中：</span></span><br><span class="line"><span class="comment"> * -XX:PermSize=5m -XX:MaxPermSize=5m</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * jdk8中：</span></span><br><span class="line"><span class="comment"> * -XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OOMTest</span> <span class="keyword">extends</span> <span class="title">ClassLoader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            OOMTest test = <span class="keyword">new</span> OOMTest();</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">                <span class="comment">//创建ClassWriter对象，用于生成类的二进制字节码</span></span><br><span class="line">                ClassWriter classWriter = <span class="keyword">new</span> ClassWriter(<span class="number">0</span>);</span><br><span class="line">                <span class="comment">//指明版本号，修饰符，类名，包名，父类，接口</span></span><br><span class="line">                classWriter.visit(Opcodes.V1_8, Opcodes.ACC_PUBLIC, <span class="string">&quot;Class&quot;</span> + i, <span class="keyword">null</span>, <span class="string">&quot;java/lang/Object&quot;</span>, <span class="keyword">null</span>);</span><br><span class="line">                <span class="comment">//返回byte[]</span></span><br><span class="line">                <span class="keyword">byte</span>[] code = classWriter.toByteArray();</span><br><span class="line">                <span class="comment">//类的加载</span></span><br><span class="line">                test.defineClass(<span class="string">&quot;Class&quot;</span> + i, code, <span class="number">0</span>, code.length);<span class="comment">//Class对象</span></span><br><span class="line">                j++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            System.out.println(j);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><img src="images/176.png" alt="img" style="zoom:70%;" /><p><strong>更改JDK1.8为JDK1.7，V1_8改为V1_6，运行结果</strong></p><img src="images/177.png" alt="img" style="zoom:70%;" /><hr><ul><li>如何解决这些OOM？<ol><li>要解决OOM异常或heap space的异常，一般的手段是首先通过内存映像分析工具（如Eclipse Memory Analyzer）对dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了内存泄露（Memory Leak）还是内存溢出（Memory Overflow）。</li><li>如果是内存泄露，可进一步通过工具查看泄露对象到GC Roots的引用链。于是就能找到泄露对象是通过怎样的路径与GC Roots相关联并导致垃圾回收器无法自动回收它们的。掌握了泄露对象的类型信息，以及GC Roots引用链的信息，就可以比较准确地定位出泄露代码的位置。</li><li>如果不存在内存泄露，换句话说就是内存中的对象确实都还必须活着，那就应当检查虚拟机的堆参数（-Xms和-Xmx），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象声明周期过长、持有状态过长的情况，尝试减少程序运行期的内存消耗。</li></ol></li></ul><h2 id="4-方法区的内部结构"><a href="#4-方法区的内部结构" class="headerlink" title="4 方法区的内部结构"></a>4 方法区的内部结构</h2><img src="images/178.png" alt="img" style="zoom:67%;" /><ul><li><p>《深入理解Java虚拟机》书中对方法区（Method Area）存储内容描述如下：它用于存储已被虚拟机加载的类型信息、常量（包含StringTable，即字符串常量池）、静态变量、即时编译器编译后的代码缓存等。</p><img src="images/179.png" alt="img" style="zoom:67%;" /><ul><li><p><strong>类型信息</strong>：对每个加载的类型（类class、接口interface、枚举enum、注解annotation），JVM必须在方法区存储以下类型信息：</p><p>① 这个类型的完整有效名称（全名=包名.类名）</p><p>② 这个类型直接父类的完整有效名（对于interface或是java.lang.Object，都没有父类）</p><p>③ 这个类型的修饰符（public,abstract,final的某个子集）</p><p>④ 这个类型直接接口的一个有序列表</p></li><li><p><strong>域（Field）信息</strong></p><ul><li>JVM必须在方法区中保存类型的所有域的相关信息以及域的声明顺序。</li><li>域的相关信息包括：域名称、域类型、域修饰符（public、private、protected、static、final、volatile、transient的某个子集）</li></ul></li><li><p><strong>方法（Method）信息</strong>：JVM必须保存所有方法的以下信息，同域信息一样包括声明顺序：</p><ul><li>方法名称</li><li>方法的返回类型（或void）</li><li>方法参数的数量和类型（按顺序）</li><li>方法的修饰符（public、private、protected、static、final、synchronized、native、abstract的一个子集）</li><li>方法的字节码（bytecodes）、操作数栈、局部变量表及大小（abstract和native方法除外）</li><li>异常表（abstract和native方法除外）<ul><li>每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引</li></ul></li></ul></li><li><p>代码演示</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MethodInnerStrucTest</span> <span class="keyword">extends</span> <span class="title">Object</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">String</span>&gt;,<span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="comment">//属性</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> num = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String str = <span class="string">&quot;测试方法的内部结构&quot;</span>;</span><br><span class="line">    <span class="comment">//构造器</span></span><br><span class="line">    <span class="comment">//方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">20</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;count = &quot;</span> + count);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">test2</span><span class="params">(<span class="keyword">int</span> cal)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">int</span> value = <span class="number">30</span>;</span><br><span class="line">            result = value / cal;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(String o)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过  javap -v -p MethodInnerStrucTest.class &gt; test.txt  将反编译的文件写入到test.txt文件中</p><img src="images/180.png" alt="img" style="zoom:80%;" /><img src="images/181.png" alt="img" style="zoom:80%;" /><img src="images/182.png" alt="img" style="zoom:70%;" /></li></ul></li></ul><hr><ul><li><p>non-final的类变量</p><ul><li><p>静态变量和类关联在一起，随着类的加载而加载，它们成为类数据在逻辑上的一部分。</p></li><li><p>类变量被类的所有实例共享，即使没有类实例时你也可以访问它。</p></li><li><p>代码演示</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MethodAreaTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Order order = <span class="keyword">null</span>;</span><br><span class="line">        order.hello();</span><br><span class="line">        System.out.println(order.count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Order</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> count = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> number = <span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;hello!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p>​            hello!</p><p>​            1</p></li><li><p>补充说明：全局常量：static final</p><ul><li><p>被声明为final的类变量的处理方法则不同，每个全局常量在编译的时候就会被分配了</p></li><li><p>通过Order.class反编译得到的结果可以看出count和number的区别</p><img src="images/183.png" alt="img" style="zoom:70%;" /></li></ul></li></ul></li></ul><hr><ul><li><p>运行时常量池 <em>vs</em> 常量池</p><img src="images/184.png" alt="img" style="zoom:67%;" /><ul><li>方法区，内部包含了运行时常量池。</li><li>字节码文件，内部包含了常量池，将该常量池加载到方法区后就成了运行时常量池</li><li>要弄清楚方法区，需要理解清除ClassFIle，因为加载类的信息都在方法区。</li><li>要弄清楚方法区的运行时常量池，需要理解清楚ClassFIle中的常量池。</li><li><a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html</a></li></ul><img src="images/185.png" alt="img" style="zoom:90%;" /><hr><img src="images/186.png" alt="img" style="zoom:80%;" /><p>一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述信息，还包含一项信息就是常量池表（COnstant Pool Table），包含各种字面量和对类型、域和方法的方法引用。</p></li><li><p>为什么需要常量池？</p><ul><li><p>一个java原文件的类、接口，编译后产生一个字节码文件。而Java中的字节码需要数据支持，通常这种数据很大以至于不能直接存到字节码中，换另一种方式，可以存到常量池，这个字节码包含了指向常量池的引用。动态链接的时候会用到运行时常量池，之前有介绍。比如：如下的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleClass</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sayHello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>class文件虽然只有194字节，但是里面却使用了String、System、PrintStream及Object等结构。这里代码量其实已经很小。如果代码多，引用的结构会更多！这里就需要常量池了！</p></li></ul></li><li><p>常量池中有什么？</p><ul><li>几种在常量池内存储的类型包括：<ul><li>数量值</li><li>字符串值</li><li>类引用（含有接口）</li><li>字段引用</li><li>方法引用</li></ul></li></ul></li><li><p>小节：常量池，可以看做一张表，虚拟机志林根据这张表找到要执行的类名、方法名、参数类型、字面量等类型。</p></li><li><p>运行时常量池</p><ul><li>运行时常量池（Runtime Constant Pool）是方法区的一部分。</li><li>常量池表（Constant Pool Table）是Class文件的一部分，用于存放编译（前端编译）期间生成的各种字面量和符号引用，<font color=red><strong>这部分内容将在类加载后存放到方法区的运行时常量池中</strong></font>。</li><li>运行时常量池，在加载类和接口到虚拟机后，就会创建对应的运行时常量池。</li><li>JVM为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的。</li><li>运行时常量池中包含多种不同的常量，包括编译期间（前端编译）就已经明确的数字字面量，也包括到到运行期解析后才能获得的方法或者字段引用。此时不再是常量池中的符号引用了，这里换为了真实地址。<ul><li>运行时常量池，相对于Class文件常量池的另一个重要特征时：<font color=red><strong>具备动态性</strong></font>。<ul><li>String.intern()</li></ul></li></ul></li><li>运行时常量池类似于传统编程语言中的符号表（symbol table），但是它所包含的数据却比符号表要更加丰富一些。</li><li>当创建类或接口的运行时常量池时，如果构造运行时常量池所需要的内存空间超过了方法区所能提供的最大值，则JVM会抛出OutOfMemoryError异常。</li></ul></li></ul><h2 id="5-方法区使用举例"><a href="#5-方法区使用举例" class="headerlink" title="5 方法区使用举例"></a>5 方法区使用举例</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MethodAreaDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> x = <span class="number">500</span>;</span><br><span class="line">        <span class="keyword">int</span> y = <span class="number">100</span>;</span><br><span class="line">        <span class="keyword">int</span> a = x / y;</span><br><span class="line">        <span class="keyword">int</span> b = <span class="number">50</span>;</span><br><span class="line">        System.out.println(a + b);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="images/187.png" alt="img" style="zoom:67%;" /><img src="images/188.png" alt="img" style="zoom:67%;" /><img src="images/189.png" alt="img" style="zoom:67%;" /><img src="images/190.png" alt="img" style="zoom:67%;" /><img src="images/191.png" alt="img" style="zoom:67%;" /><img src="images/192.png" alt="img" style="zoom:67%;" /><img src="images/193.png" alt="img" style="zoom:67%;" /><img src="images/194.png" alt="img" style="zoom:67%;" /><img src="images/195.png" alt="img" style="zoom:67%;" /><img src="images/196.png" alt="img" style="zoom:67%;" /><img src="images/197.png" alt="img" style="zoom:67%;" /><img src="images/198.png" alt="img" style="zoom:67%;" /><img src="images/199.png" alt="img" style="zoom:67%;" /><img src="images/200.png" alt="img" style="zoom:67%;" /><img src="images/201.png" alt="img" style="zoom:67%;" /><img src="images/202.png" alt="img" style="zoom:67%;" /><h2 id="6-方法区的演进细节"><a href="#6-方法区的演进细节" class="headerlink" title="6 方法区的演进细节"></a>6 方法区的演进细节</h2><ol><li><p>首先明确：只有HotSpot才有永久代。BEA JRocket、IBM J9等来说，是不存在永久代的概念的。原则上如何实现方法区属于虚拟机实现细节，不受《Java虚拟机规范》管束，并不要求统一。</p></li><li><p>Hotspot中方法区的变化：</p><table><thead><tr><th align="left">jdk1.6及以前</th><th><font color=red><strong>有永久代（permanent generation），静态变量存放在永久代上</strong></font></th></tr></thead><tbody><tr><td align="left">jdk1.7</td><td><font color=red><strong>有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中</strong></font></td></tr><tr><td align="left">jdk1.8及以后</td><td><font color=red><strong>无永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中</strong></font></td></tr></tbody></table></li></ol><hr><ul><li><p>jdk1.6</p><img src="images/203.png" alt="img" style="zoom:67%;" /></li><li><p>jdk1.7：方法区仍然使用虚拟机的内存</p><img src="images/204.png" alt="img" style="zoom:67%;" /></li><li><p>jdk1.8</p><img src="images/205.png" alt="img" style="zoom:67%;" /></li></ul><hr><ul><li><p>永久代为什么要被元空间替换？</p><ul><li><p><a href="http://openjdk.java.net/jeps/122">http://openjdk.java.net/jeps/122</a></p><img src="images/206.png" alt="img" style="zoom:90%;" /></li><li><p>随着Java8的到来，HotSpot VM中再也见不到永久代了。但是这并不意味着类的元数据也消失了。这些数据被移动到一个与堆不相连的内存本地区域，这个区域叫做元空间（Metaspace）。</p></li><li><p>由于类的元数据分配在本地内存中，元空间的最大可分配空间就是系统可用内存空间。</p></li><li><p>这项改动是由必要的，原因有：</p><p>1）<font color=blue><strong>为永久代设置空间大小是很难确定的</strong></font>。</p><p>在某些场景下，如果动态加载类过多，容易产生Perm区的OOM。比如某个实际Web工程中，因为功能点比较多，在运行过程中，要不断加载很多类，经常出现致命错误。</p><p>而元空间和永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。</p><p>2）<font color=blue><strong>对永久代调优是很困难的</strong></font>。</p></li></ul></li></ul><hr><ul><li>StringTable（字符串常量池）为什么要调整位置（从方法区移到堆中）？<ul><li>jdk7中将StringTable放到堆空间中。因为永久代的回收效率很低，在full gc的时候才会被处罚。而full gc是老年代空间不足或者永久代不足时才会触发。这就导致StringTable回收效率不高。而我们开发中会有大量的字符串被创建，回收效率低，导致永久代内存不足。放到堆中，能及时回收内存。</li></ul></li></ul><hr><ul><li><p>静态变量</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 结论：</span></span><br><span class="line"><span class="comment"> * 静态引用对应的对象实体始终都存在堆空间</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * jdk7：</span></span><br><span class="line"><span class="comment"> * -Xms200m -Xmx200m -XX:PermSize=300m -XX:MaxPermSize=300m -XX:+PrintGCDetails</span></span><br><span class="line"><span class="comment"> * jdk 8：</span></span><br><span class="line"><span class="comment"> * -Xms200m -Xmx200m -XX:MetaspaceSize=300m -XX:MaxMetaspaceSize=300m -XX:+PrintGCDetails</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StaticFieldTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] arr = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span> * <span class="number">1024</span> * <span class="number">100</span>];<span class="comment">//100MB</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(StaticFieldTest.arr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>如何证明静态变量在堆中：需要使用jdk9中引入的工具jhsdb</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 《深入理解Java虚拟机》中的案例：</span></span><br><span class="line"><span class="comment"> * staticObj、instanceObj、localObj存放在哪里？</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StaticObjTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">        <span class="keyword">static</span> ObjectHolder staticObj = <span class="keyword">new</span> ObjectHolder();</span><br><span class="line">        ObjectHolder instanceObj = <span class="keyword">new</span> ObjectHolder();</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            ObjectHolder localObj = <span class="keyword">new</span> ObjectHolder();</span><br><span class="line">            System.out.println(<span class="string">&quot;done&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ObjectHolder</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Test test = <span class="keyword">new</span> StaticObjTest.Test();</span><br><span class="line">        test.foo();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="images/207.png" alt="img" style="zoom:67%;" /><img src="images/208.png" alt="img" style="zoom:67%;" /></li></ul></li></ul><h2 id="7-方法区的垃圾回收"><a href="#7-方法区的垃圾回收" class="headerlink" title="7 方法区的垃圾回收"></a>7 方法区的垃圾回收</h2><img src="images/209.png" alt="img" style="zoom:67%;" /><img src="images/210.png" alt="img" style="zoom:67%;" /><img src="images/211.png" alt="img" style="zoom:67%;" /><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8 总结"></a>8 总结</h2><img src="images/212.png" alt="img" style="zoom:67%;" /><ul><li>常见面试题<ul><li><font color=red><strong>百度</strong></font><ul><li>三面：说一下JVM内存模型吧，有哪些区？分别是干什么的？</li></ul></li><li><font color=red><strong>蚂蚁金服</strong></font><ul><li>Java8内存分代改进</li><li>JVM内存分为哪几个区，每个区的作用是什么？</li><li>一面：JVM内存分布/内存结构？栈和堆的区别？堆的结构？为什么需要连个survivor区？</li><li>二面：Eden和Survivor的比例分配</li></ul></li><li><font color=red><strong>小米</strong></font><ul><li>jvm内存分区，为什么要有新生代和老年代？</li></ul></li><li><font color=red><strong>字节跳动</strong></font><ul><li>二面：Java的内存分区</li><li>二面：讲讲jvm运行时数据库区</li><li>什么时候对象会进入老年代？</li></ul></li><li><font color=red><strong>京东</strong></font><ul><li>JVM的内存结构，Eden和Survivor比例。</li><li>JVM内存为什么要分为新生代、老年代、持久代？新生代为什么要分为Eden和Survivor？</li></ul></li><li><font color=red><strong>天猫</strong></font><ul><li>一面：JVM内存模型及分区，需要详细到每个区放什么。</li><li>一面：JVM内存模型，Java8做了什么修改</li></ul></li><li><font color=red><strong>拼多多</strong></font><ul><li>JVM内存分为哪几个区，每个区的作用是什么？</li></ul></li><li><font color=red><strong>美团</strong></font><ul><li>java内存分配</li><li>jvm的永久代会发生垃圾回收吗？</li><li>一面：jvm内存分区，为什么需要新生代和老年代？</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(10)_堆</title>
      <link href="2020/01/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(10)_%E5%A0%86/"/>
      <url>2020/01/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(10)_%E5%A0%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>每个进程对应一个 JVM 实例，对应一个Runtime;一个进程对应多个线程，一个线程对应一个程序计数器、虚拟机栈、本地方法栈。一个进程中的线程要共享堆空间和方法区</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>一个 JVM 实例只存在一个堆内存，堆也是 Java 内存管理的核心区域</p><p>Java 堆区在 JVM 启动的时候即被创建，其空间大小也随之确定，是 JVM 管理的最大一块内存空间</p><img src="images/120.png" alt="img" style="zoom:50%;" /><ul><li><p>堆内存的大小是可以调节的</p></li><li><p>《Java虚拟机规范》规定，堆可以处于物理上不连续的内存够空间中，但是逻辑上它应该被视为连续的。</p></li><li><p>所有的线程共享Java堆，在这里还可以划分线程私有的缓冲区（Thread Local Allocation Buffer，TLAB），这样可以提高并发性</p></li><li><p>《Java虚拟机规范》中对 Java 堆的描述是：<font color=red><strong>所有的对象实例以及数组</strong></font> 都应当在运行时分配到堆上。</p><blockquote><p>The heap is the run-time data area from which memory for all class instances and arrays is allocated）</p><p>数组和对象可能永远不会存储在栈上，因为栈帧中保存引用，这个引用指向对象或者数组在堆中的位置。</p></blockquote></li><li><p>在方法结束后，堆中的对象不会马上被移除，仅仅在垃圾回收的时候才会被移除。</p></li><li><p>堆，是 GC（Garbage Collection）执行垃圾回收的重点区域</p></li></ul><h2 id="2-设置堆内存大小与OOM"><a href="#2-设置堆内存大小与OOM" class="headerlink" title="2 设置堆内存大小与OOM"></a>2 设置堆内存大小与OOM</h2><h3 id="2-1-堆空间大小的设置"><a href="#2-1-堆空间大小的设置" class="headerlink" title="2.1. 堆空间大小的设置"></a>2.1. 堆空间大小的设置</h3><p>Java 堆空间用于存储 Java 对象实例，那么堆的大小在 JVM 启动时就已经设定好了，大家可以通过选项“-Xms”和”-Xmx”来进行设置。</p><ul><li><code>-Xms</code> 用于标识堆区的起始内存，等价于 <code>-XX:InitialHeapSize</code></li><li><code>-Xmx</code> 则用于标识堆区的最大内存，等价于 <code>-XX:MaxHeapSize</code></li></ul><p>一旦堆区的内存大小超过 <code>-Xmx</code> 所指定的最大内存时，将会抛出 <code>OutOfMemoryError</code> 异常。</p><p>通常会将 <code>-Xms</code> 和 <code>-Xmx</code> 两个参数设置成相同的值，其<font color=red><strong>目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小，从而提高性能</strong></font>。</p><p>默认情况下，初始内存大小: <code>物理电脑内存大小 / 64</code>, 最大内存大小: <code>物理电脑内存大小 / 4</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 1. 设置堆空间大小的参数</span></span><br><span class="line"><span class="comment"> * -Xms 用来设置堆空间（年轻代+老年代）的初始内存大小</span></span><br><span class="line"><span class="comment"> *      -X 是jvm的运行参数</span></span><br><span class="line"><span class="comment"> *      ms 是memory start</span></span><br><span class="line"><span class="comment"> * -Xmx 用来设置堆空间（年轻代+老年代）的最大内存大小</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 2. 默认堆空间的大小</span></span><br><span class="line"><span class="comment"> *              初始内存大小：物理电脑内存大小 / 64</span></span><br><span class="line"><span class="comment"> *              最大内存大小：物理电脑内存大小 / 4</span></span><br><span class="line"><span class="comment"> * 3. 手动设置：-Xms600m -Xmx600m</span></span><br><span class="line"><span class="comment"> *     开发中建议将初始堆内存和最大的堆内存设置成相同的值。原因是扩容缩容会造成服务器不必要的压力</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 4. 查看设置的参数：方式一： jps   /  jstat -gc 进程id</span></span><br><span class="line"><span class="comment"> *                 方式二： -XX:+PrintGCDetails</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HeapSpaceInitial</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 返回 Java 虚拟机中的堆内存总量</span></span><br><span class="line">        <span class="keyword">long</span> initialMemory = Runtime.getRuntime().totalMemory() / <span class="number">1024</span> / <span class="number">1024</span>;</span><br><span class="line">        <span class="comment">// 返回 Java 虚拟机试图使用的最大堆内存量</span></span><br><span class="line">        <span class="keyword">long</span> maxMemory = Runtime.getRuntime().maxMemory() / <span class="number">1024</span> / <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;-Xms : &quot;</span> + initialMemory + <span class="string">&quot;M&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;-Xmx : &quot;</span> + maxMemory + <span class="string">&quot;M&quot;</span>);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;系统内存大小为：&quot;</span> + initialMemory * <span class="number">64.0</span> / <span class="number">1024</span> + <span class="string">&quot;G&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;系统内存大小为：&quot;</span> + maxMemory * <span class="number">4.0</span> / <span class="number">1024</span> + <span class="string">&quot;G&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">1000000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>如果没有设置任何参数，则结果：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-Xms : 245M</span><br><span class="line">-Xmx : 3641M</span><br><span class="line">系统内存大小为：15.3125G</span><br><span class="line">系统内存大小为：14.22265625G</span><br></pre></td></tr></table></figure><p><strong>如果设置参数-Xms600m -Xmx600m，此时值关注前两项结果：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-Xms : 575M</span><br><span class="line">-Xmx : 575M</span><br><span class="line">系统内存大小为：35.9375G</span><br><span class="line">系统内存大小为：2.24609375G</span><br></pre></td></tr></table></figure><blockquote><p>注:不是600M，因为年轻代采用复制算法，幸存者区有两个，但是只计算了一个</p><p>(25600+25600+153600+409600) / 1024 = 600M</p><p>(25600+153600+409600) / 1024 = 575M</p></blockquote><h3 id="2-2-OutOfMemoeyError"><a href="#2-2-OutOfMemoeyError" class="headerlink" title="2.2. OutOfMemoeyError"></a>2.2. OutOfMemoeyError</h3><ul><li>代码演示</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OOMTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        ArrayList&lt;Picture&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">20</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            list.add(<span class="keyword">new</span> Picture(<span class="keyword">new</span> Random().nextInt(<span class="number">1024</span> * <span class="number">1024</span>)));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Picture</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">byte</span>[] pixels;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Picture</span><span class="params">(<span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.pixels = <span class="keyword">new</span> <span class="keyword">byte</span>[length];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Heap</span><br><span class="line"> PSYoungGen      total 179200K, used 157034K [0x00000007b3800000, 0x00000007c0000000, 0x00000007c0000000)</span><br><span class="line">  eden space 153600K, 100% used [0x00000007b3800000,0x00000007bce00000,0x00000007bce00000)</span><br><span class="line">  from space 25600K, 13% used [0x00000007bce00000,0x00000007bd15a8d0,0x00000007be700000)</span><br><span class="line">  to   space 25600K, 0% used [0x00000007be700000,0x00000007be700000,0x00000007c0000000)</span><br><span class="line"> ParOldGen       total 409600K, used 409584K [0x000000079a800000, 0x00000007b3800000, 0x00000007b3800000)</span><br><span class="line">  object space 409600K, 99% used [0x000000079a800000,0x00000007b37fc1a0,0x00000007b3800000)</span><br><span class="line"> Metaspace       used 8573K, capacity 8816K, committed 9088K, reserved 1056768K</span><br><span class="line">  class space    used 1009K, capacity 1087K, committed 1152K, reserved 1048576K</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space</span><br><span class="line">at heap.Picture.&lt;init&gt;(OOMTest.java:24)</span><br><span class="line">at heap.OOMTest.main(OOMTest.java:15)</span><br></pre></td></tr></table></figure><p><strong>VisualVM 显示效果：</strong></p><img src="/Users/joker/Documents/Learnning/Java/截图/oom.png" alt="oom" style="zoom:30%;" /><h2 id="3-年轻代与老年代"><a href="#3-年轻代与老年代" class="headerlink" title="3 年轻代与老年代"></a>3 年轻代与老年代</h2><p>存储在 JVM 中的 Java 对象可以被划分为两类：</p><ul><li>一类是声明周期较短的瞬时对象，这类对象的创建和消亡都非常迅速</li><li>另一类对象的声明周期非常长，在某些极端的情况下还能够与 JVM 的生命周期保持一致。</li></ul><p>Java 堆区进一步细分的话，可以划分为年轻代(YoungGen)和老年代(OldGen)</p><p>其中年轻代又可以划分为 <code>Eden</code> 空间、<code>Survivor0</code> 空间和 <code>Survivor1</code> 空间（有时也叫做 from 区、to区,谁空谁为to区）</p><img src="images/138.png" alt="img" style="zoom:77%;" /><hr><p>下面的参数开发中一般不会调：</p><ul><li><p>配置年轻代和老年代在堆结构的占比</p><ul><li><p>默认**-XX:NewRatio=2**，表示年轻代占1，老年代占2，年轻代占整个堆的1/3</p></li><li><p>可以修改**-XX:NewRatio=4**，表示年轻代占1，老年代占4，新生代占整个堆的1/5</p></li><li><p>代码演示</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * -Xms600m -Xmx600m</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * -XX:NewRatio ： 设置新生代与老年代的比例。默认值是2.</span></span><br><span class="line"><span class="comment"> * -XX:SurvivorRatio ：设置新生代中Eden区与Survivor区的比例。默认值是8</span></span><br><span class="line"><span class="comment"> * -XX:-UseAdaptiveSizePolicy ：关闭自适应的内存分配策略 </span></span><br><span class="line"><span class="comment"> * -Xmn:设置新生代的空间的大小。 （一般不设置）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EdenSurvivorTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;我只是来打个酱油~&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">1000000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>\</p></li></ul></li></ul><hr><p>在 HotSpot 中，Eden 空间和另外两个 Survivor 空间缺省所占的比例是 8:1:1</p><ul><li><p>但实际上比例是 6:1:1，即使关闭自适应机制(-XX:-UseAdaptiveSizePolicy)也是6:1:1，即使通过命令（jinfo -flag NewRatio）查看看到的数值是 8</p><img src="/Users/joker/Documents/Learnning/Java/截图/截屏2021-01-27 上午10.08.43.png" alt="截屏2021-01-27 上午10.08.43" style="zoom:90%;" /></li></ul><p>想要变成 8:1:1 可以通过设置 <code>-XX:SurvivorRatio=8</code> 实现</p><ul><li><p><font color=red><strong>几乎所有的</strong></font>Java对象都是在 Eden 去被 new 出来的。如果对象太大，Eden 放不下，需要直接放到老年区，仍然放不下的话，会报错。</p></li><li><p>绝大部分 Java 对象的销毁都在新生代进行了。</p><ul><li>IBM 公司的专门研究表明，新生代中80%的对象都是“朝生夕死”的。</li></ul></li><li><p>可以使用选项“-Xmn”设置新生代最大内存大小</p><ul><li>这个参数一般使用默认值就可以了。</li><li>如果这个参数和”-XX:NewRatio”产生矛盾，以 “-Xmn”为准</li></ul></li></ul><h2 id="4-对象分配过程"><a href="#4-对象分配过程" class="headerlink" title="4 对象分配过程"></a>4 对象分配过程</h2><p>为新对象分配内存是一件非常严谨和复杂的任务，不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法与内存回收算法密切相关，所以还需要考虑 GC 执行完内存回收后是否会在内存空间中产生内存碎片。</p><ol><li><p>new 的对象首先放到 **<code>Eden区</code>**。此区有大小限制。</p></li><li><p>当 Eden 的空间填满时，程序又需创建对象，JVM 的垃圾回收器会对 <strong><code>Eden区</code></strong> 进行垃圾回收(Minor GC / Young GC)，将 <strong><code>Eden区</code></strong> 中的不再被其他对象所引用的对象进行销毁。再加载新的对象到 <strong><code>Eden区</code></strong></p></li><li><p>然后将伊甸园区中的剩余对象移动到 **<code>幸存者0区</code>**。</p></li><li><p>如果再次出发垃圾回收，此时上次幸存下来的放到 **<code>幸存者0区</code>**，如果没有回收，就会放到 **<code>幸存者1区</code>**。</p></li><li><p>如果再次经历垃圾回收，此时会重新放回 **<code>幸存者0区</code>**，接着再去 **<code>幸存者1区</code>**。</p></li><li><p>啥时候能去养老区呢？可以设置次数。默认是15次。<font color=red><strong>可以设置参数：-XX:MaxTenuringThreshold=<N>进行设置</strong></font>。</p></li><li><p>当养老区内存不足时，再次出发：Major GC，进行养老区的内存清理。</p></li><li><p>若养老区执行了Major GC之后发现依然无法进行对象的保存，就会产生OOM异常</p><ul><li><font color=red><strong>java.lang.OutOfMemoryError: Java heap space</strong></font></li></ul></li></ol><img src="images/145.png" alt="img" style="zoom:67%;" /><ul><li><p>注意点：当幸存者区满的时候不会出发Young GG；但是当伊甸园区满的时候，会出发Young GC，同时也会对幸存者区进行GC；幸存者区被动GC</p></li><li><p>总结：</p><ul><li><font color=red><strong>针对幸存者s0，s1区的总结：复制之后有交换，谁空谁是to</strong></font>。</li><li><font color=red><strong>关于垃圾回收：频繁收集新生代，较少收集老年代，几乎不动永久区/元空间</strong></font>。</li></ul></li><li><p>对象分配详细过程</p></li></ul><img src="images/146.png" alt="img" style="zoom:67%;" /><h2 id="5-Minor-GC-amp-Major-GC-amp-Full-GC"><a href="#5-Minor-GC-amp-Major-GC-amp-Full-GC" class="headerlink" title="5 Minor GC &amp; Major GC &amp; Full GC"></a>5 Minor GC &amp; Major GC &amp; Full GC</h2><p>JVM 在进行 GC 时，并非每次都对上面三个内存（年轻代、老年代、方法区）区域一起回收的，大部分时候回收的都是指新生代。</p><p>针对 HotSpot VM 的实现，它里面的 GC 按照回收区域又分为两大种类型：一种是部分收集（Partial GC），一种是整堆收集（Full GC）</p><ol><li>部分收集：不是完整收集整个Java堆的垃圾收集，其中又分为：<ul><li>新生代收集(Minor GC / Young GC): 知识新生代 (Eden / S0，S1) 的垃圾收集</li><li>老年代收集(Major GC / Old GC): 知只是老年代的垃圾收集。<ul><li>目前，只有CMS GC（一个并发的垃圾回收器）会有单独收集老年代的行为。</li><li><font color=red><strong>注意，很多时候 Major GC 会和 Full GC 混淆使用，需要具体分辨是老年代回收还是整堆回收</strong></font>。</li></ul></li><li>混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾回收<ul><li>目前，只有G1 GC才会有这种行为，这是由于G1是分为region的</li></ul></li></ul></li><li>整堆回收（Full GC）：收集整个java堆和方法区的垃圾回收。</li></ol><hr><h4 id="分代式-GC-策略的触发条件"><a href="#分代式-GC-策略的触发条件" class="headerlink" title="分代式 GC 策略的触发条件"></a>分代式 GC 策略的触发条件</h4><ol><li><p>年轻代 GC(Minor GC / Young GC)触发机制：</p><ul><li>当年轻代空间不足时，就会触发 Minor GC，这里的年轻代满指的是 Eden 代满，Survivor满不会引发GC。(每次Minor GC会清理年轻代的内存)。</li><li>因为 Java 对象<font color=red><strong>大多都具备朝生夕灭</strong></font>的特性，所以 Minor GC 会非常频繁，一般回收速度也比较快。这</li><li>Minor GC 会引发 STW ，暂停其他用户的线程，等垃圾回收结束，用户线程才回复运行。</li></ul></li><li><p>老年代 GC(Major GC / Full GC)触发机制：</p><ul><li>指发生在老年代的GC，对象从老年代消失时，我们说”Major gc”或“Full GC”发生了。</li><li>出现了Major GC，经常会伴随至少一次Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。<ul><li>也就是在老年代空间不足时，会先尝试触发Minor GC。如果之后空间还不足，则会触发Major GC</li></ul></li><li>Major GC的速度一般会比Minor GC慢10倍以上，STW的时间更长。</li><li>如果Major GC后，内存还不足，就报OOM了。</li></ul></li><li><p>Full GC 触发机制</p><ul><li><p>调用 System.gc() 时，系统建议执行 Full GC，但是不必然执行</p></li><li><p>老年代空间不足</p></li><li><p>方法区空间不足</p></li><li><p>通过Minor GC后进入老年代的平均大小大于老年代的可用内存</p></li><li><p>由Eden区、From Space区向To Space区复制时，对象的大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小</p><ul><li><font color=red><strong>Full GC 是开发或调优中尽量要避免的。这样暂停时间会短一些</strong></font>。</li></ul></li></ul></li></ol><hr><ul><li><p>代码例子</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 测试MinorGC 、 MajorGC、FullGC</span></span><br><span class="line"><span class="comment"> * -Xms9m -Xmx9m -XX:+PrintGCDetails</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GCTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            List&lt;String&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            String a = <span class="string">&quot;atguigu.com&quot;</span>;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                list.add(a);</span><br><span class="line">                a = a + a;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            t.printStackTrace();</span><br><span class="line">            System.out.println(<span class="string">&quot;遍历次数为：&quot;</span> + i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>设置参数-Xms9m -Xmx9m -XX:+PrintGCDetails后的运行效果：</strong></p><img src="images/148.png" alt="img" style="zoom:90%;" /></li></ul><h2 id="6-堆空间分代思想"><a href="#6-堆空间分代思想" class="headerlink" title="6 堆空间分代思想"></a>6 堆空间分代思想</h2><ul><li><p><font color=red><strong>为什么需要把Java堆分代？不分代就不能正常工作了吗？</strong></font></p><ul><li>经研究，不同对象的生命周期不同。70%-99%的对象是临时对象。<ul><li>新生代：有Eden、两块大小相同的Survivor（又称为from/to，s0/s1）构成，to总为空。</li><li>老年代：存放新生代中经历多次GC仍然存活的对象。</li></ul></li></ul><img src="images/149.png" alt="img" style="zoom:67%;" /><ul><li>其实不分代完全可以，<font color=red><strong>分代的唯一理由就是优化GC性能。</strong></font>如果没有分代，那所有的对象都在一块，就如同把一个学校的人都关在一个教室。GC的时候要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而很多对象都是朝生夕死的，如果分代的话，把新创建的对象放到某一地方，当GC的时候先把这块存储“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。</li></ul><img src="images/150.png" alt="img" style="zoom:67%;" /></li></ul><h2 id="7-内存分配策略（对象提升（Promotion）规则）"><a href="#7-内存分配策略（对象提升（Promotion）规则）" class="headerlink" title="7 内存分配策略（对象提升（Promotion）规则）"></a>7 内存分配策略（对象提升（Promotion）规则）</h2><h3 id="7-1-概述"><a href="#7-1-概述" class="headerlink" title="7.1. 概述"></a>7.1. 概述</h3><p>如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为1。对象在 Survivor 区每熬过一个 Minor GC，年龄就增加 1.对象年龄增加到一定程度（默认15岁，其实每个 JVM，每个 GC 有所不同）时，就会被晋升到老年代。</p><p>对象晋升老年代的年龄阈值，可以通过选项 <strong>-XX:MaxTenuringThreshold</strong> 来设置</p><h3 id="7-2-不同年龄段的对象分配原则"><a href="#7-2-不同年龄段的对象分配原则" class="headerlink" title="7.2. 不同年龄段的对象分配原则"></a>7.2. 不同年龄段的对象分配原则</h3><ul><li><p>优先分配到 Eden</p></li><li><p>大对象（指大小大于Eden区总大小的对象）直接分配到老年代,尽量避免程序中出现过多的大对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** 测试：大对象直接进入老年代</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">-Xms60m -Xmx60m -XX:NewRatio=2 -XX:SurvivorRatio=8 -XX:+PrintGCDetails</span></span><br><span class="line"><span class="comment">Eden : 16m ;    Survivor0 : 2m ;    Survivor1 : 2m ;    Old : 40m</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">YoungOldAreaTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span> * <span class="number">1024</span> * <span class="number">20</span>];  <span class="comment">// 20m</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Heap</span><br><span class="line"> PSYoungGen      total 18432K, used 2299K [0x00000007bec00000, 0x00000007c0000000, 0x00000007c0000000)</span><br><span class="line">  eden space 16384K, 14% used [0x00000007bec00000,0x00000007bee3edf0,0x00000007bfc00000)</span><br><span class="line">  from space 2048K, 0% used [0x00000007bfe00000,0x00000007bfe00000,0x00000007c0000000)</span><br><span class="line">  to   space 2048K, 0% used [0x00000007bfc00000,0x00000007bfc00000,0x00000007bfe00000)</span><br><span class="line"> ParOldGen       total 40960K, used 20480K [0x00000007bc400000, 0x00000007bec00000, 0x00000007bec00000)</span><br><span class="line">  object space 40960K, 50% used [0x00000007bc400000,0x00000007bd800010,0x00000007bec00000)</span><br><span class="line"> Metaspace       used 3081K, capacity 4496K, committed 4864K, reserved 1056768K</span><br><span class="line">  class space    used 339K, capacity 388K, committed 512K, reserved 1048576K</span><br></pre></td></tr></table></figure></li><li><p>长期存活的对象分配到老年代</p></li><li><p>动态对象年龄判断</p><ul><li>如果 Survivor 区中相同年龄的所有对象的总和大于 Survivor 空间的一半，年龄大于或者等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。</li></ul></li><li><p>空间分配担保</p><ul><li>-XX:HandlePromotionFailure</li></ul></li></ul><h2 id="8-为对象分配内存：TLAB"><a href="#8-为对象分配内存：TLAB" class="headerlink" title="8 为对象分配内存：TLAB"></a>8 为对象分配内存：TLAB</h2><h3 id="为什么有-TLAB（Thread-Local-Allocation-Buffer）？"><a href="#为什么有-TLAB（Thread-Local-Allocation-Buffer）？" class="headerlink" title="为什么有 TLAB（Thread Local Allocation Buffer）？"></a><strong>为什么有 TLAB（Thread Local Allocation Buffer）？</strong></font></h3><ul><li>堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据</li><li>由于对象实例的创建在JVM中非常频繁，因此开发环境下从堆区中划分内存空间是线程不安全的</li><li>为避免多个线程操作统一地址，需要使用加锁等机制，进而影响分配速度。</li></ul><h3 id="什么是-TLAB-？"><a href="#什么是-TLAB-？" class="headerlink" title="什么是 TLAB ？"></a><strong>什么是 TLAB ？</strong></h3><p>从内存模型而不是垃圾收集的角度，对 Eden 区域继续进行划分，JVM 为<font color=red><strong>每个线程分配一个私有缓存区域</strong></font>，它包含在 Eden 空间中。</p><ul><li><p>多线程同时分配内存时，使用 TLAB 可以避免一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此可以将这种内存分配策略称为<font color=red><strong>快速分配策略</strong></font>。</p><img src="images/152.png" alt="img" style="zoom:67%;" /></li></ul><ul><li><p>尽管不是所有的对象实例都能够在 TLAB 中成功分配内存，但 <font color=red><strong>JVM 确实将TLAB作为内存分配的首选</strong></font>。</p></li><li><p>在程序中，开发人员可以通过选项 <code>-XX:UserTlab</code> 设置是否开启TLAB空间。</p></li><li><p>默认情况下，TLAB 空间的内存非常小，<font color=red><strong>仅占有整个 Eden 空间的1%</strong></font>，可以通过选项 <code>-XX:TLABWasteTargetPercent</code>设置 TLAB 空间的百分比大小。</p></li><li><p>一旦对象在 TLAB 空间内存分配失败时，JVM 就会尝试着通过<font color=red><strong>使用加锁机制</strong></font>确保数据操作的原子性，从而直接在 Eden 空间中分配内存。</p></li></ul><h2 id="9-小结堆空间的参数设置"><a href="#9-小结堆空间的参数设置" class="headerlink" title="9 小结堆空间的参数设置"></a>9 小结堆空间的参数设置</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 测试堆空间常用的jvm参数：</span></span><br><span class="line"><span class="comment"> * -XX:+PrintFlagsInitial : 查看所有的参数的默认初始值</span></span><br><span class="line"><span class="comment"> * -XX:+PrintFlagsFinal  ：查看所有的参数的最终值（可能会存在修改，不再是初始值）</span></span><br><span class="line"><span class="comment"> *      具体查看某个参数的指令： jps：查看当前运行中的进程</span></span><br><span class="line"><span class="comment"> *                           jinfo -flag SurvivorRatio 进程id</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * -Xms：初始堆空间内存 （默认为物理内存的1/64）</span></span><br><span class="line"><span class="comment"> * -Xmx：最大堆空间内存（默认为物理内存的1/4）</span></span><br><span class="line"><span class="comment"> * -Xmn：设置新生代的大小。(初始值及最大值)</span></span><br><span class="line"><span class="comment"> * -XX:NewRatio：配置新生代与老年代在堆结构的占比，默认为2</span></span><br><span class="line"><span class="comment"> * -XX:SurvivorRatio：设置新生代中Eden和S0/S1空间的比例，默认为8</span></span><br><span class="line"><span class="comment"> * -XX:MaxTenuringThreshold：设置新生代垃圾的最大年龄，默认为15，最大值也为15</span></span><br><span class="line"><span class="comment"> * -XX:+PrintGCDetails：输出详细的GC处理日志</span></span><br><span class="line"><span class="comment"> * 打印gc简要信息：① -XX:+PrintGC   ② -verbose:gc</span></span><br><span class="line"><span class="comment"> * -XX:HandlePromotionFailure：是否设置空间分配担保</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HeapArgsTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="images/154.png" alt="img" style="zoom:90%;" /><ul><li><p>“-XX:SurvivorRatio”设置的过大会有什么影响？</p><ul><li>会导致s0/s1很小，以至于Minor GC的时候to区放不下，直接进入到了老年代，导致Minor GC的没有什么意义，分代也没有什么意义了。</li></ul></li><li><p>“-XX:SurvivorRatio”设置的过小会有什么影响？</p><ul><li>会导致Young GC过于频繁，导致STW更长，影响性能。</li></ul></li><li><p>“-XX:MaxTenuringThreshold”的取值范围是多少？为什么？</p><ul><li><p>取值范围为0~15，包含0和15，因为对象头中只有4位（bits）存放该值的信息</p></li><li><p>设置参数”-XX:MaxTenuringThreshold=20”后运行性程序会出现下述错误：</p><img src="images/155.png" alt="img" style="zoom:90%;" /></li></ul></li><li><p>“-XX:HandlePromotionFailure”说明</p><ul><li>在发生Minor GC之前，虚拟机会<font color=red><strong>检查老年代最大可用的连续空间是否大于新生代所有对象的总空间</strong></font>。<ul><li>如果大于，则此次Minor GC是安全的</li><li>如果小于，则虚拟机会查看-XX:HandlePromotionFailure设置值是否允许担保失败<ul><li>如果HandlePromotionFailure=true，那么会继续<font color=red><strong>检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小</strong></font>。<ul><li>如果大于，则尝试进行一次Minor GC，但这次Minor GC依然是由风险的；</li><li>如果小于，则改为Full GC.</li></ul></li><li>如果HandlePromotionFailure=false，则改为一次Full GC</li></ul></li></ul></li><li>在JDK6 Update24（JDK7）之后，HandlePromotionFailure参数不会再影响到虚拟机的空间分配担保策略，观察OpenJDK中源码的变化，虽然源码中还定义了HandlePromotionFailure参数，但是在代码中已经不会再使用它，JDK6 Update24之后的规则变为<font color=red><strong>只要老年代的连续空间大于新生代总对象大小</strong></font>或者<font color=red><strong>历次晋升的平均大小</strong></font>就会进行Minor GC，否则进行Full GC。</li></ul></li></ul><h2 id="10-堆是分配对象的唯一选择吗？"><a href="#10-堆是分配对象的唯一选择吗？" class="headerlink" title="10 堆是分配对象的唯一选择吗？"></a>10 堆是分配对象的唯一选择吗？</h2><ul><li><p>首先上述答案：<font color=red><strong>堆不是分配对象的唯一选择</strong></font>。</p></li><li><p>在《深入理解Java虚拟机》中关于Java堆内存有这样一段描述：</p><ul><li>随着JIT编译器的发展与<font color=red><strong>逃逸分析技术</strong></font>逐渐成熟，<font color=red><strong>栈上分配、标量替换优化技术</strong></font>将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不是那么“绝对”了。</li></ul></li><li><p>在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的尝试。但是，有一种特殊的情况，那就是<font color=red><strong>如果经过逃逸分析（Escape Analysis）后发现，一个对象并没有逃出方法的话，那么就可能会被优化成栈上分配</strong></font>。这样就无需在堆上分配，也无需进行垃圾回收了。这也是最常见的对外存储技术。</p></li><li><p>此外，前面提到的基于OpenJDK深度定制的TaoBaoVM，其中创新的GCIH（GC invisiable heap）技术实现off-heap，将生命周期较长的Java对象从heap中移至heap外，并且GC不能管理GCIH内部的Java对象，以此达到降低GC的回收频率和提升GC的回收效率。</p></li></ul><hr><ul><li><p>逃逸分析</p><ul><li><p>如何将堆上的对象分配到栈，需要使用逃逸分析手段。</p></li><li><p>这是一种可以有效减少Java程序中<font color=red><strong>同步负载和内存分配压力的跨函数全局流分析算法</strong></font></p></li><li><p>通过逃逸分析，Java HotSpot编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。</p></li><li><p>逃逸分析的基本行为就是分析对象的动态作用域：</p><ul><li>当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸。</li><li>当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为参数传递到其他地方中。</li></ul></li><li><p>例子</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 逃逸分析</span></span><br><span class="line"><span class="comment"> * 如何快速的判断是否发生了逃逸，大家就看new的对象实体是否有可能在方法外被调用。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EscapeAnalysis</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> EscapeAnalysis obj;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 方法返回EscapeAnalysis对象，发生逃逸</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> EscapeAnalysis <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> obj == <span class="keyword">null</span> ? <span class="keyword">new</span> EscapeAnalysis() : obj;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 为成员属性赋值，发生逃逸</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setObj</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.obj = <span class="keyword">new</span> EscapeAnalysis();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 思考：如果当前的obj引用声明为static的？仍然会发生逃逸。</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 对象的作用域仅在当前方法中有效，没有发生逃逸</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">useEscapeAnalysis</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        EscapeAnalysis e = <span class="keyword">new</span> EscapeAnalysis();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 引用成员变量的值，发生逃逸</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">useEscapeAnalysis1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        EscapeAnalysis e = getInstance();</span><br><span class="line">        <span class="comment">// getInstance().xxx()同样会发生逃逸</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>参数设置：</p><ul><li>在JDK 6U23版本之后，HotSpot中默认就已经开启了逃逸分析。</li><li>如果使用的是较早的版本，开发人员可以通过：<ul><li>选项“-XX:DoEscapeAnalysis”显示开启逃逸分析</li><li>通过选项“-XX:+PrintEscapeAnalysis”来查看逃逸分析的筛选结果</li></ul></li></ul></li><li><p>结论：<font color=red><strong>开发中能使用局部变量的，就不要使用在方法外定义</strong></font>。</p></li></ul></li></ul><hr><ul><li>基于逃逸分析的代码优化：使用逃逸分析，编译器可以对代码做如下优化<ul><li><font color=red><strong>栈上分配</strong></font>。将堆分配转化为占分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是占分配的候选，而不是堆分配。</li><li><font color=red><strong>同步省略</strong></font>。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步。</li><li><font color=red><strong>分离对象或标量替换</strong></font>。有的对象可能不需要作为一个连续的存储结构存在也可以被访问到那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。对于Java来说，就是对象可以不必存储在堆空间，可以存储在栈空间。</li></ul></li></ul><hr><ul><li><p>栈上分配</p><ul><li><p>JIT编译器在编译期间根据逃逸分析的结果，发现如果一个对象并没有逃逸出方法的话，就可能被优化成栈上分配。分配完成后，继续在调用栈内执行，最后形成结束，栈空间被回收，局部变量对象也被回收。这样就无需进行垃圾回收了。</p></li><li><p>常见的栈上分配的场景</p><ul><li>在逃逸分析中，已经说明了。分别是给成员变量赋值、方法返回值、实例引用传递。</li></ul></li><li><p>代码例子：逃逸分析可以加快代码运行时间</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 栈上分配测试</span></span><br><span class="line"><span class="comment"> * -Xmx1G -Xms1G -XX:-DoEscapeAnalysis -XX:+PrintGCDetails</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StackAllocation</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000000</span>; i++) &#123;</span><br><span class="line">            alloc();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 查看执行时间</span></span><br><span class="line">        <span class="keyword">long</span> end = System.currentTimeMillis();</span><br><span class="line">        System.out.println(<span class="string">&quot;花费的时间为： &quot;</span> + (end - start) + <span class="string">&quot; ms&quot;</span>);</span><br><span class="line">        <span class="comment">// 为了方便查看堆内存中对象个数，线程sleep</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">1000000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e1) &#123;</span><br><span class="line">            e1.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">alloc</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        User user = <span class="keyword">new</span> User();  <span class="comment">// 未发生逃逸</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>参数为“-Xmx1G -Xms1G -XX:-DoEscapeAnalysis -XX:+PrintGCDetails”时结果：</strong></p><p>​            花费的时间为： 100 ms</p><img src="images/156.png" alt="img" style="zoom:90%;" /><p><strong>参数为“-Xmx1G -Xms1G -XX:+DoEscapeAnalysis -XX:+PrintGCDetails”时结果：</strong></p><p>​            花费的时间为： 5 ms</p><img src="images/157.png" alt="img" style="zoom:90%;" /><p><strong>参数为“-Xmx256m -Xms256m -XX:-DoEscapeAnalysis -XX:+PrintGCDetails”时结果：</strong></p><img src="images/158.png" alt="img" style="zoom:90%;" /><p><strong>参数为“-Xmx256m -Xms256m -XX:+DoEscapeAnalysis -XX:+PrintGCDetails”时结果：</strong></p><p>​            花费的时间为： 5 ms</p></li></ul></li></ul><hr><ul><li><p>同步省略 / 同步消除</p><ul><li>线程同步的代价是相当高的，同步的后果是降低并发性和性能。</li><li>在动态编译同步块的时候，JIT编译器可以借助逃逸分析来<font color=red><strong>判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程</strong></font>。如果没有，那么JIT编译器在编译（后端编译）这个同步代码块的时候就会取消对这部分代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫同步省略，也叫作<font color=red><strong>锁消除</strong></font>。</li></ul><img src="images/159.png" alt="img" style="zoom:67%;" /><img src="images/160.png" alt="img" style="zoom:80%;" /><p>我们可以看到字节码文件中仍然有monitorexter和monitorexit，在运行时会被消除（JIT编译器编译（后端编译）运行时会被消除）</p></li></ul><hr><ul><li><p>分离对象或标量替换</p><img src="images/161.png" alt="img" style="zoom:67%;" /><img src="images/162.png" alt="img" style="zoom:67%;" /><ul><li><p>标量替换参数设置：参数-XX:EliminateAllocations  开启了标量替换（默认打开），允许将对象打散分配在栈上</p></li><li><p>代码演示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 标量替换测试</span></span><br><span class="line"><span class="comment"> *  -Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:-EliminateAllocations</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ScalarReplace</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">int</span> id;</span><br><span class="line">        <span class="keyword">public</span> String name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">alloc</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        User u = <span class="keyword">new</span> User();  <span class="comment">// 未发生逃逸</span></span><br><span class="line">        u.id = <span class="number">5</span>;</span><br><span class="line">        u.name = <span class="string">&quot;www.atguigu.com&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000000</span>; i++) &#123;</span><br><span class="line">            alloc();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> end = System.currentTimeMillis();</span><br><span class="line">        System.out.println(<span class="string">&quot;花费的时间为： &quot;</span> + (end - start) + <span class="string">&quot; ms&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>参数为“-Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:-EliminateAllocations”时结果：</strong></p><img src="images/163.png" alt="img" style="zoom:90%;" /><p><strong>参数为“-Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:+EliminateAllocations”时结果：</strong></p><p>​            花费的时间为： 5 ms</p></li></ul></li></ul><hr><ul><li><p>总结</p><img src="images/164.png" alt="img" style="zoom:67%;" /><img src="images/165.png" alt="img" style="zoom:100%;" /><img src="images/166.png" alt="img" style="zoom:67%;" /></li></ul><hr><ul><li><p>本章小结</p><img src="images/167.png" alt="img" style="zoom:67%;" /></li></ul>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(8)_本地方法接口</title>
      <link href="2020/01/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(9)_%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%8E%A5%E5%8F%A3/"/>
      <url>2020/01/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(9)_%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%8E%A5%E5%8F%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>程序计数器是一块较小的内存空间，它的作用可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。</p><a id="more"></a><h2 id="1-本地方法栈概述"><a href="#1-本地方法栈概述" class="headerlink" title="1. 本地方法栈概述"></a>1. 本地方法栈概述</h2><p>简单地讲，<font color=blue><strong>一个 Native Method 就是一个 Java 调用非 Java 代码的接口</strong></font>。一个 Native Method 是这样一个 Java 方法：该方法的实现由非 Java 语言实现，比如 C。这个特征并非 Java 所特有，很多其他的编译语言都有这一机制，比如在 C++ 中，你可以用extern “C” 告知 C++ 编译器去调用一个 C 的函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A native method is a Java method whose implementation is provided by nono-java code.</span><br></pre></td></tr></table></figure><p>在定义一个native method时，并不提供实现体，有些像定义一个 Java 的 interface，因为其实现体是由非 Java 语言在外面实现的。</p><p>本地方法的作用是融合不同编程语言为 Java 所用，它的初衷是融合 C/C++ 程序。</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(8)_虚拟机栈</title>
      <link href="2020/01/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(8)_%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/"/>
      <url>2020/01/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(8)_%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>程序计数器是一块较小的内存空间，它的作用可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。</p><a id="more"></a><h2 id="1-虚拟机栈概述"><a href="#1-虚拟机栈概述" class="headerlink" title="1. 虚拟机栈概述"></a>1. 虚拟机栈概述</h2><p>官网：<a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5.2">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5.2</a></p><h3 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1. 背景"></a>1.1. 背景</h3><ul><li>由于跨平台性的设计，Java的指令都是根据栈来设计的。不同平台 CPU 架构不同，所以不能设计为基于寄存器的。</li><li><font color=red><strong>优点是扩平台，指令集小，编译器容易实现；缺点是性能下降，实现同样的功能需要更多的指令</strong></font>。</li></ul><h3 id="1-2-概述"><a href="#1-2-概述" class="headerlink" title="1.2. 概述"></a>1.2. 概述</h3><p>Java 虚拟机栈（Java Virtual Machine Stack），早期也叫Java栈。每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧（Stack Frame）</p><h3 id="1-3-虚拟机栈中可能存在的异常"><a href="#1-3-虚拟机栈中可能存在的异常" class="headerlink" title="1.3. 虚拟机栈中可能存在的异常"></a>1.3. 虚拟机栈中可能存在的异常</h3><p>Java 虚拟机规范允许 <font color=red><strong>Java 虚拟机栈的大小是动态的或者是固定不变的</strong></font>。</p><ul><li>如果采用固定大小的 Java 虚拟机栈，那么每一个线程的 Java 虚拟机栈容量容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量，Java 虚拟机将会抛出一个 <font color=red><strong>StackOverflowError</strong></font>异常。</li><li>如果 Java 虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程的时候没有足够的内存去创建对应的虚拟机栈，那Java虚拟机将会抛出一个 <font color=red><strong>OutOfMemoryError</strong></font> 异常。</li></ul><p>StackOverflowError演示</p><h3 id="1-4-设置栈内存大小"><a href="#1-4-设置栈内存大小" class="headerlink" title="1.4. 设置栈内存大小"></a>1.4. 设置栈内存大小</h3><p>使用参数 -Xss 选项来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度</p><h2 id="2-栈的存储单位"><a href="#2-栈的存储单位" class="headerlink" title="2. 栈的存储单位"></a>2. 栈的存储单位</h2><h3 id="2-1-栈中存储什么？"><a href="#2-1-栈中存储什么？" class="headerlink" title="2.1. 栈中存储什么？"></a>2.1. 栈中存储什么？</h3><ul><li>每个线程都有自己的栈，栈中的数据都是以<font color=red><strong>栈帧（Stack Frame）</strong></font>的格式存在。</li><li>在这个线程上正在执行的每个方法都各自对应一个栈帧（Stack Frame）。</li><li>栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息。</li></ul><h3 id="2-2-栈运行原理"><a href="#2-2-栈运行原理" class="headerlink" title="2.2. 栈运行原理"></a>2.2. 栈运行原理</h3><ul><li><p>JVM 直接对 Java 栈的操作只有两个，就是对栈帧的<font color=red><strong>入栈</strong></font>和<font color=red><strong>出栈</strong></font>，遵循<font color=blue>**”先进后出”/“后进先出”原则**</font>。</p></li><li><p>在一条活动现场中，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧（栈顶栈帧）是有效的，这个栈帧被称为<font color=red><strong>当前栈帧（Current Frame）</strong></font>，与当前栈帧对应的方法就是<font color=red><strong>当前方法（Current Method）</strong></font>，定义这个方法的类就是<font color=red><strong>当前类（Current Class）</strong></font></p><img src="/Users/joker/Documents/Learnning/Java/JVM/images/83.png" alt="img" style="zoom:67%;" /></li><li><p>执行引擎运行的所有字节码指令只针对当前栈帧操作。</p></li><li><p>如果在改方法中调用了其他方法，对应的新的栈帧就会被创建出来，放在栈的顶端，称为新的当前帧。</p></li><li><p>不同线程中锁包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧之中引用另外一个线程的栈帧。</p></li><li><p>如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会对齐当前栈帧，使得前一个栈帧重新成为当前栈帧。</p></li><li><p>Java方法有两种放回函数的方式，<font color=red><strong>一种是正常的函数返回，使用return指令</strong></font>；<font color=red><strong>另一种是抛出异常</strong></font>。不管使用哪种方式，都会导致栈帧被弹出。</p></li><li><p>栈帧的内部结构</p><ul><li><p><font color=red><strong>局部变量表（Local Variables）</strong></font></p></li><li><p><font color=red><strong>操作数栈（Operand Stack）（或表达式栈）</strong></font></p></li><li><p>动态链接（Dynamic Linking）（或指向运行时常量池的方法引用）</p></li><li><p>方法返回地址（Return Address）（或方法长长退出或者异常退出的定义）</p></li><li><p>一些附加信息</p><img src="/Users/joker/Documents/Learnning/Java/JVM/images/84.png" alt="img" style="zoom:67%;" /><img src="/Users/joker/Documents/Learnning/Java/JVM/images/85.png" alt="img" style="zoom:67%;" /></li></ul></li></ul><h2 id="3-局部变量表"><a href="#3-局部变量表" class="headerlink" title="3. 局部变量表"></a>3. 局部变量表</h2><ul><li><p>局部变量表也被称为 <strong>局部变量数组</strong> 或 <strong>本地变量表</strong></p></li><li><p><font color=red><strong>定义为一个数字数组，主要用于存储方法参数和定义在方法体内的局部变量</strong></font>，这些数据类型包括各种基本数据类型、对象引用（reference），以及returnAddress类型。</p></li><li><p>由于局部变量表是建立在线程的栈上，是线程的私有数据，因此<font color=red><strong>不存在数据安全问题</strong></font></p></li><li><p><font color=red><strong>局部变量表所需要的容量大小是在编译期（前端编译）确定下来的</strong></font>，并保存在方法的Code属性的maximun local variables数据项中。在方法运行期间是不会改变局部变量表的大小的。</p></li></ul><h2 id="4-操作数栈（Operand-Stack）"><a href="#4-操作数栈（Operand-Stack）" class="headerlink" title="4. 操作数栈（Operand Stack）"></a>4. 操作数栈（Operand Stack）</h2><h2 id="5-方法返回地址（return-address）"><a href="#5-方法返回地址（return-address）" class="headerlink" title="5. 方法返回地址（return address）"></a>5. 方法返回地址（return address）</h2>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(7)_程序计数器</title>
      <link href="2020/01/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(7)_%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8/"/>
      <url>2020/01/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(7)_%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>程序计数器是一块较小的内存空间，它的作用可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。</p><a id="more"></a><h2 id="1-PC-Register-介绍"><a href="#1-PC-Register-介绍" class="headerlink" title="1. PC Register 介绍"></a>1. PC Register 介绍</h2><p>虚拟机规范：<a href="https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5.1">https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5.1</a></p><p>程序执行的最小单位是线程，线程 A 和线程 B 对 CPU 的时间片资源是抢占式争夺，任何一个线程在使用 CPU 的时候，其他线程就被挂起，无法使用 CPU。当一个优先级更高的线程要抢占当前CPU资源时，当前线程可能未必执行完毕就被挂起，此时就需要保存现场信息，以便当前线程再次抢到CPU资源后继续执行。<br><strong>程序计数器的作用就是保存现场信息，每个线程都有自己的程序计数器。</strong></p><img src="images/71.png" alt="img" style="zoom:65%;" /><h2 id="2-特点"><a href="#2-特点" class="headerlink" title="2. 特点"></a>2. 特点</h2><ul><li><p>PC 寄存器是一块很小的内存空间，几乎可以忽略不计。也是运行速度最快的内存区域。</p></li><li><p>在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期保持一致。</p></li><li><p>在 JVM 规范中规定，如果线程执行的是非 native 方法，则程序计数器中保存的是当前需要执行的指令的地址；如果线程执行的是 native 方法，则程序计数器中的值是 undefined。</p></li><li><p>PC寄存器是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成</p></li><li><p>字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令。</p></li><li><p><strong><font color=red>它是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域。</font></strong></p><blockquote><p>由于程序计数器中存储的数据所占空间的大小不会随程序的执行而发生改变，因此，对于程序计数器是不会发生内存溢出现象(OutOfMemory)的。</p></blockquote></li></ul><h2 id="3-两个常见问题"><a href="#3-两个常见问题" class="headerlink" title="3 两个常见问题"></a>3 两个常见问题</h2><h5 id="使用PC寄存器存储字节码指令地址有什么用呢？为什么使用PC寄存器记录当前线程的执行地址呢？"><a href="#使用PC寄存器存储字节码指令地址有什么用呢？为什么使用PC寄存器记录当前线程的执行地址呢？" class="headerlink" title="使用PC寄存器存储字节码指令地址有什么用呢？为什么使用PC寄存器记录当前线程的执行地址呢？"></a><font color=blue>使用PC寄存器存储字节码指令地址有什么用呢？为什么使用PC寄存器记录当前线程的执行地址呢？</font></h5><blockquote><p>因为 CPU 需要不停的切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行。<br>JVM 的字节码解释器就需要通过改变 PC 寄存器的值来明确下一条应该执行什么样的字节码指令</p></blockquote><h5 id="PC-寄存器为什么会被设定为线程私有？"><a href="#PC-寄存器为什么会被设定为线程私有？" class="headerlink" title="PC 寄存器为什么会被设定为线程私有？"></a><font color=blue>PC 寄存器为什么会被设定为线程私有？</font></h5><blockquote><p>多线程在一个特定的时间段内只会执行其中某一个线程的方法，CPU 会不停地做任务切换，导致经常中断或恢复，如何保证为了能够准确地记录各个线程正在执行的当前字节码指令地址，最好的办法自然是为每一个线程都分配一个PCm寄存器，这各个线程之间便可以进行独立计算，从而不会出现相互干扰的情况。</p><p>由于 CPU 时间片轮限制，众多线程在并发执行过程中，任何一个确定的时刻，一个处理器或者多核处理器中的一个内核，只会执行某个线程中的一条指令。这样必然导致经常中断或恢复，每个线程在创建后，都会产生自己的程序计数器和栈帧，程序计数器在各个线程之间互不影响。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(6)_运行时数据区及线程概述</title>
      <link href="2020/01/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(6)_%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%8F%8A%E7%BA%BF%E7%A8%8B%E6%A6%82%E8%BF%B0/"/>
      <url>2020/01/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(6)_%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%8F%8A%E7%BA%BF%E7%A8%8B%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>内存是非常重要的系统资源，是硬盘和CPU的中间仓库及桥梁，承载着操作系统和应用程序的实时运行。JVM内存布局规定了Java在运行过程中内存申请、分配、管理的策略，保证了JVM的高效稳定运行。<font color=red><strong>不同的JVM对于内存的划分方式和管理机制存在着部分差异</strong></font>。</p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h2><img src="images/62.png" alt="img" style="zoom:75%;" /><img src="images/63.png" alt="img" style="zoom:65%;" /><ul><li><img src="images/64.png" alt="img" style="zoom:60%;" /></li></ul><img src="images/65.png" alt="img" style="zoom:60%;" /><img src="images/66.png" alt="img" style="zoom:60%;" /><ul><li>GC调优95%都在堆区，5%在方法区（JDK8之前叫做永久代，JDK8及以后叫做元空间）</li></ul><img src="images/67.png" alt="img" style="zoom:67%;" /><h2 id="2-线程"><a href="#2-线程" class="headerlink" title="2 线程"></a>2 线程</h2><ul><li>线程是一个程序里的运行单元。JVM允许一个应用有多个线程并行的执行。</li><li>在Hotsopt JVM里，每个线程都与操作系统的本地线程直接映射。<ul><li>当一个Java线程准备好执行以后，此时一个操作系统的本地线程也同时创建。Java线程执行终止后，本地线程也会回收。</li></ul></li><li>操作系统负责所有线程的安排调度到任何一个可用的CPU熵。一旦本地线程初始化成功，它就会调用Java线程中的run()方法。</li></ul><img src="images/68.png" alt="img" style="zoom:67%;" />]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink Job 并行度设置</title>
      <link href="2019/12/30/Flink-Job-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E8%AE%BE%E7%BD%AE/"/>
      <url>2019/12/30/Flink-Job-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E8%AE%BE%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>生产环境如果 Job 突然消费不及时了，或者 Job 就根本不在消费数据了，那么该怎么办？首先得看下相关的监控查看 Job 是否在正常运行，是否出现反压的情况，是否这会生产数据量过大然而并行度却是根据之前数据量设置的，种种原因都需要一个个排查一下，然后找到根因才能够对应的去解决。这节来讲解下遇到这种问题后如何合理配置并行度呢？</p><a id="more"></a><h3 id="Source-端并行度的配置"><a href="#Source-端并行度的配置" class="headerlink" title="Source 端并行度的配置"></a>Source 端并行度的配置</h3><p>假设数据源端是 Kafka，在出现作业消费不及时的时候，首先看下 Kafka 的监控是不是现在生产者生产的数据上涨速度较快，从而导致作业目前的消费速度就是跟不上 Kafka 生产者的生产速度，如果是这样的话，那么就得查看作业的并行度和 Kafka 的分区数是否一致，如果小于 Kafka 的分区数，那么可以增大并行度至 Kafka 的分区数，然后再观察作业消费速度是否可以跟上数据生产速度；如果已经等于 Kafka 的分区数了，那得考虑下是否 Kafka 要扩大分区，但是这样可能会带来 Kafka 其他的问题，这个操作需要谨慎。</p><p>Kafka 中数据出现堆积的话，还可以分析下数据的类型，如果数据不重要，但是又要保证数据的及时性，可以修改作业让作业始终从最新的数据开始消费，丢弃之前堆积的数据，这样就可以保证数据的及时性。举个例子，假如一个实时告警作业它突然消费不及时，Kafka 中堆积了几亿条数据（数据延迟几个小时），那么如果作业调高并行度重启后，它还是从上一次提交的 offset 处开始消费的话，这样告警作业即使现在消费速度跟的上了，但是它要处理掉之前堆积的几亿条数据也是要一段时间的，那么就意味着这个作业仍将有段时间处于 ‘不可用’。因为即使判断出来要告警，可能这个告警信息的原数据已经是几个小时前的了，没准这个告警此时已经恢复了，但是还发出来告警这就意味着延迟性比较大，还会对告警消息接收者造成一定的干扰，所以这种场景下建议重启作业就直接开始从最新的数据开始消费。当然不同的场景可能不一样，如果金融行业的交易数据，那么是肯定不能允许这样丢数据的，即使堆积了，也要慢慢的去消费堆积的数据，直到后面追平至最新的数据。</p><p>在 Source 端设置并行度的话，如果数据源是 Kafka 的话，建议并行度不要超过 Kafka 的分区数，因为一个并行度会去处理一至多个分区的数据，如果设置过多的话，会出现部分并行度空闲。如果是其他的数据源，可以根据实际情况合理增大并行度来提高作业的处理数据能力。</p><h3 id="中间-Operator-并行度的配置"><a href="#中间-Operator-并行度的配置" class="headerlink" title="中间 Operator 并行度的配置"></a>中间 Operator 并行度的配置</h3><p>数据从 Source 端流入后，通常会进行一定的数据转换、聚合才能够满足需求，在数据转换中可能会和第三方系统进行交互，在交互的过程中可能会因为网络原因或者第三方服务原因导致有一定的延迟，从而导致这个数据交互的算子处理数据的吞吐量会降低，可能会造成反压，从而会影响上游的算子的消费。那么在这种情况下这些与第三方系统有交互的算子得稍微提高并行度，防止出现这种反压问题（当然反压问题不一定就这样可以解决，具体如何处理参见 9.1 节）。</p><p>除了这种与第三方服务做交互的外，另外可能的性能瓶颈也会出现在这类算子中，比如你 Kafka 过来的数据是 JSON 串的 String，然后需要转换成对象，在大数据量的情况下这个转换也是比较耗费性能的。</p><p>所以数据转换中间过程的算子也是非常重要的，如果哪一步算子的并行度设置的不合理，可能就会造成各种各样的问题出现。</p><h3 id="Sink-端并行度的配置"><a href="#Sink-端并行度的配置" class="headerlink" title="Sink 端并行度的配置"></a>Sink 端并行度的配置</h3><p>Sink 端是数据流向下游的地方，可以根据 Sink 端的数据量进行评估，可能有的作业是 Source 端的数据量最大，然后数据量不断的变少，最后到 Sink 端的数据就一点点了，比较常见的就是监控告警的场景。Source 端的数据是海量的，但是通过逐层的过滤和转换，到最后判断要告警的数据其实已经减少很多很多了，那么在最后的这个地方就可以将并行度设置的小一些。</p><p>当然也可能会有这样的情况，在 Source 端的数据量是最小的，拿到 Source 端流过来的数据后做了细粒度的拆分，那么数据量就不断的增加了，到 Sink 端的数据量就非常非常的大了。那么在 Sink 到下游的存储中间件的时候就需要提高并行度。</p><p>另外 Sink 端也是要与下游的服务进行交互，并行度还得根据下游的服务抗压能力来设置，如果在 Flink Sink 这端的数据量过大的话，然后在 Sink 处并行度也设置的很大，但是下游的服务完全撑不住这么大的并发写入，也是可能会造成下游服务直接被写挂的，下游服务可能还要对外提供一些其他的服务，如果稳定性不能保证的话，会造成很大的影响，所以最终还是要在 Sink 处的并行度做一定的权衡。</p><h3 id="Operator-Chain"><a href="#Operator-Chain" class="headerlink" title="Operator Chain"></a>Operator Chain</h3><p>对于一般的作业（无特殊耗性能处），可以尽量让算子的并行度从 Source 端到 Sink 端都保持一致，这样可以尽可能的让 Job 中的算子进行 chain 在一起，形成链，数据在链中可以直接传输，而不需要再次进行序列化与反序列化，这样带来的性能消耗就会得到降低。在 9.2 节中具体讲解了算子 chain 在一起的条件，忘记的话可以去回顾一下。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink Side Output 分流</title>
      <link href="2019/12/28/Flink-Side-Output-%E5%88%86%E6%B5%81/"/>
      <url>2019/12/28/Flink-Side-Output-%E5%88%86%E6%B5%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>通常，在 Kafka 的 topic 中会有很多数据，这些数据虽然结构是一致的，但是类型可能不一致，举个例子：Kafka 中的监控数据有很多种：机器、容器、应用、中间件等，如果要对这些数据分别处理，就需要对这些数据流进行一个拆分。</p><a id="more"></a><h3 id="使用-Filter-分流"><a href="#使用-Filter-分流" class="headerlink" title="使用 Filter 分流"></a>使用 Filter 分流</h3><p>使用 filter 算子根据数据的字段进行过滤分成机器、容器、应用、中间件等。伪代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DataStreamSource&lt;MetricEvent&gt; data = KafkaConfigUtil.buildSource(env);  <span class="comment">//从 Kafka 获取到所有的数据流</span></span><br><span class="line">SingleOutputStreamOperator&lt;MetricEvent&gt; machineData = data.filter(m -&gt; <span class="string">&quot;machine&quot;</span>.equals(m.getTags().get(<span class="string">&quot;type&quot;</span>)));  <span class="comment">//过滤出机器的数据</span></span><br><span class="line">SingleOutputStreamOperator&lt;MetricEvent&gt; dockerData = data.filter(m -&gt; <span class="string">&quot;docker&quot;</span>.equals(m.getTags().get(<span class="string">&quot;type&quot;</span>)));    <span class="comment">//过滤出容器的数据</span></span><br><span class="line">SingleOutputStreamOperator&lt;MetricEvent&gt; applicationData = data.filter(m -&gt; <span class="string">&quot;application&quot;</span>.equals(m.getTags().get(<span class="string">&quot;type&quot;</span>)));  <span class="comment">//过滤出应用的数据</span></span><br><span class="line">SingleOutputStreamOperator&lt;MetricEvent&gt; middlewareData = data.filter(m -&gt; <span class="string">&quot;middleware&quot;</span>.equals(m.getTags().get(<span class="string">&quot;type&quot;</span>)));    <span class="comment">//过滤出中间件的数据</span></span><br></pre></td></tr></table></figure><h3 id="使用-Split-分流"><a href="#使用-Split-分流" class="headerlink" title="使用 Split 分流"></a>使用 Split 分流</h3><p>先在 split 算子里面定义 OutputSelector 的匿名内部构造类，然后重写 select 方法，根据数据的类型将不同的数据放到不同的 tag 里面，这样返回后的数据格式是 SplitStream，然后要使用这些数据的时候，可以通过 select 去选择对应的数据类型，伪代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">DataStreamSource&lt;MetricEvent&gt; data = KafkaConfigUtil.buildSource(env);  <span class="comment">//从 Kafka 获取到所有的数据流</span></span><br><span class="line">SplitStream&lt;MetricEvent&gt; splitData = data.split(<span class="keyword">new</span> OutputSelector&lt;MetricEvent&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Iterable&lt;String&gt; <span class="title">select</span><span class="params">(MetricEvent metricEvent)</span> </span>&#123;</span><br><span class="line">        List&lt;String&gt; tags = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        String type = metricEvent.getTags().get(<span class="string">&quot;type&quot;</span>);</span><br><span class="line">        <span class="keyword">switch</span> (type) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;machine&quot;</span>:</span><br><span class="line">                tags.add(<span class="string">&quot;machine&quot;</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;docker&quot;</span>:</span><br><span class="line">                tags.add(<span class="string">&quot;docker&quot;</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;application&quot;</span>:</span><br><span class="line">                tags.add(<span class="string">&quot;application&quot;</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;middleware&quot;</span>:</span><br><span class="line">                tags.add(<span class="string">&quot;middleware&quot;</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> tags;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">DataStream&lt;MetricEvent&gt; machine = splitData.select(<span class="string">&quot;machine&quot;</span>);</span><br><span class="line">DataStream&lt;MetricEvent&gt; docker = splitData.select(<span class="string">&quot;docker&quot;</span>);</span><br><span class="line">DataStream&lt;MetricEvent&gt; application = splitData.select(<span class="string">&quot;application&quot;</span>);</span><br><span class="line">DataStream&lt;MetricEvent&gt; middleware = splitData.select(<span class="string">&quot;middleware&quot;</span>);</span><br></pre></td></tr></table></figure><p>上面这种只分流一次是没有问题的，注意如果要使用它来做连续的分流，那是有问题的，笔者曾经就遇到过这个问题，当时记录了博客 —— <a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a> ，当时排查这个问题还查到两个相关的 Flink Issue。</p><ul><li><a href="https://issues.apache.org/jira/browse/FLINK-5031">https://issues.apache.org/jira/browse/FLINK-5031</a></li><li><a href="https://issues.apache.org/jira/browse/FLINK-11084">https://issues.apache.org/jira/browse/FLINK-11084</a></li></ul><p>这两个 Issue 反映的就是连续 split 不起作用，在第二个 Issue 下面的评论就有回复说 Side Output 的功能比 split 更强大， split 会在后面的版本移除（其实在 1.7.x 版本就已经设置为过期），那么下面就来学习一下 Side Output。</p><h3 id="使用-Side-Output-分流"><a href="#使用-Side-Output-分流" class="headerlink" title="使用 Side Output 分流"></a>使用 Side Output 分流</h3><p>要使用 Side Output 的话，你首先需要做的是定义一个 OutputTag 来标识 Side Output，代表这个 Tag 是要收集哪种类型的数据，如果是要收集多种不一样类型的数据，那么你就需要定义多种 OutputTag。要完成本节前面的需求，需要定义 4 个 OutputTag，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建 output tag</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> OutputTag&lt;MetricEvent&gt; machineTag = <span class="keyword">new</span> OutputTag&lt;MetricEvent&gt;(<span class="string">&quot;machine&quot;</span>) &#123;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> OutputTag&lt;MetricEvent&gt; dockerTag = <span class="keyword">new</span> OutputTag&lt;MetricEvent&gt;(<span class="string">&quot;docker&quot;</span>) &#123;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> OutputTag&lt;MetricEvent&gt; applicationTag = <span class="keyword">new</span> OutputTag&lt;MetricEvent&gt;(<span class="string">&quot;application&quot;</span>) &#123;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> OutputTag&lt;MetricEvent&gt; middlewareTag = <span class="keyword">new</span> OutputTag&lt;MetricEvent&gt;(<span class="string">&quot;middleware&quot;</span>) &#123;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>定义好 OutputTag 后，可以使用下面几种函数来处理数据：</p><ul><li>ProcessFunction</li><li>KeyedProcessFunction</li><li>CoProcessFunction</li><li>ProcessWindowFunction</li><li>ProcessAllWindowFunction</li></ul><p>在利用上面的函数处理数据的过程中，需要对数据进行判断，将不同种类型的数据存到不同的 OutputTag 中去，如下代码所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">DataStreamSource&lt;MetricEvent&gt; data = KafkaConfigUtil.buildSource(env);  <span class="comment">//从 Kafka 获取到所有的数据流</span></span><br><span class="line">SingleOutputStreamOperator&lt;MetricEvent&gt; sideOutputData = data.process(<span class="keyword">new</span> ProcessFunction&lt;MetricEvent, MetricEvent&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(MetricEvent metricEvent, Context context, Collector&lt;MetricEvent&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String type = metricEvent.getTags().get(<span class="string">&quot;type&quot;</span>);</span><br><span class="line">        <span class="keyword">switch</span> (type) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;machine&quot;</span>:</span><br><span class="line">                context.output(machineTag, metricEvent);</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;docker&quot;</span>:</span><br><span class="line">                context.output(dockerTag, metricEvent);</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;application&quot;</span>:</span><br><span class="line">                context.output(applicationTag, metricEvent);</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;middleware&quot;</span>:</span><br><span class="line">                context.output(middlewareTag, metricEvent);</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                collector.collect(metricEvent);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>好了，既然上面已经将不同类型的数据放到不同的 OutputTag 里面了，那么该如何去获取呢？可以使用 getSideOutput 方法来获取不同 OutputTag 的数据，比如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;MetricEvent&gt; machine = sideOutputData.getSideOutput(machineTag);</span><br><span class="line">DataStream&lt;MetricEvent&gt; docker = sideOutputData.getSideOutput(dockerTag);</span><br><span class="line">DataStream&lt;MetricEvent&gt; application = sideOutputData.getSideOutput(applicationTag);</span><br><span class="line">DataStream&lt;MetricEvent&gt; middleware = sideOutputData.getSideOutput(middlewareTag);</span><br></pre></td></tr></table></figure><p>这样你就可以获取到 Side Output 数据了，其实在 3.4 和 3.5 节就讲了 Side Output 在 Flink 中的应用（处理窗口的延迟数据），大家如果没有印象了可以再返回去复习一下。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink Checkpoint 和 Savepoint 区别</title>
      <link href="2019/12/28/Flink-Checkpoint-%E5%92%8C-Savepoint-%E5%8C%BA%E5%88%AB/"/>
      <url>2019/12/28/Flink-Checkpoint-%E5%92%8C-Savepoint-%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Checkpoint 在 Flink 中是一个非常重要的 Feature，Checkpoint 使 Flink 的状态具有良好的容错性，通过 Checkpoint 机制，Flink 可以对作业的状态和计算位置进行恢复。</p><a id="more"></a><h3 id="Checkpoint-简介"><a href="#Checkpoint-简介" class="headerlink" title="Checkpoint 简介"></a>Checkpoint 简介</h3><p>为了保障的容错，Flink 需要对状态进行快照。Flink 可以从 Checkpoint 中恢复流的状态和位置，从而使得应用程序发生故障后能够得到与无故障执行相同的语义。</p><p>Flink 的 Checkpoint 有以下先决条件：</p><ul><li><p><strong>需要具有持久性且支持重放一定时间范围内数据的数据源。</strong></p><blockquote><p>例如：Kafka、RabbitMQ 等。这里为什么要求支持重放一定时间范围内的数据呢？因为 Flink 的容错机制决定了，当 Flink 任务失败后会自动从最近一次成功的 Checkpoint 处恢复任务，此时可能需要把任务失败前消费的部分数据再消费一遍，所以必须要求数据源支持重放。假如一个Flink 任务消费 Kafka 并将数据写入到 MySQL 中，任务从 Kafka 读取到数据，还未将数据输出到 MySQL 时任务突然失败了，此时如果 Kafka 不支持重放，就会造成这部分数据永远丢失了。支持重放数据的数据源可以保障任务消费失败后，能够重新消费来保障任务不丢数据。</p></blockquote></li><li><p><strong>需要一个能保存状态的持久化存储介质</strong></p><blockquote><p>例如：HDFS、S3 等。当 Flink 任务失败后，自动从 Checkpoint 处恢复，但是如果 Checkpoint 时保存的状态信息快照全丢了，那就会影响 Flink 任务的正常恢复。就好比我们看书时经常使用书签来记录当前看到的页码，当下次看书时找到书签的位置继续阅读即可，但是如果书签三天两头经常丢，那我们就无法通过书签来恢复阅读。</p></blockquote></li></ul><p>Flink 中 Checkpoint 是默认关闭的，对于需要保障 At Least Once 和 Exactly Once 语义的任务，强烈建议开启 Checkpoint，对于丢一小部分数据不敏感的任务，可以不开启 Checkpoint，例如：一些推荐相关的任务丢一小部分数据并不会影响推荐效果。</p><hr><h2 id="Checkpoint-使用"><a href="#Checkpoint-使用" class="headerlink" title="Checkpoint 使用"></a><strong>Checkpoint 使用</strong></h2><p>首先调用 StreamExecutionEnvironment 的方法 enableCheckpointing(n) 来开启 Checkpoint，参数 n 以毫秒为单位表示 Checkpoint 的时间间隔。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// 开启 Checkpoint，每 1000毫秒进行一次 Checkpoint</span></span><br><span class="line">env.enableCheckpointing(<span class="number">1000</span>);</span><br><span class="line"><span class="comment">// Checkpoint 语义设置为 EXACTLY_ONCE</span></span><br><span class="line">env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line"><span class="comment">// CheckPoint 的超时时间</span></span><br><span class="line">env.getCheckpointConfig().setCheckpointTimeout(<span class="number">60000</span>);</span><br><span class="line"><span class="comment">// 同一时间，只允许 有 1 个 Checkpoint 在发生</span></span><br><span class="line">env.getCheckpointConfig().setMaxConcurrentCheckpoints(<span class="number">1</span>);</span><br><span class="line"><span class="comment">// 两次 Checkpoint 之间的最小时间间隔为 500 毫秒</span></span><br><span class="line">env.getCheckpointConfig().setMinPauseBetweenCheckpoints(<span class="number">500</span>);</span><br><span class="line"><span class="comment">// 当 Flink 任务取消时，保留外部保存的 CheckPoint 信息</span></span><br><span class="line">env.getCheckpointConfig().enableExternalizedCheckpoints(ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 当有较新的 Savepoint 时，作业也会从 Checkpoint 处恢复</span></span><br><span class="line">env.getCheckpointConfig().setPreferCheckpointForRecovery(<span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// 作业最多允许 Checkpoint 失败 1 次（flink 1.9 开始支持）</span></span><br><span class="line">env.getCheckpointConfig().setTolerableCheckpointFailureNumber(<span class="number">1</span>);</span><br><span class="line"><span class="comment">// Checkpoint 失败后，整个 Flink 任务也会失败（flink 1.9 之前）</span></span><br><span class="line">env.getCheckpointConfig.setFailTasksOnCheckpointingErrors(<span class="keyword">true</span>)</span><br></pre></td></tr></table></figure><p>以上 Checkpoint 相关的参数描述如下所示：</p><ul><li>Checkpoint 语义：EXACTLY<em>ONCE 或 AT</em>LEAST<em>ONCE，EXACTLY</em>ONCE 表示所有要消费的数据被恰好处理一次，即所有数据既不丢数据也不重复消费；AT<em>LEAST</em>ONCE 表示要消费的数据至少处理一次，可能会重复消费。</li><li>Checkpoint 超时时间：如果 Checkpoint 时间超过了设定的超时时间，则 Checkpoint 将会被终止。</li><li>同时进行的 Checkpoint 数量：默认情况下，当一个 Checkpoint 在进行时，JobManager 将不会触发下一个 Checkpoint，但 Flink 允许多个 Checkpoint 同时在发生。</li><li>两次 Checkpoint 之间的最小时间间隔：从上一次 Checkpoint 结束到下一次 Checkpoint 开始，中间的间隔时间。例如，env.enableCheckpointing(60000) 表示 1 分钟触发一次 Checkpoint，同时再设置两次 Checkpoint 之间的最小时间间隔为 30 秒，假如任务运行过程中一次 Checkpoint 就用了50s，那么等 Checkpoint 结束后，理论来讲再过 10s 就要开始下一次 Checkpoint 了，但是由于设置了最小时间间隔为30s，所以需要再过 30s 后，下次 Checkpoint 才开始。注：如果配置了该参数就决定了同时进行的 Checkpoint 数量只能为 1。</li><li>当任务被取消时，外部 Checkpoint 信息是否被清理：Checkpoint 在默认的情况下仅用于恢复运行失败的 Flink 任务，当任务手动取消时 Checkpoint 产生的状态信息并不保留。当然可以通过该配置来保留外部的 Checkpoint 状态信息，这些被保留的状态信息在作业手动取消时不会被清除，这样就可以使用该状态信息来恢复 Flink 任务，对于需要从状态恢复的任务强烈建议配置为外部 Checkpoint 状态信息不清理。可选择的配置项为：</li><li>ExternalizedCheckpointCleanup.RETAIN<em>ON</em>CANCELLATION：当作业手动取消时，保留作业的 Checkpoint 状态信息。注意，这种情况下，需要手动清除该作业保留的 Checkpoint 状态信息，否则这些状态信息将永远保留在外部的持久化存储中。</li><li>ExternalizedCheckpointCleanup.DELETE<em>ON</em>CANCELLATION：当作业取消时，Checkpoint 状态信息会被删除。仅当作业失败时，作业的 Checkpoint 才会被保留用于任务恢复。</li><li>任务失败，当有较新的 Savepoint 时，作业是否回退到 Checkpoint 进行恢复：默认情况下，当 Savepoint 比 Checkpoint 较新时，任务会从 Savepoint 处恢复。</li><li>作业可以容忍 Checkpoint 失败的次数：默认值为 0，表示不能接受 Checkpoint 失败。</li></ul><p>关于 Checkpoint 时，状态后端相关的配置请参阅本课 4.2 节。</p><h3 id="Savepoint-介绍、Savepoint-与-Checkpoint-的区别及使用"><a href="#Savepoint-介绍、Savepoint-与-Checkpoint-的区别及使用" class="headerlink" title="Savepoint 介绍、Savepoint 与 Checkpoint 的区别及使用"></a>Savepoint 介绍、Savepoint 与 Checkpoint 的区别及使用</h3><p>Savepoint 与 Checkpoint 类似，同样需要把状态信息存储到外部介质，当作业失败时，可以从外部存储中恢复。Savepoint 与 Checkpoint 的区别很多：</p><table><thead><tr><th align="center">Checkpoint</th><th align="center">Savepoint</th></tr></thead><tbody><tr><td align="center">由 Flink 的 JobManager 定时自动触发并管理</td><td align="center">由用户手动触发并管理</td></tr><tr><td align="center">主要用于任务发生故障时，为任务提供给自动恢复机制</td><td align="center">主要用于升级 Flink 版本、修改任务的逻辑代码、调整算子的并行度，且必须手动恢复</td></tr><tr><td align="center">当使用 RocksDBStateBackend 时，支持增量方式对状态信息进行快照</td><td align="center">仅支持全量快照</td></tr><tr><td align="center">Flink 任务停止后，Checkpoint 的状态快照信息默认被清除</td><td align="center">一旦触发 Savepoint，状态信息就被持久化到外部存储，除非用户手动删除</td></tr><tr><td align="center">Checkpoint 设计目标：轻量级且尽可能快地恢复任务</td><td align="center">Savepoint 的生成和恢复成本会更高一些，Savepoint 更多地关注代码的可移植性和兼容任务的更改操作</td></tr></tbody></table><p>除了上述描述外，Checkpoint 和 Savepoint 在当前的实现上基本相同。</p><p>强烈建议在程序中给算子分配 Operator ID，以便来升级程序。主要通过 <code>uid(String)</code> 方法手动指定算子的 ID ，这些 ID 将用于恢复每个算子的状态。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;String&gt; stream = env.</span><br><span class="line">  <span class="comment">// Stateful source (e.g. Kafka) with ID</span></span><br><span class="line">  .addSource(<span class="keyword">new</span> StatefulSource())</span><br><span class="line">  .uid(<span class="string">&quot;source-id&quot;</span>) <span class="comment">// ID for the source operator</span></span><br><span class="line">  .shuffle()</span><br><span class="line">  <span class="comment">// Stateful mapper with ID</span></span><br><span class="line">  .map(<span class="keyword">new</span> StatefulMapper())</span><br><span class="line">  .uid(<span class="string">&quot;mapper-id&quot;</span>) <span class="comment">// ID for the mapper</span></span><br><span class="line">  <span class="comment">// Stateless printing sink</span></span><br><span class="line">  .print(); <span class="comment">// Auto-generated ID</span></span><br></pre></td></tr></table></figure><p>如果不为算子手动指定 ID，Flink 会为算子自动生成 ID。当 Flink 任务从 Savepoint 中恢复时，是按照 Operator ID 将快照信息与算子进行匹配的，只要这些 ID 不变，Flink 任务就可以从 Savepoint 中恢复。自动生成的 ID 取决于代码的结构，并且对代码更改比较敏感，因此强烈建议给程序中所有有状态的算子手动分配 Operator ID。如下左图所示，一个 Flink 任务包含了 算子 A 和 算子 B，代码中都未指定 Operator ID，所以 Flink 为 Task A 自动生成了 Operator ID 为 aaa，为 Task B 自动生成了 Operator ID 为 bbb，且 Savepoint 成功完成。但是在代码改动后，任务并不能从 Savepoint 中正常恢复，因为 Flink 为算子生成的 Operator ID 取决于代码结构，代码改动后可能会把算子 B 的 Operator ID 改变成 ccc，导致任务从 Savepoint 恢复时，SavePoint 中只有 Operator ID 为 aaa 和 bbb 的状态信息，算子 B 找不到 Operator ID 为 ccc 的状态信息，所以算子 B 不能正常恢复。这里如果在写代码时通过 <code>uid(String)</code> 手动指定了 Operator ID，就不会存在 上述问题了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-020528.jpg" alt="img"></p><p>Savepoint 需要用户手动去触发，触发 Savepoint 的方式如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink savepoint :jobId [:targetDirectory]</span><br></pre></td></tr></table></figure><p>这将触发 ID 为 <code>:jobId</code> 的作业进行 Savepoint，并返回创建的 Savepoint 路径，用户需要此路径来还原和删除 Savepoint 。</p><p>使用 YARN 触发 Savepoint 的方式如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;flink savepoint :jobId [:targetDirectory] -yid :yarnAppId</span><br></pre></td></tr></table></figure><p>这将触发 ID 为 <code>:jobId</code> 和 YARN 应用程序 ID <code>:yarnAppId</code> 的作业进行 Savepoint，并返回创建的 Savepoint 路径。</p><p>使用 Savepoint 取消 Flink 任务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;flink cancel -s [:targetDirectory] :jobId</span><br></pre></td></tr></table></figure><p>这将自动触发 ID 为 <code>:jobid</code> 的作业进行 Savepoint，并在 Checkpoint 结束后取消该任务。此外，可以指定一个目标文件系统目录来存储 Savepoint 的状态信息，也可以在 flink 的 conf 目录下 flink-conf.yaml 中配置 state.savepoints.dir 参数来指定 Savepoint 的默认目录，触发 Savepoint 时，如果不指定目录则使用该默认目录。无论使用哪种方式配置，都需要保障配置的目录能被所有的 JobManager 和 TaskManager 访问。</p><h3 id="Checkpoint-流程"><a href="#Checkpoint-流程" class="headerlink" title="Checkpoint 流程"></a>Checkpoint 流程</h3><p>Flink 任务 Checkpoint 的详细流程如下所示：</p><ol><li>JobManager 端的 CheckPointCoordinator 会定期向所有 SourceTask 发送 CheckPointTrigger，Source Task 会在数据流中安插 Checkpoint barrier</li></ol><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-06-021819.png" alt="img"></p><ol start="2"><li>当 task 收到上游所有实例的 barrier 后，向自己的下游继续传递 barrier，然后自身同步进行快照，并将自己的状态异步写入到持久化存储中</li></ol><ul><li>如果是增量 Checkpoint，则只是把最新的一部分更新写入到外部持久化存储中</li><li>为了下游尽快进行 Checkpoint，所以 task 会先发送 barrier 到下游，自身再同步进行快照</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-06-021846.png" alt="img"></p><blockquote><p>注：Task B 必须接收到上游 Task A 所有实例发送的 barrier 时，Task B 才能开始进行快照，这里有一个 barrier 对齐的概念，关于 barrier 对齐的详细介绍请参阅 9.5.1 节 Flink 内部如何保证 Exactly Once 中的 barrier 对齐部分</p></blockquote><ol start="3"><li><p>当 task 将状态信息完成备份后，会将备份数据的地址（state handle）通知给 JobManager 的CheckPointCoordinator，如果 Checkpoint 的持续时长超过了 Checkpoint 设定的超时时间CheckPointCoordinator 还没有收集完所有的 State Handle，CheckPointCoordinator 就会认为本次 Checkpoint 失败，会把这次 Checkpoint 产生的所有状态数据全部删除</p></li><li><p>如果 CheckPointCoordinator 收集完所有算子的 State Handle，CheckPointCoordinator 会把整个 StateHandle 封装成 completed Checkpoint Meta，写入到外部存储中，Checkpoint 结束</p></li></ol><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-06-021900.png" alt="img"></p><h3 id="基于-RocksDB-的增量-Checkpoint-实现原理"><a href="#基于-RocksDB-的增量-Checkpoint-实现原理" class="headerlink" title="基于 RocksDB 的增量 Checkpoint 实现原理"></a>基于 RocksDB 的增量 Checkpoint 实现原理</h3><p>当使用 RocksDBStateBackend 时，增量 Checkpoint 是如何实现的呢？</p><p>RocksDB 是一个基于 LSM 实现的 KV 数据库。LSM 全称 Log Structured Merge Trees，LSM 树本质是将大量的磁盘随机写操作转换成磁盘的批量写操作来极大地提升磁盘数据写入效率。一般 LSM Tree 实现上都会有一个基于内存的 MemTable 介质，所有的增删改操作都是写入到 MemTable 中，当 MemTable 足够大以后，将 MemTable 中的数据 flush 到磁盘中生成不可变且内部有序的 ssTable（Sorted String Table）文件，全量数据保存在磁盘的多个 ssTable 文件中。HBase 也是基于 LSM Tree 实现的，HBase 磁盘上的 HFile 就相当于这里的 ssTable 文件，每次生成的 HFile 都是不可变的而且内部有序的文件。基于 ssTable 不可变的特性，才实现了增量 Checkpoint，具体流程如下所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-06-021910.png" alt="img"></p><p>第一次 Checkpoint 时生成的状态快照信息包含了两个 sstable 文件：sstable1 和 sstable2 及 Checkpoint1 的元数据文件 MANIFEST-chk1，所以第一次 Checkpoint 时需要将 sstable1、sstable2 和 MANIFEST-chk1 上传到外部持久化存储中。第二次 Checkpoint 时生成的快照信息为 sstable1、sstable2、sstable3 及元数据文件 MANIFEST-chk2，由于 sstable 文件的不可变特性，所以状态快照信息的 sstable1、sstable2 这两个文件并没有发生变化，sstable1、sstable2 这两个文件不需要重复上传到外部持久化存储中，因此第二次 Checkpoint 时，只需要将 sstable3 和 MANIFEST-chk2 文件上传到外部持久化存储中即可。这里只将新增的文件上传到外部持久化存储，也就是所谓的增量 Checkpoint。</p><p>基于 LSM Tree 实现的数据库为了提高查询效率，都需要定期对磁盘上多个 sstable 文件进行合并操作，合并时会将删除的、过期的以及旧版本的数据进行清理，从而降低 sstable 文件的总大小。图中可以看到第三次 Checkpoint 时生成的快照信息为sstable3、sstable4、sstable5 及元数据文件 MANIFEST-chk3， 其中新增了 sstable4 文件且 sstable1 和 sstable2 文件合并成 sstable5 文件，因此第三次 Checkpoint 时只需要向外部持久化存储上传 sstable4、sstable5 及元数据文件 MANIFEST-chk3。</p><p>基于 RocksDB 的增量 Checkpoint 从本质上来讲每次 Checkpoint 时只将本次 Checkpoint 新增的快照信息上传到外部的持久化存储中，依靠的是 LSM Tree 中 sstable 文件不可变的特性。对 LSM Tree 感兴趣的同学可以深入研究 RocksDB 或 HBase 相关原理及实现。</p><h3 id="状态如何从-Checkpoint-恢复"><a href="#状态如何从-Checkpoint-恢复" class="headerlink" title="状态如何从 Checkpoint 恢复"></a>状态如何从 Checkpoint 恢复</h3><p>在 Checkpoint 和 Savepoint 的比较过程中，知道了相比 Savepoint 而言，Checkpoint 的成本更低一些，但有些场景 Checkpoint 并不能完全满足我们的需求。所以在使用过程中，如果我们的需求能使用 Checkpoint 来解决优先使用 Checkpoint。当 Flink 任务中的一些依赖组件需要升级重启时，例如 hdfs、Kafka、yarn 升级或者 Flink 任务的 Sink 端对应的 MySQL、Redis 由于某些原因需要重启时，Flink 任务在这段时间也需要重启。但是由于 Flink 任务的代码并没有修改，所以 Flink 任务启动时可以从 Checkpoint 处恢复任务，此时必须配置取消 Flink 任务时保留外部存储的 Checkpoint 状态信息。从 Checkpoint 处恢复任务的命令如下所示，checkpointMetaDataPath 表示 Checkpoint 的目录。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run -s :checkpointMetaDataPath xxx.jar [:runArgs]</span><br></pre></td></tr></table></figure><p>如果 flink on yarn 模式，启动命令如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run -s :checkpointMetaDataPath -yid :yarnAppId xxx.jar [:runArgs]</span><br></pre></td></tr></table></figure><p>问题来了，Flink 自动维护 Checkpoint，所以用户在这里并拿不到任务取消之前最后一次 Checkpoint 的目录。那怎么办呢？如下图所示，在任务取消之前，Flink 任务的 WebUI 中可以看到 Checkpoint 的目录，可以在取消任务之前将此目录保存起来，恢复时就可以从该目录恢复任务。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-020530.jpg" alt="img"></p><p>上述方法最大缺陷就是用户的人力成本太高了，假如需要重启 100 个任务，难道需要用户手动维护 100 个任务的 Checkpoint 目录吗？可以做一个简单后台项目，用于管理和发布 Flink 任务，这里讲述一种通过 rest api 来获取 Checkpoint 目录的方式。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-20531.jpg" alt="img"></p><p>如上图所示是 Flink JobManager 的 overview 页面，只需要将端口号后面的路径和参数按照以下替换即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;node107.bigdata.dmp.local.com:35524&#x2F;jobs&#x2F;a1c70b36d19b3a9fc2713ba98cfc4a4f&#x2F;metrics?get&#x3D;lastCheckpointExternalPath</span><br></pre></td></tr></table></figure><p>调用以上接口，即可返回 a1c70b36d19b3a9fc2713ba98cfc4a4f 对应的 job 最后一次 Checkpoint 的目录，返回格式如下所示。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">&quot;id&quot;</span>: <span class="string">&quot;lastCheckpointExternalPath&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;value&quot;</span>: <span class="string">&quot;hdfs:/user/flink/checkpoints/a1c70b36d19b3a9fc2713ba98cfc4a4f/chk-18&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>通过这种方式可以方便地维护所有 Flink 任务的 Checkpoint 目录，当然也可以通过 Metrics 的 Reporter 将 Checkpoint 目录保存到外部存储介质中，当任务需要从 Checkpoint 处恢复时，则从外部存储中读取到相应的 Checkpoint 目录。</p><p>当设置取消 Flink 任务保留外部的 Checkpoint 状态信息时，可能会带来的负面影响是：长期运行下去，hdfs 上将会保留很多废弃的且不再会使用的 Checkpoint 目录，所以如果开启了此配置，需要制定策略，定期清理那些不再会使用到的 Checkpoint 目录。</p><h3 id="状态如何从-Savepoint-恢复"><a href="#状态如何从-Savepoint-恢复" class="headerlink" title="状态如何从 Savepoint 恢复"></a>状态如何从 Savepoint 恢复</h3><p>如下所示，从 Savepoint 恢复任务的命令与 Checkpoint 恢复命令类似，savepointPath 表示 Savepoint 保存的目录，Savepoint 的各种触发方式都会返回 Savepoint 目录。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;flink run -s :savepointPath xxx.jar [:runArgs]</span><br></pre></td></tr></table></figure><p>如果 flink on yarn 模式，启动命令如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run -s :savepointPath -yid :yarnAppId xxx.jar [:runArgs]</span><br></pre></td></tr></table></figure><p>默认情况下，恢复操作将尝试将 Savepoint 的所有状态映射到要还原的程序。如果删除了算子，则可以通过 <code>--allowNonRestoredState</code>（short：<code>-n</code>）选项跳过那些无法映射到新程序的状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;flink run -s :savepointPath -n xxx.jar [:runArgs]</span><br></pre></td></tr></table></figure><p>如果从 Savepoint 恢复时，在任务中添加一个需要状态的新算子，会发生什么？向任务添加新算子时，它将在没有任何状态的情况下进行初始化，Savepoint 中包含每个有状态算子的状态，无状态算子根本不是 Savepoint 的一部分，新算子的行为类似于无状态算子。</p><p>如果在任务中对算子进行重新排序，会发生什么？如果给这些算子分配了 ID，它们将像往常一样恢复。如果没有分配 ID ，则有状态算子自动生成的 ID 很可能在重新排序后发生更改，这将导致无法从之前的 Savepoint 中恢复。</p><p>Savepoint 目录里的状态快照信息，目前不支持移动位置，由于技术原因元数据文件中使用绝对路径来保存数据。如果因为某种原因必须要移动 Savepoint 文件，那么有两种方案来实现：</p><ul><li>使用编辑器修改 Savepoint 的元数据文件信息，将旧路径改为新路径</li><li>可以使用 <code>SavepointV2Serializer</code> 类以编程方式读取、操作和重写元数据文件的新路径</li></ul><p>长期使用 Savepoint 同样要注意清理那些废弃 Savepoint 目录的问题。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink Parallelism 和 Slot 深度理解</title>
      <link href="2019/12/28/Flink-Parallelism-%E5%92%8C-Slot-%E6%B7%B1%E5%BA%A6%E7%90%86%E8%A7%A3/"/>
      <url>2019/12/28/Flink-Parallelism-%E5%92%8C-Slot-%E6%B7%B1%E5%BA%A6%E7%90%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>parallelism 是并行的意思，在 Flink 里面代表每个算子的并行度，适当的提高并行度可以大大提高 Job 的执行效率，比如你的 Job 消费 Kafka 数据过慢，适当调大可能就消费正常了。</p><a id="more"></a><p>相信使用过 Flink 的你或多或少遇到过下面这个问题（笔者自己的项目曾经也出现过这样的问题），错误信息如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Caused by: akka.pattern.AskTimeoutException: </span><br><span class="line">Ask timed out on [Actor[akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;taskmanager_0#15608456]] after [10000 ms]. </span><br><span class="line">Sender[null] sent message of type &quot;org.apache.flink.runtime.rpc.messages.LocalRpcInvocation&quot;.</span><br></pre></td></tr></table></figure><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/FkaM6A.jpg" alt="img"></p><p>跟着这问题在 Flink 的 Issue 列表里看到了一个类似的问题：<a href="https://gitbook.cn/gitchat/column/undefined/topic/5db6bf5cf6a6211cb961664b">https://issues.apache.org/jira/browse/FLINK-9056</a><a href="https://issues.apache.org/jira/browse/FLINK-9056">https://issues.apache.org/jira/browse/FLINK-9056</a> ，看下面的评论意思大概就是 TaskManager 的 Slot 数量不足导致的 Job 提交失败，在 Flink 1.63 中已经修复了，变成抛出异常了。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/p4Tr9Z.jpg" alt="img"></p><p>竟然知道了是因为 Slot 不足的原因了，那么我们就要先了解下 Slot 是什么呢？不过再了解 Slot 之前这里先介绍下 parallelism。</p><h3 id="什么是-Parallelism？"><a href="#什么是-Parallelism？" class="headerlink" title="什么是 Parallelism？"></a>什么是 Parallelism？</h3><p>parallelism 是并行的意思，在 Flink 里面代表每个算子的并行度，适当的提高并行度可以大大提高 Job 的执行效率，比如你的 Job 消费 Kafka 数据过慢，适当调大可能就消费正常了。</p><p>那么在 Flink 中怎么设置并行度呢？</p><h3 id="如何设置-Parallelism？"><a href="#如何设置-Parallelism？" class="headerlink" title="如何设置 Parallelism？"></a>如何设置 Parallelism？</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-06-055925.png" alt="img"></p><p>如上图，在 Flink 配置文件中可以看到默认并行度是 1。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat flink-conf.yaml | grep parallelism</span><br><span class="line"></span><br><span class="line"># The parallelism used for programs that did not specify and other parallelism.</span><br><span class="line">parallelism.default: 1</span><br></pre></td></tr></table></figure><p>所以如果在你的 Flink Job 里面不设置任何 parallelism 的话，那么它也会有一个默认的 parallelism（默认为 1），那也意味着可以修改这个配置文件的默认并行度来提高 Job 的执行效率。如果是使用命令行启动你的 Flink Job，那么你也可以这样设置并行度(使用 -p n 参数)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;flink run -p 10 &#x2F;Users&#x2F;zhisheng&#x2F;word-count.jar</span><br></pre></td></tr></table></figure><p>你也可以通过 <code>env.setParallelism(n)</code> 来设置整个程序的并行度：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env &#x3D; StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setParallelism(10);</span><br></pre></td></tr></table></figure><p>注意：这样设置的并行度是整个程序的并行度，那么后面如果每个算子不单独设置并行度覆盖的话，那么后面每个算子的并行度就都是以这里设置的并行度为准了。如何给每个算子单独设置并行度呢？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data.keyBy(<span class="keyword">new</span> xxxKey())</span><br><span class="line">    .flatMap(<span class="keyword">new</span> XxxFlatMapFunction()).setParallelism(<span class="number">5</span>)</span><br><span class="line">    .map(<span class="keyword">new</span> XxxMapFunction).setParallelism(<span class="number">5</span>)</span><br><span class="line">    .addSink(<span class="keyword">new</span> XxxSink()).setParallelism(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>如上就是给每个算子单独设置并行度，这样的话，就算程序设置了 <code>env.setParallelism(10)</code> 也是会被覆盖的。这也说明优先级是：算子设置并行度 &gt; env 设置并行度 &gt; 配置文件默认并行度。</p><p>并行度讲到这里应该都懂了，下面就继续讲什么是 Slot？</p><h3 id="什么是-Slot？"><a href="#什么是-Slot？" class="headerlink" title="什么是 Slot？"></a>什么是 Slot？</h3><p>其实 Slot 的概念在 1.2 节中已经提及到，这里再细讲一点。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/r19yJh.jpg" alt="img"></p><p>图中 TaskManager 是从 JobManager 处接收需要部署的 Task，任务能配置的最大并行度由 TaskManager 上可用的 Slot 决定。每个任务代表分配给任务槽的一组资源，Slot 在 Flink 里面可以认为是资源组，Flink 将每个任务分成子任务并且将这些子任务分配到 Slot 中，这样就可以并行的执行程序。</p><p>例如，如果 TaskManager 有四个 Slot，那么它将为每个 Slot 分配 25％ 的内存。 可以在一个 Slot 中运行一个或多个线程。 同一 Slot 中的线程共享相同的 JVM。 同一 JVM 中的任务共享 TCP 连接和心跳消息。TaskManager 的一个 Slot 代表一个可用线程，该线程具有固定的内存，注意 Slot 只对内存隔离，没有对 CPU 隔离。默认情况下，Flink 允许子任务共享 Slot，即使它们是不同 Task 的 subtask，只要它们来自相同的 Job，这种共享模式可以大大的提高资源利用率。拿下面的图片来讲解会更好些。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/ECv5y2.jpg" alt="img"></p><p>上面图片中有两个 TaskManager，每个 TaskManager 有三个 Slot，这样我们的算子最大并行度那么就可以达到 6 个，在同一个 Slot 里面可以执行 1 至多个子任务。那么再看上面的图片，source/map/keyby/window/apply 算子最大可以设置 6 个并行度，sink 只设置了 1 个并行度。</p><p>每个 Flink TaskManager 在集群中提供 Slot，Slot 的数量通常与每个 TaskManager 的可用 CPU 内核数成比例（一般情况下 Slot 个数是每个 TaskManager 的 CPU 核数）。Flink 配置文件中设置的一个 TaskManager 默认的 Slot 是 1。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-06-062913.png" alt="img"></p><p><code>taskmanager.numberOfTaskSlots: 1</code> 该参数可以根据实际情况做一定的修改。</p><h3 id="Slot-和-Parallelism-的关系"><a href="#Slot-和-Parallelism-的关系" class="headerlink" title="Slot 和 Parallelism 的关系"></a>Slot 和 Parallelism 的关系</h3><p>下面用几张图片来更加深刻的理解下 Slot 和 Parallelism，并清楚它们之间的关系。</p><p>1、Slot 是指 TaskManager 最大能并发执行的能力</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/zpX2sh.jpg" alt="img"></p><p>如上图，如果设置的单个 TaskManager 的 Slot 个数为 3，启动 3 个 TaskManager 后，那么就一共有 9 个 Slot。</p><p>2、parallelism 是指 TaskManager 实际使用的并发能力</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/npq4kW.jpg" alt="img"></p><p>运行程序默认的并行度为 1，9 个 Slot 只用了 1 个，有 8 个处于空闲，设置合适的并行度才能提高 Job 计算效率。</p><p>3、parallelism 是可配置、可指定的</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/xAuHJn.jpg" alt="img"></p><p>上图中 example2 每个算子设置的并行度是 2， example3 每个算子设置的并行度是 9。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/syrCLs.jpg" alt="img"></p><p>example4 除了 sink 是设置的并行度为 1，其他算子设置的并行度都是 9。</p><h3 id="可能会遇到-Slot-和-Parallelism-的问题"><a href="#可能会遇到-Slot-和-Parallelism-的问题" class="headerlink" title="可能会遇到 Slot 和 Parallelism 的问题"></a>可能会遇到 Slot 和 Parallelism 的问题</h3><p>好了，既然 Slot 和 Parallelism 大家都了解了，现在再来看前面提到的问题（Slot 资源不够），这时问题的答案就已经很明显了，就是程序设置的并行度超过了 TaskManager 可用的 Slot 数量，所以程序一直在等待资源调度并超过了一定的时间（该时间可配置），所以才会抛出该异常错误。</p><p>还原代码查找根因，当时笔者的程序设置的并行度是 30（设置 30 是因为 Kafka 分区数有 30 个，想着一个并行度去消费一个分区的数据），没曾想到 Flink 的 Slot 不够，后面了解到该情况后就降低并行度到 10，这样就意味着一个并行度要去消费 3 个 Kafka 分区的数据，调整并行度后速度还是跟的上并且再也没有抛出该异常了。注意如果调小并行度后消费速度过慢，那可以再试试调大些试试，如果还是这样，那么只能增加 TaskManager 的个数从而间接性的增加 Slot 个数来解决该问题了。</p><p>该问题对于刚接触 Flink 的来说是比较容易遇见的，如果你对 Slot 和 Parallelism 不了解的话，那么就会感觉很苦恼，相信你看完这篇文章后就能够豁然开朗了。另外可能还会有各种各样的并行度设置的问题，比如：</p><ul><li>程序某个算子执行了比较复杂的操作，延迟很久，导致该算子处理数据特别慢，那么可以考虑给该算子处增加并行度</li><li>Flink Source 处的并行度超过 Kafka 分区数，因为 Flink 的一个并行度可以处理一至多个分区的数据，如果并行度多于 Kafka 的分区数，那么就会造成有的并行度空闲，浪费资源，建议最多 Flink Source 端的并行度不要超过 Kafka 分区数</li></ul><p>总之，要做到既让 Job 能够及时消费数据，又能够节省资源，需要理解并合理设置并行度和 Slot。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>使用 Flink ParameterTool 读取配置</title>
      <link href="2019/12/28/%E4%BD%BF%E7%94%A8-Flink-ParameterTool-%E8%AF%BB%E5%8F%96%E9%85%8D%E7%BD%AE/"/>
      <url>2019/12/28/%E4%BD%BF%E7%94%A8-Flink-ParameterTool-%E8%AF%BB%E5%8F%96%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Flink 配置的管理很不方便，比如像算子的并行度配置、Kafka 数据源的配置（broker 地址、topic 名、group.id）、Checkpoint 是否开启、状态后端存储路径、数据库地址、用户名和密码等，Flink 作为流计算引擎，处理源源不断的数据是其本意，但是在处理数据的过程中，往往可能需要一些参数的传递</p><a id="more"></a><h3 id="Flink-Job-配置"><a href="#Flink-Job-配置" class="headerlink" title="Flink Job 配置"></a>Flink Job 配置</h3><p>在 Flink 中其实是有几种方法来管理配置。</p><h4 id="使用-Configuration"><a href="#使用-Configuration" class="headerlink" title="使用 Configuration"></a>使用 Configuration</h4><p>Flink 提供了 withParameters 方法，它可以传递 Configuration 中的参数给，要使用它，需要实现那些 Rich 函数，比如实现 RichMapFunction，而不是 MapFunction，因为 Rich 函数中有 open 方法，然后可以重写 open 方法通过 Configuration 获取到传入的参数值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// Configuration 类来存储参数</span></span><br><span class="line">Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">configuration.setString(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;zhisheng&quot;</span>);</span><br><span class="line"></span><br><span class="line">env.fromElements(WORDS)</span><br><span class="line">        .flatMap(<span class="keyword">new</span> RichFlatMapFunction&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line"></span><br><span class="line">            String name;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="comment">//读取配置</span></span><br><span class="line">                name = parameters.getString(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                String[] splits = value.toLowerCase().split(<span class="string">&quot;\\W+&quot;</span>);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> (String split : splits) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (split.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                        out.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(split + name, <span class="number">1</span>));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).withParameters(configuration)    <span class="comment">//将参数传递给函数</span></span><br><span class="line">        .print();</span><br></pre></td></tr></table></figure><p>但是要注意这个 withParameters 只在批程序中支持，流程序中是没有该方法的，并且这个 withParameters 要在每个算子后面使用才行，并不是一次使用就所有都可以获取到，如果所有算子都要该配置，那么就重复设置多次就会比较繁琐。</p><h3 id="ParameterTool-管理配置"><a href="#ParameterTool-管理配置" class="headerlink" title="ParameterTool 管理配置"></a>ParameterTool 管理配置</h3><p>上面通过 Configuration 的局限性很大，其实在 Flink 中还可以通过使用 ParameterTool 类读取配置，它可以读取环境变量、运行参数、配置文件，下面分别讲下每种如何使用。</p><h4 id="读取运行参数"><a href="#读取运行参数" class="headerlink" title="读取运行参数"></a>读取运行参数</h4><p>我们知道 Flink UI 上是支持为每个 Job 单独传入 arguments（参数）的，它的格式要求是如下这种。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--brokers 127.0.0.1:9200</span><br><span class="line">--username admin</span><br><span class="line">--password 123456</span><br></pre></td></tr></table></figure><p>或者这种</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-brokers 127.0.0.1:9200</span><br><span class="line">-username admin</span><br><span class="line">-password 123456</span><br></pre></td></tr></table></figure><p>然后在 Flink 程序中你可以直接使用 <code>ParameterTool.fromArgs(args)</code> 获取到所有的参数，然后如果你要获取某个参数对应的值的话，可以通过 <code>parameterTool.get(&quot;username&quot;)</code> 方法。那么在这个地方其实你就可以将配置放在一个第三方的接口，然后这个参数值中传入一个接口，拿到该接口后就能够通过请求去获取更多你想要的配置。</p><h4 id="读取系统属性"><a href="#读取系统属性" class="headerlink" title="读取系统属性"></a>读取系统属性</h4><p>ParameterTool 还支持通过 <code>ParameterTool.fromSystemProperties()</code> 方法读取系统属性。</p><h4 id="读取配置文件"><a href="#读取配置文件" class="headerlink" title="读取配置文件"></a>读取配置文件</h4><p>除了上面两种外，ParameterTool 还支持 <code>ParameterTool.fromPropertiesFile(&quot;/application.properties&quot;)</code> 读取 properties 配置文件。你可以将所有要配置的地方（比如并行度和一些 Kafka、MySQL 等配置）都写成可配置的，然后其对应的 key 和 value 值都写在配置文件中，最后通过 ParameterTool 去读取配置文件获取对应的值。</p><h4 id="ParameterTool-获取值"><a href="#ParameterTool-获取值" class="headerlink" title="ParameterTool 获取值"></a>ParameterTool 获取值</h4><p>ParameterTool 类提供了很多便捷方法去获取值。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-09-134119.png" alt="img"></p><p>你可以在应用程序的 main() 方法中直接使用这些方法返回的值，例如：你可以按如下方法来设置一个算子的并行度：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ParameterTool parameters = ParameterTool.fromArgs(args);</span><br><span class="line"><span class="keyword">int</span> parallelism = parameters.get(<span class="string">&quot;mapParallelism&quot;</span>, <span class="number">2</span>);</span><br><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; counts = data.flatMap(<span class="keyword">new</span> Tokenizer()).setParallelism(parallelism);</span><br></pre></td></tr></table></figure><p>因为 ParameterTool 是可序列化的，所以你可以将它当作参数进行传递给自定义的函数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ParameterTool parameters = ParameterTool.fromArgs(args);</span><br><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; counts = dara.flatMap(<span class="keyword">new</span> Tokenizer(parameters));</span><br></pre></td></tr></table></figure><p>然后在函数内部使用 ParameterTool 来获取命令行参数，这样就意味着你在作业任何地方都可以获取到参数，而不是像 withParameters 一样需要每次都设置。</p><h4 id="注册全局参数"><a href="#注册全局参数" class="headerlink" title="注册全局参数"></a>注册全局参数</h4><p>在 ExecutionConfig 中可以将 ParameterTool 注册为全作业参数的参数，这样就可以被 JobManager 的 web 端以及用户自定义函数中以配置值的形式访问。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.getConfig().setGlobalJobParameters(ParameterTool.fromArgs(args));</span><br></pre></td></tr></table></figure><p>然后就可以在用户自定义的 Rich 函数中像如下这样获取到参数值了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">env.addSource(<span class="keyword">new</span> RichSourceFunction&lt;String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;String&gt; sourceContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ParameterTool parameterTool = (ParameterTool) getRuntimeContext().getExecutionConfig().getGlobalJobParameters();</span><br><span class="line">            sourceContext.collect(System.currentTimeMillis() + parameterTool.get(<span class="string">&quot;os.name&quot;</span>) + parameterTool.get(<span class="string">&quot;user.home&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>在笔者公司内通常是以 Job 运行的环境变量为准，比如我们是运行在 K8s 上面，那么我们会为我们的这个 Flink Job 设置很多环境变量，设置的环境变量的值就得通过 ParameterTool 类去获取，我们是会优先根据环境变量的值为准，如果环境变量的值没有就会去读取应用运行参数，如果应用运行参数也没有才会去读取之前已经写好在配置文件中的配置。大概代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ParameterTool <span class="title">createParameterTool</span><span class="params">(<span class="keyword">final</span> String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ParameterTool</span><br><span class="line">            .fromPropertiesFile(ExecutionEnv.class.getResourceAsStream(<span class="string">&quot;/application.properties&quot;</span>))</span><br><span class="line">            .mergeWith(ParameterTool.fromArgs(args))</span><br><span class="line">            .mergeWith(ParameterTool.fromSystemProperties())</span><br><span class="line">            .mergeWith(ParameterTool.fromMap(getenv()));<span class="comment">// mergeWith 会使用最新的配置</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取 Job 设置的环境变量</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Map&lt;String, String&gt; <span class="title">getenv</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, String&gt; entry : System.getenv().entrySet()) &#123;</span><br><span class="line">        map.put(entry.getKey().toLowerCase().replace(<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;.&#x27;</span>), entry.getValue());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> map;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样如果 Job 要更改一些配置，直接在 Job 在 K8s 上面的环境变量进行配置就好了，修改配置后然后重启 Job 就可以运行起来了，整个过程都不需要再次将作业重新编译打包的。但是这样其实也有一定的坏处，重启一个作业的代价很大，因为在重启后你又要去保证状态要恢复到之前未重启时的状态，尽管 Flink 中的 Checkpoint 和 Savepoint 已经很强大了，但是对于复杂的它来说我们多一事不如少一事，所以其实更希望能够直接动态的获取配置，如果配置做了更改，作业能够感知到。在 Flink 中有的配置是不能够动态设置的，但是比如应用业务配置却是可以做到动态的配置，这时就需要使用比较强大的广播变量，广播变量在之前 3.4 节已经介绍过了，如果忘记可以再回去查看，另外在 11.4 节中会通过一个实际案例来教你如何使用广播变量去动态的更新配置数据。</p><h3 id="ParameterTool-源码剖析"><a href="#ParameterTool-源码剖析" class="headerlink" title="ParameterTool 源码剖析"></a>ParameterTool 源码剖析</h3><p>ParameterTool 这个类还是比较简单的，它继承自 ExecutionConfig.GlobalJobParameters 类，然后提供了上面讲的哪几种方法去获取配置数据：</p><ul><li>fromArgs(String[] args)</li><li>fromPropertiesFile(String path)</li><li>fromPropertiesFile(File file)</li><li>fromPropertiesFile(InputStream inputStream)</li><li>fromSystemProperties()</li></ul><p>还可以传入的一个 <code>Map</code> 配置进去，这样最后也是返回一个 ParameterTool 对象。另外就是提供了好些个 get() 方法去获取不同类型的参数值，也支持通过 mergeWith 方法来将两个不同的 ParameterTool 类进行合并，优先以新传入的参数为准，因为内部是使用的 Map 来存储的，mergeWith 操作会将新的 ParameterTool 数据全部 putAll 进一个 Map 集合中，所以会覆盖前一个相同 key 的值。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink CEP API 学习</title>
      <link href="2019/12/26/Flink-CEP-API-%E5%AD%A6%E4%B9%A0/"/>
      <url>2019/12/26/Flink-CEP-API-%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3 id="准备依赖"><a href="#准备依赖" class="headerlink" title="准备依赖"></a>准备依赖</h3><p>要开发 Flink CEP 应用程序，首先你得在项目的 <code>pom.xml</code> 中添加依赖。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-cep_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这个依赖有两种，一个是 Java 版本的，一个是 Scala 版本，根据项目的开发语言自行选择。</p><a id="more"></a><h3 id="Flink-CEP-应用入门"><a href="#Flink-CEP-应用入门" class="headerlink" title="Flink CEP 应用入门"></a>Flink CEP 应用入门</h3><p>准备好依赖后，我们开始第一个 Flink CEP 应用程序，这里我们只做一个简单的数据流匹配，当匹配成功后将匹配的两条数据打印出来。首先定义实体类 Event 如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Event</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Integer id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后构造读取 Socket 数据流将数据进行转换成 Event，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;Event&gt; eventDataStream = env.socketTextStream(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">9200</span>)</span><br><span class="line">    .flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, Event&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String s, Collector&lt;Event&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (StringUtil.isNotEmpty(s)) &#123;</span><br><span class="line">                String[] split = s.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                <span class="keyword">if</span> (split.length == <span class="number">2</span>) &#123;</span><br><span class="line">                    collector.collect(<span class="keyword">new</span> Event(Integer.valueOf(split[<span class="number">0</span>]), split[<span class="number">1</span>]));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><p>接着就是定义 CEP 中的匹配规则了，下面的规则表示第一个事件的 id 为 42，紧接着的第二个事件 id 要大于 10，满足这样的连续两个事件才会将这两条数据进行打印出来。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; pattern = Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(</span><br><span class="line">        <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                log.info(<span class="string">&quot;start &#123;&#125;&quot;</span>, event.getId());</span><br><span class="line">                <span class="keyword">return</span> event.getId() == <span class="number">42</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">).next(<span class="string">&quot;middle&quot;</span>).where(</span><br><span class="line">        <span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                log.info(<span class="string">&quot;middle &#123;&#125;&quot;</span>, event.getId());</span><br><span class="line">                <span class="keyword">return</span> event.getId() &gt;= <span class="number">10</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">CEP.pattern(eventDataStream, pattern).select(<span class="keyword">new</span> PatternSelectFunction&lt;Event, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">select</span><span class="params">(Map&lt;String, List&lt;Event&gt;&gt; p)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        StringBuilder builder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        log.info(<span class="string">&quot;p = &#123;&#125;&quot;</span>, p);</span><br><span class="line">        builder.append(p.get(<span class="string">&quot;start&quot;</span>).get(<span class="number">0</span>).getId()).append(<span class="string">&quot;,&quot;</span>).append(p.get(<span class="string">&quot;start&quot;</span>).get(<span class="number">0</span>).getName()).append(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">                .append(p.get(<span class="string">&quot;middle&quot;</span>).get(<span class="number">0</span>).getId()).append(<span class="string">&quot;,&quot;</span>).append(p.get(<span class="string">&quot;middle&quot;</span>).get(<span class="number">0</span>).getName());</span><br><span class="line">        <span class="keyword">return</span> builder.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;).print();<span class="comment">//打印结果</span></span><br></pre></td></tr></table></figure><p>然后笔者在终端开启 Socket，输入的两条数据如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">42,zhisheng</span><br><span class="line">20,zhisheng</span><br></pre></td></tr></table></figure><p>作业打印出来的日志如下图：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-29-072247.png" alt="img"></p><p>整个作业 print 出来的结果如下图：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-29-072320.png" alt="img"></p><p>好了，一个完整的 Flink CEP 应用程序如上，相信你也能大概理解上面的代码，接着来详细的讲解一下 Flink CEP 中的 Pattern API。</p><h3 id="Pattern-API"><a href="#Pattern-API" class="headerlink" title="Pattern API"></a>Pattern API</h3><p>你可以通过 Pattern API 去定义从流数据中匹配事件的 Pattern，每个复杂 Pattern 都是由多个简单的 Pattern 组成的，拿前面入门的应用来讲，它就是由 <code>start</code> 和 <code>middle</code> 两个简单的 Pattern 组成的，在其每个 Pattern 中都只是简单的处理了流数据。在处理的过程中需要标示该 Pattern 的名称，以便后续可以使用该名称来获取匹配到的数据，如 <code>p.get(&quot;start&quot;).get(0)</code> 它就可以获取到 Pattern 中匹配的第一个事件。接下来我们先来看下简单的 Pattern 。</p><h4 id="单个-Pattern"><a href="#单个-Pattern" class="headerlink" title="单个 Pattern"></a>单个 Pattern</h4><h5 id="数量"><a href="#数量" class="headerlink" title="数量"></a>数量</h5><p>单个 Pattern 后追加的 Pattern 如果都是相同的，那如果要都重新再写一遍，换做任何人都会比较痛苦，所以就提供了 times(n) 来表示期望出现的次数，该 times() 方法还有很多写法，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">//期望符合的事件出现 4 次</span></span><br><span class="line"> start.times(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//期望符合的事件不出现或者出现 4 次</span></span><br><span class="line"> start.times(<span class="number">4</span>).optional();</span><br><span class="line"></span><br><span class="line">  <span class="comment">//期望符合的事件出现 2 次或者 3 次或者 4 次</span></span><br><span class="line"> start.times(<span class="number">2</span>, <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//期望出现 2 次、3 次或 4 次，并尽可能多地重复</span></span><br><span class="line"> start.times(<span class="number">2</span>, <span class="number">4</span>).greedy();</span><br><span class="line"></span><br><span class="line"><span class="comment">//期望出现 2 次、3 次、4 次或者不出现</span></span><br><span class="line"> start.times(<span class="number">2</span>, <span class="number">4</span>).optional();</span><br><span class="line"></span><br><span class="line"> <span class="comment">//期望出现 0、2、3 或 4 次并尽可能多地重复</span></span><br><span class="line"> start.times(<span class="number">2</span>, <span class="number">4</span>).optional().greedy();</span><br><span class="line"></span><br><span class="line"> <span class="comment">//期望出现一个或多个事件</span></span><br><span class="line"> start.oneOrMore();</span><br><span class="line"></span><br><span class="line"> <span class="comment">//期望出现一个或多个事件，并尽可能多地重复这些事件</span></span><br><span class="line"> start.oneOrMore().greedy();</span><br><span class="line"></span><br><span class="line"> <span class="comment">//期望出现一个或多个事件或者不出现</span></span><br><span class="line"> start.oneOrMore().optional();</span><br><span class="line"></span><br><span class="line"> <span class="comment">//期望出现更多次，并尽可能多地重复或者不出现</span></span><br><span class="line"> start.oneOrMore().optional().greedy();</span><br><span class="line"></span><br><span class="line"> <span class="comment">//期望出现两个或多个事件</span></span><br><span class="line"> start.timesOrMore(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//期望出现 2 次或 2 次以上，并尽可能多地重复</span></span><br><span class="line"> start.timesOrMore(<span class="number">2</span>).greedy();</span><br><span class="line"></span><br><span class="line"> <span class="comment">//期望出现 2 次或更多的事件，并尽可能多地重复或者不出现</span></span><br><span class="line"> start.timesOrMore(<span class="number">2</span>).optional().greedy();</span><br></pre></td></tr></table></figure><h5 id="条件"><a href="#条件" class="headerlink" title="条件"></a>条件</h5><p>可以通过 <code>pattern.where()</code>、<code>pattern.or()</code> 或 <code>pattern.until()</code> 方法指定事件属性的条件。条件可以是 <code>IterativeConditions</code> 或<code>SimpleConditions</code>。比如 SimpleCondition 可以像下面这样使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">start.where(<span class="keyword">new</span> SimpleCondition&lt;Event&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(Event value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;zhisheng&quot;</span>.equals(value.getName());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h4 id="组合-Pattern"><a href="#组合-Pattern" class="headerlink" title="组合 Pattern"></a>组合 Pattern</h4><p>前面已经对单个 Pattern 做了详细对讲解，接下来讲解如何将多个 Pattern 进行组合来完成一些需求。在完成组合 Pattern 之前需要定义第一个 Pattern，然后在第一个的基础上继续添加新的 Pattern。比如定义了第一个 Pattern 如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>);</span><br></pre></td></tr></table></figure><p>接下来，可以为此指定更多的 Pattern，通过指定的不同的连接条件。比如：</p><ul><li>next()：要求比较严格，该事件一定要紧跟着前一个事件。</li><li>followedBy()：该事件在前一个事件后面就行，两个事件之间可能会有其他的事件。</li><li>followedByAny()：该事件在前一个事件后面的就满足条件，两个事件之间可能会有其他的事件，返回值比上一个多。</li><li>notNext()：不希望前一个事件后面紧跟着该事件出现。</li><li>notFollowedBy()：不希望后面出现该事件。</li></ul><p>具体怎么写呢，可以看下样例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; strict = start.next(<span class="string">&quot;middle&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line">Pattern&lt;Event, ?&gt; relaxed = start.followedBy(<span class="string">&quot;middle&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line">Pattern&lt;Event, ?&gt; nonDetermin = start.followedByAny(<span class="string">&quot;middle&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line">Pattern&lt;Event, ?&gt; strictNot = start.notNext(<span class="string">&quot;not&quot;</span>).where(...);</span><br><span class="line"></span><br><span class="line">Pattern&lt;Event, ?&gt; relaxedNot = start.notFollowedBy(<span class="string">&quot;not&quot;</span>).where(...);</span><br></pre></td></tr></table></figure><p>可能概念讲了很多，但是还是不太清楚，这里举个例子说明一下，假设有个 Pattern 是 <code>a b</code>，给定的数据输入顺序是 <code>a c b b</code>，对于上面那种不同的连接条件可能最后返回的值不一样。</p><ol><li>a 和 b 之间使用 next() 连接，那么则返回 {}，即没有匹配到数据</li><li>a 和 b 之间使用 followedBy() 连接，那么则返回 {a, b}</li><li>a 和 b 之间使用 followedByAny() 连接，那么则返回 {a, b}, {a, b}</li></ol><p>相信通过上面的这个例子讲解你就知道了它们的区别，尤其是 followedBy() 和 followedByAny()，笔者一开始也是毕竟懵，后面也是通过代码测试才搞明白它们之间的区别的。除此之外，还可以为 Pattern 定义时间约束。例如，可以通过 <code>pattern.within(Time.seconds(10))</code> 方法定义此 Pattern 应该 10 秒内完成匹配。 该时间不仅支持处理时间还支持事件时间。另外还可以与 consecutive()、allowCombinations() 等组合，更多的请看下图中 Pattern 类的方法。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-29-164118.png" alt="img"></p><h4 id="Group-Pattern"><a href="#Group-Pattern" class="headerlink" title="Group Pattern"></a>Group Pattern</h4><p>业务需求比较复杂的场景，如果要使用 Pattern 来定义的话，可能这个 Pattern 会很长并且还会嵌套，比如由 begin、followedBy、followedByAny、next 组成和嵌套，另外还可以再和 oneOrMore()、times(#ofTimes)、times(#fromTimes, #toTimes)、optional()、consecutive()、allowCombinations() 等结合使用。效果如下面这种：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Pattern&lt;Event, ?&gt; start = Pattern.begin(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;start&quot;</span>).where(...).followedBy(<span class="string">&quot;start_middle&quot;</span>).where(...)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">//next 表示连续</span></span><br><span class="line">Pattern&lt;Event, ?&gt; strict = start.next(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;next_start&quot;</span>).where(...).followedBy(<span class="string">&quot;next_middle&quot;</span>).where(...)</span><br><span class="line">).times(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//followedBy 代表在后面就行</span></span><br><span class="line">Pattern&lt;Event, ?&gt; relaxed = start.followedBy(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;followedby_start&quot;</span>).where(...).followedBy(<span class="string">&quot;followedby_middle&quot;</span>).where(...)</span><br><span class="line">).oneOrMore();</span><br><span class="line"></span><br><span class="line"><span class="comment">//followedByAny</span></span><br><span class="line">Pattern&lt;Event, ?&gt; nonDetermin = start.followedByAny(</span><br><span class="line">    Pattern.&lt;Event&gt;begin(<span class="string">&quot;followedbyany_start&quot;</span>).where(...).followedBy(<span class="string">&quot;followedbyany_middle&quot;</span>).where(...)</span><br><span class="line">).optional();</span><br></pre></td></tr></table></figure><p>关于上面这些 Pattern 操作的更详细的解释可以查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/dev/libs/cep.html#groups-of-patterns">官网</a>。</p><h4 id="事件匹配跳过策略"><a href="#事件匹配跳过策略" class="headerlink" title="事件匹配跳过策略"></a>事件匹配跳过策略</h4><p>对于给定组合的复杂 Pattern，有的事件可能会匹配到多个 Pattern，如果要控制将事件的匹配数，需要指定跳过策略。在 Flink CEP 中跳过策略有四种类型，如下所示：</p><ul><li>NO_SKIP：不跳过，将发出所有可能的匹配事件。</li><li>SKIP_TO_FIRST：丢弃包含 PatternName 第一个之前匹配事件的每个部分匹配。</li><li>SKIP_TO_LAST：丢弃包含 PatternName 最后一个匹配事件之前的每个部分匹配。</li><li>SKIP_PAST_LAST_EVENT：丢弃包含匹配事件的每个部分匹配。</li><li>SKIP_TO_NEXT：丢弃以同一事件开始的所有部分匹配。</li></ul><p>这几种策略都是根据 AfterMatchSkipStrategy 来实现的，可以看下它们的类结构图，如下所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-29-133737.png" alt="img"></p><p>关于这几种跳过策略的具体区别可以查看<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/dev/libs/cep.html#after-match-skip-strategy">官网</a>，至于如何使用跳过策略，其实 AfterMatchSkipStrategy 抽象类中已经提供了 5 种静态方法可以直接使用，方法如下：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-29-135526.png" alt="img"></p><p>使用方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">AfterMatchSkipStrategy skipStrategy = ...; <span class="comment">// 使用 AfterMatchSkipStrategy 调用不同的静态方法</span></span><br><span class="line">Pattern.begin(<span class="string">&quot;start&quot;</span>, skipStrategy);</span><br></pre></td></tr></table></figure><h3 id="检测-Pattern"><a href="#检测-Pattern" class="headerlink" title="检测 Pattern"></a>检测 Pattern</h3><p>编写好了 Pattern 之后，你需要的是将其应用在流数据中去做匹配。这时要做的就是构造一个 PatternStream，它可以通过 <code>CEP.pattern(eventDataStream, pattern)</code> 来获取一个 PatternStream 对象，在 <code>CEP.pattern()</code> 方法中，你可以选择传入两个参数（DataStream 和 Pattern），也可以选择传入三个参数 （DataStream、Pattern 和 EventComparator），因为 CEP 类中它有两个不同参数数量的 pattern 方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CEP</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">PatternStream&lt;T&gt; <span class="title">pattern</span><span class="params">(DataStream&lt;T&gt; input, Pattern&lt;T, ?&gt; pattern)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> PatternStream(input, pattern);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">PatternStream&lt;T&gt; <span class="title">pattern</span><span class="params">(DataStream&lt;T&gt; input, Pattern&lt;T, ?&gt; pattern, EventComparator&lt;T&gt; comparator)</span> </span>&#123;</span><br><span class="line">        PatternStream&lt;T&gt; stream = <span class="keyword">new</span> PatternStream(input, pattern);</span><br><span class="line">        <span class="keyword">return</span> stream.withComparator(comparator);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="选择-Pattern"><a href="#选择-Pattern" class="headerlink" title="选择 Pattern"></a>选择 Pattern</h4><p>在获取到 PatternStream 后，你可以通过 select 或 flatSelect 方法从匹配到的事件流中查询。如果使用的是 select 方法，则需要实现传入一个 PatternSelectFunction 的实现作为参数，PatternSelectFunction 具有为每个匹配事件调用的 select 方法，该方法的参数是 <code>Map&gt;</code>，这个 Map 的 key 是 Pattern 的名字，在前面入门案例中设置的 <code>start</code> 和 <code>middle</code> 在这时就起作用了，你可以通过类似 <code>get(&quot;start&quot;)</code> 方法的形式来获取匹配到 <code>start</code>的所有事件。如果使用的是 flatSelect 方法，则需要实现传入一个 PatternFlatSelectFunction 的实现作为参数，这个和 PatternSelectFunction 不一致地方在于它可以返回多个结果，因为这个接口中的 flatSelect 方法含有一个 Collector，它可以返回多个数据到下游去。两者的样例如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">CEP.pattern(eventDataStream, pattern).select(<span class="keyword">new</span> PatternSelectFunction&lt;Event, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">select</span><span class="params">(Map&lt;String, List&lt;Event&gt;&gt; p)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        StringBuilder builder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        builder.append(p.get(<span class="string">&quot;start&quot;</span>).get(<span class="number">0</span>).getId()).append(<span class="string">&quot;,&quot;</span>).append(p.get(<span class="string">&quot;start&quot;</span>).get(<span class="number">0</span>).getName()).append(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">                .append(p.get(<span class="string">&quot;middle&quot;</span>).get(<span class="number">0</span>).getId()).append(<span class="string">&quot;,&quot;</span>).append(p.get(<span class="string">&quot;middle&quot;</span>).get(<span class="number">0</span>).getName());</span><br><span class="line">        <span class="keyword">return</span> builder.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;).print();</span><br><span class="line"></span><br><span class="line">CEP.pattern(eventDataStream, pattern).flatSelect(<span class="keyword">new</span> PatternFlatSelectFunction&lt;Event, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatSelect</span><span class="params">(Map&lt;String, List&lt;Event&gt;&gt; map, Collector&lt;String&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;String, List&lt;Event&gt;&gt; entry : map.entrySet()) &#123;</span><br><span class="line">            collector.collect(entry.getKey() + <span class="string">&quot; &quot;</span> + entry.getValue().get(<span class="number">0</span>).getId() + <span class="string">&quot;,&quot;</span> + entry.getValue().get(<span class="number">0</span>).getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;).print();</span><br></pre></td></tr></table></figure><p>关于 PatternStream 中的 select 或 flatSelect 方法其实可以传入不同的参数，比如传入 OutputTag 和 PatternTimeoutFunction 去处理延迟的数据，具体查看下图。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-29-125416.png" alt="img"></p><p>如果使用的 Flink CEP 版本是大于等于 1.8 的话，还可以使用 process 方法，在上图中也可以看到在 PatternStream 类中包含了该方法。要使用 process 的话，得传入一个 PatternProcessFunction 的实现作为参数，在该实现中需要重写 processMatch 方法。使用 PatternProcessFunction 比使用 PatternSelectFunction 和 PatternFlatSelectFunction 更好的是，它支持获取应用的的上下文，那么也就意味着它可以访问时间（因为 Context 接口继承自 TimeContext 接口）。另外如果要处理延迟的数据可以与 TimedOutPartialMatchHandler 接口的实现类一起使用。</p><h3 id="CEP-时间属性"><a href="#CEP-时间属性" class="headerlink" title="CEP 时间属性"></a>CEP 时间属性</h3><h4 id="根据事件时间处理延迟数据"><a href="#根据事件时间处理延迟数据" class="headerlink" title="根据事件时间处理延迟数据"></a>根据事件时间处理延迟数据</h4><p>在 CEP 中，元素处理的顺序很重要，当时间策略设置为事件时间时，为了确保能够按照事件时间的顺序来处理元素，先来的事件会暂存在缓冲区域中，然后对缓冲区域中的这些事件按照事件时间进行排序，当水印到达时，比水印时间小的事件会按照顺序依次处理的。这意味着水印之间的元素是按照事件时间顺序处理的。</p><p>注意：当作业设置的时间属性是事件时间是，CEP 中会认为收到的水印时间是正确的，会严格按照水印的时间来处理元素，从而保证能顺序的处理元素。另外对于这种延迟的数据（和 3.5 节中的延迟数据类似），CEP 中也是支持通过 side output 设置 OutputTag 标签来将其收集。使用方式如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">PatternStream&lt;Event&gt; patternStream = CEP.pattern(inputDataStream, pattern);</span><br><span class="line"></span><br><span class="line">OutputTag&lt;String&gt; lateDataOutputTag = <span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">&quot;late-data&quot;</span>)&#123;&#125;;</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;ComplexEvent&gt; result = patternStream</span><br><span class="line">    .sideOutputLateData(lateDataOutputTag)</span><br><span class="line">    .select(</span><br><span class="line">        <span class="keyword">new</span> PatternSelectFunction&lt;Event, ComplexEvent&gt;() &#123;...&#125;</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">DataStream&lt;String&gt; lateData = result.getSideOutput(lateDataOutputTag);</span><br></pre></td></tr></table></figure><h4 id="时间上下文"><a href="#时间上下文" class="headerlink" title="时间上下文"></a>时间上下文</h4><p>在 PatternProcessFunction 和 IterativeCondition 中可以通过 TimeContext 访问当前正在处理的事件的时间（Event Time）和此时机器上的时间（Processing Time）。你可以查看到这两个类中都包含了 Context，而这个 Context 继承自 TimeContext，在 TimeContext 接口中定义了获取事件时间和处理时间的方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">TimeContext</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">timestamp</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">currentProcessingTime</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink CEP深入理解</title>
      <link href="2019/12/26/Flink-CEP%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/"/>
      <url>2019/12/26/Flink-CEP%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>CEP 的英文全称是 Complex Event Processing，翻译成中文为复杂事件处理。它可以用于处理实时数据并在事件流到达时从事件流中提取信息，并根据定义的规则来判断事件是否匹配，如果匹配则会触发新的事件做出响应。除了支持单个事件的简单无状态的模式匹配（例如基于事件中的某个字段进行筛选过滤），也可以支持基于关联／聚合／时间窗口等多个事件的复杂有状态模式的匹配（例如判断用户下单事件后 30 分钟内是否有支付事件）。</p><a id="more"></a><h3 id="CEP-是什么？"><a href="#CEP-是什么？" class="headerlink" title="CEP 是什么？"></a>CEP 是什么？</h3><p>CEP 的英文全称是 Complex Event Processing，翻译成中文为复杂事件处理。</p><p><font color='blue'>CEP 可以用于处理实时数据并在事件流到达时从事件流中提取信息，根据定义的规则来判断事件是否匹配，如果匹配则会触发新的事件做出响应。除了支持单个事件的简单无状态的模式匹配（例如基于事件中的某个字段进行筛选过滤），也可以支持基于关联／聚合／时间窗口等多个事件的复杂有状态模式的匹配（例如判断用户下单事件后 30 分钟内是否有支付事件）。</font></p><p>因为这种事件匹配通常是根据提前制定好的规则去匹配的，而这些规则一般来说不仅多，而且复杂，所以就会引入一些规则引擎来处理这种复杂事件匹配。市面上常用的规则引擎有如下这些。</p><h3 id="规则引擎对比"><a href="#规则引擎对比" class="headerlink" title="规则引擎对比"></a>规则引擎对比</h3><h4 id="Drools"><a href="#Drools" class="headerlink" title="Drools"></a>Drools</h4><p>Drools 是一款使用 Java 编写的开源规则引擎，通常用来解决业务代码与业务规则的分离，它内置的 Drools Fusion 模块也提供 CEP 的功能。</p><p>优势：</p><ul><li>功能较为完善，具有如系统监控、操作平台等功能。</li><li>规则支持动态更新。</li></ul><p>劣势：</p><ul><li>以内存实现时间窗功能，无法支持较长跨度的时间窗。</li><li>无法有效支持定时触达（如用户在浏览发生一段时间后触达条件判断）。</li></ul><h4 id="Aviator"><a href="#Aviator" class="headerlink" title="Aviator"></a>Aviator</h4><p>Aviator 是一个高性能、轻量级的 Java 语言实现的表达式求值引擎，主要用于各种表达式的动态求值。</p><p>优势：</p><ul><li>支持大部分运算操作符。</li><li>支持函数调用和自定义函数。</li><li>支持正则表达式匹配。</li><li>支持传入变量并且性能优秀。</li></ul><p>劣势：</p><ul><li>没有 if else、do while 等语句，没有赋值语句，没有位运算符。</li></ul><h4 id="EasyRules"><a href="#EasyRules" class="headerlink" title="EasyRules"></a>EasyRules</h4><p>EasyRules 集成了 MVEL 和 SpEL 表达式的一款轻量级规则引擎。</p><p>优势：</p><ul><li>轻量级框架，学习成本低。</li><li>基于 POJO。</li><li>为定义业务引擎提供有用的抽象和简便的应用</li><li>支持从简单的规则组建成复杂规则</li></ul><h4 id="Esper"><a href="#Esper" class="headerlink" title="Esper"></a>Esper</h4><p>Esper 设计目标为 CEP 的轻量级解决方案，可以方便的嵌入服务中，提供 CEP 功能。</p><p>优势：</p><ul><li>轻量级可嵌入开发，常用的 CEP 功能简单好用。</li><li>EPL 语法与 SQL 类似，学习成本较低。</li></ul><p>劣势：</p><ul><li>单机全内存方案，需要整合其他分布式和存储。</li><li>以内存实现时间窗功能，无法支持较长跨度的时间窗。</li><li>无法有效支持定时触达（如用户在浏览发生一段时间后触达条件判断）。</li></ul><h4 id="Flink-CEP"><a href="#Flink-CEP" class="headerlink" title="Flink CEP"></a>Flink CEP</h4><p>Flink 是一个流式系统，具有高吞吐低延迟的特点，Flink CEP 是一套极具通用性、易于使用的实时流式事件处理方案。</p><p>优势：</p><ul><li>继承了 Flink 高吞吐的特点</li><li>事件支持存储到外部，可以支持较长跨度的时间窗。</li><li>可以支持定时触达（用 followedBy ＋ PartternTimeoutFunction 实现）</li></ul><p>劣势：</p><ul><li>无法动态更新规则（痛点）</li></ul><h3 id="Flink-CEP-介绍"><a href="#Flink-CEP-介绍" class="headerlink" title="Flink CEP 介绍"></a>Flink CEP 介绍</h3><p>Flink CEP是在 Flink 之上实现的复杂事件处理(CEP)库，它允许我们在事件流中检测事件的模式。</p><p>因为搭配了 Flink 实时处理的能力，所以 Flink CEP 能够在流处理的场景去做一些实时的复杂事件匹配，它与传统的数据库查询是不一致的，比如，传统的数据库的数据是静态的，但是查询却是动态的，所以传统的数据库查询做不到实时的反馈查询结果，而 Flink CEP 则是查询规则是静态的，数据是动态实时的，如果它作用于一个无限的数据流上，这就意味着它可以将某种规则的数据匹配一直保持下去（除非作业停止）；另外 Flink CEP 不需要去存储那些与匹配不相关联的数据，遇到这种数据它会立即丢弃。</p><p>虽然 Flink CEP 拥有 Flink 的本身优点和支持复杂场景的规则处理，但是它本身其实也有非常严重的缺点，那就是不能够动态的更新规则。通常引入规则引擎比较友好的一点是可以将一些业务规则抽象出来成为配置，然后更改这些配置后其实是能够自动生效的，但是在 Flink 中却无法做到这点，甚至规则通常还是要写死在代码里面。</p><p><font color='grey'>举个例子，你在一个 Flink CEP 的作业中定义了一条规则：机器的 CPU 使用率连续 30 秒超过 90% 则发出告警，然后将这个作业上线，上线后发现告警很频繁，你可能会觉得可能规则之前定义的不合适，那么接下来你要做的就是将作业取消，然后重新修改代码并进行编译打包成一个 fat jar，接着上传该 jar 并运行。整个流程下来，你有没有想过会消耗多长的时间？五分钟？或者更长？但是你的目的就是要修改一个配置，如果你在作业中将上面的 30 秒和 90% 做成了配置，可能这样所需要的时间会减少，你只需要重启作业，然后通过传入新的参数将作业重新启动，但是重启作业这步是不是不能少，然而对于流作业来说，重启作业带来的代价很大。</font></p><h3 id="Flink-CEP-如何动态更新规则"><a href="#Flink-CEP-如何动态更新规则" class="headerlink" title="Flink CEP 如何动态更新规则"></a>Flink CEP 如何动态更新规则</h3><p>国内的 Flink 技术分享会却看到有几家公司对这块做了优化，让 Flink CEP 支持动态的更新规则，下面分享一下他们几家公司的思路。</p><ul><li>A 公司：用户更新规则后，新规则会被翻译成 Java 代码，并编译打包成可执行 jar，停止作业并使用 Savepoint 将状态保存下来，启动新的作业并读取之前保存的状态，会根据规则文件中的数量和复杂度对作业的数量做一个规划，防止单作业负载过高，架构如下图所示。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-28-142601.png" alt="img"></p><ul><li>B 公司：规则中心存储规则，规则里面直接存储了 Java 代码，加载这些规则后然后再用 Groovy 做动态编译解析，其架构如下图所示。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-28-143822.png" alt="img"></p><ul><li>C 公司：增加函数，在函数方法中监听规则的变化，如果需要更新则通过 Groovy 加载 Pattern 类进行动态注入，采用 Zookeeper 和 MySQL 管理规则，如果规则发生变化，则从数据库中获取到新的规则，然后更新 Flink CEP 中的 NFA 逻辑，注意状态要根据业务需要选择是否重置，其架构设计如下图所示。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-28-150827.png" alt="img"></p><p>第一种方法，笔者不推荐，因为它这样的做法还是要将作业重启，无非就是做了一个自动化的操作，不是人为的手动重启，从 B 公司和 C 公司两种方法可以发现要实现 Flink CEP 动态的更新规则无非要做的就是：</p><ul><li>监听规则的变化</li><li>将规则变成 Java 代码</li><li>通过 Groovy 动态编译解析</li><li>更改 NFA 的内部逻辑</li><li>状态是否保留</li></ul><h3 id="Flink-CEP-使用场景分析"><a href="#Flink-CEP-使用场景分析" class="headerlink" title="Flink CEP 使用场景分析"></a>Flink CEP 使用场景分析</h3><p>上面虽然提到了一个 Flink CEP 的痛点，但是并不能就此把它的优势给抹去，它可以运用的场景其实还有很多，这里笔者拿某些场景来做个分析。</p><h4 id="实时反作弊和风控"><a href="#实时反作弊和风控" class="headerlink" title="实时反作弊和风控"></a>实时反作弊和风控</h4><p>对于电商来说，羊毛党是必不可少的，国内拼多多曾爆出 100 元的无门槛券随便领，当晚被人褥几百亿，对于这种情况肯定是没有做好及时的风控。另外还有就是商家上架商品时通过频繁修改商品的名称和滥用标题来提高搜索关键字的排名、批量注册一批机器账号快速刷单来提高商品的销售量等作弊行为，各种各样的作弊手法也是需要不断的去制定规则去匹配这种行为。</p><h4 id="实时营销"><a href="#实时营销" class="headerlink" title="实时营销"></a>实时营销</h4><p>分析用户在手机 APP 的实时行为，统计用户的活动周期，通过为用户画像来给用户进行推荐。比如用户在登录 APP 后 1 分钟内只浏览了商品没有下单；用户在浏览一个商品后，3 分钟内又去查看其他同类的商品，进行比价行为；用户商品下单后 1 分钟内是否支付了该订单。如果这些数据都可以很好的利用起来，那么就可以给用户推荐浏览过的类似商品，这样可以大大提高购买率。</p><h4 id="实时网络攻击检测"><a href="#实时网络攻击检测" class="headerlink" title="实时网络攻击检测"></a>实时网络攻击检测</h4><p>当下互联网安全形势仍然严峻，网络攻击屡见不鲜且花样众多，这里我们以 DDOS（分布式拒绝服务攻击）产生的流入流量来作为遭受攻击的判断依据。对网络遭受的潜在攻击进行实时检测并给出预警，云服务厂商的多个数据中心会定时向监控中心上报其瞬时流量，如果流量在预设的正常范围内则认为是正常现象，不做任何操作；如果某数据中心在 10 秒内连续 5 次上报的流量超过正常范围的阈值，则触发一条警告的事件；如果某数据中心 30 秒内连续出现 30 次上报的流量超过正常范围的阈值，则触发严重的告警。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 状态后端存储</title>
      <link href="2019/12/19/Flink-%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF%E5%AD%98%E5%82%A8/"/>
      <url>2019/12/19/Flink-%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF%E5%AD%98%E5%82%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Flink 提供了以下三种开箱即用的<strong>状态后端</strong>(用于存储状态数据)，可以为所有 Flink 作业配置相同的状态后端，也可以为每个 Flink 作业配置指定的状态后端。当需要对具体的某一种 State 做 Checkpoint 时，此时就需要具体的状态后端存储，刚好 Flink 内置提供了不同的状态后端存储，用于指定状态的存储方式和位置。状态可以存储在 Java 堆内存中或者堆外</p><a id="more"></a><h3 id="State-Backends"><a href="#State-Backends" class="headerlink" title="State Backends"></a>State Backends</h3><p>当需要对具体的某一种 State 做 Checkpoint 时，此时就需要具体的状态后端存储，Flink 内置提供了不同的状态后端存储，用于指定状态的存储方式和位置。状态可以存储在 Java 堆内存中或者堆外，在 Flink 安装路径下 conf 目录中的 flink-conf.yaml 配置文件中也有状态后端存储相关的配置，Flink 还特有一个 CheckpointingOptions 类来控制 state 存储的相关配置，该类中有如下配置：</p><ol><li>state.backend: 用于存储和进行状态 checkpoint 的状态后端存储方式，无默认值</li><li>state.checkpoints.num-retained: 要保留的已完成 checkpoint 的最大数量，默认值为 1</li><li>state.backend.async: 状态后端是否使用异步快照方法，默认值为 true</li><li>state.backend.incremental: 状态后端是否创建增量检查点，默认值为 false</li><li>state.backend.local-recovery: 状态后端配置本地恢复，默认情况下，本地恢复被禁用</li><li>taskmanager.state.local.root-dirs: 定义存储本地恢复的基于文件的状态的目录</li><li>state.savepoints.dir: 存储 savepoints 的目录</li><li>state.checkpoints.dir: 存储 checkpoint 的数据文件和元数据</li><li>state.backend.fs.memory-threshold: 状态数据文件的最小大小，默认值是 1024</li></ol><p>虽然配置这么多，但是，Flink 还支持基于每个 Job 单独设置状态后端存储，方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">env.setStateBackend(<span class="keyword">new</span> MemoryStateBackend());  <span class="comment">//设置堆内存存储</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//env.setStateBackend(new FsStateBackend(checkpointDir, asyncCheckpoints));   //设置文件存储</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//env.setStateBackend(new RocksDBStateBackend(checkpointDir, incrementalCheckpoints));  //设置 RocksDB 存储</span></span><br></pre></td></tr></table></figure><p>Flink提供了以下三种开箱即用的状态后端(用于存储状态数据)，可以为所有 Flink 作业配置相同的状态后端(flink-conf.yaml )，也可以为每个 Flink 作业配置指定的状态后端。</p><ol><li>MemoryStateBackend</li><li>FsStateBackend</li><li>RocksDBStateBackend</li></ol><p><img src="../images/flink/2.png"></p><h3 id="MemoryStateBackend-使用及剖析"><a href="#MemoryStateBackend-使用及剖析" class="headerlink" title="MemoryStateBackend 使用及剖析"></a>MemoryStateBackend 使用及剖析</h3><p><font color='blue'>如果 Job 没有配置指定状态后端存储的话，就会默认采取 MemoryStateBackend 策略。</font></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019-04-28 00:16:41.892 [Sink: zhisheng (1/4)] INFO  org.apache.flink.streaming.runtime.tasks.StreamTask  - No state backend has been configured, using default (Memory / Job Manager) MemoryStateBackend (data in heap memory / checkpoints to Job Manager) (checkpoints: &#x27;null&#x27;, savepoints: &#x27;null&#x27;, asynchronous: TRUE, maxStateSize: 5242880)</span><br></pre></td></tr></table></figure><p><font color='blue'>如果没有配置任何状态存储，使用默认的 MemoryStateBackend 策略，这种状态后端存储把数据以内部对象的形式保存在 Task Managers 的内存（JVM 堆）中，当应用程序触发 checkpoint 时，会将此时的状态进行快照然后存储在 Job Manager 的内存中。因为状态是存储在内存中的，所以这种情况会有点限制</font></font></p><ol><li>不适合在生产环境中使用，仅用于本地测试的情况较多，主要适用于状态很小的 Job，因为它会将状态最终存储在 Job Manager 中，如果状态较大的话，那么会使得 Job Manager 的内存比较紧张，从而导致 Job Manager 会出现 OOM 等问题，然后造成连锁反应使所有的 Job 都挂掉，所以 Job 的状态与之前的 Checkpoint 的数据所占的内存要小于 JobManager 的内存。</li><li>每个单独的状态大小不能超过最大的 DEFAULT<em>MAX</em>STATE_SIZE(5MB)，可以通过构造 MemoryStateBackend 参数传入不同大小的 maxStateSize。</li><li>Job 的操作符状态和 keyed 状态加起来都不要超过 RPC 系统的默认配置 10 MB，虽然可以修改该配置，但是不建议去修改。</li></ol><p>另外就是 MemoryStateBackend 支持配置是否是异步快照还是同步快照，它有一个字段 asynchronousSnapshots 来表示，可选值有：</p><ul><li>TRUE（true 代表使用异步的快照，这样可以避免因快照而导致数据流处理出现阻塞等问题）</li><li>FALSE（同步）</li><li>UNDEFINED（默认值）</li></ul><h3 id="FsStateBackend-使用及剖析"><a href="#FsStateBackend-使用及剖析" class="headerlink" title="FsStateBackend 使用及剖析"></a>FsStateBackend 使用及剖析</h3><p><font color='blue'>这种状态后端存储也是将工作状态存储在 Task Manager 中的内存（JVM 堆）中，但是 checkpoint 的时候，它和 MemoryStateBackend 不一样，它是将状态存储在文件（可以是本地文件，也可以是 HDFS）中，这个文件具体是哪种需要配置</font></p><p>比如：”hdfs://namenode:40010/flink/checkpoints” 或 “file://flink/checkpoints” (通常使用 HDFS 比较多，如果是使用本地文件，可能会造成 Job 恢复的时候找不到之前的 checkkpoint，因为 Job 重启后如果由调度器重新分配在不同的机器的 Task Manager 执行时就会导致这个问题，所以还是建议使用 HDFS 或者其他的分布式文件系统)。</p><p>同样 FsStateBackend 也是支持通过 asynchronousSnapshots 字段来控制是使用异步还是同步来进行 checkpoint 的，异步可以避免在状态 checkpoint 时阻塞数据流的处理，然后还有一点的就是在 FsStateBackend 有个参数 fileStateThreshold，如果状态大小比 MAX<em>FILE</em>STATE_THRESHOLD（1MB） 小的话，那么会将状态数据直接存储在 meta data 文件中，而不是存储在配置的文件中（避免出现很小的状态文件），如果该值为 “-1” 表示尚未配置，在这种情况下会使用默认值（1024，该默认值可以通过 <code>state.backend.fs.memory-threshold</code>来配置）。</p><p>那么我们该什么时候使用 FsStateBackend 呢？</p><ul><li>如果你要处理大状态，长窗口等有状态的任务，那么 FsStateBackend 就比较适合</li><li>使用分布式文件系统，如 HDFS 等，这样 failover 时 Job 的状态可以恢复</li></ul><p>使用 FsStateBackend 需要注意的地方有什么呢？</p><ul><li>工作状态仍然是存储在 Task Manager 中的内存中，虽然在 Checkpoint 的时候会存在文件中，所以还是得注意这个状态要保证不超过 Task Manager 的内存</li></ul><h3 id="如何使用-RocksDBStateBackend-及剖析"><a href="#如何使用-RocksDBStateBackend-及剖析" class="headerlink" title="如何使用 RocksDBStateBackend 及剖析"></a>如何使用 RocksDBStateBackend 及剖析</h3><p><font color='blue'>RocksDBStateBackend 和上面两种都有点不一样，RocksDB 是一种嵌入式的本地数据库，它会在本地文件系统中维护状态，KeyedStateBackend 等会直接写入本地 RocksDB 中，它还需要配置一个文件系统（一般是 HDFS），比如 <code>hdfs://namenode:40010/flink/checkpoints</code>，当触发 checkpoint 的时候，会把整个 RocksDB 数据库复制到配置的文件系统中去，当 failover 时从文件系统中将数据恢复到本地。</font></p><p>官方推荐使用 RocksDB 来作为状态的后端存储</p><ol><li>state 直接存放在 RocksDB 中，不需要存在内存中，这样就可以减少 Task Manager 的内存压力，如果是存内存的话大状态的情况下会导致 GC 次数比较多，同时还能在 checkpoint 时将状态持久化到远端的文件系统，那么就比较适合在生产环境中使用</li><li>RocksDB 本身支持 checkpoint 功能</li><li>RocksDBStateBackend 支持增量的 checkpoint，在 RocksDBStateBackend 中有一个字段 enableIncrementalCheckpointing 来确认是否开启增量的 checkpoint，默认是不开启的，在 CheckpointingOptions 类中有个 state.backend.incremental 参数来表示，增量 checkpoint 非常使用于超大状态的场景。</li></ol><p><strong>RocksDBStateBackend 这个类的相关属性以及构造函数。</strong></p><p><strong>属性</strong>：</p><ul><li>checkpointStreamBackend：用于创建 checkpoint 流的状态后端</li><li>localRocksDbDirectories：RocksDB 目录的基本路径，默认是 Task Manager 的临时目录</li><li>enableIncrementalCheckpointing：是否增量 checkpoint</li><li>numberOfTransferingThreads：用于传输(下载和上传)状态的线程数量，默认为 1</li><li>enableTtlCompactionFilter：是否启用压缩过滤器来清除带有 TTL 的状态</li></ul><p><strong>构造函数</strong>：</p><ul><li>RocksDBStateBackend(String checkpointDataUri)：单参数，只传入一个路径</li><li>RocksDBStateBackend(String checkpointDataUri, boolean enableIncrementalCheckpointing)：两个参数，传入 checkpoint 数据目录路径和是否开启增量 checkpoint</li><li>RocksDBStateBackend(StateBackend checkpointStreamBackend)：传入一种 StateBackend</li><li>RocksDBStateBackend(StateBackend checkpointStreamBackend, TernaryBoolean enableIncrementalCheckpointing)：传入一种 StateBackend 和是否开启增量 checkpoint</li><li>RocksDBStateBackend(RocksDBStateBackend original, Configuration config, ClassLoader classLoader)：私有的构造方法，用于重新配置状态后端</li></ul><p>既然知道这么多构造函数了，那么使用就很简单了，根据你的场景考虑使用哪种构造函数创建 RocksDBStateBackend 对象就行了，然后通过 <code>env.setStateBackend()</code> 传入对象实例就行，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//env.setStateBackend(new RocksDBStateBackend(checkpointDir, incrementalCheckpoints));  //设置 RocksDB 存储</span></span><br></pre></td></tr></table></figure><p>那么在使用 RocksDBStateBackend 时该注意什么呢：</p><ul><li>当使用 RocksDB 时，状态大小将受限于磁盘可用空间的大小</li><li>状态存储在 RocksDB 中，整个更新和获取状态的操作都是要通过序列化和反序列化才能完成的，跟状态直接存储在内存中，性能可能会略低些</li><li>如果你应用程序的状态很大，那么使用 RocksDB 无非是最佳的选择</li></ul><p>另外在 Flink 源码中有一个专门的 RocksDBOptions 来表示 RocksDB 相关的配置：</p><ul><li>state.backend.rocksdb.localdir：本地目录(在 Task Manager 上)，RocksDB 将其文件放在其中</li><li>state.backend.rocksdb.timer-service.factory：定时器服务实现，默认值是 HEAP</li><li>state.backend.rocksdb.checkpoint.transfer.thread.num：用于在后端传输(下载和上载)文件的线程数，默认是 1</li><li>state.backend.rocksdb.ttl.compaction.filter.enabled：是否启用压缩过滤器来清除带有 TTL 的状态，默认值是 false</li></ul><h3 id="如何选择状态后端存储？"><a href="#如何选择状态后端存储？" class="headerlink" title="如何选择状态后端存储？"></a>如何选择状态后端存储？</h3><p>通过上面三种 State Backends 的介绍，让大家了解了状态存储有哪些种类，然后对每种状态存储是该如何使用的、它们内部的实现、使用场景、需要注意什么都细讲了一遍，三种存储方式各有特点，可以满足不同场景的需求，通常来说，在开发程序之前，我们要先分析自己 Job 的场景和状态大小的预测，然后根据预测来进行选择何种状态存储，如果拿捏不定的话，建议先在测试环境进行测试，只有选择了正确的状态存储后端，这样才能够保证后面自己的 Job 在生产环境能够稳定的运行。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 常用的 Source 和 Sink Connectors</title>
      <link href="2019/12/18/Flink-%E5%B8%B8%E7%94%A8%E7%9A%84-Source-%E5%92%8C-Sink-Connectors/"/>
      <url>2019/12/18/Flink-%E5%B8%B8%E7%94%A8%E7%9A%84-Source-%E5%92%8C-Sink-Connectors/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Flink Job 的大致结构就是 <code>Source ——&gt; Transformation ——&gt; Sink</code>。</p><a id="more"></a><h3 id="Data-Source-介绍"><a href="#Data-Source-介绍" class="headerlink" title="Data Source 介绍"></a>Data Source 介绍</h3><p>Data Source 是什么呢？就字面意思其实就可以知道：数据来源。</p><p>Flink 做为一款流式计算框架，它可用来做批处理，即处理静态的数据集、历史的数据集；也可以用来做流处理，即处理实时的数据流（做计算操作），然后将处理后的数据实时下发，只要数据源源不断过来，Flink 就能够一直计算下去。</p><p>Flink 中你可以使用 <code>StreamExecutionEnvironment.addSource(sourceFunction)</code> 来为你的程序添加数据来源。</p><p>Flink 已经提供了若干实现好了的 source function，当然你也可以通过实现 SourceFunction 来自定义非并行的 source 或者实现 ParallelSourceFunction 接口或者扩展 RichParallelSourceFunction 来自定义并行的 source。</p><p>那么常用的 Data Source 有哪些呢？</p><h3 id="常用的-Data-Source"><a href="#常用的-Data-Source" class="headerlink" title="常用的 Data Source"></a>常用的 Data Source</h3><p>StreamExecutionEnvironment 中可以使用以下这些已实现的 stream source。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-083744.png" alt="img"></p><p>总的来说可以分为下面几大类：</p><h4 id="基于集合"><a href="#基于集合" class="headerlink" title="基于集合"></a>基于集合</h4><ol><li>fromCollection(Collection) - 从 Java 的 Java.util.Collection 创建数据流。集合中的所有元素类型必须相同。</li><li>fromCollection(Iterator, Class) - 从一个迭代器中创建数据流。Class 指定了该迭代器返回元素的类型。</li><li>fromElements(T …) - 从给定的对象序列中创建数据流。所有对象类型必须相同。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">DataStream&lt;Event&gt; input = env.fromElements(</span><br><span class="line">    <span class="keyword">new</span> Event(<span class="number">1</span>, <span class="string">&quot;barfoo&quot;</span>, <span class="number">1.0</span>),</span><br><span class="line">    <span class="keyword">new</span> Event(<span class="number">2</span>, <span class="string">&quot;start&quot;</span>, <span class="number">2.0</span>),</span><br><span class="line">    <span class="keyword">new</span> Event(<span class="number">3</span>, <span class="string">&quot;foobar&quot;</span>, <span class="number">3.0</span>),</span><br><span class="line">    ...</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ol><li>fromParallelCollection(SplittableIterator, Class) - 从一个迭代器中创建并行数据流。Class 指定了该迭代器返回元素的类型。</li><li>generateSequence(from, to) - 创建一个生成指定区间范围内的数字序列的并行数据流。</li></ol><h4 id="基于文件"><a href="#基于文件" class="headerlink" title="基于文件"></a>基于文件</h4><p>1、readTextFile(path) - 读取文本文件，即符合 TextInputFormat 规范的文件，并将其作为字符串返回。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">DataStream&lt;String&gt; text = env.readTextFile(<span class="string">&quot;file:///path/to/file&quot;</span>);</span><br></pre></td></tr></table></figure><p>2、readFile(fileInputFormat, path) - 根据指定的文件输入格式读取文件（一次）。</p><p>3、readFile(fileInputFormat, path, watchType, interval, pathFilter, typeInfo) - 这是上面两个方法内部调用的方法。它根据给定的 fileInputFormat 和读取路径读取文件。根据提供的 watchType，这个 source 可以定期（每隔 interval 毫秒）监测给定路径的新数据（FileProcessingMode.PROCESS<em>CONTINUOUSLY），或者处理一次路径对应文件的数据并退出（FileProcessingMode.PROCESS</em>ONCE）。你可以通过 pathFilter 进一步排除掉需要处理的文件。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">DataStream&lt;MyEvent&gt; stream = env.readFile(</span><br><span class="line">        myFormat, myFilePath, FileProcessingMode.PROCESS_CONTINUOUSLY, <span class="number">100</span>,</span><br><span class="line">        FilePathFilter.createDefaultFilter(), typeInfo);</span><br></pre></td></tr></table></figure><p><strong>实现:</strong></p><p>在具体实现上，Flink 把文件读取过程分为两个子任务，即目录监控和数据读取。每个子任务都由单独的实体实现。目录监控由单个非并行（并行度为1）的任务执行，而数据读取由并行运行的多个任务执行。后者的并行性等于作业的并行性。单个目录监控任务的作用是扫描目录（根据 watchType 定期扫描或仅扫描一次），查找要处理的文件并把文件分割成切分片（splits），然后将这些切分片分配给下游 reader。reader 负责读取数据。每个切分片只能由一个 reader 读取，但一个 reader 可以逐个读取多个切分片。</p><p><strong>重要注意：</strong></p><p>如果 watchType 设置为 FileProcessingMode.PROCESS_CONTINUOUSLY，则当文件被修改时，其内容将被重新处理。这会打破“exactly-once”语义，因为在文件末尾附加数据将导致其所有内容被重新处理。</p><p>如果 watchType 设置为 FileProcessingMode.PROCESS_ONCE，则 source 仅扫描路径一次然后退出，而不等待 reader 完成文件内容的读取。当然 reader 会继续阅读，直到读取所有的文件内容。关闭 source 后就不会再有检查点。这可能导致节点故障后的恢复速度较慢，因为该作业将从最后一个检查点恢复读取。</p><h4 id="基于-Socket"><a href="#基于-Socket" class="headerlink" title="基于 Socket"></a>基于 Socket</h4><p>socketTextStream(String hostname, int port) - 从 socket 读取。元素可以用分隔符切分。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; dataStream = env</span><br><span class="line">        .socketTextStream(<span class="string">&quot;localhost&quot;</span>, <span class="number">9999</span>) <span class="comment">// 监听 localhost 的 9999 端口过来的数据</span></span><br><span class="line">        .flatMap(<span class="keyword">new</span> Splitter())</span><br><span class="line">        .keyBy(<span class="number">0</span>)</span><br><span class="line">        .timeWindow(Time.seconds(<span class="number">5</span>))</span><br><span class="line">        .sum(<span class="number">1</span>);</span><br></pre></td></tr></table></figure><h4 id="自定义"><a href="#自定义" class="headerlink" title="自定义"></a>自定义</h4><p>addSource - 添加一个新的 source function。例如，你可以用 addSource(new FlinkKafkaConsumer011&lt;&gt;(…)) 从 Apache Kafka 读取数据。</p><p><strong>说说上面几种的特点</strong></p><ol><li>基于集合：有界数据集，更偏向于本地测试用</li><li>基于文件：适合监听文件修改并读取其内容</li><li>基于 Socket：监听主机的 host port，从 Socket 中获取数据</li><li>自定义 addSource：大多数的场景数据都是无界的，会源源不断过来。比如去消费 Kafka 某个 topic 上的数据，这时候就需要用到这个 addSource，可能因为用的比较多的原因吧，Flink 直接提供了 FlinkKafkaConsumer011 等类可供你直接使用。你可以去看看 FlinkKafkaConsumerBase 这个基础类，它是 Flink Kafka 消费的最根本的类。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">DataStream&lt;KafkaEvent&gt; input = env</span><br><span class="line">        .addSource(</span><br><span class="line">            <span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">                parameterTool.getRequired(<span class="string">&quot;input-topic&quot;</span>), <span class="comment">//从参数中获取传进来的 topic </span></span><br><span class="line">                <span class="keyword">new</span> KafkaEventSchema(),</span><br><span class="line">                parameterTool.getProperties())</span><br><span class="line">            .assignTimestampsAndWatermarks(<span class="keyword">new</span> CustomWatermarkExtractor()));</span><br></pre></td></tr></table></figure><p>Flink 目前支持如下面常见的 Source：</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/UTfWCZ.jpg" alt="img"></p><p>如果你想自定义自己的 Source 呢？在后面 3.8 节会讲解。</p><h3 id="Data-Sink-介绍"><a href="#Data-Sink-介绍" class="headerlink" title="Data Sink 介绍"></a>Data Sink 介绍</h3><p>Data sink 有点把数据存储下来（落库）的意思。Flink 在拿到数据后做一系列的计算后，最后要将计算的结果往下游发送。比如将数据存储到 MySQL、ElasticSearch、Cassandra，或者继续发往 Kafka、 RabbitMQ 等消息队列，更或者直接调用其他的第三方应用服务（比如告警）。</p><h3 id="常用的-Data-Sink"><a href="#常用的-Data-Sink" class="headerlink" title="常用的 Data Sink"></a>常用的 Data Sink</h3><p>上面介绍了 Flink Data Source 有哪些，这里也看看 Flink Data Sink 支持的有哪些。</p><p><img src="https://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/images/siWsAK.jpg" alt="img"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-084839.png" alt="img"></p><p>可以看到有 Kafka、ElasticSearch、Socket、RabbitMQ、JDBC、Cassandra POJO、File、Print 等 Sink 的方式。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 多种时间语义对比</title>
      <link href="2019/12/18/Flink-%E5%A4%9A%E7%A7%8D%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89%E5%AF%B9%E6%AF%94/"/>
      <url>2019/12/18/Flink-%E5%A4%9A%E7%A7%8D%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89%E5%AF%B9%E6%AF%94/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Flink 在流应用程序中支持不同的 <strong>Time</strong> 概念，有 Processing Time、Event Time 和 Ingestion Time。下面我们一起来看看这三个 Time。</p><a id="more"></a><h3 id="Processing-Time"><a href="#Processing-Time" class="headerlink" title="Processing Time"></a>Processing Time</h3><p><strong>Processing Time 是指事件被处理时机器的系统时间。</strong></p><p><font color='grey'>如果 Flink Job 设置的时间策略是 Processing Time 的话，那么后面所有基于时间的操作（如时间窗口）都将会使用当时机器的系统时间。每小时 Processing Time 窗口将包括在系统时钟指示整个小时之间到达特定操作的所有事件。</font></p><p><font color='grey'>例如，如果应用程序在上午 9:15 开始运行，则第一个每小时 Processing Time 窗口将包括在上午 9:15 到上午 10:00 之间处理的事件，下一个窗口将包括在上午 10:00 到 11:00 之间处理的事件。</font></p><p>Processing Time 是最简单的 “Time” 概念，不需要流和机器之间的协调，它提供了最好的性能和最低的延迟。但是，在分布式和异步的环境下，Processing Time 不能提供确定性，因为它容易受到事件到达系统的速度（例如从消息队列）、事件在系统内操作流动的速度以及中断的影响。</p><h3 id="Event-Time"><a href="#Event-Time" class="headerlink" title="Event Time"></a>Event Time</h3><p><strong>Event Time 是指事件发生的时间，一般就是数据本身携带的时间。这个时间通常是在事件到达 Flink 之前就确定的，并且可以从每个事件中获取到事件时间戳。</strong></p><p><strong>在 Event Time 中，时间取决于数据，而跟其他没什么关系。Event Time 程序必须指定如何生成 Event Time 水印，这是表示 Event Time 进度的机制。</strong></p><p><font color='grey'>完美的说，无论事件什么时候到达或者其怎么排序，最后处理 Event Time 将产生完全一致和确定的结果。但是，除非事件按照已知顺序（事件产生的时间顺序）到达，否则处理 Event Time 时将会因为要等待一些无序事件而产生一些延迟。由于只能等待一段有限的时间，因此就难以保证处理 Event Time 将产生完全一致和确定的结果。</font></p><p><font color='grey'>假设所有数据都已到达，Event Time 操作将按照预期运行，即使在处理无序事件、延迟事件、重新处理历史数据时也会产生正确且一致的结果。 例如，每小时事件时间窗口将包含带有落入该小时的事件时间戳的所有记录，不管它们到达的顺序如何（是否按照事件产生的时间）。</font></p><h3 id="Ingestion-Time"><a href="#Ingestion-Time" class="headerlink" title="Ingestion Time"></a>Ingestion Time</h3><p><strong>Ingestion Time 是事件进入 Flink 的时间。 在数据源操作处（进入 Flink source 时），每个事件将进入 Flink 时当时的时间作为时间戳，并且基于时间的操作（如时间窗口）会利用这个时间戳。</strong></p><p>Ingestion Time 在概念上位于 Event Time 和 Processing Time 之间。 与 Processing Time 相比，成本可能会高一点，但结果更可预测。因为 Ingestion Time 使用稳定的时间戳（只在进入 Flink 的时候分配一次），所以对事件的不同窗口操作将使用相同的时间戳（第一次分配的时间戳），而在 Processing Time 中，每个窗口操作符可以将事件分配给不同的窗口（基于机器系统时间和到达延迟）。</p><p>与 Event Time 相比，Ingestion Time 程序无法处理任何无序事件或延迟数据，但程序中不必指定如何生成水印。</p><p>在 Flink 中，Ingestion Time 与 Event Time 非常相似，唯一区别就是 Ingestion Time 具有自动分配时间戳和自动生成水印功能。</p><h3 id="三种-Time-对比结果"><a href="#三种-Time-对比结果" class="headerlink" title="三种 Time 对比结果"></a>三种 Time 对比结果</h3><p>一张图概括上面说的三种 Time：</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-01-18 上午10.55.42.png" alt="截屏2021-01-18 上午10.55.42" style="zoom:50%;" /><h3 id="使用场景分析"><a href="#使用场景分析" class="headerlink" title="使用场景分析"></a>使用场景分析</h3><p>通过上面两个图相信大家已经对 Flink 中的这三个 Time 有所了解了，那么我们实际生产环境中通常该如何选择哪种 Time 呢？</p><p>一般来说在生产环境中将 Event Time 与 Processing Time 对比的比较多，这两个也是我们常用的策略，Ingestion Time 一般用的较少。</p><p>用 Processing Time 的场景大多是用户不关心事件时间，它只需要关心这个时间窗口要有数据进来，只要有数据进来，就可以对进来窗口中的数据进行一系列的计算操作，然后再将计算后的数据发往下游。</p><p>而用 Event Time 的场景一般是业务需求需要时间这个字段（比如购物时是要先有下单事件、再有支付事件；借贷事件的风控是需要依赖时间来做判断的；机器异常检测触发的告警也是要具体的异常事件的时间展示出来；商品广告及时精准推荐给用户依赖的就是用户在浏览商品的时间段/频率/时长等信息），只能根据事件时间来处理数据，而且还要从事件中获取到事件的时间。</p><p>但是使用事件时间的话，就可能有这样的情况：数据源采集的数据往消息队列中发送时可能因为网络抖动、服务可用性、消息队列的分区数据堆积的影响而导致数据到达的不一定及时，可能会出现数据出现一定的乱序、延迟几分钟等，庆幸的是 Flink 支持通过 WaterMark 机制来处理这种延迟的数据。关于 WaterMark 的机制我会在后面的文章讲解。</p><h3 id="设置-Time-策略"><a href="#设置-Time-策略" class="headerlink" title="设置 Time 策略"></a>设置 Time 策略</h3><p>在创建完流运行环境的时候，然后就可以通过 <code>env.setStreamTimeCharacteristic</code> 设置时间策略：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 其他两种:</span></span><br><span class="line"><span class="comment">// env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime);</span></span><br><span class="line"><span class="comment">// env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime);</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink Window 机制深入理解</title>
      <link href="2019/12/17/Flink-Window-%E6%9C%BA%E5%88%B6%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/"/>
      <url>2019/12/17/Flink-Window-%E6%9C%BA%E5%88%B6%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>目前有许多数据分析的场景从批处理到流处理的演变， 虽然可以将批处理作为流处理的特殊情况来处理，但是分析无穷集的流数据通常需要思维方式的转变并且具有其自己的术语，例如，“windowing（窗口化）”、“at-least-once（至少一次）”、“exactly-once（只有一次）” 。</p><a id="more"></a><h2 id="Flink-Window-基础概念与实现原理"><a href="#Flink-Window-基础概念与实现原理" class="headerlink" title="Flink Window 基础概念与实现原理"></a>Flink Window 基础概念与实现原理</h2><p>Apache Flink 是一个为生产环境而生的流处理器，具有易于使用的 API，可以用于定义高级流分析程序。Flink 的 API 在数据流上具有非常灵活的窗口定义，使其在其他开源流处理框架中脱颖而出。</p><h3 id="Window-有什么作用？"><a href="#Window-有什么作用？" class="headerlink" title="Window 有什么作用？"></a>Window 有什么作用？</h3><p>通常来讲，Window 就是用来对一个无限的流设置一个有限的集合，在有界的数据集上进行操作的一种机制。Window 又可以分为基于时间（Time-based）的 Window 以及基于数量（Count-based）的 window。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-01-19 上午8.47.04.png" alt="截屏2021-01-19 上午8.47.04" style="zoom:30%;" /><h3 id="Flink-自带的-Window"><a href="#Flink-自带的-Window" class="headerlink" title="Flink 自带的 Window"></a>Flink 自带的 Window</h3><p>Flink 认为 Batch 是 Streaming 的一个特例，所以 Flink 底层引擎是一个流式引擎，在上面实现了流处理和批处理。而窗口 [window] 就是从 Streaming 到 Batch 的一个桥梁。</p><p>在流处理应用中，数据是连续不断的，因此我们不可能等到所有数据都到了才开始处理。当然我们可以每来一个消息就处理一次，但是有时我们需要做一些聚合类的处理，例如：在过去的1分钟内有多少用户点击了我们的网页。在这种情况下，我们必须定义一个窗口，用来收集最近一分钟内的数据，并对这个窗口内的数据进行计算。</p><p>Flink 在 KeyedStream 中提供了下面几种 Window：</p><ul><li>以时间驱动的 Time Window</li><li>以事件数量驱动的 Count Window</li><li>以会话间隔驱动的 Session Window</li></ul><p>提供上面三种 Window 机制后，由于某些特殊的需要，DataStream API 也提供了定制化的 Window 操作，供用户自定义 Window。</p><p>下面将先围绕上面说的三种 Window 来进行分析并教大家如何使用，然后对其原理分析，最后在解析其源码实现。</p><h3 id="Time-Window-使用"><a href="#Time-Window-使用" class="headerlink" title="Time Window 使用"></a>Time Window 使用</h3><p>正如命名那样，Time Window 根据时间来聚合流数据。例如：一分钟的时间窗口就只会收集一分钟的元素，并在一分钟过后对窗口中的所有元素应用于下一个算子。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(<span class="number">1</span>)</span><br><span class="line">    .timeWindow(Time.minutes(<span class="number">1</span>)) <span class="comment">//time Window 每分钟统计一次数量和</span></span><br><span class="line">    .sum(<span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>在第一个窗口中（1 ～ 2 分钟）和为 7、第二个窗口中（2 ～ 3 分钟）和为 12、第三个窗口中（3 ～ 4 分钟）和为 7、第四个窗口中（4 ～ 5 分钟）和为 19。</p><p>另外在 Time Window 中还支持滑动的时间窗口，比如定义了一个每 30s 滑动一次的 1 分钟时间窗口，它会每隔 30s 去统计过去一分钟窗口内的数据，同样使用也很简单，输入两个时间参数，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(<span class="number">1</span>)</span><br><span class="line">    .timeWindow(Time.minutes(<span class="number">1</span>), Time.seconds(<span class="number">30</span>)) <span class="comment">//sliding time Window 每隔 30s 统计过去一分钟的数量和</span></span><br><span class="line">    .sum(<span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>滑动时间窗口的数据聚合流程如下图所示：</p><h3 id="Count-Window-使用"><a href="#Count-Window-使用" class="headerlink" title="Count Window 使用"></a>Count Window 使用</h3><p>Apache Flink 还提供计数窗口功能，如果计数窗口的值设置的为 3 ，那么将会在窗口中收集 3 个事件，并在添加第 3 个元素时才会计算窗口中所有事件的值。</p><ul><li><p><strong><code>Tumbling Count Window</code></strong></p><blockquote><p>当我们想要每100个用户购买行为事件统计购买总数，那么每当窗口中填满100个元素了，就会对窗口进行计算，这种窗口我们称之为滚动计数窗口</p></blockquote></li><li><p><strong><code>Sliding Count Window</code></strong></p><blockquote><p>但是对于某些应用，它们需要的窗口是不间断的，需要平滑地进行窗口聚合。比如，我们可以每30秒计算一次最近一分钟用户购买的商品总数。这种窗口我们称为滑动时间窗口（Sliding Time Window）。在滑窗中，一个元素可以对应多个窗口。通过使用 DataStream API，我们可以这样实现：</p></blockquote></li></ul><p>在 Flink 中使用 Count Window 非常简单，输入一个 long 类型的参数，这个参数代表窗口中事件的数量，使用如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(<span class="number">1</span>)</span><br><span class="line">    .countWindow(<span class="number">3</span>) <span class="comment">//统计每 3 个元素的数量之和</span></span><br><span class="line">    .sum(<span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>计数窗口的数据窗口聚合流程如下图所示：</p><p>另外在 Count Window 中还支持滑动的计数窗口，比如定义了一个每 3 个事件滑动一次的 4 个事件的计数窗口，它会每隔 3 个事件去统计过去 4 个事件计数窗口内的数据，使用也很简单，输入两个 long 类型的参数，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(<span class="number">1</span>) </span><br><span class="line">    .countWindow(<span class="number">4</span>, <span class="number">3</span>) <span class="comment">//每隔 3 个元素统计过去 4 个元素的数量之和</span></span><br><span class="line">    .sum(<span class="number">1</span>);</span><br></pre></td></tr></table></figure><h3 id="Session-Window-使用"><a href="#Session-Window-使用" class="headerlink" title="Session Window 使用"></a>Session Window 使用</h3><p>Apache Flink 还提供了会话窗口，使用该窗口的时候可以传入一个时间参数（表示某种数据维持的会话持续时长），如果超过这个时间，就代表着超出会话时长。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataStream.keyBy(<span class="number">1</span>)</span><br><span class="line">    .window(ProcessingTimeSessionWindows.withGap(Time.seconds(<span class="number">5</span>)))<span class="comment">//表示如果 5s 内没出现数据则认为超出会话时长，然后计算这个窗口的和</span></span><br><span class="line">    .sum(<span class="number">1</span>);</span><br></pre></td></tr></table></figure><h3 id="如何自定义-Window？"><a href="#如何自定义-Window？" class="headerlink" title="如何自定义 Window？"></a>如何自定义 Window？</h3><p>Apache Flink 还提供了用户可自定义的 Window</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-073301.png" alt="img"></p><h3 id="3-2-8-Window-源码定义"><a href="#3-2-8-Window-源码定义" class="headerlink" title="3.2.8 Window 源码定义"></a>3.2.8 Window 源码定义</h3><p>Flink 中自带的 Window 主要利用了 KeyedStream 的 API 来实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Window</span> </span>&#123;</span><br><span class="line">    <span class="comment">//获取属于此窗口的最大时间戳</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">long</span> <span class="title">maxTimestamp</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看源码可以看见 Window 这个抽象类有如下实现类：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-17-163050.png" alt="img"></p><p><strong>TimeWindow</strong> 源码定义如下:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimeWindow</span> <span class="keyword">extends</span> <span class="title">Window</span> </span>&#123;</span><br><span class="line">    <span class="comment">//窗口开始时间</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> start;</span><br><span class="line">    <span class="comment">//窗口结束时间</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> end;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>GlobalWindow</strong> 源码定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GlobalWindow</span> <span class="keyword">extends</span> <span class="title">Window</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> GlobalWindow INSTANCE = <span class="keyword">new</span> GlobalWindow();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">GlobalWindow</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">    <span class="comment">//对外提供 get() 方法返回 GlobalWindow 实例，并且是个全局单例</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> GlobalWindow <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> INSTANCE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Window-组件之-WindowAssigner-使用及源码分析"><a href="#Window-组件之-WindowAssigner-使用及源码分析" class="headerlink" title="Window 组件之 WindowAssigner 使用及源码分析"></a>Window 组件之 WindowAssigner 使用及源码分析</h3><p>到达窗口操作符的元素被传递给 WindowAssigner。WindowAssigner 将元素分配给一个或多个窗口，可能会创建新的窗口。</p><p>窗口本身只是元素列表的标识符，它可能提供一些可选的元信息，例如 TimeWindow 中的开始和结束时间。注意，元素可以被添加到多个窗口，这也意味着一个元素可以同时在多个窗口存在。我们来看下 WindowAssigner 的代码的定义吧：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">WindowAssigner</span>&lt;<span class="title">T</span>, <span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window</span>&gt; <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="comment">//分配数据到窗口并返回窗口集合</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> Collection&lt;W&gt; <span class="title">assignWindows</span><span class="params">(T element, <span class="keyword">long</span> timestamp, WindowAssignerContext context)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看源码可以看见 WindowAssigner 这个抽象类有如下实现类：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-17-163413.png" alt="img"></p><p>这些 WindowAssigner 实现类的作用介绍：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-05-16-155715.jpg" alt="img"></p><p>TumblingEventTimeWindows 的源码分析，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TumblingEventTimeWindows</span> <span class="keyword">extends</span> <span class="title">WindowAssigner</span>&lt;<span class="title">Object</span>, <span class="title">TimeWindow</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">//定义属性</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> size;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> offset;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//构造方法</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="title">TumblingEventTimeWindows</span><span class="params">(<span class="keyword">long</span> size, <span class="keyword">long</span> offset)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (Math.abs(offset) &gt;= size) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;TumblingEventTimeWindows parameters must satisfy abs(offset) &lt; size&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.size = size;</span><br><span class="line">        <span class="keyword">this</span>.offset = offset;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//重写 WindowAssigner 抽象类中的抽象方法 assignWindows</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Collection&lt;TimeWindow&gt; <span class="title">assignWindows</span><span class="params">(Object element, <span class="keyword">long</span> timestamp, WindowAssignerContext context)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//实现该 TumblingEventTimeWindows 中的具体逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//其他方法，对外提供静态方法，供其他类调用</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>1、定义好实现类的属性</p><p>2、根据定义的属性添加构造方法</p><p>3、重写 WindowAssigner 中的 assignWindows 等方法</p><p>4、定义其他的方法供外部调用</p><h3 id="Window-组件之-Trigger-使用及源码分析"><a href="#Window-组件之-Trigger-使用及源码分析" class="headerlink" title="Window 组件之 Trigger 使用及源码分析"></a>Window 组件之 Trigger 使用及源码分析</h3><p>Trigger 表示触发器，每个窗口都拥有一个 Trigger（触发器），该 Trigger 决定何时计算和清除窗口。当先前注册的计时器超时时，将为插入窗口的每个元素调用触发器。在每个事件上，触发器都可以决定触发，即清除（删除窗口并丢弃其内容），或者启动并清除窗口。一个窗口可以被求值多次，并且在被清除之前一直存在。注意，在清除窗口之前，窗口将一直消耗内存。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Trigger</span>&lt;<span class="title">T</span>, <span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window</span>&gt; <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="comment">//当有数据进入到 Window 运算符就会触发该方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> TriggerResult <span class="title">onElement</span><span class="params">(T element, <span class="keyword">long</span> timestamp, W window, TriggerContext ctx)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">    <span class="comment">//当使用触发器上下文设置的处理时间计时器触发时调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> TriggerResult <span class="title">onProcessingTime</span><span class="params">(<span class="keyword">long</span> time, W window, TriggerContext ctx)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">    <span class="comment">//当使用触发器上下文设置的事件时间计时器触发时调用该方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> TriggerResult <span class="title">onEventTime</span><span class="params">(<span class="keyword">long</span> time, W window, TriggerContext ctx)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当有数据流入 Window 运算符时就会触发 onElement 方法、当处理时间和事件时间生效时会触发 onProcessingTime 和 onEventTime 方法。每个触发动作的返回结果用 TriggerResult 定义。继续来看下 TriggerResult 的源码定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">TriggerResult</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//不做任何操作</span></span><br><span class="line">    CONTINUE(<span class="keyword">false</span>, <span class="keyword">false</span>),</span><br><span class="line"></span><br><span class="line">    <span class="comment">//处理并移除窗口中的数据</span></span><br><span class="line">    FIRE_AND_PURGE(<span class="keyword">true</span>, <span class="keyword">true</span>),</span><br><span class="line"></span><br><span class="line">    <span class="comment">//处理窗口数据，窗口计算后不做清理</span></span><br><span class="line">    FIRE(<span class="keyword">true</span>, <span class="keyword">false</span>),</span><br><span class="line"></span><br><span class="line">    <span class="comment">//清除窗口中的所有元素，并且在不计算窗口函数或不发出任何元素的情况下丢弃窗口</span></span><br><span class="line">    PURGE(<span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看源码可以看见 Trigger 这个抽象类有如下实现类：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-17-163751.png" alt="img"></p><p>这些 Trigger 实现类的作用介绍：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-05-17-145735.jpg" alt="img"></p><p>如果你细看了上面图中某个类的具体实现的话，你会发现一个规律，拿 CountTrigger 的源码来分析，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CountTrigger</span>&lt;<span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window</span>&gt; <span class="keyword">extends</span> <span class="title">Trigger</span>&lt;<span class="title">Object</span>, <span class="title">W</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">//定义属性</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> maxCount;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ReducingStateDescriptor&lt;Long&gt; stateDesc = <span class="keyword">new</span> ReducingStateDescriptor&lt;&gt;(<span class="string">&quot;count&quot;</span>, <span class="keyword">new</span> Sum(), LongSerializer.INSTANCE);</span><br><span class="line">    <span class="comment">//构造方法</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">CountTrigger</span><span class="params">(<span class="keyword">long</span> maxCount)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.maxCount = maxCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//重写抽象类 Trigger 中的抽象方法 </span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TriggerResult <span class="title">onElement</span><span class="params">(Object element, <span class="keyword">long</span> timestamp, W window, TriggerContext ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//实现 CountTrigger 中的具体逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TriggerResult <span class="title">onEventTime</span><span class="params">(<span class="keyword">long</span> time, W window, TriggerContext ctx)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> TriggerResult.CONTINUE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TriggerResult <span class="title">onProcessingTime</span><span class="params">(<span class="keyword">long</span> time, W window, TriggerContext ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> TriggerResult.CONTINUE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>套路</strong>：</p><ol><li>定义好实现类的属性</li><li>根据定义的属性添加构造方法</li><li>重写 Trigger 中的 onElement、onEventTime、onProcessingTime 等方法</li><li>定义其他的方法供外部调用</li></ol><h3 id="Window-组件之-Evictor-使用及源码分析"><a href="#Window-组件之-Evictor-使用及源码分析" class="headerlink" title="Window 组件之 Evictor 使用及源码分析"></a>Window 组件之 Evictor 使用及源码分析</h3><p>Evictor 表示驱逐者，它可以遍历窗口元素列表，并可以决定从列表的开头删除首先进入窗口的一些元素，然后其余的元素被赋给一个计算函数，如果没有定义 Evictor，触发器直接将所有窗口元素交给计算函数。</p><p>我们来看看 Evictor 的源码定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Evictor</span>&lt;<span class="title">T</span>, <span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window</span>&gt; <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="comment">//在窗口函数之前调用该方法选择性地清除元素</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">evictBefore</span><span class="params">(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, <span class="keyword">int</span> size, W window, EvictorContext evictorContext)</span></span>;</span><br><span class="line">    <span class="comment">//在窗口函数之后调用该方法选择性地清除元素</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">evictAfter</span><span class="params">(Iterable&lt;TimestampedValue&lt;T&gt;&gt; elements, <span class="keyword">int</span> size, W window, EvictorContext evictorContext)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看源码可以看见 Evictor 这个接口有如下实现类：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-17-163942.png" alt="img"></p><p>这些 Evictor 实现类的作用介绍：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-05-17-153505.jpg" alt="img"></p><p>如果你细看了上面三种中某个类的实现的话，你会发现一个规律，比如我就拿 CountEvictor 的源码来分析，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CountEvictor</span>&lt;<span class="title">W</span> <span class="keyword">extends</span> <span class="title">Window</span>&gt; <span class="keyword">implements</span> <span class="title">Evictor</span>&lt;<span class="title">Object</span>, <span class="title">W</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义属性</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> maxCount;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> doEvictAfter;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//构造方法</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">CountEvictor</span><span class="params">(<span class="keyword">long</span> count, <span class="keyword">boolean</span> doEvictAfter)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.maxCount = count;</span><br><span class="line">        <span class="keyword">this</span>.doEvictAfter = doEvictAfter;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//构造方法</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">CountEvictor</span><span class="params">(<span class="keyword">long</span> count)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.maxCount = count;</span><br><span class="line">        <span class="keyword">this</span>.doEvictAfter = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//重写 Evictor 中的 evictBefore 方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">evictBefore</span><span class="params">(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, <span class="keyword">int</span> size, W window, EvictorContext ctx)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!doEvictAfter) &#123;</span><br><span class="line">            <span class="comment">//调用内部的关键实现方法 evict</span></span><br><span class="line">            evict(elements, size, ctx);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//重写 Evictor 中的 evictAfter 方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">evictAfter</span><span class="params">(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, <span class="keyword">int</span> size, W window, EvictorContext ctx)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (doEvictAfter) &#123;</span><br><span class="line">            <span class="comment">//调用内部的关键实现方法 evict</span></span><br><span class="line">            evict(elements, size, ctx);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">evict</span><span class="params">(Iterable&lt;TimestampedValue&lt;Object&gt;&gt; elements, <span class="keyword">int</span> size, EvictorContext ctx)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//内部的关键实现方法</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//其他的方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>套路</strong>：</p><ol><li>定义好实现类的属性</li><li>根据定义的属性添加构造方法</li><li>重写 Evictor 中的 evictBefore 和 evictAfter 方法</li><li>定义关键的内部实现方法 evict，处理具体的逻辑</li><li>定义其他的方法供外部调用</li></ol><p>上面我们详细讲解了 Window 中的组件 WindowAssigner、Trigger、Evictor，然后继续回到问题：如何自定义 Window？</p><p>上文讲解了 Flink 自带的 Window（Time Window、Count Window、Session Window），然后还分析了他们的源码实现，通过这几个源码，我们可以发现，它最后调用的都有一个方法，那就是 Window 方法，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//提供自定义 Window</span></span><br><span class="line"><span class="keyword">public</span> &lt;W extends Window&gt; <span class="function">WindowedStream&lt;T, KEY, W&gt; <span class="title">window</span><span class="params">(WindowAssigner&lt;? <span class="keyword">super</span> T, W&gt; assigner)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> WindowedStream&lt;&gt;(<span class="keyword">this</span>, assigner);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//构造一个 WindowedStream 实例</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">WindowedStream</span><span class="params">(KeyedStream&lt;T, K&gt; input,</span></span></span><br><span class="line"><span class="function"><span class="params">        WindowAssigner&lt;? <span class="keyword">super</span> T, W&gt; windowAssigner)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.input = input;</span><br><span class="line">    <span class="keyword">this</span>.windowAssigner = windowAssigner;</span><br><span class="line">    <span class="comment">//获取一个默认的 Trigger</span></span><br><span class="line">    <span class="keyword">this</span>.trigger = windowAssigner.getDefaultTrigger(input.getExecutionEnvironment());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这个 Window 方法传入的参数是一个 WindowAssigner 对象（你可以利用 Flink 现有的 WindowAssigner，也可以根据上面的方法来自定义自己的 WindowAssigner），然后再通过构造一个 WindowedStream 实例（在构造实例的会传入 WindowAssigner 和获取默认的 Trigger）来创建一个 Window。</p><p>另外你可以看到滑动计数窗口，在调用 window 方法之后，还调用了 WindowedStream 的 evictor 和 trigger 方法，trigger 方法会覆盖掉你之前调用 Window 方法中默认的 trigger，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//滑动计数窗口</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> WindowedStream&lt;T, KEY, GlobalWindow&gt; <span class="title">countWindow</span><span class="params">(<span class="keyword">long</span> size, <span class="keyword">long</span> slide)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> window(GlobalWindows.create()).evictor(CountEvictor.of(size)).trigger(CountTrigger.of(slide));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//trigger 方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> WindowedStream&lt;T, K, W&gt; <span class="title">trigger</span><span class="params">(Trigger&lt;? <span class="keyword">super</span> T, ? <span class="keyword">super</span> W&gt; trigger)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (windowAssigner <span class="keyword">instanceof</span> MergingWindowAssigner &amp;&amp; !trigger.canMerge()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">&quot;A merging window assigner cannot be used with a trigger that does not support merging.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (windowAssigner <span class="keyword">instanceof</span> BaseAlignedWindowAssigner) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">&quot;Cannot use a &quot;</span> + windowAssigner.getClass().getSimpleName() + <span class="string">&quot; with a custom trigger.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//覆盖之前的 trigger</span></span><br><span class="line">    <span class="keyword">this</span>.trigger = trigger;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的各种窗口实现，你就会发现了：Evictor 是可选的，但是 WindowAssigner 和 Trigger 是必须会有的，这种创建 Window 的方法充分利用了 KeyedStream 和 WindowedStream 的 API，再加上现有的 WindowAssigner、Trigger、Evictor，你就可以创建 Window 了，另外你还可以自定义这三个窗口组件的实现类来满足你公司项目的需求。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 状态一致性</title>
      <link href="2019/12/16/Flink%20%E7%8A%B6%E6%80%81%E4%B8%80%E8%87%B4%E6%80%A7/"/>
      <url>2019/12/16/Flink%20%E7%8A%B6%E6%80%81%E4%B8%80%E8%87%B4%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><h1 id="2-状态一致性分类"><a href="#2-状态一致性分类" class="headerlink" title="2. 状态一致性分类"></a>2. 状态一致性分类</h1><h2 id="2-1-AT-MOST-ONCE"><a href="#2-1-AT-MOST-ONCE" class="headerlink" title="2.1. AT-MOST-ONCE"></a>2.1. <code>AT-MOST-ONCE</code></h2><h2 id="2-2-AT-LEAST-ONCE"><a href="#2-2-AT-LEAST-ONCE" class="headerlink" title="2.2. AT-LEAST-ONCE"></a>2.2. <code>AT-LEAST-ONCE</code></h2><h2 id="2-3-EXACTLY-ONCE"><a href="#2-3-EXACTLY-ONCE" class="headerlink" title="2.3. EXACTLY-ONCE"></a>2.3. <code>EXACTLY-ONCE</code></h2><blockquote><p> <code>Flink</code> 使用 <code>checkpoint</code>保证 <code>EXACTLY-ONCE</code></p></blockquote><h1 id="3-端到端状态一致性"><a href="#3-端到端状态一致性" class="headerlink" title="3. 端到端状态一致性"></a>3. 端到端状态一致性</h1><blockquote><p><strong><code>Flink</code> 通过快照机制和 <code>Barrier</code> 来实现一致性的保证，当任务中途 <code>crash</code> 或者<code>cancel</code> 之后，可以通过<code>checkpoing</code> 或者 <code>savepoint</code> 来进行恢复，实现数据流的重放。从而让任务达到一致性的效果，这种一致性需要开启 <code>exactly_once</code>模式之后才行。</strong></p><p>需要记住的是这边的 <code>Flink</code>  <code>exactly_once</code> 只是说在 <code>Flink</code> 内部是 <code>exactly_once</code> 的，并不能保证与外部存储交互时的 <code>exactly_once</code>，如果要实现外部存储连接后的 <code>exactly_once</code>，需要进行做一些特殊的处理。</p></blockquote><h2 id="3-1-预写日志"><a href="#3-1-预写日志" class="headerlink" title="3.1. 预写日志"></a>3.1. 预写日志</h2><h2 id="3-2-两阶段提交"><a href="#3-2-两阶段提交" class="headerlink" title="3.2. 两阶段提交"></a>3.2. 两阶段提交</h2><h1 id="4-Flink-Kafka-端到端状态一致性"><a href="#4-Flink-Kafka-端到端状态一致性" class="headerlink" title="4. Flink + Kafka 端到端状态一致性"></a>4. <code>Flink</code> + <code>Kafka</code> 端到端状态一致性</h1>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark Streaming 和 Kafka 整合开发</title>
      <link href="2019/12/15/Spark%20Streaming%20%E5%92%8C%20Kafka%20%E6%95%B4%E5%90%88%E5%BC%80%E5%8F%91/"/>
      <url>2019/12/15/Spark%20Streaming%20%E5%92%8C%20Kafka%20%E6%95%B4%E5%90%88%E5%BC%80%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Apache Kafka 是一个分布式的消息发布-订阅系统。可以说，任何实时大数据处理工具缺少与 Kafka 整合都是不完整的。本文将介绍如何使用 Spark Streaming 从 Kafka 中接收数据，</p><p>这里介绍两种方法</p><ol><li>使用 Receivers 和 Kafka 高层次的 API</li><li>使用 Direct API，这是使用低层次的 KafkaAPI，并没有使用到 Receivers，是 Spark 1.3.0中开始引入的。这两种方法有不同的编程模型，性能特点和语义担保</li></ol><a id="more"></a><h2 id="基于-Receivers-的方法"><a href="#基于-Receivers-的方法" class="headerlink" title="基于 Receivers 的方法"></a>基于 Receivers 的方法</h2><p>使用了 Receivers 来接收数据。Receivers 的实现使用到 Kafka 高层次的消费者API。对于所有的Receivers，接收到的数据将会保存在 Spark executors 中，然后由 Spark Streaming 启动的 Job 来处理这些数据。</p><p>然而，在默认的配置下，这种方法在失败的情况下会丢失数据，为了保证零数据丢失，你可以在 Spark Streaming 中使用 WAL 日志，这是在 Spark 1.2.0 才引入的功能，这使得我们可以将接收到的数据保存到WAL 中，所以在失败的时候，我们可以从 WAL 中恢复，而不至于丢失数据。</p><h3 id="Direct-API"><a href="#Direct-API" class="headerlink" title="Direct API"></a>Direct API</h3><p>和基于 Receiver 接收数据不一样，这种方式定期地从 Kafka 的 <code>topic+partition</code> 中查询最新的偏移量，再根据定义的偏移量范围在每个 batch 里面处理数据。当作业需要处理的数据来临时，Spark 通过调用 Kafka 的简单消费者 API 读取一定范围的数据。</p><p>和基于 Receiver 方式相比，这种方式主要有一些几个优点：</p><ol><li><p><strong>简化并行</strong></p><p>我们不需要创建多个Kafka 输入流，然后union他们。而使用directStream，Spark Streaming将会创建和 Kafka 分区一样的 RDD 分区个数，而且会从 Kafka 并行地读取数据，也就是说Spark分区将会和Kafka分区有一一对应的关系，这对我们来说很容易理解和使用；</p></li><li><p><strong>高效</strong></p><p>第一种实现零数据丢失是通过将数据预先保存在 WAL 中，这将会复制一遍数据，这种方式实际上很不高效，因为这导致了数据被拷贝两次：一次是被 Kafka 复制；另一次是写到WAL中。但是本文介绍的方法因为没有Receiver，从而消除了这个问题，所以不需要WAL日志；</p></li><li><p><strong>恰好一次语义（Exactly-once semantics）</strong></p><p>文章中通过使用Kafka高层次的API把偏移量写入Zookeeper中，这是读取Kafka中数据的传统方法。虽然这种方法可以保证零数据丢失，但是还是存在一些情况导致数据会丢失，因为在失败情况下通过Spark Streaming读取偏移量和Zookeeper中存储的偏移量可能不一致。而本文提到的方法是通过Kafka低层次的API，并没有使用到Zookeeper，偏移量仅仅被Spark Streaming保存在Checkpoint中。这就消除了Spark Streaming和Zookeeper中偏移量的不一致，而且可以保证每个记录仅仅被Spark Streaming读取一次，即使是出现故障。</p></li></ol><p>但是本方法唯一的坏处就是没有更新 Zookeeper 中的偏移量，所以基于 Zookeeper 的 Kafka 监控工具将会无法显示消费的状况。然而你可以通过 Spark 提供的 API 手动地将偏移量写入到 Zookeeper 中。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h4 id="Spark-Streaming-和-Kafka-整合是如何保证数据零丢失"><a href="#Spark-Streaming-和-Kafka-整合是如何保证数据零丢失" class="headerlink" title="Spark Streaming 和 Kafka 整合是如何保证数据零丢失 ? "></a><font color='blue'>Spark Streaming 和 Kafka 整合是如何保证数据零丢失 ? </font></h4><p>当我们正确地部署好 Spark Streaming，我们就可以使用 Spark Streaming 提供的零数据丢失机制。为了体验这个关键的特性，你需要满足以下几个先决条件：</p><ol><li>输入的数据来自可靠的数据源和可靠的接收器</li><li>应用程序的 metadata 被 application 的 driver 持久化了(checkpointed)</li><li>启用了 WAL 特性(Write ahead log)</li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Watermark 与 Window 结合来处理延迟数据</title>
      <link href="2019/12/15/Watermark-%E4%B8%8E-Window-%E7%BB%93%E5%90%88%E6%9D%A5%E5%A4%84%E7%90%86%E5%BB%B6%E8%BF%9F%E6%95%B0%E6%8D%AE/"/>
      <url>2019/12/15/Watermark-%E4%B8%8E-Window-%E7%BB%93%E5%90%88%E6%9D%A5%E5%A4%84%E7%90%86%E5%BB%B6%E8%BF%9F%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在设置 Periodic Watermark 时，是允许提供一个参数，表示数据最大的延迟时间。其实这个值要结合自己的业务以及数据的情况来设置，如果该值设置的太小会导致数据因为网络或者其他的原因从而导致乱序或者延迟的数据太多，那么最后窗口触发的时候，可能窗口里面的数据量很少，那么这样计算的结果很可能误差会很大，对于有的场景（要求正确性比较高）是不太符合需求的。但是如果该值设置的太大，那么就会导致很多窗口一直在等待延迟的数据，从而一直不触发，这样首先就会导致数据的实时性降低，另外将这么多窗口的数据存在内存中，也会增加作业的内存消耗，从而可能会导致作业发生 OOM 的问题。</p><a id="more"></a><p>综上建议：</p><ul><li>合理设置允许数据最大延迟时间</li><li>不太依赖事件时间的场景就不要设置时间策略为 EventTime</li></ul><h3 id="延迟数据该如何处理-三种方法"><a href="#延迟数据该如何处理-三种方法" class="headerlink" title="延迟数据该如何处理(三种方法)"></a>延迟数据该如何处理(三种方法)</h3><h4 id="丢弃（默认）"><a href="#丢弃（默认）" class="headerlink" title="丢弃（默认）"></a>丢弃（默认）</h4><p>在 Flink 中，对这么延迟数据的默认处理方式是丢弃。</p><h4 id="allowedLateness-再次指定允许数据延迟的时间"><a href="#allowedLateness-再次指定允许数据延迟的时间" class="headerlink" title="allowedLateness 再次指定允许数据延迟的时间"></a>allowedLateness 再次指定允许数据延迟的时间</h4><p>allowedLateness 表示允许数据延迟的时间，这个方法是在 WindowedStream 中的，用来设置允许窗口数据延迟的时间，超过这个时间的元素就会被丢弃，这个的默认值是 0，该设置仅针对于以事件时间开的窗口，它的源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> WindowedStream&lt;T, K, W&gt; <span class="title">allowedLateness</span><span class="params">(Time lateness)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">long</span> millis = lateness.toMilliseconds();</span><br><span class="line">    checkArgument(millis &gt;= <span class="number">0</span>, <span class="string">&quot;The allowed lateness cannot be negative.&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.allowedLateness = millis;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之前有多个小伙伴问过我 Watermark 中允许的数据延迟和这个数据延迟的区别是啥？我的回复是该允许延迟的时间是在 Watermark 允许延迟的基础上增加的时间。那么具体该如何使用 allowedLateness 呢。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dataStream.assignTimestampsAndWatermarks(<span class="keyword">new</span> TestWatermarkAssigner())</span><br><span class="line">    .keyBy(<span class="keyword">new</span> TestKeySelector())</span><br><span class="line">    .timeWindow(Time.milliseconds(<span class="number">1</span>), Time.milliseconds(<span class="number">1</span>))</span><br><span class="line">    .allowedLateness(Time.milliseconds(<span class="number">2</span>))  <span class="comment">//表示允许再次延迟 2 毫秒</span></span><br><span class="line">    .apply(<span class="keyword">new</span> WindowFunction&lt;Integer, String, Integer, TimeWindow&gt;() &#123;</span><br><span class="line">        <span class="comment">//计算逻辑</span></span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><h4 id="sideOutputLateData-收集迟到的数据"><a href="#sideOutputLateData-收集迟到的数据" class="headerlink" title="sideOutputLateData 收集迟到的数据"></a>sideOutputLateData 收集迟到的数据</h4><p>sideOutputLateData 这个方法同样是 WindowedStream 中的方法，该方法会将延迟的数据发送到给定 OutputTag 的 side output 中去，然后你可以通过 <code>SingleOutputStreamOperator.getSideOutput(OutputTag)</code> 来获取这些延迟的数据。具体的操作方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义 OutputTag</span></span><br><span class="line">OutputTag&lt;Integer&gt; lateDataTag = <span class="keyword">new</span> OutputTag&lt;Integer&gt;(<span class="string">&quot;late&quot;</span>)&#123;&#125;;</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;String&gt; windowOperator = dataStream</span><br><span class="line">        .assignTimestampsAndWatermarks(<span class="keyword">new</span> TestWatermarkAssigner())</span><br><span class="line">        .keyBy(<span class="keyword">new</span> TestKeySelector())</span><br><span class="line">        .timeWindow(Time.milliseconds(<span class="number">1</span>), Time.milliseconds(<span class="number">1</span>))</span><br><span class="line">        .allowedLateness(Time.milliseconds(<span class="number">2</span>))</span><br><span class="line">        .sideOutputLateData(lateDataTag)    <span class="comment">//指定 OutputTag</span></span><br><span class="line">        .apply(<span class="keyword">new</span> WindowFunction&lt;Integer, String, Integer, TimeWindow&gt;() &#123;</span><br><span class="line">            <span class="comment">//计算逻辑</span></span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">windowOperator.addSink(resultSink);</span><br><span class="line"></span><br><span class="line"><span class="comment">//通过指定的 OutputTag 从 Side Output 中获取到延迟的数据之后，你可以通过 addSink() 方法存储下来，这样可以方便你后面去排查哪些数据是延迟的。</span></span><br><span class="line">windowOperator.getSideOutput(lateDataTag)</span><br><span class="line">        .addSink(lateResultSink);</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 数据倾斜</title>
      <link href="2019/12/15/Flink-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/"/>
      <url>2019/12/15/Flink-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在大数据计算场景，无论使用 MapReduce、Spark 还是 Flink 计算框架，无论是批处理还是流处理都存在数据倾斜的问题，通过本节学习产生数据倾斜的原因及如何在生产环境解决数据倾斜。</p><a id="more"></a><h3 id="数据倾斜简介"><a href="#数据倾斜简介" class="headerlink" title="数据倾斜简介"></a>数据倾斜简介</h3><p>分析一个计算各 app PV 的案例，如下图所示，圆球表示 app1 的日志，方块表示 app2 的日志，Source 端从外部系统读取用户上报的各 app 行为日志，要计算各 app 的 PV，所以按照 app 进行 keyBy，相同 app 的数据发送到同一个 Operator 实例中处理，keyBy 后对 app 的 PV 值进行累加来，最后将计算的 PV 结果输出到外部 Sink 端。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004442.jpg" alt="img"></p><p>可以看到在任务运行过程中，计算 Count 的算子有两个并行度，其中一个并行度处理 app1 的数据，另一个并行度处理 app2 的数据。由于 app1 比较热门，所以 app1 的日志量远大于 app2 的日志量，造成计算 app1 PV 的并行度压力过大成为整个系统的瓶颈，而计算 app2 PV 的并行度数据量较少所以 CPU、内存以及网络资源的使用率整体都比较低，这就是产生数据倾斜的案例。</p><h3 id="判断是否存在数据倾斜"><a href="#判断是否存在数据倾斜" class="headerlink" title="判断是否存在数据倾斜"></a>判断是否存在数据倾斜</h3><p>这里再通过一个案例来讲述 Flink 任务如何来判断是否存在数据倾斜，如下图所示，是 Flink Web UI Job 页面展示的任务执行计划，可以看到任务经过 Operator Chain 后，总共有两个 Task，上游 Task 将数据 keyBy 后发送到下游 Task，如何判断第二个 Task 计算的数据是否存在数据呢？</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004443.jpg" alt="img"></p><p>如下图所示，通过 Flink Web UI 中 Job 页面的第一个 Subtasks 选项卡，可以看到任务的两个 Task，点击 Task，可以看到 Task 相应的 Subtask 详情。例如 Subtask 的启动时间、结束时间、持续时长、接收数据量的字节数以及接收数据的个数。图中可以看到，相同 Task 的多个 Subtask 中，有的 Subtask 接收到 1.69 TB 的数据量，有的 Subtask 接收到 17.6 TB 的数据量，通过 Flink Web UI 可以精确地看到每个 Subtask 处理了多少数据，即可判断出 Flink 任务是否存在数据倾斜，接下来学习 Flink 中如何来解决数据倾斜。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004431.jpg" alt="img"></p><h3 id="分析和解决数据倾斜问题"><a href="#分析和解决数据倾斜问题" class="headerlink" title="分析和解决数据倾斜问题"></a>分析和解决数据倾斜问题</h3><p>在 Flink 中，很多因素都会导致数据倾斜，例如 9.6.1 节描述的 keyBy 后的聚合操作存在数据倾斜。keyBy 之前的数据直接来自于数据源，一般不会出现数据倾斜，除非数据源中的数据发生了数据倾斜。本小节将从多个角度来解决数据倾斜。</p><h5 id="keyBy-后的聚合操作存在数据倾斜"><a href="#keyBy-后的聚合操作存在数据倾斜" class="headerlink" title="keyBy 后的聚合操作存在数据倾斜"></a>keyBy 后的聚合操作存在数据倾斜</h5><p>Flink 社区关于数据倾斜的解决方案炒得最热的也莫过于 LocalKeyBy 了。Flink 中数据倾斜一般发生于 keyBy 之后的聚合操作，LocalKeyBy 的思想是：在 keyBy 上游算子数据发送之前，首先在上游算子的本地对数据进行聚合后再发送到下游，使下游接收到的数据量大大减少，从而使得 keyBy 之后的聚合操作不再是任务的瓶颈。</p><p>如下图所示，Source 算子向下游发送数据之前，首先对数据进行预聚合，Source Subtask 0 预聚合后，圆圈 PV 值为 5、方块 PV 值为 2，Source Subtask 1 预聚合后，圆圈 PV 值为 6、方块 PV 值为 1。keyBy 后，Count 算子进行 PV 值的累加，计算圆圈 PV 的 Subtask 接收到 5 和 6，只需要将 5+6 即可计算出圆圈总 PV 值为 11，计算方块 PV 的 Subtask 接收到 2 和 1，只需要将 2 +1 即可计算出方块总 PV 值为 3，最后将圆圈和方块的 PV 结果输出到 Sink 端即可。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004439.jpg" alt="img"></p><p>使用该方案计算 PV，带来了两个非常大的好处。</p><ul><li>在上游算子中对数据进行了预聚合，因此大大减少了上游往下游发送的数据量，从而减少了网络间的数据传输，节省了集群的带宽资源。上图案例中如果不聚合，上游需要往下游发送 14 条数据，聚合后仅仅需要发送 4 条数据即可。如果上游算子接收 1 万条数据后聚合一次，那么数据的压缩比会更大，优化效果会更加明显。</li><li>下游拿到的直接是上游聚合好的中间结果，因此下游 Count 算子计算的数据量大大减少，而且 Count 算子不再会有数据倾斜的问题。</li></ul><p>上游算子相比之前多了一个聚合的工作，所以压力必然会增加，但是只要数据源不发生数据倾斜，那么上游 Source 算子的各并行度之间的负载就会比较均衡。</p><p>这里就是 MapReduce 中 Combiner 的思想嘛，在 Map 端对数据进行预聚合之后，再将预聚合后的数据发送到 Reduce 端去处理，从而大大减少了 shuffle 的数据量。</p><p>虽然思想一样，但 Flink 流处理的预聚合相比 MapReduce 的批处理而言，带来了一个新的挑战：Flink 是天然的流式处理，即来一条数据处理一条（这里不考虑 Flink 网络传输层的 Buffer 机制），但是聚合操作要求必须是多条数据或者一批数据才能聚合，单条数据没有办法通过聚合来减少数据量。</p><p>所以从 Flink LocalKeyBy 实现原理来讲，必然会存在一个积攒批次的过程，在上游算子中必须攒够一定的数据量，对这些数据聚合后再发送到下游。既然是积攒批次，那肯定有一个积攒批次的策略，上图案例可以理解为每个批次 7 条数据，当读取到 7 条数据后，将这 7 条数据聚合后发送到下游。</p><p><strong>具体实现逻辑是：内存里维护一个计数器，每来一条数据计数器加一，并将数据聚合放到内存 Buffer 中，当计数器到达 7 时，将内存 Buffer 中的数据发送到下游、计数器清零、Buffer 清空。</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LocalKeyByFlatMap</span> <span class="keyword">extends</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Long</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//本地 buffer，存放 local 端缓存的 app 的 pv 信息</span></span><br><span class="line">    <span class="keyword">private</span> HashMap&lt;String, Long&gt; localPvStat;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//缓存的数据量大小，即：缓存多少数据再向下游发送</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> batchSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计数器，获取当前批次接收的数据量</span></span><br><span class="line">    <span class="keyword">private</span> AtomicInteger currentSize = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);;</span><br><span class="line"></span><br><span class="line">    LocalKeyByFlatMap(<span class="keyword">int</span> batchSize)&#123;</span><br><span class="line">        <span class="keyword">this</span>.batchSize = batchSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String in, Collector collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//  将新来的数据添加到 buffer 中</span></span><br><span class="line">        Long pv = localPvStat.getOrDefault(in, <span class="number">0L</span>);</span><br><span class="line">        localPvStat.put(in, pv + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果到达设定的批次，则将 buffer 中的数据发送到下游</span></span><br><span class="line">        <span class="keyword">if</span>(currentSize.incrementAndGet() &gt;= batchSize)&#123;</span><br><span class="line">            <span class="comment">// 遍历 Buffer 中数据，发送到下游</span></span><br><span class="line">            <span class="keyword">for</span>(Map.Entry&lt;String, Long&gt; appIdPv: localPvStat.entrySet()) &#123;</span><br><span class="line">                collector.collect(Tuple2.of(appIdPv.getKey(), appIdPv.getValue()));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// buffer 清空，计数器清零</span></span><br><span class="line">            localPvStat.clear();</span><br><span class="line">            currentSize.set(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码逻辑比较简单，使用了 FlatMap 算子来做缓冲，每来一条数据都需要检索，为了提高检索效率，所以这里使用 HashMap 类型的 localPvStat 用来做 Buffer 来缓存数据，currentSize 记录当前批次已经往 localPvStat 中写入的数据量。在 LocalKeyByFlatMap 构造器中需要初始化 batchSize，即批次大小。flatMap 方法将新数据添加到 localPvStat 中，currentSize 进行加一操作，且 currentSize 加一后如果大于 batchSize 则表示当前批次的数据已经够了，需要将数据发送到下游，则遍历 localPvStat，将 Buffer 中的数据发送到下游，并将 localPvStat 清空且 currentSize 清零。</p><p>代码逻辑简单易懂，但是问题又来了，在积攒批次的过程中，如果发生故障，Flink 任务能保障 Exactly Once 吗？</p><p>直接给出答案：不能保证 Exactly Once，可能会丢数据，为什么呢？</p><p>如下图所示，batchSize 设置的 7，但是当 JobManager 触发 Checkpoint 的时候，Source Subtask 0 消费到 offset 为 13 的位置、Source Subtask 1 消费到 offset 为 12 的位置，所以 Source 0 会将 offset=13 保存到状态后端，Source 1 会将 offset=12 保存到状态后端。接着 Checkpoint barrier 跟随着数据往下游发送到 LocalKeyBy，此时 LocalKeyBy 0 的 Buffer 中只有 6 条数据、LocalKeyBy 1 的 Buffer 中只有 5 条数据，所以 LocalKeyBy 0 和 1 都不会将数据发送到下游。但是 barrier 会接着往下游传递到 Count 算子，Count 算子会对自身状态信息进行快照，Count 0 会将圆圈 PV=11 保存到状态后端、Count 1 会将圆圈 PV=3 保存到状态后端，各 task 向 JobManager 反馈，最后 Checkpoint 成功了，紧接着数据正常开始处理。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004433.jpg" alt="img"></p><p>数据正常处理一段时间后，由于机器故障 Flink 任务突然挂了，如下图所示，Flink 任务会从状态恢复，Source Subtask 0 从 offset 为 13 的位置开始消费 Kafka，Source Subtask 1 从 offset 为 12 的位置开始消费 Kafka。Count 0 恢复后保存圆圈的 PV 为 11，Count 1 恢复后保存方块的 PV 为 3。此时任务从状态中恢复完成，正常开始处理数据，请问 Flink 任务从状态恢复后丢数据了吗？</p><p>丢了，因为 Source 0 对应的 offset 13 表示 Source 0 消费了 13 条数据，但是其中有 6 条数据缓存在 LocalKeyBy 0 的 Buffer 中没及时发送到下游，所以这 6 条数据丢了，同理 Source 1 对应的 offset 12 表示 Source 1 消费了 12 条数据，其中还有 5 条数据缓存在 LocalKeyBy 1 的 Buffer 中没及时发送到下游，所以这 5 条数据也丢了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-13-%E7%A7%AF%E6%94%92%E6%89%B9%E6%AC%A1%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%20Restore.png" alt="img"></p><p>通过上述详细案例分析，知道了我们设计的 LocalKeyBy 虽然能够提高性能，但存在丢数据的风险。，<strong>Flink 虽然支持 Exactly Once，但不是说你的代码随便瞎写 Flink 也能保证 Exactly Once，做为使用 Flink 的一员，我们应该根据原理书写出能保证 Flink Exactly Once 的代码。</strong></p><p>上述方案该如何完善才能保证 Exactly Once 呢？在 Checkpoint 时上述方案会把 LocalKeyBy 算子 Buffer 中的数据丢弃，所以重点应该是如何来保证 LocalKeyBy 算子 Buffer 中的数据不丢。在 Checkpoint 时可以将 Buffer 中还未发送到下游的数据保存到 Flink 的状态中，这样当 Flink 任务从 Checkpoint 处恢复时，可以将那些在 Buffer 中的数据从状态后端恢复。如下图所示，相比上述方案，Checkpoint 时会将 LocalKeyBy 算子 Buffer 中的数据也保存到状态后端。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-4434.jpg" alt="img"></p><p>如下图所示，当 Flink 任务从 Checkpoint 处恢复时，不仅恢复 offset 信息和 PV 信息，还需要把 LocalKeyBy 算子 Buffer 中的数据恢复，这样就可以保证不丢数据了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004436.jpg" alt="img"></p><p>具体代码如何实现呢？Checkpoint 时 LocalKeyBy 算子可能还有缓冲的数据没发送到下游，为了保证 Exactly Once，这里需要将 Buffer 中的数据保存在状态中。</p><p>Flink 有两种 State 分别是 OperatorState 和 KeyedState，OperatorState 是一个 Operator 实例对应一个State，KeyedState 是每个 key 对应一个 State，KeyedState 只能作用于 keyby 算子之后的 KeyedStream。</p><p>上图中我们可以看出，LocalKeyBy 算子位于 keyBy 算子之前，因此 LocalKeyBy 算子内部不能使用 KeyedState，只能使用 OperatorState，且 OperatorState 只支持一种数据结构，即 ListState，所以这里 buffer 中的数据只能保存在 OperatorState 类型的 ListState 中。当 Checkpoint 时，需要将内存 buffer 中的数据添加到 ListState，状态中需要保存 KV 类型的数据，key 是 appId、value 是 app 对应的 PV 值。</p><p>这里为了在 ListState 中保存 KV 格式的数据，需要将 buffer 中 KV 类型的数据转化为 Tuple2 类型后再添加到 ListState 中。代码具体实现如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LocalKeyByFlatMap</span> <span class="keyword">extends</span> <span class="title">RichFlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Long</span>&gt;&gt; <span class="keyword">implements</span> <span class="title">CheckpointedFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Checkpoint 时为了保证 Exactly Once，将 buffer 中的数据保存到该 ListState 中</span></span><br><span class="line">    <span class="keyword">private</span> ListState&lt;Tuple2&lt;String, Long&gt;&gt; localPvStatListState;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//本地 buffer，存放 local 端缓存的 app 的 pv 信息</span></span><br><span class="line">    <span class="keyword">private</span> HashMap&lt;String, Long&gt; localPvStat;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//缓存的数据量大小，即：缓存多少数据再向下游发送</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> batchSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计数器，获取当前批次接收的数据量</span></span><br><span class="line">    <span class="keyword">private</span> AtomicInteger currentSize;</span><br><span class="line"></span><br><span class="line">    LocalKeyByFlatMap(<span class="keyword">int</span> batchSize)&#123;</span><br><span class="line">        <span class="keyword">this</span>.batchSize = batchSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String in, Collector collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//  将新来的数据添加到 buffer 中</span></span><br><span class="line">        Long pv = localPvStat.getOrDefault(in, <span class="number">0L</span>);</span><br><span class="line">        localPvStat.put(in, pv + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果到达设定的批次，则将 buffer 中的数据发送到下游</span></span><br><span class="line">        <span class="keyword">if</span>(currentSize.incrementAndGet() &gt;= batchSize)&#123;</span><br><span class="line">            <span class="comment">// 遍历 Buffer 中数据，发送到下游</span></span><br><span class="line">            <span class="keyword">for</span>(Map.Entry&lt;String, Long&gt; appIdPv: localPvStat.entrySet()) &#123;</span><br><span class="line">                collector.collect(Tuple2.of(appIdPv.getKey(), appIdPv.getValue()));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// Buffer 清空，计数器清零</span></span><br><span class="line">            localPvStat.clear();</span><br><span class="line">            currentSize.set(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(FunctionSnapshotContext functionSnapshotContext)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 将 buffer 中的数据保存到状态中，来保证 Exactly Once</span></span><br><span class="line">        localPvStatListState.clear();</span><br><span class="line">        <span class="keyword">for</span>(Map.Entry&lt;String, Long&gt; appIdPv: localPvStat.entrySet()) &#123;</span><br><span class="line">            localPvStatListState.add(Tuple2.of(appIdPv.getKey(), appIdPv.getValue()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 从状态中恢复 buffer 中的数据</span></span><br><span class="line">        localPvStatListState = context.getOperatorStateStore().getListState(</span><br><span class="line">                <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(<span class="string">&quot;localPvStat&quot;</span>,</span><br><span class="line">                        TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">                        &#125;)));</span><br><span class="line">        localPvStat = <span class="keyword">new</span> HashMap();</span><br><span class="line">        <span class="keyword">if</span>(context.isRestored()) &#123;</span><br><span class="line">            <span class="comment">// 从状态中恢复数据到 localPvStat 中</span></span><br><span class="line">            <span class="keyword">for</span>(Tuple2&lt;String, Long&gt; appIdPv: localPvStatListState.get())&#123;</span><br><span class="line">                localPvStat.put(appIdPv.f0, appIdPv.f1);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//  从状态恢复时，默认认为 buffer 中数据量达到了 batchSize，需要向下游发送数据了</span></span><br><span class="line">            currentSize = <span class="keyword">new</span> AtomicInteger(batchSize);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            currentSize = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述改进方案后的 LocalKeyByFlatMap 相比之前方案仅仅增加了一个属性，即：<code>ListState&gt;</code> 类型的 localPvStatListState 用来存放 Checkpoint 时 buffer 中那些可能丢失的数据。在 snapshotState 方法中将 buffer 中的数据保存到状态中，在 initializeState 方法中将状态中恢复的数据 put 到 buffer 中并初始化计数器 currentSize。代码相对比较简答，容易看懂。</p><p>请问上述代码能保障 buffer 中的数据不丢吗？如果不修改 Source Task 和 LocalKeyByFlatMap 算子的并行度，理论来讲可以保证 Exactly Once，但是一旦修改并行度，还能保证 Exactly Once 吗？当并行度降低后，getOperatorStateStore().getListState() 恢复 ListState 时，会把 ListState 中的状态信息均匀分布到各个 Operator 实例中。当上述案例中 LocalKeyBy 的并行度从 2 调节为 1 时，数据恢复如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004441.jpg" alt="img"></p><p>首先 Source 端 partition 0 和 partition 1 的 offset 信息恢复没有问题，Count 算子圆圈和方块的 PV 信息恢复也没有问题。关键在于 LocalKeyBy 算子中 PV 信息恢复时会丢数据吗？状态恢复时，从状态中将 PV 信息恢复到 buffer 中的核心代码如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从状态中恢复数据到 localPvStat 中</span></span><br><span class="line"><span class="keyword">for</span>(Tuple2&lt;String, Long&gt; appIdPv: localPvStatListState.get())&#123;</span><br><span class="line">    localPvStat.put(appIdPv.f0, appIdPv.f1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从状态中会恢复 4 个 Tuple2，分别是 &lt;圆圈,4&gt;、&lt;方块,2&gt;、&lt;圆圈,4&gt;、&lt;方块,1&gt;，这里有两个圆圈、两个方块，恢复到 HashMap 类型的 localPvStat，HashMap 中相同的 key 不能重复，所以 HashMap 中不可能保存两个圆圈和两个方块。恢复时 app 相同的数据，应该将其 PV 值累加，所以恢复的结果应该是 &lt;圆圈,8&gt;、&lt;方块,3&gt;。但是上述代码，仅仅是覆盖操作，假如遍历状态时返回的顺序为 &lt;圆圈,4&gt;、&lt;方块,2&gt;、&lt;圆圈,4&gt;、&lt;方块,1&gt;，那么上述恢复流程为：将上述元素依次 put 到 HashMap 中，所以 HashMap 类型的 buffer 恢复完数据后，buffer 中保存的 PV 信息为 &lt;圆圈,4&gt;、&lt;方块,1&gt;。显然恢复过程中的覆盖操作将状态数据 &lt;圆圈,4&gt;、&lt;方块,2&gt; 丢了，所以上述方案如果不修改并行度时，不会丢数据，如果修改并行度时，可能会丢数据。</p><p>在使用状态来保证 Exactly Once 时，必须考虑修改并行度后，状态如何正常恢复的情况。优化后的代码如下所示，仅仅修改 initializeState 方法中恢复状态的逻辑：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从状态中恢复 buffer 中的数据</span></span><br><span class="line"><span class="keyword">for</span>(Tuple2&lt;String, Long&gt; appIdPv: localPvStatListState.get())&#123;</span><br><span class="line">    <span class="keyword">long</span> pv = localPvStat.getOrDefault(appIdPv.f0, <span class="number">0L</span>);</span><br><span class="line">    <span class="comment">// 如果出现 pv != 0，说明改变了并行度，</span></span><br><span class="line">    <span class="comment">// ListState 中的数据会被均匀分发到新的 subtask 中</span></span><br><span class="line">    <span class="comment">// 所以单个 subtask 恢复的状态中可能包含两个相同的 app 的数据</span></span><br><span class="line">    localPvStat.put(appIdPv.f0, pv + appIdPv.f1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码中，首先从 buffer 中获取当前 app 的 PV 数据，如果 buffer 中不包含当前 app 则 PV 值返回 0，如果 buffer 中包含了当前 app 则返回相应的 PV 值，将 buffer 中的 pv 加当前的 pv，put 到 buffer 中即可保证恢复时不丢数据。</p><p>到这里 LocalKeyBy 的思路及具体代码实现都讲完了，也带着大家分析了多种可能丢数据的情况，并一一解决。上述完整的代码实现请参阅。上述代码实现有个局限性，就是需要了解业务，按照下游的聚合逻辑，在上游 keyBy 之前同样也需要实现一遍。关于通用的 LocalKeyBy 实现，Flink 源码中目前还没有此功能，对具体实现原理感兴趣的可以参阅腾讯杨华老师贡献的 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-44%3A+Support+Local+Aggregation+in+Flink">FLIP-44</a>。</p><h5 id="keyBy-之前发生数据倾斜"><a href="#keyBy-之前发生数据倾斜" class="headerlink" title="keyBy 之前发生数据倾斜"></a>keyBy 之前发生数据倾斜</h5><p>上一部分分析了 keyBy 后由于数据本身的特征可能会发生数据倾斜，可以在 keyBy 之前进行一次预聚合，从而使得 keyBy 后的数据量大大降低。但是如果 keyBy 之前就存在数据倾斜呢？这样上游算子的某些实例可能处理的数据较多，某些实例可能处理的数据较少，产生该情况可能是因为数据源的数据本身就不均匀，例如由于某些原因 Kafka 的 topic 中某些 partition 的数据量较大，某些 partition 的数据量较少。对于不存在 keyBy 的 Flink 任务也会出现该情况，解决思路都一样，主要在于没有 shuffle 的 Flink 任务如何来解决数据倾斜。对于这种情况，需要让 Flink 任务强制进行 shuffle。如何强制 shuffle 呢？了解一下 DataStream 的物理分区策略。</p><table><thead><tr><th align="left">分区策略</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">dataStream.partitionCustom(partitioner, “someKey”); dataStream.partitionCustom(partitioner, 0);</td><td align="left">根据指定的字段进行分区，指定字段值相同的数据发送到同一个 Operator 实例处理</td></tr><tr><td align="left">dataStream.shuffle();</td><td align="left">将数据随机地分配到下游 Operator 实例</td></tr><tr><td align="left">dataStream.rebalance();</td><td align="left">使用轮循的策略将数据发送到下游 Operator 实例</td></tr><tr><td align="left">dataStream.rescale();</td><td align="left">基于 rebalance 优化的策略，依然使用轮循策略，但仅仅是 TaskManager 内的轮循，只会在 TaskManager 本地进行 shuffle 操作，减少了网络传输</td></tr><tr><td align="left">dataStream.broadcast();</td><td align="left">将数据广播到下游所有的 Operator 实例</td></tr></tbody></table><p>在这里需要解决数据倾斜，只需要使用 shuffle、rebalance 或 rescale 即可将数据均匀分配，从而解决数据倾斜的问题。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink WaterMark 深入理解</title>
      <link href="2019/12/13/Flink-WaterMark-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/"/>
      <url>2019/12/13/Flink-WaterMark-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>如果在进行 Window 计算操作的时候，如果使用的时间是 Processing Time，那么在 Flink 消费数据的时候，它完全不需要关心的数据本身的时间，意思也就是说不需要关心数据到底是延迟数据还是乱序数据。因为 Processing Time 只是代表数据在 Flink 被处理时的时间，这个时间是顺序的。但是如果你使用的是 Event Time 的话，那么你就不得不面临着这么个问题：事件乱序 &amp; 事件延迟。</p><a id="more"></a><p>在理想的情况下，Event Time 和 Process Time 是相等的，数据发生的时间与数据处理的时间没有延迟，但是现实流处理从事件产生，到流经 source，再到 operator，中间是有一个过程和时间的。虽然大部分情况下，流到 operator 的数据都是按照事件产生的时间顺序来的，但是也不排除由于网络延迟, 分布式等原因，导致乱序的产生，特别是使用 kafka 的话，多个分区的数据无法保证有序。</p><p><strong>然而在有些场景下，其实是特别依赖于事件时间而不是处理时间，比如：</strong></p><ul><li>错误日志的时间戳，代表着发生的错误的具体时间，开发们只有知道了这个时间戳，才能去还原那个时间点系统到底发生了什么问题，或者根据那个时间戳去关联其他的事件，找出导致问题触发的罪魁祸首</li><li>设备传感器或者监控系统实时上传对应时间点的设备周围的监控情况，通过监控大屏可以实时查看，不错漏重要或者可疑的事件</li></ul><p>这种情况下，最有意义的事件发生的顺序，而不是事件到达 Flink 后被处理的顺序。Flink 支持用户以事件时间来定义窗口（也支持以处理时间来定义窗口），那么这样就要去解决上面所说的两个问题。针对上面的问题（事件乱序 &amp; 事件延迟），Flink 引入了 Watermark 机制来解决。</p><h3 id="Watermark-是什么？"><a href="#Watermark-是什么？" class="headerlink" title="Watermark 是什么？"></a>Watermark 是什么？</h3><p>举个例子：</p><p><strong><font color='grey'>统计 8:00 ~ 9:00 这个时间段打开淘宝 App 的用户数量，Flink 这边可以开个窗口做聚合操作，但是由于网络的抖动或者应用采集数据发送延迟等问题，于是无法保证在窗口时间结束的那一刻窗口中是否已经收集好了在 8:00 ~ 9:00 中用户打开 App 的事件数据，但又不能无限期的等下去？当基于事件时间的数据流进行窗口计算时，最为困难的一点也就是如何确定对应当前窗口的事件已经全部到达。然而实际上并不能百分百的准确判断，因此业界常用的方法就是基于已经收集的消息来估算是否还有消息未到达，这就是 Watermark 的思想。</font></strong></p><p>Watermark 是一种衡量 Event Time 进展的机制，它是数据本身的一个隐藏属性，数据本身携带着对应的 Watermark。Watermark 本质来说就是一个时间戳，代表着比这时间戳早的事件已经全部到达窗口，即假设不会再有比这时间戳还小的事件到达，这个假设是触发窗口计算的基础，只有 Watermark 大于窗口对应的结束时间，窗口才会关闭和进行计算。按照这个标准去处理数据，那么如果后面还有比这时间戳更小的数据，那么就视为迟到的数据，对于这部分迟到的数据，Flink 也有相应的机制去处理。</p><p>下面通过几个图来了解一下 Watermark 是如何工作的！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-08-154340.jpg" alt="img"></p><p>上图中的数据是 Flink 从消息队列中消费的，然后在 Flink 中有个 4s 的时间窗口（根据事件时间定义的窗口），消息队列中的数据是乱序过来的，数据上的数字代表着数据本身的 timestamp，<code>W(4)</code> 和 <code>W(9)</code> 是水印。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-08-154747.jpg" alt="img"></p><p>经过 Flink 的消费，数据 <code>1</code>、<code>3</code>、<code>2</code> 进入了第一个窗口，然后 <code>7</code> 会进入第二个窗口，接着 <code>3</code> 依旧会进入第一个窗口，然后就有水印了，此时水印过来了，就会发现水印的 timestamp 和第一个窗口结束时间是一致的，那么它就表示在后面不会有比 <code>4</code> 还小的数据过来了，接着就会触发第一个窗口的计算操作，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-08-155309.jpg" alt="img"></p><p>那么接着后面的数据 <code>5</code> 和 <code>6</code> 会进入到第二个窗口里面，数据 <code>9</code> 会进入在第三个窗口里面。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-08-155558.jpg" alt="img"></p><p>那么当遇到水印 <code>9</code> 时，发现水印比第二个窗口的结束时间 <code>8</code> 还大，所以第二个窗口也会触发进行计算，然后以此继续类推下去。</p><p>相信看完上面几个图的讲解，你已经知道了 Watermark 的工作原理是啥了，那么在 Flink 中该如何去配置水印呢，下面一起来看看。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-01-19 上午10.59.07.png" alt="截屏2021-01-19 上午10.59.07" style="zoom:50%;" /><h3 id="Flink-中-Watermark-的设置"><a href="#Flink-中-Watermark-的设置" class="headerlink" title="Flink 中 Watermark 的设置"></a>Flink 中 Watermark 的设置</h3><p>在 Flink 中，数据处理中需要通过调用 DataStream 中的 assignTimestampsAndWatermarks 方法来分配时间和水印，该方法可以传入两种参数，一个是 AssignerWithPeriodicWatermarks，另一个是 AssignerWithPunctuatedWatermarks。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> SingleOutputStreamOperator&lt;T&gt; <span class="title">assignTimestampsAndWatermarks</span><span class="params">(AssignerWithPeriodicWatermarks&lt;T&gt; timestampAndWatermarkAssigner)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> inputParallelism = getTransformation().getParallelism();</span><br><span class="line">    <span class="keyword">final</span> AssignerWithPeriodicWatermarks&lt;T&gt; cleanedAssigner = clean(timestampAndWatermarkAssigner);</span><br><span class="line"></span><br><span class="line">    TimestampsAndPeriodicWatermarksOperator&lt;T&gt; operator = <span class="keyword">new</span> TimestampsAndPeriodicWatermarksOperator&lt;&gt;(cleanedAssigner);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transform(<span class="string">&quot;Timestamps/Watermarks&quot;</span>, getTransformation().getOutputType(), operator).setParallelism(inputParallelism);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> SingleOutputStreamOperator&lt;T&gt; <span class="title">assignTimestampsAndWatermarks</span><span class="params">(AssignerWithPunctuatedWatermarks&lt;T&gt; timestampAndWatermarkAssigner)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> inputParallelism = getTransformation().getParallelism();</span><br><span class="line">    <span class="keyword">final</span> AssignerWithPunctuatedWatermarks&lt;T&gt; cleanedAssigner = clean(timestampAndWatermarkAssigner);</span><br><span class="line"></span><br><span class="line">    TimestampsAndPunctuatedWatermarksOperator&lt;T&gt; operator = <span class="keyword">new</span> TimestampsAndPunctuatedWatermarksOperator&lt;&gt;(cleanedAssigner);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transform(<span class="string">&quot;Timestamps/Watermarks&quot;</span>, getTransformation().getOutputType(), operator).setParallelism(inputParallelism);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以设置 Watermark 是有如下两种方式：</p><ul><li><p>AssignerWithPunctuatedWatermarks：数据流中每一个递增的 EventTime 都会产生一个 Watermark。</p><blockquote><p>在实际的生产环境中，在 TPS 很高的情况下会产生大量的 Watermark，可能在一定程度上会对下游算子造成一定的压力，所以只有在实时性要求非常高的场景才会选择这种方式来进行水印的生成。</p></blockquote></li><li><p>AssignerWithPeriodicWatermarks：周期性的（一定时间间隔或者达到一定的记录条数）产生一个 Watermark。</p><blockquote><p>在实际的生产环境中，通常这种使用较多，它会周期性产生 Watermark 的方式，但是必须结合时间或者积累条数两个维度，否则在极端情况下会有很大的延时，所以 Watermark 的生成方式需要根据业务场景的不同进行不同的选择。</p></blockquote></li></ul><p>下面再分别详细讲下这两种的实现方式。</p><h3 id="Punctuated-Watermark"><a href="#Punctuated-Watermark" class="headerlink" title="Punctuated Watermark"></a>Punctuated Watermark</h3><p>AssignerWithPunctuatedWatermarks 接口中包含了 checkAndGetNextWatermark 方法，这个方法会在每次 extractTimestamp() 方法被调用后调用，它可以决定是否要生成一个新的水印，返回的水印只有在不为 null 并且时间戳要大于先前返回的水印时间戳的时候才会发送出去，如果返回的水印是 null 或者返回的水印时间戳比之前的小则不会生成新的水印。</p><p>那么该怎么利用这个来定义水印生成器呢？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordPunctuatedWatermark</span> <span class="keyword">implements</span> <span class="title">AssignerWithPunctuatedWatermarks</span>&lt;<span class="title">Word</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Nullable</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Watermark <span class="title">checkAndGetNextWatermark</span><span class="params">(Word lastElement, <span class="keyword">long</span> extractedTimestamp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> extractedTimestamp % <span class="number">3</span> == <span class="number">0</span> ? <span class="keyword">new</span> Watermark(extractedTimestamp) : <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Word element, <span class="keyword">long</span> previousElementTimestamp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> element.getTimestamp();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需要注意的是这种情况下可以为每个事件都生成一个水印，但是因为水印是要在下游参与计算的，所以过多的话会导致整体计算性能下降。</p><h3 id="3-5-4-Periodic-Watermark"><a href="#3-5-4-Periodic-Watermark" class="headerlink" title="3.5.4 Periodic Watermark"></a>3.5.4 Periodic Watermark</h3><p>通常在生产环境中使用 AssignerWithPeriodicWatermarks 来定期分配时间戳并生成水印比较多，那么先来讲下这个该如何使用。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordWatermark</span> <span class="keyword">implements</span> <span class="title">AssignerWithPeriodicWatermarks</span>&lt;<span class="title">Word</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> currentTimestamp = Long.MIN_VALUE;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Word word, <span class="keyword">long</span> previousElementTimestamp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (word.getTimestamp() &gt; currentTimestamp) &#123;</span><br><span class="line">            <span class="keyword">this</span>.currentTimestamp = word.getTimestamp();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> currentTimestamp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Nullable</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Watermark <span class="title">getCurrentWatermark</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> maxTimeLag = <span class="number">5000</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Watermark(currentTimestamp == Long.MIN_VALUE ? Long.MIN_VALUE : currentTimestamp - maxTimeLag);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的是我根据 Word 数据自定义的水印周期性生成器，在这个类中，有两个方法 extractTimestamp() 和 getCurrentWatermark()。extractTimestamp() 方法是从数据本身中提取 Event Time，该方法会返回当前时间戳与事件时间进行比较，如果事件的时间戳比 currentTimestamp 大的话，那么就将当前事件的时间戳赋值给 currentTimestamp。getCurrentWatermark() 方法是获取当前的水位线，这里有个 maxTimeLag 参数代表数据能够延迟的时间，上面代码中定义的 <code>long maxTimeLag = 5000;</code> 表示最大允许数据延迟时间为 5s，超过 5s 的话如果还来了之前早的数据，那么 Flink 就会丢弃了，因为 Flink 的窗口中的数据是要触发的，不可能一直在等着这些迟到的数据（由于网络的问题数据可能一直没发上来）而不让窗口触发结束进行计算操作。</p><p>通过定义这个时间，可以避免部分数据因为网络或者其他的问题导致不能够及时上传从而不把这些事件数据作为计算的，那么如果在这延迟之后还有更早的数据到来的话，那么 Flink 就会丢弃了，所以合理的设置这个允许延迟的时间也是一门细活，得观察生产环境数据的采集到消息队列再到 Flink 整个流程是否会出现延迟，统计平均延迟大概会在什么范围内波动。这也就是说明了一个事实那就是 Flink 中设计这个水印的根本目的是来解决部分数据乱序或者数据延迟的问题，而不能真正做到彻底解决这个问题，不过这一特性在相比于其他的流处理框架已经算是非常给力了。</p><p>AssignerWithPeriodicWatermarks 这个接口有四个实现类，分别如下图：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-082804.png" alt="img"></p><ul><li>BoundedOutOfOrdernessTimestampExtractor：该类用来发出滞后于数据时间的水印，它的目的其实就是和我们上面定义的那个类作用是类似的，你可以传入一个时间代表着可以允许数据延迟到来的时间是多长。该类内部实现如下：</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-083043.png" alt="img"></p><p>你可以像下面一样使用该类来分配时间和生成水印：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Time.seconds(10) 代表允许延迟的时间大小</span></span><br><span class="line">dataStream.assignTimestampsAndWatermarks(<span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;Event&gt;(Time.seconds(<span class="number">10</span>)) &#123;</span><br><span class="line">    <span class="comment">//重写 BoundedOutOfOrdernessTimestampExtractor 中的 extractTimestamp()抽象方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> event.getTimestamp();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><ul><li>CustomWatermarkExtractor：这是一个自定义的周期性生成水印的类，在这个类里面的数据是 KafkaEvent。</li><li>AscendingTimestampExtractor：时间戳分配器和水印生成器，用于时间戳单调递增的数据流，如果数据流的时间戳不是单调递增，那么会有专门的处理方法，代码如下：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(T element, <span class="keyword">long</span> elementPrevTimestamp)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">long</span> newTimestamp = extractAscendingTimestamp(element);</span><br><span class="line">    <span class="keyword">if</span> (newTimestamp &gt;= <span class="keyword">this</span>.currentTimestamp) &#123;</span><br><span class="line">        <span class="keyword">this</span>.currentTimestamp = ne∏wTimestamp;</span><br><span class="line">        <span class="keyword">return</span> newTimestamp;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        violationHandler.handleViolation(newTimestamp, <span class="keyword">this</span>.currentTimestamp);</span><br><span class="line">        <span class="keyword">return</span> newTimestamp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>IngestionTimeExtractor：依赖于机器系统时间，它在 extractTimestamp 和 getCurrentWatermark 方法中是根据 <code>System.currentTimeMillis()</code> 来获取时间的，而不是根据事件的时间，如果这个时间分配器是在数据源进 Flink 后分配的，那么这个时间就和 Ingestion Time 一致了，所以命名也取的就是叫 IngestionTimeExtractor。</li></ul><p><strong>注意</strong>：</p><p>1、使用这种方式周期性生成水印的话，你可以通过 <code>env.getConfig().setAutoWatermarkInterval(...);</code> 来设置生成水印的间隔（每隔 n 毫秒）。</p><p>2、通常建议在数据源（source）之后就进行生成水印，或者做些简单操作比如 filter/map/flatMap 之后再生成水印，越早生成水印的效果会更好，也可以直接在数据源头就做生成水印。比如你可以在 source 源头类中的 run() 方法里面这样定义</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;MyType&gt; ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="comment">/* condition */</span>) &#123;</span><br><span class="line">        MyType next = getNext();</span><br><span class="line">        ctx.collectWithTimestamp(next, next.getEventTimestamp());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (next.hasWatermarkTime()) &#123;</span><br><span class="line">            ctx.emitWatermark(<span class="keyword">new</span> Watermark(next.getWatermarkTime()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="每个-Kafka-分区的时间戳"><a href="#每个-Kafka-分区的时间戳" class="headerlink" title="每个 Kafka 分区的时间戳"></a>每个 Kafka 分区的时间戳</h3><p>当以 Kafka 来作为数据源的时候，通常每个 Kafka 分区的数据时间戳是递增的（事件是有序的），但是当你作业设置多个并行度的时候，Flink 去消费 Kafka 数据流是并行的，那么并行的去消费 Kafka 分区的数据就会导致打乱原每个分区的数据时间戳的顺序。在这种情况下，你可以使用 Flink 中的 <code>Kafka-partition-aware</code> 特性来生成水印，使用该特性后，水印会在 Kafka 消费端生成，然后每个 Kafka 分区和每个分区上的水印最后的合并方式和水印在数据流 shuffle 过程中的合并方式一致。</p><p>如果事件时间戳严格按照每个 Kafka 分区升序，则可以使用前面提到的 AscendingTimestampExtractor 水印生成器来为每个分区生成水印。下面代码教大家如何使用 <code>per-Kafka-partition</code> 来生成水印。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FlinkKafkaConsumer011&lt;Event&gt; kafkaSource = <span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(<span class="string">&quot;zhisheng&quot;</span>, schema, props);</span><br><span class="line">kafkaSource.assignTimestampsAndWatermarks(<span class="keyword">new</span> AscendingTimestampExtractor&lt;Event&gt;() &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractAscendingTimestamp</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> event.eventTimestamp();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">DataStream&lt;Event&gt; stream = env.addSource(kafkaSource);</span><br></pre></td></tr></table></figure><p>下图表示水印在 Kafka 分区后如何通过流数据流传播：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-09-014107.jpg" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 任务提交流程</title>
      <link href="2019/12/11/Flink%20%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/"/>
      <url>2019/12/11/Flink%20%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>用户提交的 <code>Flink Job</code> 会被转化成一个 <code>DAG</code> 任务运行，分别是：<code>StreamGraph</code>、<code>JobGraph</code>、<code>ExecutionGraph</code>，<code>Flink</code> 中 <code>JobManager</code> 与 <code>TaskManager</code>，<code>JobManager</code> 与 <code>Client</code> 的交互是基于Akka工具包的，是通过消息驱动。整个Flink Job的提交还包含着ActorSystem的创建，JobManager的启动，TaskManager的启动和注册。</p><a id="more"></a><h1 id="1-任务提交流程"><a href="#1-任务提交流程" class="headerlink" title="1. 任务提交流程"></a>1. 任务提交流程</h1><h2 id="1-1-Standalone"><a href="#1-1-Standalone" class="headerlink" title="1.1. Standalone"></a>1.1. <code>Standalone</code></h2><blockquote><ol><li><code>App</code> 程序通过 <code>rest</code> 接口提交给 <code>Dispatcher</code>[ <code>rest</code>接口是跨平台，并且可以直接穿过防火墙，不需考虑拦截]。</li><li><code>Dispatcher</code> 把 <code>JobManager</code> 进程启动，把应用交给<code>JobManager</code>。</li><li>JobManager拿到应用后，向ResourceManager申请资源（slots），ResouceManager会启动对应的TaskManager进程，TaskManager空闲的slots会向ResourceManager注册。</li><li>ResourceManager会根据JobManager申请的资源数量，向TaskManager发出指令（这些slots由你提供给JobManager）。</li><li>接着，TaskManager可以直接和JobManager通信了（它们之间会有心跳包的连接），TaskManager向JobManager提供slots，JobManager向TaskManager分配在slots中执行的任务。</li><li>最后，在执行任务过程中，不同的TaskManager会有数据之间的交换。</li></ol></blockquote><h2 id="1-2-Yarn"><a href="#1-2-Yarn" class="headerlink" title="1.2. Yarn"></a>1.2. <code>Yarn</code></h2><blockquote><ol><li>提交 <code>App</code> 之前，先上传 <code>Flink</code> 的 <code>Jar</code> 包和配置到 <code>HDFS</code> ，以便 <code>JobManager</code> 和 <code>TaskManager</code> 共享<code>HDFS</code> 的数据。</li><li>客户端向ResourceManager提交Job，ResouceManager接到请求后，先分配container资源，然后通知NodeManager启动ApplicationMaster。</li><li>ApplicationMaster会加载HDFS的配置，启动对应的JobManager，然后JobManager会分析当前的作业图，将它转化成执行图（包含了所有可以并发执行的任务），从而知道当前需要的具体资源。</li><li>接着，JobManager会向ResourceManager申请资源，ResouceManager接到请求后，继续分配container资源，然后通知ApplictaionMaster启动更多的TaskManager（先分配好container资源，再启动TaskManager）。container在启动TaskManager时也会从HDFS加载数据。</li><li>最后，TaskManager启动后，会向JobManager发送心跳包。JobManager向TaskManager分配任务。</li></ol></blockquote><h1 id="2-Graph"><a href="#2-Graph" class="headerlink" title="2. Graph"></a>2. <code>Graph</code></h1><h2 id="2-1-StreamGraph"><a href="#2-1-StreamGraph" class="headerlink" title="2.1. StreamGraph"></a>2.1. <code>StreamGraph</code></h2><h2 id="2-2-JobGraph"><a href="#2-2-JobGraph" class="headerlink" title="2.2. JobGraph"></a>2.2. <code>JobGraph</code></h2><h2 id="2-3-ExecutionGraph"><a href="#2-3-ExecutionGraph" class="headerlink" title="2.3. ExecutionGraph"></a>2.3. <code>ExecutionGraph</code></h2><h2 id="2-4-物理执行图"><a href="#2-4-物理执行图" class="headerlink" title="2.4. 物理执行图"></a>2.4. <code>物理执行图</code></h2>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello Flink</title>
      <link href="2019/12/10/Flink%E6%A6%82%E8%BF%B0/"/>
      <url>2019/12/10/Flink%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>Flink 核心是一个流式的数据流执行引擎，其针对数据流的分布式计算提供了数据分布、数据通信以及容错机制等功能。基于流执行引擎，Flink 提供了诸多更高抽象层的 API 以便用户编写分布式任务</p><h2 id="1-1-无界数据流与有界数据流"><a href="#1-1-无界数据流与有界数据流" class="headerlink" title="1.1.无界数据流与有界数据流"></a>1.1.无界数据流与有界数据流</h2><h3 id="1-1-1-无界数据流"><a href="#1-1-1-无界数据流" class="headerlink" title="1.1.1.无界数据流"></a>1.1.1.无界数据流</h3><p><strong>无界数据流有一个开始但是没有结束 ，</strong> 它们不会在生成时终止并 提供数据，必须连续处理无界流，也就是说必须在获取后立即 处理 event 。对于无界 数据流我们无法等待所有数据都到达， 因为输入是无界的， 并且在任何时间点都不 会完成。处理无界数据通常要求以特定顺序（例如事件发生的顺序）获取 event ，以 便能够推断结果完整性 ，无界流的处理称为流处理 。</p><h3 id="1-1-2-有界数据流"><a href="#1-1-2-有界数据流" class="headerlink" title="1.1.2.有界数据流"></a>1.1.2.有界数据流</h3><p><strong>有界数据流有明确定义的开始和结束，</strong> 可以在执行任何计算之前 通过获取所有数据来处理有界流， 处理有界流不需要有序获取， 因为可以始终对有 界数据集进行排序， 有界流的处理也称为批处理。</p><h2 id="1-2-批处理和流处理"><a href="#1-2-批处理和流处理" class="headerlink" title="1.2.批处理和流处理"></a>1.2.批处理和流处理</h2><p>批处理的特点是有界、持久、大量， 批处理非常适合需要访问全套记录才能完成的计算工作， 一般用于离线统计。 </p><p>流处理的特点是无界、实时， 流处理方式无需针对整个数据集执行操作， 而是对通过系统传输的每个数据项执行操作 ， 一般用于实时统计 。</p><h2 id="1-3-Flink-批流一体处理"><a href="#1-3-Flink-批流一体处理" class="headerlink" title="1.3.Flink 批流一体处理"></a>1.3.Flink 批流一体处理</h2><p>在 Spark 生态体系中， 对于批处理和流处理采用了不同的技术框架，批处理由 Spark SQL 实现， 流处理由 Spark Streaming 实现， 这也是大部分框架采用的策略， 使用独立的处理器实现批处理和流处理， 而 Flink 可以同时实现批处理和流处理。</p><p>Apache Flink  是一个面向分布式数据流处理和批量数据处理的开源计算平台，能够基于同一个 Flink 运行时 (Flink Runtime) ， 提供支持流处理和批处理两种类 型应用的功能 。 现有的开源计算 方案， 会把流处理和批处理作为两种不同的应用类 型，因为它们要实现的目标是完全不相同的：流处理一般需要支持低延迟、 Exactly-once 保证 ， 而 批处理需要支持高吞吐、高效处理 ， 所以在实现的时候通常 是分别给出两套实现方法， 或者通过一个独立的开源框架来实现其中每一种处理方 案。</p><p>Flink 是完全支持流处理，作为流处理时将输入数据流视为无界数据流 ； 批处理被作为一种特殊的流处理， 只是它的输入数据流被定义为有界的 。 </p><h2 id="1-4-Flink-amp-Spark-Streaming"><a href="#1-4-Flink-amp-Spark-Streaming" class="headerlink" title="1.4.Flink &amp; Spark Streaming"></a>1.4.<strong>Flink &amp; Spark Streaming</strong></h2><p><strong>Flink 是标准的实时流处理引擎，基于事件驱动。而 Spark Streaming 是微批[Micro-Batch的模型。</strong></p><h3 id="1-4-1-任务调度"><a href="#1-4-1-任务调度" class="headerlink" title="1.4.1.任务调度"></a><strong>1.4.1.任务调度</strong></h3><p>Spark Streaming 连续不断的生成微小的数据批次，构建有向无环图 DAG，Spark Streaming 会依次创建 DStreamGraph、JobGenerator、JobScheduler。</p><p>Flink 根据用户提交的代码生成 StreamGraph，经过优化生成 JobGraph，然后提交给 JobManager进行处理，JobManager 会根据 JobGraph 生成 ExecutionGraph，ExecutionGraph 是 Flink 调度最核心的数据结构，JobManager 根据 ExecutionGraph 对 Job 进行调度。</p><h3 id="1-4-2-时间机制"><a href="#1-4-2-时间机制" class="headerlink" title="1.4.2. 时间机制"></a><strong>1.4.2. 时间机制</strong></h3><p>Spark Streaming 支持的时间机制有限，只支持<strong>处理时间</strong>。<br>Flink 支持了流处理程序在时间上的三个定义：<strong>处理时间、事件时间、注入时间</strong>。同时也支持 <strong>watermark</strong> 机制来处理滞后数据。</p><h3 id="1-4-3-容错机制"><a href="#1-4-3-容错机制" class="headerlink" title="1.4.3. 容错机制"></a><strong>1.4.3. 容错机制</strong></h3><p>对于 Spark Streaming 任务，我们可以设置 checkpoint，然后假如发生故障并重启，我们可以从上次 checkpoint 之处恢复，但是这个行为只能使得数据不丢失，可能会重复处理，不能做到恰一次处理语义。</p><h1 id="2-系统架构"><a href="#2-系统架构" class="headerlink" title="2.系统架构"></a>2.系统架构</h1><p>当 Flink 集群启动后，首先会启动一个JobManger 和一个或多个的 TaskManager。由  Client 提交任务给 JobManager，JobManager 再调度任务到各个 TaskManager 去执行， TaskManager 将心跳和统计信息汇报给 JobManager。</p><h2 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h2><p>Client 为提交 Job 的客户端，可以是运行在任何机器上[与 JobManager 环境连通即可]。提交 Job 后，Client 可以结束进程，也可以不结束并等待结果返回。</p><h2 id="Dispatcher"><a href="#Dispatcher" class="headerlink" title="Dispatcher"></a>Dispatcher</h2><p> 提供 REST 接口来接收 client 的 application 提交，它负责启动 TaskManager 和提交 application，同时运行 Web UI。</p><h2 id="JobManager"><a href="#JobManager" class="headerlink" title="JobManager"></a>JobManager</h2><p><strong>JobManager  负责整个 Flink  集群任务的调度以及资源的管理，从客户端中获取提交的 Flink Job，然后根据集群中 TaskManager 上 TaskSlot 的使用情况，为提交的Job 分配相应的 TaskSlot 资源并命令 TaskManager 启动从客户端中获取的应用。</strong> </p><p><strong>JobManager 相当于整个集群的 Master 节点，且整个集群有且只有一个活跃的 JobManager ，负责整个集群的任务调度和资源管理。</strong></p><p>JobManager包含了3个重要的组件</p><h3 id="Actor"><a href="#Actor" class="headerlink" title="Actor"></a>Actor</h3><p>JobManager 和 TaskManager 之间通过 Actor System 进行通信，获取任务执行的情况并通过 Actor System 将应用的任务执行情况发送给客户端。</p><h3 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h3><h3 id="检查点"><a href="#检查点" class="headerlink" title="检查点"></a>检查点</h3><p>Flink的检查点机制是保证其一致性容错功能的骨架。它持续的为分布式的数据流和有状态的operator生成一致性的快照。Flink的容错机制持续的构建轻量级的分布式快照，因此负载非常低。通常这些有状态的快照都被放在HDFS中存储（state backend）。程序一旦失败，Flink将停止executor并从最近的完成了的检查点开始恢复（依赖可重发的数据源+快照）</p><h2 id="TaskManager"><a href="#TaskManager" class="headerlink" title="TaskManager"></a>TaskManager</h2><p> <strong>TaskManager  相当于整个集群的 Slave 节点，负责具体的任务执行和对应任务在每个节点上的资源申请和管理。</strong></p><p> 客户端通过将编写好的 Flink 应用编译打包，提交到 JobManager，然后 JobManager 会根据已注册在 JobManager 中 TaskManager 的资源情况，将任务分配给有资源的 TaskManager节点，然后启动并运行任务。</p><p> TaskManager 从 JobManager 接收 Job然后使用 Slot 资源启动 Task，建立数据接入的网络连接，接收数据并开始数据处理。同时 TaskManager 之间的数据交互都是通过数据流的方式进行的。</p><p> 可以看出，<strong>Flink 的任务运行其实是采用多线程的方式，这和 MapReduce 多 进程的方式有很大的区别</strong>，Flink 能够极大提高 CPU 使用效率，在多个任务和 Task之间通过 TaskSlot 方式共享系统资源，每个 TaskManager 中通过管理多个 TaskSlot 资源池进行对资源进行有效管理。</p><h3 id="Slots"><a href="#Slots" class="headerlink" title="Slots"></a>Slots</h3><p><strong>Flink 中每一个 TaskManager 都是一个 JVM 进程，他可能会在独立的线程上执行一个或多个 subtask</strong></p><p><strong>为了控制一个 TaskManager 能接收多少个 task，TaskManager通过 task slot 来进行控制， 一个TaskManager至少有一个 slot</strong></p><ul><li><p><strong>Slot 共享</strong></p><p> 默认情况下，Flink 允许 subtasks共享 slot</p><p> 条件是它们都来自<strong>同一个 Job 的不同 task 的 subtask</strong>。结果可能是一个 slot 持有该 job的整个pipeline。</p><p> <strong>优点</strong></p><ul><li><p>Flink 集群需要的任务槽与作业中使用的最高并行度正好相同(前提，保持默认SlotSharingGroup)。也就是说我们不需要再去计算一个程序总共会起多少个task了。</p></li><li><p>更容易获得更充分的资源利用。如果没有slot共享，那么非密集型操作source/flatmap就会占用同密集型操作 keyAggregation/sink 一样多的资源。如果有slot共享，将task的2个并行度增加到6个，能充分利用slot资源，同时保证每个TaskManager能平均分配到重的subtasks。</p></li></ul></li><li><p><strong>SlotSharingGroup[soft]</strong></p><p> SlotSharingGroup 是Flink中用来实现 slot  共享的类，它尽可能地让 subtasks 共享一个slot。</p><p> 保证同一个 group 的并行度相同的 sub-tasks 共享同一个slots。</p><p> 算子的默认group为default [即默认一个 Job下 的 subtask都可以共享一个 slot]</p><p> 为了防止不合理的共享，用户也能通过API来强制指定 operator 的共享组</p><p> 比如：someStream.filter(…).slotSharingGroup(“group1”);就强制指定了filter的slot共享组为group1。</p><p> 怎么确定一个未做SlotSharingGroup设置算子的SlotSharingGroup什么呢(根据上游算子的group 和自身是否设置group共同确定)。适当设置可以减少每个slot运行的线程数，从而整体上减少机器的负载。</p></li></ul><h1 id="3-Flink-部署模式"><a href="#3-Flink-部署模式" class="headerlink" title="3.Flink 部署模式"></a>3.Flink 部署模式</h1><p>Flink 是支持以 Standalone、YARN、Kubernetes、Mesos 等形式部署的。</p><ul><li>Local：直接在 IDE 中运行 Flink Job 时则会在本地启动一个 mini Flink 集群</li><li>Standalone：在 Flink 目录下执行 <code>bin/start-cluster.sh</code> 脚本则会启动一个 Standalone 模式的集群</li><li>YARN：YARN 是 Hadoop 集群的资源管理系统，它可以在群集上运行各种分布式应用程序，Flink 可与其他应用并行于 YARN 中，Flink on YARN 的架构如下：</li></ul><h1 id="4-Flink-作业提交架构流程"><a href="#4-Flink-作业提交架构流程" class="headerlink" title="4.Flink 作业提交架构流程"></a>4.Flink 作业提交架构流程</h1><p>Flink 作业提交架构流程可见下图：</p><img src="/Users/joker/Documents/chen_blog/images/截屏2021-01-20 上午9.26.58.png" alt="截屏2021-01-20 上午9.26.58" style="zoom:50%;" /><ol><li><p>Program Code</p><p>用户编写的 Flink 应用程序代码。</p></li><li><p>Job Client</p><p>Job Client 不是 Flink 程序执行的内部部分，但它是任务执行的起点。Job Client 负责接受用户的程序代码，然后创建数据流，将数据流提交给 Job Manager 以便进一步执行。执行完成后，Job Client 将结果返回给用户。</p></li><li><p>Job Manager</p><p>主进程（也称为作业管理器）协调和管理程序的执行。它的主要职责包括安排任务、管理 checkpoint 、故障恢复等。机器集群中至少要有一个 master，master 负责调度 task、协调 checkpoints 和容灾，高可用设置的话可以有多个 master，但要保证一个是 leader，其他是 standby。Job Manager 包含 Actor system、Scheduler、Check pointing 三个重要的组件。</p></li><li><p>Task Manager</p><p>从 Job Manager 处接收需要部署的 Task。Task Manager 是在 JVM 中的一个或多个线程中执行任务的工作节点。任务执行的并行性由每个 Task Manager 上可用的任务槽（Slot 个数）决定。每个任务代表分配给任务槽的一组资源。例如，如果 Task Manager 有四个插槽，那么它将为每个插槽分配 25％ 的内存。可以在任务槽中运行一个或多个线程。同一插槽中的线程共享相同的 JVM。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 保证Exactly Once[2]</title>
      <link href="2019/12/10/Flink-%E4%BF%9D%E8%AF%81Exactly-Once-2/"/>
      <url>2019/12/10/Flink-%E4%BF%9D%E8%AF%81Exactly-Once-2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>FlinkKafkaConsumer 做为 Source，从 Kafka 读取数据到 Flink 中，首先想一下设计 FlinkKafkaConsumer，需要考虑哪些？</p><a id="more"></a><h3 id="分析-FlinkKafkaConsumer-的设计思想"><a href="#分析-FlinkKafkaConsumer-的设计思想" class="headerlink" title="分析 FlinkKafkaConsumer 的设计思想"></a>分析 FlinkKafkaConsumer 的设计思想</h3><p>FlinkKafkaConsumer 做为 Source，从 Kafka 读取数据到 Flink 中，首先想一下设计 FlinkKafkaConsumer，需要考虑哪些？</p><ul><li>Flink 中 kafka 的 offset 保存在哪里，具体如何保存呢？任务重启恢复时，如何读取之前消费的 offset？</li><li>如果 Source 端并行度改变了，如何来恢复 offset？</li><li>如何保证每个 FlinkKafkaConsumer 实例消费的 partition 负载均衡？如何保证不出现有的实例消费 5 个 kafka partition，有的实例仅消费 1 个 kafka partition？</li><li>当前消费的 topic 如果动态增加了 partition，Flink 如何实现自动发现并消费？</li></ul><p>带着这些问题来看一看 FlinkKafkaConsumer 是怎么解决上述问题的。</p><h4 id="Kafka-offset-存储及如何实现-Consumer-实例消费-partition-的负载均衡"><a href="#Kafka-offset-存储及如何实现-Consumer-实例消费-partition-的负载均衡" class="headerlink" title="Kafka offset 存储及如何实现 Consumer 实例消费 partition 的负载均衡"></a>Kafka offset 存储及如何实现 Consumer 实例消费 partition 的负载均衡</h4><p>Flink 将任务恢复需要的信息都保存在状态中，当然 Kafka 的 offset 信息也保存在 Flink 的状态中，当任务从状态中恢复时会从状态中读取相应的 offset，并从 offset 位置开始消费。</p><p>在 Flink 中有两个基本的 State：Keyed State 和 Operator State。</p><ul><li>Keyed State 只能用于 KeyedStream 的 function 和 Operator 中，一个 Key 对应一个 State；</li><li>而 Operator State 可以用于所有类型的 function 和 Operator 中，一个 Operator 实例对应一个 State，假如一个算子并行度是 5 且使用 Operator State，那么这个算子的每个并行度都对应一个 State，总共 5 个 State。</li></ul><p>FlinkKafkaConsumer 做为 Source 只能使用 Operator State，Operator State 只支持一种数据结构 ListState，可以当做 List 类型的 State。所以 FlinkKafkaConsumer 中，将状态保存在 Operator State 对应的 ListState 中。具体如何保存呢？需要先了解每个 FlinkKafkaConsumer 具体怎么消费 Kafka。</p><p>对于同一个消费者组，Kafka 要求 topic 的每个 partition 只能被一个 Consumer 实例消费，相反一个 Consumer 实例可以去消费多个 partition。当 Flink 消费 Kafka 时，出现了以下三种情况：</p><table><thead><tr><th align="left">情况</th><th align="left">现象</th></tr></thead><tbody><tr><td align="left">FlinkKafkaConsumer 并行度大于 topic 的 partition 数</td><td align="left">有些 FlinkKafkaConsumer 不会消费 Kafka</td></tr><tr><td align="left">FlinkKafkaConsumer 并行度等于 topic 的 partition 数</td><td align="left">每个 FlinkKafkaConsumer 消费 1 个 partition</td></tr><tr><td align="left">FlinkKafkaConsumer 并行度小于 topic 的 partition 数</td><td align="left">每个 FlinkKafkaConsumer 至少消费 1 个 partition，可能会消费多个 partition</td></tr></tbody></table><p>Flink 是如何为每个 Consumer 实例合理地分配去消费哪些 partition 呢？源码中 KafkaTopicPartitionAssigner 类的 assign 方法，负责分配 partition 给 Consumer 实例。assign 方法的输入参数为 KafkaTopicPartition 和 Consumer 的并行度，KafkaTopicPartition 主要包含两个字段：String 类型的 topic 和 int 类型的 partition。assign 方法返回该 KafkaTopicPartition 应该分配给哪个 Consumer 实例去消费。假如 Consumer 的并行度为 5，表示包含了 5 个 subtask，assign 方法的返回值范围为 0~4，分别表示该 partition 分配给 subtask0-subtask4。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> partition Kafka 中 topic 和 partition 信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> numParallelSubtasks subtask 的数量</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> 该 KafkaTopicPartition 分配给哪个 subtask 去消费</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">assign</span><span class="params">(KafkaTopicPartition partition, <span class="keyword">int</span> numParallelSubtasks)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> startIndex = ((partition.getTopic().hashCode() * <span class="number">31</span>) &amp; <span class="number">0x7FFFFFFF</span>) % numParallelSubtasks;</span><br><span class="line">    <span class="keyword">return</span> (startIndex + partition.getPartition()) % numParallelSubtasks;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>assign 方法是如何给 KafkaTopicPartition 分配 Consumer 实例的呢？</p><p>第一行代码根据 topic name 的 hashCode 运算后对 subtask 的数量求余生成一个 startIndex，第二行代码用 startIndex + partition 编号对 subtask 的数量求余，可以保证该 topic 的 0 号 partition 分配给 startIndex 对应的 subtask，后续的 partition 依次分配给后续的 subtask。</p><p>例如，名为 “test-topic” 的 topic 有 11 个 partition 分别为 partition0-partition10，Consumer 有 5 个并行度分别为 subtask0-subtask4。计算后的 startIndex 为 1，表示 partition0 分配给 subtask1，partition1 分配给 subtask2 以此类推，subtask 与 partition 的对应关系如下图所示。</p><p>assign 方法给 partition 分配 subtask 实际上是轮循的策略，首先计算一个起点 startIndex 分配给 partition0，后续的 partition 轮循地分配给 subtask，从而使得每个 subtask 消费的 partition 得以均衡。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-122937.jpg" alt="img"></p><p>每个 subtask 只负责一部分 partition，所以在维护 partition 的 offset 信息时，每个 subtask 只需要将自己消费的 partition 的 offset 信息保存到状态中即可。</p><p>保存的格式理论来讲应该是 kv 键值对，key 为 KafkaTopicPartition，value 为 Long 类型的 offset 值。但 Flink 的 Operator State 只支持 ListState 一种数据结构，不支持 kv 格式，可以将 KafkaTopicPartition 和 Long 封装为 Tuple2&lt;KafkaTopicPartition, Long&gt; 存储到 ListState 中。如下所示，Flink 源码中确实如此，使用 ListState&lt;Tuple2&lt;KafkaTopicPartition, Long&gt;&gt; 类型的 unionOffsetStates 来保存 Kafka 的 offset 信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Accessor for state in the operator state backend. */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> ListState&lt;Tuple2&lt;KafkaTopicPartition, Long&gt;&gt; unionOffsetStates;</span><br></pre></td></tr></table></figure><p>当 Flink 应用从 Checkpoint 恢复任务时，会从 unionOffsetStates 中读取上一次 Checkpoint 保存的 offset 信息，并从 offset 的位置开始继续消费，从而实现 Flink 任务的故障容错。例如，任务重启后，Operator State 是一个 Operator 实例对应一个 State，subtask0 依然消费 partition4 和 partition9，subtask0 从自己的 State 中可以读取到 partition4 和 partition9 消费的 offset，从 offset 位置接着往后消费即可。问题来了，若 FlinkKafkaConsumer 的并行度改变后，offset 信息如何恢复呢？</p><h4 id="Source-端并行度改变了，如何来恢复-offset"><a href="#Source-端并行度改变了，如何来恢复-offset" class="headerlink" title="Source 端并行度改变了，如何来恢复 offset"></a>Source 端并行度改变了，如何来恢复 offset</h4><p>subtask1 当前消费了 3 个 partition，而其他 subtask 仅消费 2 个 partition，当发现 subtask1 读取 Kafka 成为瓶颈后，需要调大 Consumer 的并行度，使得每个 subtask 最多仅消费 2 个 partition。将 Consumer 实例的并行度增大到 6 以后，分配器对 partition 重新分配给 6 个 subtask，计算后的 startIndex 为 0，表示 partition0 分配给 subtask0，后续的 partition 采用轮循策略，partition 与 subtask 的对应关系如下。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-122939.jpg" alt="img"></p><p>之前 subtask0 消费 partition 4 和 9，并行度调大以后，subtask0 被分配消费 partition 0 和 6。但是 Flink 任务从 Checkpoint 恢复后，能保证 subtask0 读取到 partition 0 和 6 的 offset 吗？这个就需要深入了解当 Flink 算子并行度改变后，Operator State 的 ListState 两种恢复策略。两种策略如下所示，在 initializeState 方法中执行相应 API 来恢复。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">OperatorStateStore stateStore = context.getOperatorStateStore();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过 getListState 获取 ListState</span></span><br><span class="line">stateStore.getListState(ListStateDescriptor&lt;S&gt; var1);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过 getUnionListState 获取 ListState</span></span><br><span class="line">stateStore.getUnionListState(ListStateDescriptor&lt;S&gt; var1);</span><br></pre></td></tr></table></figure><p>当并行度改变后，getListState 恢复策略是均匀分配，将 ListState 中保存的所有元素均匀地分配到所有并行度中，每个 subtask 获取到其中一部分状态信息。</p><p>getUnionListState 策略是将所有的状态信息合并后，每个 subtask 都获取到全量的状态信息。在 FlinkKafkaConsumer 中，假如使用 getListState 来获取 ListState，采用均匀分配状态信息的策略，Flink 可能给 subtask0 分配了 partition0 和 partition1 的 offset 信息，但实际上分配器让 subtask0 去消费 partition0 和 partition6，此时 subtask0 并拿不到 partition 6 的 offset 信息，不知道该从 partition 6 哪个位置消费，所以均匀分配状态信息的策略并不能满足需求。</p><p>这里应该使用 getUnionListState 来获取 ListState，也就是说每个 subtask 都可以获取到所有 partition 的 offset 信息，然后根据分配器让 subtask 0 去消费 partition0 和 partition6 时，subtask0 只需要从全量的 offset 中拿到 partition0 和 partition6 的状态信息即可。</p><p>这么做会使得每个 subtask 获取到一些无用的 offset 的信息，但实际上这些 offset 信息占用的空间会比较小，所以该方案成本比较低。关于 OperatorState 的 ListState 两种获取方式请参考代码：</p><blockquote><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-state/src/main/java/com/zhisheng/state/operator/state/UnionListStateExample.java">https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-state/src/main/java/com/zhisheng/state/operator/state/UnionListStateExample.java</a></p></blockquote><p>FlinkKafkaConsumer 初始化时，恢复 offset 相关的源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// initializeState  方法中用于恢复 offset 状态信息</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    OperatorStateStore stateStore = context.getOperatorStateStore();</span><br><span class="line">    <span class="comment">// 此处省略了兼容 Flink 1.2 之前状态 API 的场景</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 此处使用的 getUnionListState，而不是 getListState。因为重启后，可能并行度被改变了</span></span><br><span class="line">    <span class="keyword">this</span>.unionOffsetStates = stateStore.getUnionListState(<span class="keyword">new</span> ListStateDescriptor&lt;&gt;(</span><br><span class="line">            OFFSETS_STATE_NAME,</span><br><span class="line">            TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;KafkaTopicPartition, Long&gt;&gt;() &#123;&#125;)));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (context.isRestored() &amp;&amp; !restoredFromOldState) &#123;</span><br><span class="line">        restoredState = <span class="keyword">new</span> TreeMap&lt;&gt;(<span class="keyword">new</span> KafkaTopicPartition.Comparator());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将状态中恢复的 offset 信息 put 到 TreeMap 类型的 restoredState 中，方便查询</span></span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;KafkaTopicPartition, Long&gt; kafkaOffset : unionOffsetStates.get()) &#123;</span><br><span class="line">            restoredState.put(kafkaOffset.f0, kafkaOffset.f1);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// open 方法对 FlinkKafkaConsumer 做初始化</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration configuration)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="comment">// 创建 Kafka partition 的发现器，用于检测该 subtask 应该去消费哪些 partition</span></span><br><span class="line">    <span class="keyword">this</span>.partitionDiscoverer = createPartitionDiscoverer(</span><br><span class="line">            topicsDescriptor,</span><br><span class="line">            getRuntimeContext().getIndexOfThisSubtask(),</span><br><span class="line">            getRuntimeContext().getNumberOfParallelSubtasks());</span><br><span class="line">    <span class="keyword">this</span>.partitionDiscoverer.open();</span><br><span class="line">    <span class="comment">// subscribedPartitionsToStartOffsets 存储当前 subtask 需要消费的 partition 及对应的 offset 初始信息</span></span><br><span class="line">    subscribedPartitionsToStartOffsets = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="comment">//用 partition 发现器获取该 subtask 应该消费且新发现的 partition</span></span><br><span class="line">    <span class="keyword">final</span> List&lt;KafkaTopicPartition&gt; allPartitions = partitionDiscoverer.discoverPartitions();</span><br><span class="line">    <span class="comment">// restoredState 在 initializeState 时初始化，所以 != null 表示任务从 Checkpoint 处恢复</span></span><br><span class="line">    <span class="keyword">if</span> (restoredState != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (KafkaTopicPartition partition : allPartitions) &#123;</span><br><span class="line">            <span class="comment">// 若分配给该 subtask 的 partition 在 restoredState 中不包含</span></span><br><span class="line">            <span class="comment">// 说明该 partition 是新创建的 partition，默认从 earliest 开始消费</span></span><br><span class="line">              <span class="comment">// 并添加到 restoredState 中</span></span><br><span class="line">            <span class="keyword">if</span> (!restoredState.containsKey(partition)) &#123;</span><br><span class="line">                restoredState.put(partition, KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;KafkaTopicPartition, Long&gt; restoredStateEntry : restoredState.entrySet()) &#123;</span><br><span class="line">            <span class="comment">// 遍历 restoredState，使用分配器检测当前的 partition 是否分配给当前的 subtask</span></span><br><span class="line">            <span class="comment">// assign 方法返回当前 partition 应该分配的 subtask index 编号</span></span><br><span class="line">            <span class="comment">// getRuntimeContext().getIndexOfThisSubtask()  返回当前 subtask 的 index 编号</span></span><br><span class="line">            <span class="keyword">if</span> (KafkaTopicPartitionAssigner.assign(</span><br><span class="line">                restoredStateEntry.getKey(), getRuntimeContext().getNumberOfParallelSubtasks())</span><br><span class="line">                    == getRuntimeContext().getIndexOfThisSubtask())&#123;</span><br><span class="line">                <span class="comment">// 如果当前遍历的 partition 分配给当前 subtask 来消费，则将 partition 信息加到  subscribedPartitionsToStartOffsets 中</span></span><br><span class="line">                subscribedPartitionsToStartOffsets.put(restoredStateEntry.getKey(), restoredStateEntry.getValue());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// else 表示任务不是从 Checkpoint 处恢复，本次源码主要分析状态恢复，不考虑该情况</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对 offset 信息快照相关的源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(FunctionSnapshotContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="comment">// 把旧的 offset 信息从 unionOffsetStates 清除掉</span></span><br><span class="line">    unionOffsetStates.clear();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> AbstractFetcher&lt;?, ?&gt; fetcher = <span class="keyword">this</span>.kafkaFetcher;</span><br><span class="line">    <span class="comment">// 通过提取器从 Kafka 读取数据，若 fetcher == null 表示提取器还未初始化</span></span><br><span class="line">    <span class="keyword">if</span> (fetcher == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// Kafka 提取器还未初始化，说明还未从 Kafka 中读取数据</span></span><br><span class="line">                <span class="comment">// 所以遍历 subscribedPartitionsToStartOffsets，将 offset 的初始信息写入到状态中</span></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;KafkaTopicPartition, Long&gt; subscribedPartition : subscribedPartitionsToStartOffsets.entrySet()) &#123;</span><br><span class="line">            unionOffsetStates.add(Tuple2.of(subscribedPartition.getKey(), subscribedPartition.getValue()));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (offsetCommitMode == OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">            <span class="comment">// 将 offset put 到 pendingOffsetsToCommit，后续 Commit 到 Kafka </span></span><br><span class="line">            pendingOffsetsToCommit.put(context.getCheckpointId(), restoredState);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 从 Kafka 提取器中获取该 subtask 订阅的 partition 当前消费的 offset 信息</span></span><br><span class="line">        HashMap&lt;KafkaTopicPartition, Long&gt; currentOffsets = fetcher.snapshotCurrentState();</span><br><span class="line">        <span class="keyword">if</span> (offsetCommitMode == OffsetCommitMode.ON_CHECKPOINTS) &#123;</span><br><span class="line">            <span class="comment">// 将 offset put 到 pendingOffsetsToCommit，后续 Commit 到 Kafka </span></span><br><span class="line">            pendingOffsetsToCommit.put(context.getCheckpointId(), currentOffsets);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;KafkaTopicPartition, Long&gt; kafkaTopicPartitionLongEntry : currentOffsets.entrySet()) &#123;</span><br><span class="line">            <span class="comment">// 将该 subtask 订阅的 partition 以及当前 partition 消费到的 offset 写入到状态中</span></span><br><span class="line">            unionOffsetStates.add(</span><br><span class="line">                    Tuple2.of(kafkaTopicPartitionLongEntry.getKey(), kafkaTopicPartitionLongEntry.getValue()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述源码分析描述了，当 Checkpoint 时 FlinkKafkaConsumer 如何将 offset 信息保存到状态中，当任务从 Checkpoint 处恢复时 FlinkKafkaConsumer 如何从状态中获取相应的 offset 信息，并解答了当 Source 并行度改变时 FlinkKafkaConsumer 如何来恢复 offset 信息。</p><h4 id="如何实现自动发现当前消费-topic-下新增的-partition"><a href="#如何实现自动发现当前消费-topic-下新增的-partition" class="headerlink" title="如何实现自动发现当前消费 topic 下新增的 partition"></a>如何实现自动发现当前消费 topic 下新增的 partition</h4><p>当 FlinkKafkaConsumer 初始化时，每个 subtask 会订阅一批 partition，但是当 Flink 任务运行过程中，如果被订阅的 topic 创建了新的 partition，FlinkKafkaConsumer 如何实现动态发现新创建的 partition 并消费呢？</p><p>在使用 FlinkKafkaConsumer 时，可以通过 Properties 传递一些配置参数，当配置了参数FlinkKafkaConsumerBase.KEY_PARTITION<em>DISCOVERY_INTERVAL</em>MILLIS 时，就会开启 partition 的动态发现，该参数表示间隔多久检测一次是否有新创建的 partition。那具体实现原理呢？相关源码的 UML 图如下所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-15-132311.png" alt="img"></p><p>笔者生产环境使用的 FlinkKafkaConsumer011，FlinkKafkaConsumer011 继承 FlinkKafkaConsumer09，FlinkKafkaConsumer09 继承 FlinkKafkaConsumerBase。将参数 KEY_PARTITION<em>DISCOVERY_INTERVAL_MILLIS 传递给 FlinkKafkaConsumer011 时，在 FlinkKafkaConsumer09 的构造器中会调用 getLong(checkNotNull(props, “props”), KEY_PARTITION_DISCOVERY_INTERVAL</em>MILLIS, PARTITION_DISCOVERY_DISABLED) 解析该参数，并最终赋值给 FlinkKafkaConsumerBase 的 discoveryIntervalMillis 属性。后续相关源码如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FlinkKafkaConsumerBase 的 run 方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;T&gt; sourceContext)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">      ...</span><br><span class="line">    <span class="keyword">if</span> (discoveryIntervalMillis == PARTITION_DISCOVERY_DISABLED) &#123;</span><br><span class="line">            kafkaFetcher.runFetchLoop();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// discoveryIntervalMillis 被设置了，则开启 PartitionDiscovery</span></span><br><span class="line">            runWithPartitionDiscovery();</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// runWithPartitionDiscovery 方法会调用 createAndStartDiscoveryLoop 方法</span></span><br><span class="line"><span class="comment">// createAndStartDiscoveryLoop 方法内创建了一个线程去循环检测发现新分区</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">createAndStartDiscoveryLoop</span><span class="params">(AtomicReference&lt;Exception&gt; discoveryLoopErrorRef)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//  创建一个线程去循环检测发现新分区</span></span><br><span class="line">    discoveryLoopThread = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">        <span class="keyword">while</span> (running) &#123;</span><br><span class="line">            <span class="keyword">final</span> List&lt;KafkaTopicPartition&gt; discoveredPartitions;</span><br><span class="line">            <span class="comment">//  用 partition 发现器获取该 subtask 应该消费且新发现的 partition</span></span><br><span class="line">            discoveredPartitions = partitionDiscoverer.discoverPartitions();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 发现了新的 partition，则添加到 Kafka 提取器</span></span><br><span class="line">            <span class="keyword">if</span> (running &amp;&amp; !discoveredPartitions.isEmpty()) &#123;</span><br><span class="line">                <span class="comment">//  kafkaFetcher 添加 新发现的 partition</span></span><br><span class="line">                kafkaFetcher.addDiscoveredPartitions(discoveredPartitions);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (running &amp;&amp; discoveryIntervalMillis != <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">//  sleep 设置的间隔时间</span></span><br><span class="line">                Thread.sleep(discoveryIntervalMillis);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="string">&quot;Kafka Partition Discovery for &quot;</span> + getRuntimeContext().getTaskNameWithSubtasks());</span><br><span class="line"></span><br><span class="line">    discoveryLoopThread.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>discoveryLoopThread 线程中每间隔 discoveryIntervalMillis 时间会调用 partition 发现器获取该 subtask 应该消费且新发现的 partition，在 open 方法初始化时，同样也调用 partitionDiscoverer.discoverPartitions() 方法来获取新发现的 partition，partition 发现器的 discoverPartitions 方法第一次调用时，会返回该 subtask 所有的 partition，后续调用只会返回新发现的且应该被当前 subtask 消费的 partition。discoverPartitions 方法源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;KafkaTopicPartition&gt; <span class="title">discoverPartitions</span><span class="params">()</span> <span class="keyword">throws</span> WakeupException, ClosedException </span>&#123;</span><br><span class="line">    List&lt;KafkaTopicPartition&gt; newDiscoveredPartitions;</span><br><span class="line">    <span class="comment">// 获取订阅的 Topic 的所有 partition </span></span><br><span class="line">    newDiscoveredPartitions = getAllPartitionsForTopics(topicsDescriptor.getFixedTopics());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 剔除 旧的 partition 和 不应该被该 subtask 去消费的 partition</span></span><br><span class="line">    Iterator&lt;KafkaTopicPartition&gt; iter = newDiscoveredPartitions.iterator();</span><br><span class="line">    KafkaTopicPartition nextPartition;</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        nextPartition = iter.next();</span><br><span class="line">        <span class="comment">// setAndCheckDiscoveredPartition 方法设计比较巧妙，</span></span><br><span class="line">          <span class="comment">// 将旧的 partition 和 不应该被该 subtask 消费的 partition，返回 false</span></span><br><span class="line">        <span class="comment">// 将这些partition 剔除，就是新发现的 partition</span></span><br><span class="line">        <span class="keyword">if</span> (!setAndCheckDiscoveredPartition(nextPartition)) &#123;</span><br><span class="line">            iter.remove();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> newDiscoveredPartitions;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// discoveredPartitions 中存放着所有发现的 partition</span></span><br><span class="line"><span class="keyword">private</span> Set&lt;KafkaTopicPartition&gt; discoveredPartitions = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// setAndCheckDiscoveredPartition 方法实现</span></span><br><span class="line"><span class="comment">// 当参数的 partition 是新发现的 partition 且应该被当前 subtask 消费时，返回 true</span></span><br><span class="line"><span class="comment">// 旧的 partition 和 不应该被该 subtask 消费的 partition，返回 false</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">setAndCheckDiscoveredPartition</span><span class="params">(KafkaTopicPartition partition)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// discoveredPartitions 中不存在，表示发现了新的 partition，将其加入到 discoveredPartitions  </span></span><br><span class="line">    <span class="keyword">if</span> (!discoveredPartitions.contains(partition)) &#123;</span><br><span class="line">        discoveredPartitions.add(partition);</span><br><span class="line">        <span class="comment">// 再通过分配器来判断该 partition 是否应该被当前 subtask 去消费</span></span><br><span class="line">        <span class="keyword">return</span> KafkaTopicPartitionAssigner.assign(partition, numParallelSubtasks) == indexOfThisSubtask;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码中依赖 Set 类型的 discoveredPartitions 来判断 partition 是否是新的 partition，刚开始 discoveredPartitions 是一个空的 Set，所以任务初始化第一次调用发现器的 discoverPartitions 方法时，会把所有属于当前 subtask 的 partition 都返回，来保证所有属于当前 subtask 的 partition 都能被消费到。之后任务运行过程中，若创建了新的 partition，则新 partition 对应的那一个 subtask 会自动发现并从 earliest 位置开始消费，新创建的 partition 对其他 subtask 并不会产生影响。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 保证Exactly Once[1]</title>
      <link href="2019/12/10/Flink-%E4%BF%9D%E8%AF%81Exactly-Once-1/"/>
      <url>2019/12/10/Flink-%E4%BF%9D%E8%AF%81Exactly-Once-1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在分布式场景下，应用程序随时可能出现任何形式的故障，例如：机器硬件故障、程序 OOM 等。当应用程序出现故障时，Flink 为了保证数据消费的 Exactly Once，需要有相应的故障容错能力。Flink 是通过周期性 Checkpoint 的方式来实现故障容错，这里使用的是基于 Chandy-Lamport 改进的算法。</p><a id="more"></a><h3 id="Flink-内部如何保证-Exactly-Once？"><a href="#Flink-内部如何保证-Exactly-Once？" class="headerlink" title="Flink 内部如何保证 Exactly Once？"></a>Flink 内部如何保证 Exactly Once？</h3><p>Flink 官网的定义是 Stateful Computations over Data Streams（数据流上的有状态计算），那到底什么是状态呢？举一个无状态计算的例子，比如：我们只是进行一个字符串拼接，输入 a，输出a_666；输入b，输出 b_666。无状态表示计算输出的结果跟之前的状态没关系，符合幂等性。</p><p>幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生副作用。而计算 PV、UV 就属于有状态计算。实时计算 PV 时，每次都需要从某个存储介质的结果表中拿到之前的 PV 值，+1 后 set 到结果表中。有状态计算表示输出的结果跟之前的状态有关系，不符合幂等性，访问多次，PV 会增加。</p><h4 id="Flink-的-Checkpoint-功能简介"><a href="#Flink-的-Checkpoint-功能简介" class="headerlink" title="Flink 的 Checkpoint 功能简介"></a>Flink 的 Checkpoint 功能简介</h4><p><strong>Flink Checkpoint 机制的存在就是为了解决 Flink 任务在运行过程中由于各种原因导致任务失败后，能够正常恢复任务。</strong></p><p><strong>Checkpoint 是通过给程序做快照的方式使得将整个程序某些时刻的状态保存下来，当任务挂掉之后，默认从最近一次保存的完整快照处进行恢复任务。</strong></p><p>SnapShot 翻译为快照，是指将程序中某些信息存一份，后期可以用这些信息来恢复任务。对于一个 Flink 任务来讲，快照里面到底保存着什么信息呢？理论知识一般比较晦涩难懂，我们分析一个案例，用案例辅助大家理解快照里面到底存储什么信息。</p><blockquote><p>计算各个 app 的 PV，使用 Flink 该怎么统计呢？</p></blockquote><p>可以把要统计的 app_id 做为 key，对应的 PV 值做为 value，将统计的结果放到一个 Map 集合中，这个 Map 集合可以是内存里的 HashMap 或其他 kv 数据库，例如放到 Redis 的 key、value 结构中。从 Kafka 读取到一条条日志，由于要统计各 app 的 PV，所以我们需要从日志中解析出 app_id 字段，每来一条日志，只需要从 Map 集合将相应 app_id 的 PV 值拿出来，+1 后 put 到 Map 中，这样我们的 Map 中永远保存着所有 app 最新的 PV 数据。详细流程如下所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151541.jpg" alt="flink任务task图.png"></p><p>图中包含三部分：第一个是 Kafka 的一个名为 test 的 Topic，我们的数据来源于这个 Topic，第二个是 Flink 的 Source Task，是 Flink 应用程序读取数据的 Task，第三个是计算 PV 的 Flink Task，用于统计各个 app 的 PV 值，并将 PV 结果输出到 Map 集合。</p><p>Flink 的 Source Task 记录了当前消费到 test Topic 所有 partition 的 offset，为了方便理解 Checkpoint 的作用，这里先用一个 partition 进行讲解，假设名为 test 的 Topic 只有一个 partition0。</p><p>例：(0,60000) 表示 0 号 partition，目前消费到 offset 为 60000 的数据。Flink 的 PV task 记录了当前计算的各 app 的 PV 值，为了方便讲解，这里假设有两个 app：app1、app2。</p><p>例：(app1,50000) (app2,10000) 表示 app1 当前 PV 值为50000、app2 当前 PV 值为 10000。计算过程中，每来一条数据，只需要确定相应 app_id，将相应的 PV 值 +1 后 put 到 map 中即可。</p><p>该案例中，Checkpoint 到底记录了什么信息呢？记录的其实就是第 n 次 Checkpoint 消费的 offset 信息和各 app 的 PV 值信息，记录下发生 Checkpoint 当前的状态信息，并将该状态信息保存到相应的状态后端。（注：<strong>状态后端是保存状态的地方</strong>，决定状态如何保存，如何保证状态高可用，我们只需要知道，我们能从状态后端拿到 offset 信息和 PV 信息即可。状态后端必须是高可用的，否则我们的状态后端经常出现故障，会导致无法通过 Checkpoint 来恢复我们的应用程序）。下面列出了第 100 次 Checkpoint 的时候，状态后端保存的状态信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chk-100</span><br><span class="line">    - offset：(0,60000)</span><br><span class="line">    - PV：(app1,50000) (app2,10000)</span><br></pre></td></tr></table></figure><p>该状态信息表示第 100 次 Checkpoint 的时候，partition 0 offset 消费到了 60000，PV 统计结果为 (app1,50000) (app2,10000)。如果任务挂了，如何恢复？</p><p>假如我们设置了一分钟进行一次 Checkpoint，第 100 次 Checkpoint 成功后，过了十秒钟，offset 已经消费到 (0,60100)，PV 统计结果变成了 (app1,50080) (app2,10020)，突然任务挂了，怎么办？</p><p>其实很简单，Flink 只需要从最近一次成功的 Checkpoint，也就是从第 100 次 Checkpoint 保存的 offset(0,60000) 处接着消费即可，当然 PV 值也要从第 100 次 Checkpoint 里保存的 PV 值 (app1,50000) (app2,10000) 进行累加，不能从 (app1,50080) (app2,10020) 处进行累加，因为 **partition 0 offset 消费到 60000 时，对应的 PV 统计结果为 (app1,50000) (app2,10000)**。</p><p>当然如果你想从 offset(0,60100)、PV(app1,50080)(app2,10020) 这个状态恢复，也是做不到的，因为那个时刻程序突然挂了，这个状态根本没有保存下来，只有在 Checkpoint 的时候，才会把这些完整的状态保存到状态后端，供我们恢复任务。我们能做的最高效方式就是从最近一次成功的 Checkpoint 处恢复，也就是一直所说的 chk-100。以上基本就是 Checkpoint 承担的工作，为了方便理解，描述的业务场景比较简单。</p><p>补充两个问题：计算 PV 的 task 在一直运行，它怎么知道什么时候去做 Checkpoint 呢？计算 PV 的 task 怎么保证它自己计算的 PV 值 (app1,50000) (app2,10000) 就是 offset(0,60000) 那一刻的统计结果呢？Flink 在数据中加了一个叫做 barrier 的东西，下图中红圈处就是两个 barrier。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151548.jpg" alt="img"></p><p>barrier 从 Source Task 处生成，一直流到 Sink Task，期间所有的 Task 只要碰到 barrier，就会触发自身进行快照。如图所示，Checkpoint barrier n-1 处做的快照就是指 Job 从开始处理到 barrier n-1 所有的状态数据，barrier n 处做的快照就是指从 Job 开始到处理到 barrier n 所有的状态数据。</p><p>对应到 PV 案例中就是，Source Task 接收到 JobManager 的编号为 chk-100 的 Checkpoint 触发请求后，发现自己恰好接收到 Kafka offset(0,60000) 处的数据，所以会往 offset(0,60000) 数据之后 offset(0,60001) 数据之前插入一个barrier，然后自己开始做快照，也就是将 offset(0,60000) 保存到状态后端 chk-100 中。</p><p>然后，Source Task 会把 barrier 和我们要处理的数据一块往下游发送，当统计 PV 的 task 接收到 barrier 后，意味着 barrier 之前的数据已经被 PV task 处理完了，此时也会暂停处理 barrier 之后的数据，将自己内存中保存的 PV 信息 (app1,50000) (app2,10000) 保存到状态后端 chk-100 中。Flink 大概就是通过以上过程来保存快照的。</p><p>上述过程中，barrier 的作用就是为了把数据区分开，barrier 之前的数据是本次 Checkpoint 之前必须处理完的数据，barrier 之后的数据在本次 Checkpoint 之前不能被处理。</p><p>Checkpoint 过程中有一个同步做快照的环节不能处理 barrier 之后的数据，为什么呢？如果做快照的同时，也在处理数据，那么处理的数据可能会修改快照内容，所以先暂停处理数据，把内存中快照保存好后，再处理数据。</p><p>结合案例来讲就是，PV task 在对 (app1,50000)、(app2,10000) 做快照的同时，如果 barrier 之后的数据还在处理，可能会导致状态信息还没保存到磁盘，状态已经变成了 (app1,50001) (app2,10001)，导致我们最后快照里保存的 PV 值变成了 (app1,50001) (app2,10001)，这样如果从 Checkpoint 恢复任务时，我们从 offset 60000 开始消费，PV 值从 (app1,50001) (app2,10001) 开始累加，就会造成计算的 PV 结果偏高，结果不准确，就不能保证 Exactly Once。</p><p>所以，Checkpoint 同步做快照的过程中，不能处理 barrier 之后的数据。Checkpoint 将快照信息写入到磁盘后，为了保证快照信息的高可用，需要将快照上传到 HDFS，这个上传快照到 HDFS 的过程是异步进行的，这个过程也可以处理 barrier 之后的数据，处理 barrier 之后的数据不会影响到磁盘上的快照信息。</p><p>从 PV 案例再分析 Flink 是如何做 Checkpoint 并从 Checkpoint 处恢复任务的，首先 JobManager 端会向所有 SourceTask 发送 Checkpoint，Source Task 会在数据流中安插 Checkpoint barrier。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151547.jpg" alt="单并行度 PV 案例 Checkpoint 过程图示1"></p><p>Source Task 安插好 barrier 后，会将 barrier 跟数据一块发送给下游，然后自身开始做快照，并将快照信息 offset(0,60000) 发送到高可用的持久化存储介质，例如 HDFS 上。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151542.jpg" alt="单并行度 PV 案例 Checkpoint 过程图示2"></p><p>下游的 PV task 接收到 barrier 后，也会做快照，并将快照信息 PV：(app1,50000) (app2,10000) 发送到 HDFS。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151543.jpg" alt="img"></p><p>假设第 100 次 Checkpoint 完成后，一段时间后任务挂了，Flink 任务会自动从状态后端恢复任务。Source Task 去读取自己需要的状态信息 offset(0,60000)，并从 offset 为 60000 的位置接着开始消费数据，PV task 也会去读取需要的状态信息 PV：(app1,50000) (app2,10000)，并在该状态值的基础上，往上累积计算 PV 值。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151544.jpg" alt="img"></p><h4 id="多并行度、多-Operator-情况下，Checkpoint-的过程"><a href="#多并行度、多-Operator-情况下，Checkpoint-的过程" class="headerlink" title="多并行度、多 Operator 情况下，Checkpoint 的过程"></a>多并行度、多 Operator 情况下，Checkpoint 的过程</h4><p>上一节中讲述了单并行度情况下 Checkpoint 的过程，但是生产环境中，一般都是多并行度，而且算子也会比较多，这种情况下 Checkpoint 的过程就会变得复杂。分布式状态容错面临的问题与挑战：</p><ul><li>如何确保状态拥有<strong>精确一次</strong>的容错保证？</li><li>如何在分布式场景下替多个拥有本地状态的算子产生<strong>一个全域一致的快照</strong>？</li><li>如何在<strong>不中断运算</strong>的前提下产生快照？</li></ul><p>多并行度、多 Operator 实例的情况下，如何做全域一致的快照？所有的 Operator 运行过程中接收到所有上游算子发送 barrier 后，对自身的状态进行一次快照，保存到相应状态后端。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151553.jpg" alt="img"></p><p>当任务从状态恢复时，每个 Operator 从状态后端读取自己相应的状态信息，数据源会从状态中保存的位置开始重新消费，后续的其他算子也会基于 Checkpoint 中保存的状态进行计算。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151556.jpg" alt="多并行度下，任务从 Checkpoint 恢复图示"></p><p>整个 Checkpoint 的过程跟之前单并行度类似，图中有 4 个带状态的 Operator 实例，相应的状态后端就可以想象成 4 个格子。整个 Checkpoint 的过程可以当做 Operator 实例填自己格子的过程，Operator 实例将自身的状态写到状态后端中相应的格子，当所有的格子填满可以简单地认为一次完整的 Checkpoint 做完了。</p><p>上面只是快照的过程，Checkpoint 执行过程如下：</p><p>\1. JobManager 端的 CheckPointCoordinator 向所有 Source Task 发送 CheckPointTrigger，Source Task 会在数据流中安插 Checkpoint barrier。</p><p>\2. 当 task 收到所有的 barrier 后，向自己的下游继续传递 barrier，然后自身执行快照，并将自己的状态<strong>异步写入到持久化存储</strong>中。</p><ul><li>增量 CheckPoint 只是把最新的一部分数据更新写入到外部存储；</li><li>为了下游尽快开始做 CheckPoint，所以会先发送 barrier 到下游，自身再同步进行快照。</li></ul><p>\3. 当 task 对状态的快照信息完成备份后，会将备份数据的地址（state handle）通知给 JobManager 的 CheckPointCoordinator。</p><ul><li>如果 Checkpoint 的持续时长超过了 Checkpoint 设定的超时时间，CheckPointCoordinator 还没有收集完所有的 State Handle，CheckPointCoordinator就会认为本次 Checkpoint 失败，会把这次 Checkpoint 产生的所有状态数据全部删除。</li></ul><p>\4. CheckPointCoordinator 把整个 StateHandle 封装成 completed Checkpoint Meta，写入到 HDFS，整个 Checkpoint 结束。</p><h4 id="barrier-对齐"><a href="#barrier-对齐" class="headerlink" title="barrier 对齐"></a>barrier 对齐</h4><p>什么是 barrier 对齐？如图所示，当前的 Operator 实例接收上游两个流的数据，一个是字母流，一个是数字流。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151558.jpg" alt="img"></p><p>当 Checkpoint 时，上游字母流和数字流都会往 Operator 实例发送 Checkpoint barrier，但是由于每个算子的执行速率不同，所以不可能保证上游两个流的 barrier 同时到达 Operator 实例，那图中的 Operator 实例到底什么时候进行快照呢？接收到任意一个 barrier 就可以开始进行快照了吗，还是接收到所有的 barrier 才能开始进行快照呢？</p><p>答案是：当一个 Operator 实例有多个输入流时，Operator 实例需要在做快照之前进行 barrier 对齐，等待所有输入流的 barrier 都到达。barrier 对齐的详细过程如下所示：</p><ol><li>对于一个有多个输入流的 Operator 实例，当 Operator 实例从其中一个输入流接收到 Checkpoint barrier n 时，就不能处理来自该流的任何数据记录了，直到它从其他所有输入流接收到 barrier n 为止，否则 <strong>Operator 实例 Checkpoint n 的快照会混入快照 n 的记录和快照 n+1 的记录</strong>。如上图中第 1 个小图所示，数字流的 barrier 先到达了。</li><li>接收到 barrier n 的流暂时被搁置，从这些流接收的记录不会被处理，而是放入输入缓冲区。图 2 中，我们可以看到虽然数字流对应的 barrier 已经到达了，但是 barrier 之后的 1、2、3 这些数据只能放到缓冲区中，等待字母流的 barrier 到达。</li><li>一旦最后所有输入流都接收到 barrier n，Operator 实例就会把 barrier 之前所有已经处理完成的数据和 barrier n 一块发送给下游。然后 Operator 实例就可以对状态信息进行快照。如图 3 所示，Operator 实例接收到上游所有流的 barrier n，此时 Operator 实例就可以将 barrier 和 barrier 之前的数据发送到下游，然后自身状态进行快照。</li><li>快照做完后，Operator 实例将继续处理缓冲区的记录，然后就可以处理输入流的数据。如图 4 所示，先处理完缓冲区数据，就可以正常处理输入流的数据了。</li></ol><p>上面的过程就是 Flink 在 Operator 实例有多个输入流的情况下，整个 barrier 对齐的过程。那什么是 barrier 不对齐呢？</p><p>barrier 不对齐是指当还有其他流的 barrier 还没到达时，为了提高 Operator 实例的处理性能，Operator 实例会直接处理 barrier 之后的数据，等到所有流的barrier 都到达后，就可以对该 Operator 做 Checkpoint 快照了。</p><p>对应到图中就是，barrier 不对齐时会直接把 barrier 之后的数据 1、2、3 直接处理掉，而<strong>不是</strong>放到缓冲区中等待其他的输入流的 barrier 到达，当所有输入流的 barrier 都到达后，才开始对 Operator 实例的状态信息进行快照，这样会导致做快照之前，Operator 实例已经处理了一些 barrier n 之后的数据。</p><p>Checkpoint 的目的是为了保存快照信息，如果 barrier 不对齐，那么 Operator 实例在做第 n 次 Checkpoint 之前，已经处理了一些 barrier n 之后的数据，当程序从第 n 次 Checkpoint 恢复任务时，程序会从第 n 次 Checkpoint 保存的 offset 位置开始消费数据，就会导致一些数据被处理了两次，就出现了重复消费。如果进行 barrier 对齐，就不会出现这种重复消费的问题，所以，<strong>barrier 对齐就可以实现 Exactly Once，barrier 不对齐就变成了 At Least Once。</strong></p><p>再结合计算 PV 的案例来证明一下，为什么 barrier 对齐就可以实现 Exactly Once，barrier 不对齐就变成了 At Least Once。之前的案例为了简单，描述的 Kafka topic 只有 1 个 partition，这里为了讲述 barrier 对齐，假设 topic 有 2 个 partittion，且计算的是我们平台的总 PV，也就是说不需要区分 app，每条一条数据，我们都需要将其 PV 值 +1 即可。如下图所示，Flink 应用程序有两个 Source Task，一个计算 PV 的 Task，这里计算 PV 的 Task 就出现了存在多个输入流的情况。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151546.jpg" alt="img"></p><p>假设 barrier 不对齐，那么 Checkpoint 过程是怎么样呢？</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151554.jpg" alt="img"></p><p>如左图所示，Source Subtask 0 和 Subtask 1 已经完成了快照操作，它们的状态信息为 offset(0,10000)(1,10005)，表示 partition0 消费到 offset 为 10000 的位置，partition 1 消费到 offset 为 10005 的位置。当 Source Subtask 1 的 barrier 到达 PV task 时，计算的 PV 结果为 20002，但 PV task 还没有接收到 Source Subtask 0 发送的 barrier，所以 PV task 还不能对自身状态信息进行快照。由于设置的 barrier 不对齐，所以此时 PV task 会继续处理 Source Subtask 0 和 Source Subtask 1 传来的数据。</p><p>很快，如右图所示，PV task 接收到 Source Subtask 0 发来的 barrier，但是 PV task 已经处理了 Source Subtask 1 barrier 之后的三条数据，所以 PV 值目前已经为 20008 了，这里的 PV=20008 实际上已经处理到 partition 1 offset 为 10008 的位置，此时 PV task 会对自身的状态信息（PV = 20008）做快照，整体的快照信息为 offset(0,10000)(1,10005) PV=20008。</p><p>接着程序在继续运行，过了 10 秒，由于某个服务器故障，导致我们的 Operator 实例有一个挂了，所以 Flink 会从最近一次 Checkpoint 保存的状态恢复。那具体是怎么恢复的呢？</p><p>Flink 同样会起三个 Operator 实例，我还称它们是 Source Subtask 0、Source Subtask 1 和 PV task。三个 Operator 会从状态后端读取保存的状态信息。Source Subtask 0 会从 partition 0 offset 为 10000 的位置开始消费，Source Subtask 1 会从 partition 1 offset 为 10005 的位置开始消费，PV task 会基于 PV=20008 进行累加统计。然后就会发现的 PV 值 20008 实际上已经包含了 partition 1 的offset 10005<del>10008 的数据，所以 partition 1 从 offset 10005 恢复任务时，partition1 的 offset 10005</del>10008 的数据被消费了两次，出现了重复消费的问题，所以 barrier 不对齐只能保证 At Least Once。</p><p>如果设置为 barrier 对齐，这里能保证 Exactly Once 吗？如下图所示，当 PV task 接收到 Source Subtask 1 的 barrier 后，并不会处理 Source Subtask 1 barrier 之后的数据，而是把这些数据放到 PV task 的输入缓冲区中，直到等到 Source Subtask 0 的 barrier 到达后，PV task 才会对自身状态信息进行快照。</p><p>此时 PV task 会把 PV=20005 保存到快照信息中，整体的快照状态信息为 offset(0,10000)(1,10005) PV=20005，当任务从 Checkpoint 恢复时，Source Subtask 0 会从 partition 0 offset 为 10000 的位置开始消费，Source Subtask 1 会从 partition 1 offset 为 10005 的位置开始消费，PV task 会基于 PV=20005 进行累加统计，所以 barrier 对齐能保证 Flink 内部的 Exactly Once。</p><p>在 Flink 应用程序中，当 Checkpoint 语义设置 Exactly Once 或 At Least Once 时，唯一的区别就是 barrier 对不对齐。当设置为 Exactly Once 时，就会 barrier 对齐，当设置为 At Least Once 时，就会 barrier 不对齐。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151555.jpg" alt="img"></p><p>通过本案例，我们应该发现了 barrier 在 Flink 的 Checkpoint 中起着非常大的作用。barrier 告诉 Flink 应用程序，Checkpoint 之前哪些数据不应该被处理，barrier 对齐的过程其实就是为了防止 Flink 应用程序处理重复的数据。</p><p>总结一下，满足哪些条件时，会出现 barrier 对齐？在代码中设置了 Flink 的 Checkpoint 语义是 Exactly Once，其次 Operator 实例必须有多个输入流才会出现 barrier 对齐。</p><p>对齐，汉语词汇，释义为使两个以上事物配合或接触得整齐。由汉语解释可得对齐肯定需要两个以上事物，所以必须有多个输入流才可能存在对齐。</p><p>barrier 对齐就是上游多个流配合使得数据对齐的过程。言外之意：如果 Operator 实例只有一个输入流，就根本不存在 barrier 对齐，自己跟自己默认永远都是对齐的，所以当我们的应用程序从 Source 到 Sink 所有算子的并行度都是 1 的话，就算设置的 At Least Once，无形中也实现了 barrier 对齐，此时 Checkpoint 设置成 Exactly Once 和 At Least Once 一点区别都没有，都可以保证 Exactly Once。</p><p>看到这里你应该已经知道了哪种情况会出现重复消费了，也应该要掌握为什么 barrier 对齐就能保证 Exactly Once，为什么 barrier 不对齐就是 At Least Once。</p><p>barrier 对齐其实是要付出代价的，从 barrier 对齐的过程可以看出，PV task 明明可以更高效的处理数据，但因为 barrier 对齐，导致 Source Subtask 1 barrier 之后的数据被放到缓冲区中，暂时性地没有被处理，假如生产环境中，Source Subtask 0 的 barrier 迟迟没有到达，比 Source Subtask 1 延迟了 30 秒，那么这 30 秒期间，Source Subtask 1 barrier 之后的数据不能被处理，所以 PV task 相当于被闲置了。</p><p>所以，当我们的一些业务场景对 Exactly Once 要求不高时，我们可以设置 Flink 的 Checkpoint 语义是 At Least Once 来小幅度的提高应用程序的执行效率。Flink Web UI 的 Checkpoint 选项卡中可以看到 barrier 对齐的耗时，如果发现耗时比较长，且对 Exactly Once 语义要求不高时，可以考虑使用该优化方案。</p><p>前面提到如何在不中断运算的前提下产生快照？在 Flink 的 Checkpoint 过程中，无论下游算子有没有做完快照，只要上游算子将 barrier 发送到下游且上游算子自身已经做完快照时，那么上游算子就可以处理 barrier 之后的数据了，从而使得整个系统 Checkpoint 的过程影响面尽量缩到最小，来提升系统整体的吞吐量。</p><p>在整个 Checkpoint 的过程中，还存在一个问题，假设我们设置的 10 分钟一次 Checkpoint。在第 n 次 Checkpoint 成功后，过了 9 分钟，任务突然挂了，我们需要从最近一次成功的 Checkpoint 处恢复任务，也就是从 9 分钟之前的状态恢复任务，就需要把这 9分钟的数据全部再消费一次，成本比较大。</p><p>有的同学可能会想，那可以不可以设置为 100ms 就做一次 Checkpoint 呢？这样的话，当任务出现故障时，就不需要从 9 分钟前的状态进行恢复了，直接从 100ms 之前的状态恢复即可，恢复就会很快，不需要处理大量重复数据了。</p><p>但是，这样做会导致应用程序频繁的访问状态后端，一般我们为了高可用，会把状态里的数据比如 offset(0,60000) PV(app1,50000)(app2,10000) 信息保存到 HDFS 中，如果频繁访问 HDFS，肯定会造成吞吐量下降，所以一般我们的 Checkpoint 时间间隔可以设置为分钟级别，例如 1 分钟、3 分钟，对于状态很大的任务每次 Checkpoint 访问 HDFS 比较耗时，我们甚至可以设置为 5 分钟一次 Checkpoint，毕竟我们的应用程序挂的概率并不高，偶尔一次从 5 分钟前的状态恢复，我们是可以接受的。</p><p>可以根据业务场景合理地调节 Checkpoint 的间隔时长，对于状态很小的 Job Checkpoint 会很快，我们可以调小时间间隔，对于状态比较大的 Job Checkpoint 会比较慢，我们可以调大 Checkpoint 时间间隔。</p><p>有的同学可能还有疑问，明明说好的 Exactly Once，但在 Checkpoint 成功后 10s 发生了故障，从最近一次成功的 Checkpoint 处恢复时，由于发生故障前的 10s Flink 也在处理数据，所以 Flink 应用程序肯定是把一些数据重复处理了呀。</p><p>在面对任意故障时，不可能保证每个算子中用户定义的逻辑在每个事件中只执行一次，因为用户代码被部分执行的可能性是永远存在的。那么，当引擎声明 Exactly Once 处理语义时，它们能保证什么呢？如果不能保证用户逻辑只执行一次，那么哪些逻辑只执行一次？当引擎声明 Exactly Once 处理语义时，它们实际上是在说，它们可以保证引擎管理的状态更新只提交一次到持久的后端存储。换言之，无论以什么维度计算 PV、无论 Flink 应用程序发生多少次故障导致重启从 Checkpoint 恢复，Flink 都可以保证 PV 结果是准确的，不会因为各种任务重启而导致 PV 值计算偏高。</p><p>为了下游尽快做 Checkpoint，所以会先发送 barrier 到下游，自身再同步进行快照。这一步，如果向下发送 barrier 后，自己同步快照慢怎么办？下游已经同步好了，自己还没？可能会出现下游比上游快照还早的情况，但是这不影响快照结果，只是下游做快照更及时了，我只要保证下游把 barrier 之前的数据都处理了，并且不处理 barrier 之后的数据，然后做快照，那么下游也同样支持 Exactly Once。</p><p>这个问题不要从全局思考，单独思考上游和下游的实例，你会发现上下游的状态都是准确的，既没有丢，也没有重复计算。这里需要注意，如果有一个 Operator 的 Checkpoint 失败了或者因为 Checkpoint 超时也会导致失败，那么 JobManager 会认为整个 Checkpoint 失败。失败的 Checkpoint 是不能用来恢复任务的，必须所有的算子的 Checkpoint 都成功，那么这次 Checkpoint 才能认为是成功的，才能用来恢复任务。</p><p>对应到 PV 案例就是，PV task 做快照速度较快，PV=20005 较早地写入到了 HDFS，但是 offset(0,10000)(1,10005) 过了几秒才写入到 HDFS，这种情况就算出现了，也不会影响计算结果，因为我们的快照信息是完全正确的。</p><p>再分享一个案例，Flink 的 Checkpoint 语义设置了 Exactly Once，程序中设置了 1 分钟 1 次 Checkpoint，5 秒向 MySQL 写一次数据，并 commit。最后发现 MySQL 中数据重复了。为什么会重复呢？Flink 要求端对端的 Exactly Once 都必须实现 TwoPhaseCommitSinkFunction。如果你的 Checkpoint 成功了，过了 30 秒突然程序挂了，由于 5 秒 Commit 一次，所以在应用程序挂之前的 30 秒实际上已经写入了 6 批数据进入 MySQL。从 Checkpoint 处恢复时，之前提交的 6 批数据就会重复写入，所以出现了重复消费。</p><p>Flink 的 Exactly Once 有两种情况，一个是我们本节所讲的 Flink 内部的 Exactly Once，一个是端对端的 Exactly Once。关于端对端如何保证 Exactly Once，我们在下一节中深入分析。</p><h3 id="端对端如何保证-Exactly-Once？"><a href="#端对端如何保证-Exactly-Once？" class="headerlink" title="端对端如何保证 Exactly Once？"></a>端对端如何保证 Exactly Once？</h3><p>Flink 与外部存储介质之间进行数据交互统称为端对端或 end to end 数据传输。上一节讲述了 Flink 内部如何保证 Exactly Once，这一节来分析端对端的 Exactly Once。</p><p>正如上述 Flink 写 MySQL 的案例所示，在第 n 次 Checkpoint 结束后，第 n+1 次 Checkpoint 之前，如果 Flink 应用程序已经向外部的存储介质中成功写入并提交了一些数据后，Flink 应用程序由于某些原因挂了，导致任务从第 n 次 Checkpoint 处恢复。这种情况下，就会导致第 n 次 Checkpoint 结束后且任务失败之前往外部存储介质中写入的那一部分数据重复写入两次，可能会导致相同的数据在存储介质中存储了两份，从而端对端的一致性语义保证从 Exactly Once 退化为 At Least Once。</p><p>这里只考虑了数据重复的情况，为什么不考虑丢数据的情况呢？在写数据时可以对异常进行捕获增加重试策略，如果重试多次还没有成功可以让 Flink 任务失败，Flink 任务就会从最近一次成功的 Checkpoint 处恢复，就不会出现丢数据的情况，所以我们本节内容主要用来解决数据重复的问题。</p><p>针对上述端对端 Exactly Once 的问题，我们可以使用以下方案来解决：</p><ol><li>假如我们使用的存储介质支持按照全局主键去重，那么比较容易实现 Exactly Once，无论相同的数据往外部存储中写入了几次，外部存储都会进行去重，只保留一条数据。例如，app1 的 PV 值为 10，现在把（key=app1，value=10）往 Redis 中写入 10 次，只是说把 value 值覆盖了 10 次，并不会导致结果错误，这种方案属于幂等性写入。</li><li>我们上述案例中为什么会导致重复写入数据到外部存储呢？是因为在下一次 Checkpoint 之前如果任务失败时，一些数据已经成功写入到了外部存储中，没办法删除那些数据。既然问题是这样，那可以想办法把“向外部存储中提交数据”与 Checkpoint 强关联，两次 Checkpoint 之间不允许向外部存储介质中提交数据，Checkpoint 的时候再向外部存储提交。如果提交成功，则 Checkpoint 成功，提交失败，则 Checkpoint 也失败。这样在下一次 Checkpoint 之前，如果任务失败，也没有重复数据被提交到外部存储。这里只是描述一下大概思想，好多细节这里并没有详细描述，会在下文中详细描述。基于上述思想，Flink 实现了 TwoPhaseCommitSinkFunction，它提取了两阶段提交协议的通用逻辑，使得通过 Flink 来构建端到端的 Exactly Once 程序成为可能。它提供了一个抽象层，用户只需要实现少数方法就能实现端到端的 Exactly Once 语义。不过这种方案必须要求我们的输出端（Sink 端）必须支持事务。</li></ol><p>下面我们通过两部分来详细介绍上述两种方案。</p><h4 id="幂等性写入如何保证端对端的-Exactly-Once"><a href="#幂等性写入如何保证端对端的-Exactly-Once" class="headerlink" title="幂等性写入如何保证端对端的 Exactly Once"></a>幂等性写入如何保证端对端的 Exactly Once</h4><p>实时 ETL 当 HBase 做为 Sink 端时，就是典型的应用场景。把日志中的主键做为 HBase 的 rowkey，就可以保证数据不重复，实现比较简单，这里不多赘述。</p><p>继续探讨实时计算各 app PV 的案例，将统计结果以普通键值对的形式保存到 Redis 中供业务方查询。到底如何实现，才能保证 Redis 中的结果是精准的呢？在之前 Strom 或 Spark Streaming 的方案中，将统计的 PV 结果保存在 Redis 中，每来一条数据，从 Redis 中获取相应 app 对应的 PV 值然后内存中进行 +1 后，再将 PV 值 put 到 Redis 中。</p><p>例如：Redis 中保存 app1 的 PV 为 10，现在来了一条 app1 的日志，首先从 Redis 中获取 app1 的 PV 值 =10，内存中 10+1=11，将 (app1,11) put 到 Redis 中，这里的 11 就是我们统计的 app1 的 PV 结果。可以将这种方案优化为 incr 或 incrby，直接对 Redis 中的 10 进行累加，不需要手动在内存中进行累加操作。</p><p>当然 Flink 也可以用上述的这种方案来统计各 app 的 PV，但是上述方案并不能保证 Exactly Once，为什么呢？当第 n 次 Checkpoint 时，app1 的 PV 结果为 10000，第 n 次 Checkpoint 结束后运行了 10 秒，Redis 中 app1 的 PV 结果已经累加到了 10200。此时如果任务挂了，从第 n 次 Checkpoint 恢复任务时，会继续按照 Redis 中保存的 PV=10200 进行累加，但是正确的结果应该是从 PV=10000 开始累加。</p><p>如果按照上面的方案统计 PV，就可能会出现统计值偏高的情况。这里也证实了一点：并不是说 Flink 程序的 Checkpoint 语义设置为 Exactly Once，就能保证我们的统计结果或者各种输出结果都能满足 Exactly Once。为了编写真正满足 Exactly Once 的代码，我们需要对 Flink 的 Checkpoint 原理做一些了解，编写对 Exactly Once 友好的代码。</p><p>那如何编写代码才能使得最后在 Redis 中保存的 PV 结果满足 Exactly Once 呢？上一节中，讲述了 Flink 内部状态可以保证 Exactly Once，这里可以将统计的 PV 结果保存在 Flink 内部的状态里，每次基于状态进行累加操作，并将累加到的结果 put 到 Redis 中，这样当任务从 Checkpoint 处恢复时，并不是基于 Redis 中实时统计的 PV 值进行累加，而是基于 Checkpoint 中保存的 PV 值进行累加，Checkpoint 中会保存每次 Checkpoint 时对应的 PV 快照信息，例如：第 n 次 Checkpoint 会把当时 pv=10000 保存到快照信息里，同时状态后端还保存着一份实时的状态信息用于实时累加。</p><p>示例代码如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// 1 分钟一次 Checkpoint</span></span><br><span class="line">env.enableCheckpointing(TimeUnit.MINUTES.toMillis(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">CheckpointConfig checkpointConf = env.getCheckpointConfig();</span><br><span class="line"><span class="comment">// Checkpoint 语义 EXACTLY ONCE</span></span><br><span class="line">checkpointConf.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line">checkpointConf.enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);</span><br><span class="line"></span><br><span class="line">Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;localhost:9092&quot;</span>);</span><br><span class="line">props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;app-pv-stat&quot;</span>);</span><br><span class="line"></span><br><span class="line">DataStreamSource&lt;String&gt; appInfoSource = env.addSource(<span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">        <span class="comment">// kafka topic， String 序列化</span></span><br><span class="line">        <span class="string">&quot;app-topic&quot;</span>,  <span class="keyword">new</span> SimpleStringSchema(), props));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 按照 appId 进行 keyBy</span></span><br><span class="line">appInfoSource.keyBy((KeySelector&lt;String, String&gt;) appId -&gt; appId)</span><br><span class="line">        .map(<span class="keyword">new</span> RichMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">            <span class="keyword">private</span> ValueState&lt;Long&gt; pvState;</span><br><span class="line">            <span class="keyword">private</span> <span class="keyword">long</span> pv = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">super</span>.open(parameters);</span><br><span class="line">                <span class="comment">// 初始化状态</span></span><br><span class="line">                pvState = getRuntimeContext().getState(</span><br><span class="line">                        <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(<span class="string">&quot;pvStat&quot;</span>,</span><br><span class="line">                        TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Long&gt;() &#123;&#125;)));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Long&gt; <span class="title">map</span><span class="params">(String appId)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="comment">// 从状态中获取该 app 的 PV 值，+1 后，update 到状态中</span></span><br><span class="line">                <span class="keyword">if</span>(<span class="keyword">null</span> == pvState.value())&#123;</span><br><span class="line">                    pv = <span class="number">1</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    pv = pvState.value();</span><br><span class="line">                    pv += <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                pvState.update(pv);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(appId, pv);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">        .print();</span><br><span class="line"></span><br><span class="line">env.execute(<span class="string">&quot;Flink PV stat&quot;</span>);</span><br></pre></td></tr></table></figure><p>详细代码请参考：</p><blockquote><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-examples/src/main/java/com/zhisheng/examples/streaming/checkpoint/PvStatExactlyOnce.java">PvStatExactlyOnce.java</a></p></blockquote><p>代码中设置 1 分钟一次 Checkpoint，Checkpoint 语义 EXACTLY ONCE，从 Kafka 中读取数据，这里为了简化代码，所以 Kafka 中读取的直接就是 String 类型的 appId，按照 appId KeyBy 后，执行 RichMapFunction，RichMapFunction 的 open 方法中会初始化 ValueState<Long> 类型的 pvState，pvState 就是上文一直强调的状态信息，每次 Checkpoint 的时候，会把 pvState 的状态信息快照一份到 HDFS 来提供恢复。</p><p>这里按照 appId 进行 keyBy，所以每一个 appId 都会对应一个 pvState，pvState 里存储着该 appId 对应的 pv 值。每来一条数据都会执行一次 map 方法，当这条数据对应的 appId 是新 app 时，pvState 里就没有存储这个 appId 当前的 pv 值，将 pv 值赋值为 1，当 pvState 里存储的 value 不为 null 时，拿出 pv 值 +1后 update 到 pvState 里。map 方法再将 appId 和 pv 值发送到下游算子，下游直接调用了 print 进行输出，这里完全可以替换成相应的 RedisSink 或 HBaseSink。</p><p>本案例中计算 pv 的工作交给了 Flink 内部的 ValueState，不依赖外部存储介质进行累加，外部介质承担的角色仅仅是提供数据给业务方查询，所以无论下游使用什么形式的 Sink，只要 Sink 端能够按照主键去重，该统计方案就可以保证 Exactly Once。本案例使用的 ValueState，关于 State 的详细使用请参阅第 3.1 节。</p><h4 id="TwoPhaseCommitSinkFunction-如何保证端对端的-Exactly-Once"><a href="#TwoPhaseCommitSinkFunction-如何保证端对端的-Exactly-Once" class="headerlink" title="TwoPhaseCommitSinkFunction 如何保证端对端的 Exactly Once"></a>TwoPhaseCommitSinkFunction 如何保证端对端的 Exactly Once</h4><p>Flink 的源码中有这么一段注释：</p><blockquote><p>This is a recommended base class for all of the {@link SinkFunction} that intend to implement exactly-once semantic.</p></blockquote><p>意思是对于打算实现 Exactly Once 语义的所有 SinkFunction 都推荐继承该抽象类。在介绍 TwoPhaseCommitSinkFunction 之前，先了解一下 2PC 分布式一致性协议。</p><p>在分布式系统中，每一个机器节点虽然都能明确地知道自己在进行事务操作过程中的结果是成功或失败，但无法直接获取到其他分布式节点的操作结果。因此，当一个事务操作需要跨越多个分布式节点的时候，为了让每个节点都能够获取到其他节点的事务执行状况，需要引入一个“协调者（Coordinator）”节点来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点被称为“参与者（Participant）”。协调者负责调度参与者的行为，并最终决定这些参与者是否要把事务真正的提交。</p><p>普通的事务可以保证单个事务内所有操作要么全部成功，要么全部失败，而分布式系统中具体如何保证多台节点上执行的事务要么所有节点事务都成功，要么所有节点事务都失败呢？先了解一下 2PC 一致性协议。</p><p>2PC 是 Two-Phase Commit 的缩写，即两阶段提交。2PC 将分布式事务分为了两个阶段，分别是提交事务请求（投票）和执行事务提交。协调者会根据参与者在第一阶段的投票结果，来决定第二阶段是否真正的执行事务，具体流程如下。</p><p><strong>提交事务请求（投票）阶段</strong></p><ol><li>协调者向所有参与者发送 prepare 请求与事务内容，询问是否可以准备事务提交，并等待参与者的响应。</li><li>各参与者执行事务操作，并记录 Undo 日志（用于回滚）和 Redo日志（用于重放），但不真正提交。</li><li>参与者向协调者返回事务操作的执行结果，执行成功返回 Yes，否则返回 No。</li></ol><p><strong>执行事务提交阶段</strong></p><p>分为成功与失败两种情况。</p><p>若第一阶段所有参与者都返回 Yes，说明事务可以提交：</p><ol><li>协调者向所有参与者发送 Commit 请求。</li><li>参与者收到 Commit 请求后，会正式执行事务提交操作，并在提交完成后释放事务资源。</li><li>完成事务提交后，向协调者发送 Ack 消息。</li><li>协调者收到所有参与者的 Ack 消息，完成事务。</li><li>参与者收到 Commit 请求后，将事务真正地提交上去，并释放占用的事务资源，并向协调者返回 Ack。</li><li>协调者收到所有参与者的 Ack 消息，事务成功完成。</li></ol><p>若第一阶段有参与者返回 No 或者超时未返回，说明事务中断，需要回滚：</p><ol><li>协调者向所有参与者发送 Rollback 请求。</li><li>参与者收到 Rollback 请求后，根据 Undo 日志回滚到事务执行前的状态，释放占用的事务资源。</li><li>参与者在完成事务回滚后，向协调者返回 Ack。</li><li>协调者收到所有参与者的 Ack 消息，事务回滚完成。</li></ol><p>简单来讲，2PC 讲一个事务的处理过程分为了投票和执行两个阶段，其核心是每个事务都采用先尝试后提交的处理方式。下面分别图示出这两种情况：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151552.jpg" alt="img"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151557.jpg" alt="img"></p><p>2PC 的优点：原理简单，实现方便。</p><p>2PC 的缺点：</p><ul><li>协调者单点问题：协调者在整个 2PC 协议中非常重要，一旦协调者故障，则 2PC 将无法运转。</li><li>过于保守：在 2PC 的阶段一，如果参与者出现故障而导致协调者无法获取到参与者的响应信息，这时协调者只能依靠自身的超时机制来判断是否需要中断事务，这种策略比较保守。换言之，2PC 没有涉及较为完善的容错机制，任意一个节点失败都会导致整个事务的失败。</li><li>同步阻塞：执行过程是完全同步的，各个参与者在等待其他参与者投票响应的的过程中，将无法进行其他任何操作。</li><li>数据不一致：在二阶段提交协议的阶段二，当协调者向所有的参与者发送 Commit 请求后，出现了局部网络异常或局部参与者机器故障等因素导致一部分的参与者执行了 Commit 操作，而发生故障的参与者没有执行 Commit，于是整个分布式系统便出现了数据不一致现象。</li></ul><p>Flink 的 TwoPhaseCommitSinkFunction 是基于 2PC 实现的。Flink 的 JobManager 对应到 2PC 中的协调者，Operator 实例对应到 2PC 中的参与者。TwoPhaseCommitSinkFunction 实现了 CheckpointedFunction 和 CheckpointListener 接口。</p><p>CheckpointedFunction 接口中有两个方法 snapshotState 和 initializeState，snapshotState 方法会在 Checkpoint 时且做快照之前被调用，initializeState 方法会在自定义 Function 初始化恢复状态时被调用。</p><p>CheckpointListener 接口中有一个 notifyCheckpointComplete 方法，Operator 实例的 Checkpoint 成功后，会反馈给 JobManager，当 JobManager 接收到所有 Operator 实例 Checkpoint 成功的通知后，就认为本次 Checkpoint 成功了，会给所有 Operator 实例发送一个 Checkpoint 完成的通知，Operator 实例接收到通知后，就会调用 notifyCheckpointComplete 方法。</p><p>TwoPhaseCommitSinkFunction定义了如下 5 个抽象方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 处理每一条数据</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">(TXN transaction, IN value, Context context)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 开始一个事务，返回事务信息的句柄</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> TXN <span class="title">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 预提交（即提交请求）阶段的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">preCommit</span><span class="params">(TXN transaction)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 正式提交阶段的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">(TXN transaction)</span></span>;</span><br><span class="line"><span class="comment">// 取消事务，Rollback 相关的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">abort</span><span class="params">(TXN transaction)</span></span>;</span><br></pre></td></tr></table></figure><p>TwoPhaseCommitSinkFunction 里这些方法什么时候会被执行呢？如下图所示，在状态初始化的 initializeState 方法内或者每次 Checkpoint 的 snapshotState 方法内都会调用 beginTransaction 方法开启新的事务。开启新的事务后，Flink 开始处理数据，每来一条数据都会调用 invoke 方法，按照业务逻辑将数据添加到本次的事务中。等到下一次 Checkpoint 执行 snapshotState 时，会调用 preCommit 方法进行预提交，预提交一般会对事务进行 flush 操作，到这里为止可以理解为 2PC 的第一阶段。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-15-TwoPhaseCommitSinkFunction%20%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5.png" alt="img">)</p><p>第一阶段运行期间无论是机器故障还是 invoke 失败或者 preCommit 对应预提交的 flush 失败都可以理解为 2PC 的第一阶段返回了 No，即投票失败就会执行 2PC 第二阶段的 Rollback，对应到 TwoPhaseCommitSinkFunction 中就是执行 abort 方法，abort 方法内一般会对本次事务进行 abortTransaction 操作。</p><p>只有当 2PC 的第一阶段所有参与者都完全成功，也就是说 Flink TwoPhaseCommitSinkFunction 对应的所有并行度在本次事务中 invoke 全部成功且 preCommit 对应预提交的 flush 也全部成功才认为 2PC 的第一阶段返回了Yes，即投票成功就会执行 2PC 第二阶段的 Commit，对应到 TwoPhaseCommitSinkFunction 中就是执行 Commit 方法，Commit 方法内一般会对本次事务进行 commitTransaction 操作，以上就是 Flink 中 TwoPhaseCommitSinkFunction 的大概执行流程。</p><p>在第一阶段结束时，数据被写入到了外部存储，但是当事务的隔离级别为读已提交（Read Committed）时，在外部存储中并读取不到我们写入的数据，因为并没有执行 Commit 操作。如下图所示，是第二阶段的两种情况。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-15-TwoPhaseCommitSinkFunction%20%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5.png" alt="img"></p><p>FlinkKafkaProducer011 继承了 TwoPhaseCommitSinkFunction，如下图所示，Flink 应用使用 FlinkKafkaProducer011 时，Checkpoint 的时候不仅要将快照保存到状态后端，还要执行 preCommit 操作将缓存中的数据 flush 到 Sink 端的 Kafka 中。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151549.jpg" alt="img"></p><p>当所有的实例快照完成且所有 Sink 实例执行完 preCommit 操作时，会把快照完成的消息发送给 JobManager，JobManager 收到所有实例的 Checkpoint 完成消息时，就认为这次 Checkpoint 完成了，会向所有的实例发送 Checkpoint 完成的通知（Notify Checkpoint Completed），当 FlinkKafkaProducer011 接收到 Checkpoint 完成的消息时，就会执行 Commit 方法。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151550.jpg" alt="img"></p><p>上文提到过 2PC 有一些缺点存在，关于协调者和参与者故障的问题，对应到 Flink 中如果节点发生故障会申请资源并从最近一次成功的 Checkpoint 处恢复任务，所以，节点故障的问题 Flink 已经解决了。关于 2PC 同步阻塞的问题，2PC 算法在没有等到第一阶段所有参与者的投票之前肯定是不能执行第二阶段的 Commit，所以基于 2PC 实现原理同步阻塞的问题没有办法解决，除非使用其他算法。</p><p>那数据不一致的问题呢？</p><p>在整个的第一阶段不会真正地提交数据到 Kafka，所以只要设置事务隔离识别为读已提交（Read Committed），那么第一阶段就不会导致数据不一致的问题。</p><p>那 Flink 的第二阶段呢？</p><p>Flink 中，Checkpoint 成功后，会由 JobManager 给所有的实例发送 Checkpoint 完成的通知，然后 KafkaSink 在 notifyCheckpointComplete 方法内执行 commit。假如现在执行第 n 次 Checkpoint，快照完成且预提交完成，我们认为第 n 次 Checkpoint 已经成功了，这里一定要记住无论第二阶段是否 commit 成功，Flink 都会认为第 n 次 Checkpoint 已经结束了，换言之 Flink 可能会出现第 n 次 Checkpoint 成功了，但是第 n 次 Checkpoint 对应的事务 commit 并没有成功。</p><p>当 Checkpoint 成功后，JobManager 会向所有的 KafkaSink 发送 Checkpoint 完成的通知，所有的 KafkaSink 接收到通知后才会执行 Commit 操作。假如 JobManager 发送通知时出现了故障，导致 KafkaSink 的所有并行度都没有收到通知或者只有其中一部分 KafkaSink 接收到了通知，最后有一部分的 KafkaSink 执行了 Commit，另外一部分 KafkaSink 并没有执行 Commit，此时出现了 Checkpoint 成功，但是数据并没有完整地提交到 Kafka 的情况，出现了数据不一致的问题。</p><p>那 Flink 如何解决这个问题呢？</p><p>在任务执行过程中，如果因为各种原因导致有任意一个 KafkaSink 没有 Commit 成功，就会认为 Flink 任务出现故障，就会从最近一次成功的 Checkpoint 处恢复任务，也就是从第 n 次 Checkpoint 处恢复，TwoPhaseCommitSinkFunction 将每次 Checkpoint 时需要 Commit 的事务保存在状态里，当从第 n 次 Checkpoint 恢复时会从状态中拿到第 n 次 Checkpoint 可能没有提交的事务并执行 Commit，通过这种方式来保证所有的 KafkaSink 都能将事务进行 Commit，从而解决了 2PC 协议中可能出现的数据不一致的问题。</p><p>也就是说 Flink 任务重启后，会检查之前 Checkpoint 是否有未提交的事务，如果有则执行 Commit，从而保证了 Checkpoint 之前的数据被完整地提交。</p><p>简单描述一下 FlinkKafkaProducer011 的实现原理：</p><ul><li>FlinkKafkaProducer011 继承了 TwoPhaseCommitSinkFunction，所有并行度在 initializeState 初始化状态时，会开启新的事务，并把状态里保存的之前未提交事务进行 commit。</li><li>接下来开始调用 invoke 方法处理数据，会把数据通过事务 api 发送到 Kafka。一段时间后，开始 Checkpoint，checkpoint 时 snapshotState 方法会被执行，snapshotState 方法会调用 preCommit 方法并把当前还未 Commit 的事务添加到状态中来提供故障容错。</li><li>snapshotState 方法执行完成后，会对自身状态信息进行快照并上传到 HDFS 上来提供恢复。所有的实例都将状态信息备份完成后就认为本次 Checkpoint 结束了，此时 JobManager 会向所有的实例发送 Checkpoint 完成的通知，各实例收到通知后，会调用 notifyCheckpointComplete 方法把未提交的事务进行 commit。</li><li>期间如果出现其中某个并行度出现故障，JobManager 会停止此任务，向所有的实例发送通知，各实例收到通知后，调用 close 方法，关闭 Kafka 事务 Producer。</li></ul><p>以上就是 FlinkKafkaProducer011 实现原理的简单描述，具体实现细节请参考源码。</p><p>TwoPhaseCommitSinkFunction 还存在一个问题，假如我们设置的一分钟一次 Checkpoint，事务隔离级别设置为读已提交时，那么我们这一分钟内写入的数据，都必须等到 Checkpoint 结束后，下游才能读取到，导致我们的 Flink 任务数据延迟了一分钟。所以我们要结合这个特性，合理的设置我们的 Checkpoint 周期。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 重启策略</title>
      <link href="2019/12/09/Flink-%E9%87%8D%E5%90%AF%E7%AD%96%E7%95%A5/"/>
      <url>2019/12/09/Flink-%E9%87%8D%E5%90%AF%E7%AD%96%E7%95%A5/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3 id="Flink-Job-常见重启错误"><a href="#Flink-Job-常见重启错误" class="headerlink" title="Flink Job 常见重启错误"></a>Flink Job 常见重启错误</h3><p>不知道大家是否有遇到过这样的问题：整个 Job 一直在重启，并且还会伴随着一些错误（可以通过 UI 查看 Exceptions 日志）</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-04-152844.png" alt="img"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-06-140519.png" alt="img"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-26-2019-05-14_00-59-25.png" alt="img"></p><p>其实遇到上面这种问题比较常见的，比如有时候因为数据的问题（不合规范、为 null 等），这时在处理这些脏数据的时候可能就会遇到各种各样的异常错误，比如空指针、数组越界、数据类型转换错误等。可能你会说只要过滤掉这种脏数据就行了，或者进行异常捕获就不会导致 Job 不断重启的问题了。</p><p>确实如此，如果做好了脏数据的过滤和异常的捕获，Job 的稳定性确实有保证，但是复杂的 Job 下每个算子可能都会产生出脏数据（包含源数据可能也会为空或者不合法的数据），你不可能在每个算子里面也用一个大的 try catch 做一个异常捕获，所以脏数据和异常简直就是防不胜防，不过我们还是要尽力的保证代码的健壮性，但是也要配置好 Flink Job 的 RestartStrategy（重启策略）。</p><h3 id="RestartStrategy"><a href="#RestartStrategy" class="headerlink" title="RestartStrategy"></a>RestartStrategy</h3><p>RestartStrategy，重启策略，在遇到机器或者代码等不可预知的问题时导致 Job 或者 Task 挂掉的时候，它会根据配置的重启策略将 Job 或者受影响的 Task 拉起来重新执行，以使得作业恢复到之前正常执行状态。Flink 中的重启策略决定了是否要重启 Job 或者 Task，以及重启的次数和每次重启的时间间隔。</p><h3 id="为什么需要-RestartStrategy？"><a href="#为什么需要-RestartStrategy？" class="headerlink" title="为什么需要 RestartStrategy？"></a>为什么需要 RestartStrategy？</h3><p>重启策略会让 Job 从上一次完整的 Checkpoint 处恢复状态，保证 Job 和挂之前的状态保持一致，另外还可以让 Job 继续处理数据，不会出现 Job 挂了导致消息出现大量堆积的问题，合理的设置重启策略可以减少 Job 不可用时间和避免人工介入处理故障的运维成本，因此重启策略对于 Flink Job 的稳定性来说有着举足轻重的作用。</p><h3 id="怎么配置-RestartStrategy？"><a href="#怎么配置-RestartStrategy？" class="headerlink" title="怎么配置 RestartStrategy？"></a>怎么配置 RestartStrategy？</h3><p>既然 Flink 中的重启策略作用这么大，那么该如何配置呢？其实如果 Flink Job 没有单独设置重启重启策略的话，则会使用集群启动时加载的默认重启策略，如果 Flink Job 中单独设置了重启策略则会覆盖默认的集群重启策略。默认重启策略可以在 Flink 的配置文件 <code>flink-conf.yaml</code> 中设置，由 <code>restart-strategy</code> 参数控制，有 fixed-delay（固定延时重启策略）、failure-rate（故障率重启策略）、none（不重启策略）三种可以选择，如果选择的参数不同，对应的其他参数也不同。下面分别介绍这几种重启策略和如何配置。</p><h4 id="FixedDelayRestartStrategy（固定延时重启策略）"><a href="#FixedDelayRestartStrategy（固定延时重启策略）" class="headerlink" title="FixedDelayRestartStrategy（固定延时重启策略）"></a>FixedDelayRestartStrategy（固定延时重启策略）</h4><p>FixedDelayRestartStrategy 是固定延迟重启策略，程序按照集群配置文件中或者程序中额外设置的重启次数尝试重启作业，如果尝试次数超过了给定的最大次数，程序还没有起来，则停止作业，另外还可以配置连续两次重启之间的等待时间，在 <code>flink-conf.yaml</code> 中可以像下面这样配置。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">fixed-delay</span></span><br><span class="line"><span class="attr">restart-strategy.fixed-delay.attempts:</span> <span class="number">3</span>  <span class="comment">#表示作业重启的最大次数，启用 checkpoint 的话是 Integer.MAX_VALUE，否则是 1。</span></span><br><span class="line"><span class="attr">restart-strategy.fixed-delay.delay:</span> <span class="number">10</span> <span class="string">s</span>  <span class="comment">#如果设置分钟可以类似 1 min，该参数表示两次重启之间的时间间隔，当程序与外部系统有连接交互时延迟重启可能会有帮助，启用 checkpoint 的话，延迟重启的时间是 10 秒，否则使用 akka.ask.timeout 的值。</span></span><br></pre></td></tr></table></figure><p>在程序中设置固定延迟重启策略的话如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.fixedDelayRestart(</span><br><span class="line">  <span class="number">3</span>, <span class="comment">// 尝试重启的次数</span></span><br><span class="line">  Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">// 延时</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure><h4 id="FailureRateRestartStrategy（故障率重启策略）"><a href="#FailureRateRestartStrategy（故障率重启策略）" class="headerlink" title="FailureRateRestartStrategy（故障率重启策略）"></a>FailureRateRestartStrategy（故障率重启策略）</h4><p>FailureRateRestartStrategy 是故障率重启策略，在发生故障之后重启作业，如果固定时间间隔之内发生故障的次数超过设置的值后，作业就会失败停止，该重启策略也支持设置连续两次重启之间的等待时间。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">failure-rate</span></span><br><span class="line"><span class="attr">restart-strategy.failure-rate.max-failures-per-interval:</span> <span class="number">3</span>  <span class="comment">#固定时间间隔内允许的最大重启次数，默认 1</span></span><br><span class="line"><span class="attr">restart-strategy.failure-rate.failure-rate-interval:</span> <span class="number">5</span> <span class="string">min</span>  <span class="comment">#固定时间间隔，默认 1 分钟</span></span><br><span class="line"><span class="attr">restart-strategy.failure-rate.delay:</span> <span class="number">10</span> <span class="string">s</span> <span class="comment">#连续两次重启尝试之间的延迟时间，默认是 akka.ask.timeout </span></span><br></pre></td></tr></table></figure><p>可以在应用程序中这样设置来配置故障率重启策略：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.failureRateRestart(</span><br><span class="line">  <span class="number">3</span>, <span class="comment">// 固定时间间隔允许 Job 重启的最大次数</span></span><br><span class="line">  Time.of(<span class="number">5</span>, TimeUnit.MINUTES), <span class="comment">// 固定时间间隔</span></span><br><span class="line">  Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">// 两次重启的延迟时间</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure><h4 id="NoRestartStrategy（不重启策略）"><a href="#NoRestartStrategy（不重启策略）" class="headerlink" title="NoRestartStrategy（不重启策略）"></a>NoRestartStrategy（不重启策略）</h4><p>NoRestartStrategy 作业不重启策略，直接失败停止，在 <code>flink-conf.yaml</code> 中配置如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">none</span></span><br></pre></td></tr></table></figure><p>在程序中如下设置即可配置不重启：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.noRestart());</span><br></pre></td></tr></table></figure><h4 id="Fallback（备用重启策略）"><a href="#Fallback（备用重启策略）" class="headerlink" title="Fallback（备用重启策略）"></a>Fallback（备用重启策略）</h4><p>如果程序没有启用 Checkpoint，则采用不重启策略，如果开启了 Checkpoint 且没有设置重启策略，那么采用固定延时重启策略，最大重启次数为 Integer.MAX_VALUE。</p><p>在应用程序中配置好了固定延时重启策略，可以测试一下代码异常后导致 Job 失败后重启的情况，然后观察日志，可以看到 Job 重启相关的日志：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Try to restart or fail the job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0) if no longer possible.</span><br><span class="line">[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0) switched from state FAILING to RESTARTING.</span><br><span class="line">[flink-akka.actor.default-dispatcher-5] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Restarting the job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0).</span><br></pre></td></tr></table></figure><p>最后重启次数达到配置的最大重启次数后 Job 还没有起来的话，则会停止 Job 并打印日志：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[flink-akka.actor.default-dispatcher-2] INFO org.apache.flink.runtime.executiongraph.ExecutionGraph - Could not restart the job zhisheng default RestartStrategy example (a890361aed156610b354813894d02cd0) because the restart strategy prevented it.</span><br></pre></td></tr></table></figure><p>Flink 中几种重启策略的设置如上，大家可以根据需要选择合适的重启策略，比如如果程序抛出了空指针异常，但是你配置的是一直无限重启，那么就会导致 Job 一直在重启，这样无非再浪费机器资源，这种情况下可以配置重试固定次数，每次隔多久重试的固定延时重启策略，这样在重试一定次数后 Job 就会停止，如果对 Job 的状态做了监控告警的话，那么你就会收到告警信息，这样也会提示你去查看 Job 的运行状况，能及时的去发现和修复 Job 的问题。</p><h3 id="RestartStrategy-源码剖析"><a href="#RestartStrategy-源码剖析" class="headerlink" title="RestartStrategy 源码剖析"></a>RestartStrategy 源码剖析</h3><p>再介绍重启策略应用程序代码配置的时候不知道你有没有看到设置重启策略都是使用 RestartStrategies 类，通过该类的方法就可以创建不同的重启策略，在 RestartStrategies 类中提供了五个方法用来创建四种不同的重启策略（有两个方法是创建 FixedDelay 重启策略的，只不过方法的参数不同），如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-151745.png" alt="img"></p><p>在每个方法内部其实调用的是 RestartStrategies 中的内部静态类，分别是 NoRestartStrategyConfiguration、FixedDelayRestartStrategyConfiguration、FailureRateRestartStrategyConfiguration、FallbackRestartStrategyConfiguration，这四个类都继承自 RestartStrategyConfiguration 抽象类。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-151617.png" alt="img"></p><p>上面是定义的四种重启策略的配置类，在 Flink 中是靠 RestartStrategyResolving 类中的 resolve 方法来解析 RestartStrategies.RestartStrategyConfiguration，然后根据配置使用 RestartStrategyFactory 创建 RestartStrategy。RestartStrategy 是一个接口，它有 canRestart 和 restart 两个方法，它有四个实现类： FixedDelayRestartStrategy、FailureRateRestartStrategy、ThrowingRestartStrategy、NoRestartStrategy。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-151311.png" alt="img"></p><h3 id="Failover-Strategies（故障恢复策略）"><a href="#Failover-Strategies（故障恢复策略）" class="headerlink" title="Failover Strategies（故障恢复策略）"></a>Failover Strategies（故障恢复策略）</h3><p>Flink 通过重启策略和故障恢复策略来控制 Task 重启：重启策略决定是否可以重启以及重启的间隔；故障恢复策略决定哪些 Task 需要重启。在 Flink 中支持两种不同的故障重启策略，该策略可以在 flink-conf.yaml 中的配置，默认为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">jobmanager.execution.failover-strategy:</span> <span class="string">region</span></span><br></pre></td></tr></table></figure><p>该配置有两个可选值，full（重启所有的 Task）和 region（重启 pipelined region），在 Flink 1.9 中默认设置的恢复策略变成 region 了。</p><p>参考 Flink Issue：<a href="https://issues.apache.org/jira/browse/FLINK-13223">https://issues.apache.org/jira/browse/FLINK-13223</a></p><h4 id="重启所有的任务"><a href="#重启所有的任务" class="headerlink" title="重启所有的任务"></a>重启所有的任务</h4><p>在 full 故障恢复策略下，Task 发生故障时会重启作业中的所有 Task 来恢复，会造成一定的资源浪费，但却是恢复作业一致性的最安全策略，会在其他 Failover 策略失败时作为保底策略使用。</p><h4 id="基于-Region-的局部故障重启策略"><a href="#基于-Region-的局部故障重启策略" class="headerlink" title="基于 Region 的局部故障重启策略"></a>基于 Region 的局部故障重启策略</h4><p>基于 Region 的局部故障恢复策略会将作业中的 Task 划分为数个 Region，根据数据传输决定的，有数据传输的 Task 会被放在同一个 Region，不同 Region 之间无数据交换。如果有 Task 发生故障的时候，它会重启发生错误的 Task 所在 Region 的所有 Task，这种策略相对于重启所有的 Task 策略来说重启的 Task 数量会变少。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-131936.png" alt="img"></p><p>如上图如果 C2 Task 因为错误挂了，它会根据数据流往上找到 Source，然后根据 Source 可以知道数据流到下游的所有 Task，进而将这些 Task 重启（见下图）。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-140828.png" alt="img"></p><p>当然你会发现上面这种重启方式其实重启的 Task 数量还是不少，为了进一步减少需要重新启动的 Task 数量，可以使用某些类型的数据流交换，将 Task 运算的结果暂存在中间，然后如果有 Task 失败了，那么就往前去找中间结果，然后重启中间结果到数据流向的最后 Task 之间所有的 Task。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-144622.png" alt="img"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-144713.png" alt="img"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-145101.png" alt="img"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-08-150015.png" alt="img"></p><p>从上面四个图可以看到这样的话，故障恢复的需要重启的 Task 数量就降低了，但是适合这种的策略的场景是有限的，详情可以参考：</p><blockquote><p><a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-1+:+Fine+Grained+Recovery+from+Task+Failures">https://cwiki.apache.org/confluence/display/FLINK/FLIP-1+%3A+Fine+Grained+Recovery+from+Task+Failures</a></p></blockquote><p>在查看源码的时候还看到一种恢复策略是 RestartIndividualStrategy，这种策略只会重启挂掉的那个 Task，如果该 Task 没有包含数据源，这会导致它不能重流数据而导致一部分数据丢失，所以这种策略的使用是有局限性的，不能保证数据的一致性。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink State 深入理解</title>
      <link href="2019/12/07/Flink-State-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/"/>
      <url>2019/12/07/Flink-State-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Flink 是一款有状态的流处理框架</p><h1 id="State-概述"><a href="#State-概述" class="headerlink" title="State 概述"></a>State 概述</h1><h2 id="为什么需要-state？"><a href="#为什么需要-state？" class="headerlink" title="为什么需要 state？"></a>为什么需要 state？</h2><p>对于流处理系统，数据是一条一条被处理的，如果没有对数据处理的进度进行记录，那么如果这个处理数据的 Job 因为机器问题或者其他问题而导致重启，那么它是不知道上一次处理数据是到哪个地方了，这样的情况下如果是批数据，倒是可以很好的解决（重新将这份固定的数据再执行一遍），但是流数据那就麻烦了，你根本不知道什么在 Job 挂的那个时刻数据消费到哪里了？那么你重启的话该从哪里开始重新消费呢？你可以有以下选择（因为你可能也不确定 Job 挂的具体时间）：</p><ol><li>Job 挂的那个时间之前：如果是从 Job 挂之前开始重新消费的话，那么会导致部分数据（从新消费的时间点到之前 Job 挂的那个时间点之前的数据）重复消费</li><li>Job 挂的那个时间之后：如果是从 Job 挂之后开始消费的话，那么会导致部分数据（从 Job 挂的那个时间点到新消费的时间点产生的数据）丢失，没有消费</li></ol><p><img src="/images/flink/1.png"></p><p>为解决上面两种情况（数据重复消费或者数据没有消费）的发生，Flink state 诞生了，state 中存储着每条数据消费后数据的消费点（生产环境需要持久化这些状态）,当 Job 因为某种错误或者其他原因导致重启时，就能够从 checkpoint 中的 state 数据进行恢复</p><h2 id="state-种类"><a href="#state-种类" class="headerlink" title="state 种类"></a>state 种类</h2><p><strong>在 Flink 中有两个基本的 state：Keyed state 和 Operator state</strong></p><h3 id="Keyed-State"><a href="#Keyed-State" class="headerlink" title="Keyed State"></a>Keyed State</h3><p><strong>Keyed State 总是和具体的 key 相关联，也只能在 KeyedStream 的 function 和 operator 上使用。可以将 Keyed State 当作是 Operator State 的一种特例，但是它是被分区或分片的。每个 Keyed State 分区对应一个 key 的 Operator State，对于某个 key 在某个分区上有唯一的状态。</strong></p><h3 id="Operator-State"><a href="#Operator-State" class="headerlink" title="Operator State"></a>Operator State</h3><p>对 Operator State 而言，每个 operator state 都对应着一个并行实例。</p><p>Kafka Connector 就是一个很好的例子。每个 Kafka consumer 的并行实例都会持有一份topic partition 和 offset 的 map，这个 map 就是它的 Operator State。</p><p>当并行度发生变化时，Operator State 可以将状态在所有的并行实例中进行重分配，并且提供了多种方式来进行重分配。</p><p>当并行度发生变化时，Operator State 可以将状态在所有的并行实例中进行重分配，并且提供了多种方式来进行重分配。</p><hr><hr><h3 id="Raw-and-Managed-State"><a href="#Raw-and-Managed-State" class="headerlink" title="Raw and Managed State"></a>Raw and Managed State</h3><p><strong>Keyed State 和 Operator State 都有两种存在形式，即 Raw State（原始状态）和 Managed State（托管状态）。</strong></p><p><strong>Raw State</strong></p><blockquote><p>原始状态是算子保存它们自己的数据结构中的 state，当 checkpoint 时，原始状态会以字节流的形式写入进 checkpoint 中。Flink 并不知道 State 的数据结构长啥样，仅能看到原生的字节数组。</p></blockquote><p><strong>Managed State</strong></p><blockquote><p>托管状态可以使用 Flink 提供的数据结构来表示，例如内部哈希表或者 RocksDB。具体有 ValueState，ListState 等。Flink 会对这些状态进行编码然后将它们写入到 checkpoint 中。</p></blockquote><p>DataStream 的所有 function 都可以使用托管状态，但是原生状态只能在自定义 operator 的时候使用。相对于原生状态，推荐使用托管状态，因为如果使用托管状态，当并行度发生改变时，Flink 可以自动的帮你重分配 state，同时还可以更好的管理内存。</p><p>注意：如果你的托管状态需要特殊的序列化，目前 Flink 还不支持。</p><hr><hr><h3 id="使用托管-Keyed-State"><a href="#使用托管-Keyed-State" class="headerlink" title="使用托管 Keyed State"></a>使用托管 Keyed State</h3><p>托管的 Keyed State 接口提供对不同类型状态（这些状态的范围都是当前输入元素的 key）的访问，这意味着这种状态只能在通过 stream.keyBy() 创建的 KeyedStream 上使用。</p><p>我们首先来看一下有哪些可以使用的状态，然后再来看看它们在程序中是如何使用的：</p><ol><li><p>ValueState</p><p>保存一个可以更新和获取的值（每个 Key 一个 value），可以用 update(T) 来更新 value，可以用 value() 来获取 value。</p></li><li><p>ListState</p><p>保存一个值的列表，用 add(T) 或者 addAll(List) 来添加，用 Iterable get() 来获取。</p></li><li><p>ReducingState</p><p>保存一个值，这个值是状态的很多值的聚合结果，接口和 ListState 类似，但是可以用相应的 ReduceFunction 来聚合。</p></li><li><p>AggregatingState</p><p>保存很多值的聚合结果的单一值，与 ReducingState 相比，不同点在于聚合类型可以和元素类型不同，提供 AggregateFunction 来实现聚合。</p><p>FoldingState</p><p>与 AggregatingState 类似，除了使用 FoldFunction 进行聚合。</p><p><font color='red'>注意：FoldingState 已经不推荐使用，可以用 AggregatingState 来代替。</font></p></li><li><p>MapState: 保存一组映射，可以将 kv 放进这个状态，使用 put(UK, UV) 或者 putAll(Map) 添加，或者使用 get(UK) 获取。</p></li></ol><p>所有类型的状态都有一个 clear() 方法来清除当前的状态。</p><p>需要注意，上面的这些状态对象仅用来和状态打交道，状态不一定保存在内存中，也可以存储在磁盘或者其他地方。另外，你获取到的状态的值是取决于输入元素的 key，因此如果 key 不同，那么在一次调用用户函数中获得的值可能与另一次调用的值不同。</p><p>要使用一个状态对象，需要先创建一个 StateDescriptor，它包含了状态的名字（你可以创建若干个 state，但是它们必须要有唯一的值以便能够引用它们），状态的值的类型，或许还有一个用户定义的函数，比如 ReduceFunction。根据你想要使用的 state 类型，你可以创建 ValueStateDescriptor、ListStateDescriptor、ReducingStateDescriptor、FoldingStateDescriptor 或者 MapStateDescriptor。</p><p>状态只能通过 RuntimeContext 来获取，所以只能在 RichFunction 里面使用。RichFunction 中你可以通过 RuntimeContext 用下述方法获取状态：</p><ul><li>ValueState getState(ValueStateDescriptor)</li><li>ReducingState getReducingState(ReducingStateDescriptor)</li><li>ListState getListState(ListStateDescriptor)</li><li>AggregatingState getAggregatingState(AggregatingState)</li><li>FoldingState getFoldingState(FoldingStateDescriptor)</li><li>MapState getMapState(MapStateDescriptor)</li></ul><p>上面讲了这么多概念，那么来一个例子来看看如何使用状态：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CountWindowAverage</span> <span class="keyword">extends</span> <span class="title">RichFlatMapFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">Long</span>, <span class="title">Long</span>&gt;, <span class="title">Tuple2</span>&lt;<span class="title">Long</span>, <span class="title">Long</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//ValueState 使用方式，第一个字段是 count，第二个字段是运行的和 </span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> ValueState&lt;Tuple2&lt;Long, Long&gt;&gt; sum;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(Tuple2&lt;Long, Long&gt; input, Collector&lt;Tuple2&lt;Long, Long&gt;&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//访问状态的 value 值</span></span><br><span class="line">        Tuple2&lt;Long, Long&gt; currentSum = sum.value();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//更新 count</span></span><br><span class="line">        currentSum.f0 += <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//更新 sum</span></span><br><span class="line">        currentSum.f1 += input.f1;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//更新状态</span></span><br><span class="line">        sum.update(currentSum);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//如果 count 等于 2, 发出平均值并清除状态</span></span><br><span class="line">        <span class="keyword">if</span> (currentSum.f0 &gt;= <span class="number">2</span>) &#123;</span><br><span class="line">            out.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(input.f0, currentSum.f1 / currentSum.f0));</span><br><span class="line">            sum.clear();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration config)</span> </span>&#123;</span><br><span class="line">        ValueStateDescriptor&lt;Tuple2&lt;Long, Long&gt;&gt; descriptor =</span><br><span class="line">                <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(</span><br><span class="line">                        <span class="string">&quot;average&quot;</span>, <span class="comment">//状态名称</span></span><br><span class="line">                        TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;Long, Long&gt;&gt;() &#123;&#125;), <span class="comment">//类型信息</span></span><br><span class="line">                        Tuple2.of(<span class="number">0L</span>, <span class="number">0L</span>)); <span class="comment">//状态的默认值</span></span><br><span class="line">        sum = getRuntimeContext().getState(descriptor);<span class="comment">//获取状态</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">env.fromElements(Tuple2.of(<span class="number">1L</span>, <span class="number">3L</span>), Tuple2.of(<span class="number">1L</span>, <span class="number">5L</span>), Tuple2.of(<span class="number">1L</span>, <span class="number">7L</span>), Tuple2.of(<span class="number">1L</span>, <span class="number">4L</span>), Tuple2.of(<span class="number">1L</span>, <span class="number">2L</span>))</span><br><span class="line">        .keyBy(<span class="number">0</span>)</span><br><span class="line">        .flatMap(<span class="keyword">new</span> CountWindowAverage())</span><br><span class="line">        .print();</span><br><span class="line"></span><br><span class="line"><span class="comment">//结果会打印出 (1,4) 和 (1,5)</span></span><br></pre></td></tr></table></figure><p>这个例子实现了一个简单的计数器，我们使用元组的第一个字段来进行分组(这个例子中，所有的 key 都是 1)，这个 CountWindowAverage 函数将计数和运行时总和保存在一个 ValueState 中，一旦计数等于 2，就会发出平均值并清理 state，因此又从 0 开始。请注意，如果在第一个字段中具有不同值的元组，则这将为每个不同的输入 key保存不同的 state 值。</p><h3 id="State-TTL-存活时间"><a href="#State-TTL-存活时间" class="headerlink" title="State TTL(存活时间)"></a>State TTL(存活时间)</h3><h4 id="State-TTL-介绍"><a href="#State-TTL-介绍" class="headerlink" title="State TTL 介绍"></a>State TTL 介绍</h4><p>TTL 可以分配给任何类型的 Keyed state，如果一个状态设置了 TTL，那么当状态过期时，那么之前存储的状态值会被清除。所有的状态集合类型都支持单个入口的 TTL，这意味着 List 集合元素和 Map 集合都支持独立到期。为了使用状态 TTL，首先必须要构建 StateTtlConfig 配置对象，然后可以通过传递配置在 State descriptor 中启用 TTL 功能：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.StateTtlConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueStateDescriptor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.time.Time;</span><br><span class="line"></span><br><span class="line">StateTtlConfig ttlConfig = StateTtlConfig</span><br><span class="line">    .newBuilder(Time.seconds(<span class="number">1</span>))</span><br><span class="line">    .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)</span><br><span class="line">    .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">ValueStateDescriptor&lt;String&gt; stateDescriptor = <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(<span class="string">&quot;zhisheng&quot;</span>, String.class);</span><br><span class="line">stateDescriptor.enableTimeToLive(ttlConfig);    <span class="comment">//开启 ttl</span></span><br></pre></td></tr></table></figure><p>上面配置中有几个选项需要注意：</p><p>1、newBuilder 方法的第一个参数是必需的，它代表着状态存活时间。</p><p>2、UpdateType 配置状态 TTL 更新时（默认为 OnCreateAndWrite）：</p><ul><li>StateTtlConfig.UpdateType.OnCreateAndWrite: 仅限创建和写入访问时更新</li><li>StateTtlConfig.UpdateType.OnReadAndWrite: 除了创建和写入访问，还支持在读取时更新</li></ul><p>3、StateVisibility 配置是否在读取访问时返回过期值（如果尚未清除），默认是 NeverReturnExpired：</p><ul><li>StateTtlConfig.StateVisibility.NeverReturnExpired: 永远不会返回过期值</li><li>StateTtlConfig.StateVisibility.ReturnExpiredIfNotCleanedUp: 如果仍然可用则返回</li></ul><p>在 NeverReturnExpired 的情况下，过期状态表现得好像它不再存在，即使它仍然必须被删除。该选项对于在 TTL 之后必须严格用于读取访问的数据的用例是有用的，例如，应用程序使用隐私敏感数据.</p><p>另一个选项 ReturnExpiredIfNotCleanedUp 允许在清理之前返回过期状态。</p><p>注意：</p><ul><li>状态后端会存储上次修改的时间戳以及对应的值，这意味着启用此功能会增加状态存储的消耗，堆状态后端存储一个额外的 Java 对象，其中包含对用户状态对象的引用和内存中原始的 long 值。RocksDB 状态后端存储为每个存储值、List、Map 都添加 8 个字节。</li><li>目前仅支持参考 processing time 的 TTL</li><li>使用启用 TTL 的描述符去尝试恢复先前未使用 TTL 配置的状态可能会导致兼容性失败或者 StateMigrationException 异常。</li><li>TTL 配置并不是 Checkpoint 和 Savepoint 的一部分，而是 Flink 如何在当前运行的 Job 中处理它的方式。</li><li>只有当用户值序列化器可以处理 null 值时，具体 TTL 的 Map 状态当前才支持 null 值，如果序列化器不支持 null 值，则可以使用 NullableSerializer 来包装它（代价是需要一个额外的字节）。</li></ul><h4 id="清除过期-state"><a href="#清除过期-state" class="headerlink" title="清除过期 state"></a>清除过期 state</h4><p>默认情况下，过期值只有在显式读出时才会被删除，例如通过调用 ValueState.value()。</p><p>注意：这意味着默认情况下，如果未读取过期状态，则不会删除它，这可能导致状态不断增长，这个特性在 Flink 未来的版本可能会发生变化。</p><p>此外，你可以在获取完整状态快照时激活清理状态，这样就可以减少状态的大小。在当前实现下不清除本地状态，但是在从上一个快照恢复的情况下，它不会包括已删除的过期状态，你可以在 StateTtlConfig 中这样配置：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.StateTtlConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.time.Time;</span><br><span class="line"></span><br><span class="line">StateTtlConfig ttlConfig = StateTtlConfig</span><br><span class="line">    .newBuilder(Time.seconds(<span class="number">1</span>))</span><br><span class="line">    .cleanupFullSnapshot()</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><p>此配置不适用于 RocksDB 状态后端中的增量 checkpoint。对于现有的 Job，可以在 StateTtlConfig 中随时激活或停用此清理策略，例如，从保存点重启后。</p><p>除了在完整快照中清理外，你还可以在后台激活清理。如果使用的后端支持以下选项，则会激活 StateTtlConfig 中的默认后台清理：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.StateTtlConfig;</span><br><span class="line">StateTtlConfig ttlConfig = StateTtlConfig</span><br><span class="line">    .newBuilder(Time.seconds(<span class="number">1</span>))</span><br><span class="line">    .cleanupInBackground()</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><p>要在后台对某些特殊清理进行更精细的控制，可以按照下面的说明单独配置它。目前，堆状态后端依赖于增量清理，RocksDB 后端使用压缩过滤器进行后台清理。</p><p>我们再来看看 TTL 对应着的类 StateTtlConfig 类中的具体实现，这样我们才能更加的理解其使用方式。</p><p>在该类中的属性有如下：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-143816.png" alt="img"></p><ul><li>DISABLED：它默认创建了一个 UpdateType 为 Disabled 的 StateTtlConfig</li><li>UpdateType：这个是一个枚举，包含 Disabled（代表 TTL 是禁用的，状态不会过期）、OnCreateAndWrite、OnReadAndWrite 可选</li><li>StateVisibility：这也是一个枚举，包含了 ReturnExpiredIfNotCleanedUp、NeverReturnExpired</li><li>TimeCharacteristic：这是时间特征，其实是只有 ProcessingTime 可选</li><li>Time：设置 TTL 的时间，这里有两个参数 unit 和 size</li><li>CleanupStrategies：TTL 清理策略，在该类中又有字段 isCleanupInBackground（是否在后台清理） 和相关的清理 strategies（包含 FULL<em>STATE</em>SCAN<em>SNAPSHOT、INCREMENTAL</em>CLEANUP 和 ROCKSDB<em>COMPACTION</em>FILTER），同时该类中还有 CleanupStrategy 接口，它的实现类有 EmptyCleanupStrategy（不清理，为空）、IncrementalCleanupStrategy（增量的清除）、RocksdbCompactFilterCleanupStrategy（在 RocksDB 中自定义压缩过滤器）。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-144111.png" alt="img"></p><h3 id="如何使用托管-Operator-State"><a href="#如何使用托管-Operator-State" class="headerlink" title="如何使用托管 Operator State"></a>如何使用托管 Operator State</h3><p>为了使用托管的 Operator State，必须要有一个有状态的函数，这个函数可以实现 CheckpointedFunction 或者 ListCheckpointed 接口。</p><p>下面分别讲一下如何使用：</p><h4 id="CheckpointedFunction"><a href="#CheckpointedFunction" class="headerlink" title="CheckpointedFunction"></a>CheckpointedFunction</h4><p>如果是实现 CheckpointedFunction 接口的话，那么我们先来看下这个接口里面有什么方法呢：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//当请求 checkpoint 快照时，将调用此方法</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(FunctionSnapshotContext context)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//在分布式执行期间创建并行功能实例时，将调用此方法。 函数通常在此方法中设置其状态存储数据结构</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception</span>;</span><br></pre></td></tr></table></figure><p>当有请求执行 checkpoint 的时候，snapshotState() 方法就会被调用，initializeState() 方法会在每次初始化用户定义的函数时或者从更早的 checkpoint 恢复的时候被调用，因此 initializeState() 不仅是不同类型的状态被初始化的地方，而且还是 state 恢复逻辑的地方。</p><p>目前，List 类型的托管状态是支持的，状态被期望是一个可序列化的对象的 List，彼此独立，这样便于重分配，换句话说，这些对象是可以重新分配的 non-keyed state 的最小粒度，根据状态的访问方法，定义了重新分配的方案：</p><ul><li>Even-split redistribution：每个算子会返回一个状态元素列表，整个状态在逻辑上是所有列表的连接。在重新分配或者恢复的时候，这个状态元素列表会被按照并行度分为子列表，每个算子会得到一个子列表。这个子列表可能为空，或包含一个或多个元素。举个例子，如果使用并行性 1，算子的检查点状态包含元素 element1 和 element2，当将并行性增加到 2 时，element1 可能最终在算子实例 0 中，而 element2 将转到算子实例 1 中。</li><li>Union redistribution：每个算子会返回一个状态元素列表，整个状态在逻辑上是所有列表的连接。在重新分配或恢复的时候，每个算子都会获得完整的状态元素列表。</li></ul><p>如下示例是一个有状态的 SinkFunction 使用 CheckpointedFunction 来发送到外部之前缓存数据，使用了Even-split策略。</p><p>下面是一个有状态的 SinkFunction 的示例，它使用 CheckpointedFunction 来缓存数据，然后再将这些数据发送到外部系统，使用了 Even-split 策略：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BufferingSink</span> <span class="keyword">implements</span> <span class="title">SinkFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt;, <span class="title">CheckpointedFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> threshold;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> ListState&lt;Tuple2&lt;String, Integer&gt;&gt; checkpointedState;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> List&lt;Tuple2&lt;String, Integer&gt;&gt; bufferedElements;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">BufferingSink</span><span class="params">(<span class="keyword">int</span> threshold)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.threshold = threshold;</span><br><span class="line">        <span class="keyword">this</span>.bufferedElements = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">(Tuple2&lt;String, Integer&gt; value, Context contex)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        bufferedElements.add(value);</span><br><span class="line">        <span class="keyword">if</span> (bufferedElements.size() == threshold) &#123;</span><br><span class="line">            <span class="keyword">for</span> (Tuple2&lt;String, Integer&gt; element: bufferedElements) &#123;</span><br><span class="line">                <span class="comment">//将数据发到外部系统</span></span><br><span class="line">            &#125;</span><br><span class="line">            bufferedElements.clear();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(FunctionSnapshotContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        checkpointedState.clear();</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;String, Integer&gt; element : bufferedElements) &#123;</span><br><span class="line">            checkpointedState.add(element);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; descriptor =</span><br><span class="line">            <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(</span><br><span class="line">                <span class="string">&quot;buffered-elements&quot;</span>,</span><br><span class="line">                TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;&#125;));</span><br><span class="line"></span><br><span class="line">        checkpointedState = context.getOperatorStateStore().getListState(descriptor);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (context.isRestored()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (Tuple2&lt;String, Integer&gt; element : checkpointedState.get()) &#123;</span><br><span class="line">                bufferedElements.add(element);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>initializeState 方法将 FunctionInitializationContext 作为参数，它用来初始化 non-keyed 状态。注意状态是如何初始化的，类似于 Keyed state，StateDescriptor 包含状态名称和有关状态值的类型的信息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; descriptor =</span><br><span class="line">    <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(</span><br><span class="line">        <span class="string">&quot;buffered-elements&quot;</span>,</span><br><span class="line">        TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;Long, Long&gt;&gt;() &#123;&#125;));</span><br><span class="line"></span><br><span class="line">checkpointedState = context.getOperatorStateStore().getListState(descriptor);</span><br></pre></td></tr></table></figure><h4 id="ListCheckpointed"><a href="#ListCheckpointed" class="headerlink" title="ListCheckpointed"></a>ListCheckpointed</h4><p>是一种受限的 CheckpointedFunction，只支持 List 风格的状态和 even-spit 的重分配策略。该接口里面的方法有：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-144503.png" alt="img"></p><ul><li>snapshotState(): 获取函数的当前状态。状态必须返回此函数先前所有的调用结果。</li><li>restoreState(): 将函数或算子的状态恢复到先前 checkpoint 的状态。此方法在故障恢复后执行函数时调用。如果函数的特定并行实例无法恢复到任何状态，则状态列表可能为空。</li></ul><h3 id="Stateful-Source-Functions"><a href="#Stateful-Source-Functions" class="headerlink" title="Stateful Source Functions"></a>Stateful Source Functions</h3><p>与其他算子相比，有状态的 source 函数需要注意的地方更多，比如为了保证状态的更新和结果的输出原子性，用户必须在 source 的 context 上加锁。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">CounterSource</span> <span class="keyword">extends</span> <span class="title">RichParallelSourceFunction</span>&lt;<span class="title">Long</span>&gt; <span class="keyword">implements</span> <span class="title">ListCheckpointed</span>&lt;<span class="title">Long</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//一次语义的当前偏移量</span></span><br><span class="line">    <span class="keyword">private</span> Long offset = <span class="number">0L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//作业取消标志</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> isRunning = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;Long&gt; ctx)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Object lock = ctx.getCheckpointLock();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (isRunning) &#123;</span><br><span class="line">            <span class="comment">//输出和状态更新是原子性的</span></span><br><span class="line">            <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">                ctx.collect(offset);</span><br><span class="line">                offset += <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        isRunning = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Long&gt; <span class="title">snapshotState</span><span class="params">(<span class="keyword">long</span> checkpointId, <span class="keyword">long</span> checkpointTimestamp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Collections.singletonList(offset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">restoreState</span><span class="params">(List&lt;Long&gt; state)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Long s : state)</span><br><span class="line">            offset = s;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>或许有些算子想知道什么时候 checkpoint 全部做完了，可以参考使用 org.apache.flink.runtime.state.CheckpointListener 接口来实现，在该接口里面有 notifyCheckpointComplete 方法。</p><hr><h3 id="Broadcast-State"><a href="#Broadcast-State" class="headerlink" title="Broadcast State"></a>Broadcast State</h3><h4 id="Broadcast-State-如何使用"><a href="#Broadcast-State-如何使用" class="headerlink" title="Broadcast State 如何使用"></a>Broadcast State 如何使用</h4><p>前面提到了两种 Operator state 支持的动态扩展方法：even-split redistribution 和 union redistribution。Broadcast State 是 Flink 支持的另一种扩展方式，它用来支持将某一个流的数据广播到下游所有的 Task 中，数据都会存储在下游 Task 内存中，接收到广播的数据流后就可以在操作中利用这些数据，一般我们会将一些规则数据进行这样广播下去，然后其他的 Task 也都能根据这些规则数据做配置，更常见的就是规则动态的更新，然后下游还能够动态的感知。</p><p>Broadcast state 的特点是：</p><ul><li>使用 Map 类型的数据结构</li><li>仅适用于同时具有广播流和非广播流作为数据输入的特定算子</li><li>可以具有多个不同名称的 Broadcast state</li></ul><p>那么我们该如何使用 Broadcast State 呢？下面通过一个例子来讲解一下，在这个例子中，我要广播的数据是监控告警的通知策略规则，然后下游拿到我这个告警通知策略去判断哪种类型的告警发到哪里去，该使用哪种方式来发，静默时间多长等。</p><p>第一个数据流是要处理的数据源，流中的对象具有告警或者恢复的事件，其中用一个 type 字段来标识哪个事件是告警，哪个事件是恢复，然后还有其他的字段标明是哪个集群的或者哪个项目的，简单代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DataStreamSource&lt;AlertEvent&gt; alertData = env.addSource(<span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(<span class="string">&quot;alert&quot;</span>,</span><br><span class="line">        <span class="keyword">new</span> AlertEventSchema(),</span><br><span class="line">        parameterTool.getProperties()));</span><br></pre></td></tr></table></figure><p>然后第二个数据流是要广播的数据流，它是告警通知策略数据（定时从 MySQL 中读取的规则表），简单代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DataStreamSource&lt;Rule&gt; alarmdata = env.addSource(<span class="keyword">new</span> GetAlarmNotifyData());</span><br><span class="line"></span><br><span class="line"><span class="comment">// MapState 中保存 (RuleName, Rule) ，在描述类中指定 State name</span></span><br><span class="line">MapStateDescriptor&lt;String, Rule&gt; ruleStateDescriptor = <span class="keyword">new</span> MapStateDescriptor&lt;&gt;(</span><br><span class="line">            <span class="string">&quot;RulesBroadcastState&quot;</span>,</span><br><span class="line">            BasicTypeInfo.STRING_TYPE_INFO,</span><br><span class="line">            TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Rule&gt;() &#123;&#125;));</span><br><span class="line"></span><br><span class="line"><span class="comment">// alarmdata 使用 MapStateDescriptor 作为参数广播，得到广播流</span></span><br><span class="line">BroadcastStream&lt;Rule&gt; ruleBroadcastStream = alarmdata.broadcast(ruleStateDescriptor);</span><br></pre></td></tr></table></figure><p>然后你要做的是将两个数据流进行连接，连接后再根据告警规则数据流的规则数据进行处理（这个告警的逻辑很复杂，我们这里就不再深入讲），伪代码大概如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">alertData.connect(ruleBroadcastStream)</span><br><span class="line">    .process(</span><br><span class="line">        <span class="keyword">new</span> KeyedBroadcastProcessFunction&lt;AlertEvent, Rule&gt;() &#123;</span><br><span class="line">            <span class="comment">//根据告警规则的数据进行处理告警事件</span></span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">//可能还有更多的操作</span></span><br></pre></td></tr></table></figure><p><code>alertData.connect(ruleBroadcastStream)</code> 该 connect 方法将两个流连接起来后返回一个 BroadcastConnectedStream 对象，如果对 BroadcastConnectedStream 不太清楚的可以回看下文章 <a href="https://gitbook.cn/gitchat/column/undefined/topic/5db6a754f6a6211cb9616526">4如何使用 DataStream API 来处理数据？</a> 再次复习一下。BroadcastConnectedStream 调用 process() 方法执行处理逻辑，需要指定一个逻辑实现类作为参数，具体是哪种实现类取决于非广播流的类型：</p><ul><li>如果非广播流是 keyed stream，需要实现 KeyedBroadcastProcessFunction</li><li>如果非广播流是 non-keyed stream，需要实现 BroadcastProcessFunction</li></ul><p>那么该怎么获取这个 Broadcast state 呢，它需要通过上下文来获取:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ctx.getBroadcastState(ruleStateDescriptor)</span><br></pre></td></tr></table></figure><h4 id="BroadcastProcessFunction-和-KeyedBroadcastProcessFunction"><a href="#BroadcastProcessFunction-和-KeyedBroadcastProcessFunction" class="headerlink" title="BroadcastProcessFunction 和 KeyedBroadcastProcessFunction"></a>BroadcastProcessFunction 和 KeyedBroadcastProcessFunction</h4><p>这两个抽象函数有两个相同的需要实现的接口:</p><ul><li>processBroadcastElement()：处理广播流中接收的数据元</li><li>processElement()：处理非广播流数据的方法</li></ul><p>用于处理非广播流是 non-keyed stream 的情况:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BroadcastProcessFunction</span>&lt;<span class="title">IN1</span>, <span class="title">IN2</span>, <span class="title">OUT</span>&gt; <span class="keyword">extends</span> <span class="title">BaseBroadcastProcessFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(IN1 value, ReadOnlyContext ctx, Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">processBroadcastElement</span><span class="params">(IN2 value, Context ctx, Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用于处理非广播流是 keyed stream 的情况</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">KeyedBroadcastProcessFunction</span>&lt;<span class="title">KS</span>, <span class="title">IN1</span>, <span class="title">IN2</span>, <span class="title">OUT</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(IN1 value, ReadOnlyContext ctx, Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">processBroadcastElement</span><span class="params">(IN2 value, Context ctx, Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onTimer</span><span class="params">(<span class="keyword">long</span> timestamp, OnTimerContext ctx, Collector&lt;OUT&gt; out)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这两个接口提供的上下文对象有所不同。非广播方（processElement）使用 ReadOnlyContext，而广播方（processBroadcastElement）使用 Context。这两个上下文对象（简称 ctx）通用的方法接口有：</p><ul><li>访问 Broadcast state：ctx.getBroadcastState(MapStateDescriptorstateDescriptor)</li><li>查询数据元的时间戳：ctx.timestamp()</li><li>获取当前水印：ctx.currentWatermark()</li><li>获取当前处理时间：ctx.currentProcessingTime()</li><li>向旁侧输出（side-outputs）发送数据：ctx.output(OutputTag outputTag, X value)</li></ul><p>这两者不同之处在于对 Broadcast state 的访问限制：广播方对其具有读和写的权限（read-write），非广播方只有读的权限（read-only），为什么要这么设计呢，主要是为了保证 Broadcast state 在算子的所有并行实例中是相同的。由于 Flink 中没有跨任务的通信机制，在一个任务实例中的修改不能在并行任务间传递，而广播端在所有并行任务中都能看到相同的数据元，只对广播端提供可写的权限。同时要求在广播端的每个并行任务中，对接收数据的处理是相同的。如果忽略此规则会破坏 State 的一致性保证，从而导致不一致且难以诊断的结果。也就是说，processBroadcast() 的实现逻辑必须在所有并行实例中具有相同的确定性行为。</p><h4 id="使用-Broadcast-state-需要注意"><a href="#使用-Broadcast-state-需要注意" class="headerlink" title="使用 Broadcast state 需要注意"></a>使用 Broadcast state 需要注意</h4><p>前面介绍了 Broadcast state，并将 BroadcastProcessFunction 和 KeyedBroadcastProcessFunction 做了个对比，那么接下来强调一下使用 Broadcast state 时需要注意的事项：</p><ul><li>没有跨任务的通信，这就是为什么只有广播方可以修改 Broadcast state 的原因。</li><li>用户必须确保所有任务以相同的方式为每个传入的数据元更新 Broadcast state，否则可能导致结果不一致。</li><li>跨任务的 Broadcast state 中的事件顺序可能不同，虽然广播的元素可以保证所有元素都将转到所有下游任务，但元素到达的顺序可能不一致。因此，Broadcast state 更新不能依赖于传入事件的顺序。</li><li>所有任务都会把 Broadcast state 存入 checkpoint，虽然 checkpoint 发生时所有任务都具有相同的 Broadcast state。这是为了避免在恢复期间所有任务从同一文件中进行恢复（避免热点），然而代价是 state 在 checkpoint 时的大小成倍数（并行度数量）增加。</li><li>Flink 确保在恢复或改变并行度时不会有重复数据，也不会丢失数据。在具有相同或改小并行度后恢复的情况下，每个任务读取其状态 checkpoint。在并行度增大时，原先的每个任务都会读取自己的状态，新增的任务以循环方式读取前面任务的检查点。</li><li>不支持 RocksDB state backend，Broadcast state 在运行时保存在内存中。</li></ul><h3 id="Queryable-State"><a href="#Queryable-State" class="headerlink" title="Queryable State"></a>Queryable State</h3><p>Queryable State，顾名思义，就是可查询的状态。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-06-29-075631.jpg" alt="img"></p><p>传统管理这些状态的方式是通过将计算后的状态结果存储在第三方 KV 存储中，然后由第三方应用去获取这些 KV 状态，但是在 Flink 种，现在有了 Queryable State，意味着允许用户对流的内部状态进行实时查询。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-06-29-091521.jpg" alt="img"></p><p>那么就不再像其他流计算框架，需要将结果存储到其他外部存储系统才能够被查询到，这样我们就可以不再需要等待状态写入外部存储（这块可能是其他系统的主要瓶颈之一），甚至可以做到无需任何数据库就可以让用户直接查询到数据，这使得数据获取到的时间会更短，更及时，如果你有这块的需求（需要将某些状态数据进行展示，比如数字大屏），那么就强烈推荐使用 Queryable State。目前可查询的 state 主要针对可分区的 state，如 keyed state 等。</p><p>在 Flink 源码中，为此还专门有一个 module 来讲 Queryable State 呢！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-23-144649.png" alt="img"></p><p>那么我们该如何使用 Queryable State 呢？有如下两种方式 ：</p><ul><li>QueryableStateStream, 将 KeyedStream 转换为 QueryableStateStream，类似于 Sink，后续不能进行任何转换操作</li><li>StateDescriptor#setQueryable(String queryableStateName)，将 Keyed State 设置为可查询的 （不支持 Operator State）</li></ul><p>外部应用在查询 Flink 应用程序内部状态的时候要使用 QueryableStateClient, 提交异步查询请求来获取状态。如何使状态可查询呢，假如已经创建了一个状态可查询的 Job，并通过 JobClient 提交 Job，那么它在 Flink 内部的具体实现如下图（图片来自 <a href="http://vishnuviswanath.com/flink_queryable_state1.html">Queryable States in ApacheFlink - How it works</a>）所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-06-29-073842.jpg" alt="img"></p><p>上面讲解了让 State 可查询的原理，如果要在 Flink 集群中使用的话，首先得将 Flink 安装目录下 opt 里面的 <code>flink-queryable-state-runtime_2.11-1.9.0.jar</code> 复制到 lib 目录下，默认 lib 目录是不包含这个 jar 的。</p><p>然后你可以像下面这样操作让状态可查询：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Reducing state</span></span><br><span class="line">ReducingStateDescriptor&lt;Tuple2&lt;Integer, Long&gt;&gt; reducingState = <span class="keyword">new</span> ReducingStateDescriptor&lt;&gt;(</span><br><span class="line">        <span class="string">&quot;zhisheng&quot;</span>,</span><br><span class="line">        <span class="keyword">new</span> SumReduce(),</span><br><span class="line">        source.getType());</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> String queryName = <span class="string">&quot;zhisheng&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> QueryableStateStream&lt;Integer, Tuple2&lt;Integer, Long&gt;&gt; queryableState =</span><br><span class="line">        dataStream.keyBy(<span class="keyword">new</span> KeySelector&lt;Tuple2&lt;Integer, Long&gt;, Integer&gt;() &#123;</span><br><span class="line">            <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">4126824763829132959L</span>;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Integer <span class="title">getKey</span><span class="params">(Tuple2&lt;Integer, Long&gt; value)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> value.f0;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).asQueryableState(queryName, reducingState);</span><br></pre></td></tr></table></figure><p>除了上面的 Reducing，你还可以使用 ValueState、FoldingState，还可以直接通过asQueryableState(queryName），注意不支持 ListState，调用 asQueryableState 方法后会返回 QueryableStateStream，接着无需再做其他操作。</p><p>那么用户如果定义了 Queryable State 的话，该怎么来查询对应的状态呢？下面来看看具体逻辑：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-06-29-074814.jpg" alt="img"></p><p>简单来说，当用户在 Job 中定义了 queryable state 之后，就可以在外部通过QueryableStateClient 来查询对应的状态实时值，你可以创建如下方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建 Queryable State Client</span></span><br><span class="line">QueryableStateClient client = <span class="keyword">new</span> QueryableStateClient(host, port);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">QueryableStateClient</span><span class="params">(<span class="keyword">final</span> InetAddress remoteAddress, <span class="keyword">final</span> <span class="keyword">int</span> remotePort)</span> </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">this</span>.client = <span class="keyword">new</span> Client&lt;&gt;(</span><br><span class="line">            <span class="string">&quot;Queryable State Client&quot;</span>, <span class="number">1</span>,</span><br><span class="line">            messageSerializer, <span class="keyword">new</span> DisabledKvStateRequestStats());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 QueryableStateClient 中有几个不同参数的 getKvState 方法，参数可有 JobID、queryableStateName、key、namespace、keyTypeInfo、namespaceTypeInfo、StateDescriptor，其实内部最后调用的是一个私有的 getKvState 方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> CompletableFuture&lt;KvStateResponse&gt; <span class="title">getKvState</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> JobID jobId, <span class="keyword">final</span> String queryableStateName,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> <span class="keyword">int</span> keyHashCode, <span class="keyword">final</span> <span class="keyword">byte</span>[] serializedKeyAndNamespace)</span> </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">//构造 KV state 查询的请求</span></span><br><span class="line">    KvStateRequest request = <span class="keyword">new</span> KvStateRequest(jobId, queryableStateName, keyHashCode, serializedKeyAndNamespace);</span><br><span class="line">    <span class="comment">//这个 client 是在构造 QueryableStateClient 中赋值的，这个 client 是 Client&lt;KvStateRequest, KvStateResponse&gt;，发送请求后会返回 CompletableFuture&lt;KvStateResponse&gt;</span></span><br><span class="line">    <span class="keyword">return</span> client.sendRequest(remoteAddress, request);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 Flink 源码中专门有一个 QueryableStateOptions 类来设置可查询状态相关的配置，有如下这些配置。</p><p>服务器端：</p><ul><li>queryable-state.proxy.ports：可查询状态代理的服务器端口范围的配置参数，默认是 9069</li><li>queryable-state.proxy.network-threads：客户端代理的网络线程数，默认是 0</li><li>queryable-state.proxy.query-threads：客户端代理的异步查询线程数，默认是 0</li><li>queryable-state.server.ports：可查询状态服务器的端口范围，默认是 9067</li><li>queryable-state.server.network-threads：KvState 服务器的网络线程数</li><li>queryable-state.server.query-threads：KvStateServerHandler 的异步查询线程数</li><li>queryable-state.enable：是否启用可查询状态代理和服务器</li></ul><p>客户端：</p><ul><li>queryable-state.client.network-threads：KvState 客户端的网络线程数</li></ul><p><strong>注意</strong>：</p><p>可查询状态的生命周期受限于 Job 的生命周期，例如，任务在启动时注册可查询状态，在清理的时候会注销它。在未来的版本中，可能会将其解耦，以便在任务完成后仍可以允许查询到任务的状态。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark 任务调度机制</title>
      <link href="2019/12/02/Spark%20%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6/"/>
      <url>2019/12/02/Spark%20%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在生产环境下， Spark 集群的部署方式一般为 YARN-Cluster 模式，因此本文基于YARN-Cluster 模式</p><a id="more"></a><h1 id="Spark-任务提交流程"><a href="#Spark-任务提交流程" class="headerlink" title="Spark 任务提交流程"></a><strong>Spark 任务提交流程</strong></h1><p>YARN-Cluster 模式中提交 Spark 应用程序</p><p>首先通过 Client 向 ResourceManager 请求启动一个 Application，同时检查是否有足够的资源满足 Application 的需求，如果资源条件满足，则准备 ApplicationMaster 的启动上下文，交给ResourceManager，并循环监控 Application 状态。</p><p>当提交的资源队列中有资源时，ResourceManager 会在某个 NodeManager 上启动 ApplicationMaster 进程，ApplicationMaster 会单独启动 Driver 后台线程，当 Driver 启动后，ApplicationMaster 会通过本地的 RPC 连接 Driver ，并开始向 ResourceManager 申请 Container 资源运行 Executor 进程, 当 ResourceManager 返回 Container 资源，ApplicationMaster 则在对应的 Container 上启动 Executor 。</p><p>Driver 线程主要是初始化 SparkContext 对象，准备运行所需的上下文，然后一方面保持与 ApplicationMaster 的 RPC 连接，通过 ApplicationMaster 申请资源，另一方面根据用户业务逻辑开始调度任务，将任务下发到已有的空闲 Executor 上。</p><p>当 ResourceManager 向 ApplicationMaster 返 回 Container 资源时 ， ApplicationMaster 就尝试在对应的 Container 上启动 Executor 进程，Executor 进程起来后， 会向 Driver 反向注册， 注册成功后保持与 Driver 的心跳，同时等待 Driver 分发任务，当分发的任务执行完毕后，将任务状态上报给 Driver。</p><h1 id="Spark-任务调度概述"><a href="#Spark-任务调度概述" class="headerlink" title="Spark 任务调度概述"></a>Spark 任务调度概述</h1><p>Driver 线程初始化 SparkContext 对象，准备运行所需的上下文，一方面保持与 ApplicationMaster 的 RPC 连接，通过 ApplicationMaster 申请资源，另一方面根据用户业务逻辑开始调度任务，将任务下发到已有的空闲 Executor 上。</p><p><strong>Driver 会根据用户程序逻辑准备任务，并根据 Executor 资源情况逐步分发任务。</strong> 在详细阐述任务调度前，首先说明下 Spark 里的几个概念。一个 Spark 应用程序包括Job、Stage 以及 Task 三个概念：</p><ul><li>Job 是以 Action 方法为界，遇到一个 Action 方法则触发一个Job</li><li>Stage 是 Job 的子集，以宽依赖为界。遇到 Shuffle 做一次划分</li><li>Task 是 Stage 的子集，以并行度(分区数)来衡量,分区数是多少，则有多少个 task</li></ul><p>Spark 的任务调度总体来说分两路进行，一路是 Stage 级的调度， 一路是 Task 级的调度，总体调度流程如下图所示：</p><img src="../images/spark/6.png" alt="" style="zoom:50%;" /><p>Spark RDD 通过其 Transactions 操作，形成了 RDD 血缘关系图，即 DAG ，最后通过 Action 的调用，触发 Job 并调度执行。</p><p><strong>DAGScheduler 负责 Stage 级的调度，主要是将 Job 切分成若干 Stages，并将每个 Stage 打包成 TaskSet 交给 TaskScheduler 调度。</strong></p><p><strong>TaskScheduler 负责 Task 级的调度，将 DAGScheduler 给过来的 TaskSet 按照指定的调度策略分发到 Executor 上执行，调度过程中 SchedulerBackend 负责提供可用资源， 其中 SchedulerBackend 有多种实现， 分别对接不同的资源管理系统。</strong></p><h1 id="Spark-Stage-级调度"><a href="#Spark-Stage-级调度" class="headerlink" title="Spark Stage 级调度"></a>Spark Stage 级调度</h1><p>DAGScheduler 是实现了面向 stage 的调度，它可以为每个 Job 计算出一个 DAG，追踪 RDD 和 stage 的输出是否被持久化，并且寻找到一个最优调度机制来运行 Job.</p><ol><li><p>接收用户提交的 Job；</p></li><li><p>将 Job 划分为不同 stage 的 DAG图，记录哪些 RDD、Stage 被物化存储，并在每一个 stage 内产生一系列的 task，并封装成 TaskSet；</p></li><li><p>要保证相互依赖的 Job/stage 能够得到顺利的调度执行，DAGScheduler 必然需要监控当前Job / Stage乃至Task的完成情况。</p></li><li><p>结合当前的缓存情况，决定每个 Task 的最佳位置(移动计算而不是移动数据，任务在数据所在的节点上运行)，将 TaskSet 提交给 TaskScheduler;</p><p>DAGScheduler 找到哪些 RDDs 已经被 cache 了来避免重计算它们，而且同样地记住哪些ShuffleMapStages 已经生成了输出文件来避免重建一个 shuffle 的 map 侧计算任务。</p></li><li><p>重新提交 Shuffle 输出丢失的 Stage 给 TaskScheduler</p><p>处理由于 shuffle 输出文件丢失导致的失败，在这种情况下，旧的 stage 可能会被重新提交。一个 stage 内部的失败，如果不是由于 shuffle 文件丢失导致的，会被 TaskScheduler 处理，它会被多次重试每一个 task，直到最后一个。实在不行，才会被取消整个 stage。</p></li></ol><h3 id="Stage-划分"><a href="#Stage-划分" class="headerlink" title="Stage 划分"></a>Stage 划分</h3><p>SparkContext 将 Job 提交给 DAGScheduler，DAGScheduler 将一个 Job 划分为若干 Stages ，<strong>具体划分策略是，以 Shuffle 为界，划分 Stage ,由最终的 RDD 不断通过依赖回溯判断父依赖是否是宽依赖，窄依赖的 RDD 被划分到同一个 Stage 中，进行 pipeline 式的计算，划分的 Stages 分两类，一类叫做 ResultStage 为 DAG 下游的 Stage，由 Action 方法决定； 另一类叫做 ShuffleMapStage，其为下游 Stage 准备数据。</strong></p><h3 id="生成-Job，提交-Stage"><a href="#生成-Job，提交-Stage" class="headerlink" title="生成 Job，提交 Stage"></a><strong>生成 Job，提交 Stage</strong></h3><p><strong>一个 Stage 是否被提交，需要判断它的父 Stage 是否执行，只有在父 Stage 执行完毕才能提交当前 Stage，如果一个 Stage 没有父 Stage，那么从该 Stage 开始提交。Stage 提交时会将 Task 信息[分区信息以及方法等]序列化并被打包成 TaskSet 交给 TaskScheduler，一个 Partition 对应一个 Task。</strong></p><h1 id="Spark-Task-级调度"><a href="#Spark-Task-级调度" class="headerlink" title="Spark Task 级调度"></a>Spark Task 级调度</h1><p>Spark Task 的调度是由 TaskScheduler 来完成。DAGScheduler 将 Stage 打包到 TaskSet 交给 TaskScheduler，TaskScheduler 会将 TaskSet 封装为 TaskSetManager 加入到调度队列中。</p><img src="../images/spark/7.png" alt="" style="zoom:50%;" /><p><strong>TaskSetManager 负责监控管理同一个 Stage 中的 Tasks，TaskScheduler 就是以 TaskSetManager 为单元来调度任务 。</strong></p><p>TaskScheduler 初始化后会启动 SchedulerBackend，它负责跟外界打交道，接收 Executor 的注册信息，并维护 Executor 的状态，同时它在启动后会定期地去询问 TaskScheduler 是否有任务要运行，也就是说， 它会定期地问 TaskScheduler “我有这么余量，你要不要啊”，TaskScheduler 在  SchedulerBackend 问它的时候，会从调度队列中按照指定的调度策略选择 TaskSetManager 去运行。</p><p>SchedulerBackend负责与Cluster Manager交互，取得分配给 Application 的资源，并将资源传给TaskScheduler，由 TaskScheduler 为 Task 最终分配计算资源</p><h3 id="调度策略"><a href="#调度策略" class="headerlink" title="调度策略"></a>调度策略</h3><p>TaskScheduler 会先把 DAGScheduler 提交过来的 TaskSet 封装成 TaskSetManager 放到任务队列里，然后再从任务队列里按照一定的规则把它们取出来放在 SchedulerBackend 给过来的 Executor 上运行。这个调度过程实际上还是比较粗粒度的，是面向 TaskSetManager 的。</p><p>调度队列的层次结构如下图所示</p><img src="../images/spark/8.png" alt="" style="zoom:50%;" /><p>TaskScheduler 支持两种调度策略，一种是 FIFO，也是默认的调度策略，另一种是 FAIR。</p><p>在 TaskScheduler 初始化过程中会实例化 rootPool，表示树的根节点， 是 Pool 类型。</p><ul><li><p><strong>FIFO 调度策略</strong></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">FIFOSchedulingAlgorithm</span> <span class="keyword">extends</span> <span class="title">SchedulingAlgorithm</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">comparator</span></span>(s1: <span class="type">Schedulable</span>, s2: <span class="type">Schedulable</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> priority1 = s1.priority <span class="comment">// jobId</span></span><br><span class="line">    <span class="keyword">val</span> priority2 = s2.priority</span><br><span class="line">    <span class="keyword">var</span> res = math.signum(priority1 - priority2)</span><br><span class="line">    <span class="keyword">if</span> (res == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">val</span> stageId1 = s1.stageId</span><br><span class="line">      <span class="keyword">val</span> stageId2 = s2.stageId</span><br><span class="line">      res = math.signum(stageId1 - stageId2)</span><br><span class="line">    &#125;</span><br><span class="line">    res &lt; <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>比较 s1和 s2 所属的 JobId，值越小，优先级越高</li><li>如果两个 JobId 的优先级相同， 则对 s1，s2所属的 StageId 进行比，值越小，优先级越高</li></ul></li><li><p><strong>Fair 调度策略</strong></p><p>FAIR 模式中有一个 Root Pool 和多个子 Pool，各个子 Pool 中 存储着所有待分配的 TaskSetManager 。</p><img src="../images/spark/9.png" alt="" style="zoom:50%;" /><p>可以通过在 Properties 中指定 spark.scheduler.pool 属性，指定某个调度池作为 TaskSetManager 的父调度池，如果根调度池不存在此属性值对应的调度池，会创建以此属性值为名称的调度池作为 TaskSetManager 的父调度池，并将此调度池作为根调度池的子调度池。</p><p>在 FAIR 模式中，需要先对 子Pool 进行排序，再对 子Pool 里面的 TaskSetManager 进行排序，因为 Pool 和 TaskSetManager 都继承了 Schedulable 特质，因此使用相同的排序算法 。</p><p>每个要排序的对象包含三个属性 : runningTasks 值[正在运行的 Task 数]、 minShare 值、 weight 值，比较时会综合考量三个属性值。</p><p>注意，minShare 、weight 的值均在公平调度配置文件 fairscheduler.xml 中被指定， 调度池在构建阶段会读取此文件的相关配置。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">  <span class="tag">&lt;<span class="name">allocations</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">pool</span> <span class="attr">name</span>=<span class="string">&quot;production&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">schedulingMode</span>&gt;</span>FAIR<span class="tag">&lt;/<span class="name">schedulingMode</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">weight</span>&gt;</span>1<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">minShare</span>&gt;</span>2<span class="tag">&lt;/<span class="name">minShare</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">pool</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">pool</span> <span class="attr">name</span>=<span class="string">&quot;test&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">schedulingMode</span>&gt;</span>FIFO<span class="tag">&lt;/<span class="name">schedulingMode</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">weight</span>&gt;</span>2<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">minShare</span>&gt;</span>3<span class="tag">&lt;/<span class="name">minShare</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">pool</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">allocations</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li><p><strong>runningTasks 比 minShare 小的先执行</strong></p><blockquote><p>如果 A 对象的 runningTasks 大于它的 minShare，B 对象的 runningTasks 小于它的 minShare,那么 B 排在 A 前面</p></blockquote></li><li><p><strong>minShare 使用率低的先执行</strong></p><blockquote><p>如果A，B 对象的 runningTasks 都小于它的 minShare ，那么就比较 runningTasks 和 minShare 的比值 [minShare使用率]谁小谁排前面</p></blockquote></li><li><p><strong>权重使用率低的先执行</strong></p><blockquote><p>如果A、B 对象 的 runningTasks 都大于它们的 minShare ，那么就比较 runningTasks 与 weight 的比值(权重使用率),谁小谁排前面。</p></blockquote></li><li><p><strong>如果上述比较均相等，则比较名字</strong></p></li></ul><p>FAIR 模式排序完成后，所有的 TaskSetManager 被放入一个 ArrayBuffer 里，之后依次被取出并发送给 Executor 执行 。</p></li></ul><p>从调度队列中拿到 TaskSetManager 后，由于 TaskSetManager 封装了一个 Stage 的所有 Task， 并负责管理调度这些 Task，接下来 TaskSetManager 按照一定的规则逐个取出 Task 给 TaskScheduler，TaskScheduler 提交给 SchedulerBackend 去发到 Executor 执行。</p><h3 id="本地化调度"><a href="#本地化调度" class="headerlink" title="本地化调度"></a>本地化调度</h3><p>DAGScheduler 划分 Stage, 通过调用 submitStage 来提交一个 Stage 对应的 tasks， submitStage 会调用 submitMissingTasks，submitMissingTasks 确定每个需要计算的 task 的 preferredLocations，通过调用 getPreferrdeLocations() 得到 partition 的优先位置，由于一个 partition 对应一个task， 此 partition 的优先位置就是 task 的优先位置，对于要提交到 TaskScheduler 的 TaskSet 中的每一个 task ，该 task 优先位置与其对应的 partition 对应的优先位置一致 </p><p>根据每个 task 的优先位置，确定 task 的 Locality 级别，Locality一共有五种，优先级由高到低顺序</p><table><thead><tr><th>PROCESS_LOCAL</th><th>进程本地化，task 和数据在同一个 Executor 中，性能最好。</th></tr></thead><tbody><tr><td><strong>NODE_LOCAL</strong></td><td>节点本地化，task 和数据在同一个节点中，但是 task 和数据不在同一个 Executor 中，数据需要在进程间进行传输。</td></tr><tr><td><strong>RACK_LOCAL</strong></td><td>机架本地化，task 和数据在同一个机架的两个节点上，数据需要通过网络在节点之间进行传输。</td></tr><tr><td><strong>NO_PREF</strong></td><td>数据从哪里访问都一样快，不需要位置优先</td></tr><tr><td><strong>ANY</strong></td><td>task 和数据不在一个机架中，性能最差。</td></tr></tbody></table><p>在调度执行时，Spark 总是会尽量让每个 task 以最高的本地性级别来启动，当一个 task 以X本地性级别启动，但是该本地性级别对应的所有节点都没有空闲资源而启动失败，此时并不会马上降低本地性级别启动而是在某个时间长度内再次以 X 本地性级别来启动该 task，若超过限时时间则降级启动，去尝试下一个本地性级别，依次类推。</p><p>可以通过调大每个类别的最大容忍延迟时间，在等待阶段对应的 Executor 可能 就会有相应的资源去执行此 task，这就在在一定程度上提到了运行性能。</p><h3 id="失败重试与黑名单机制"><a href="#失败重试与黑名单机制" class="headerlink" title="失败重试与黑名单机制"></a>失败重试与黑名单机制</h3><p>除了选择合适的 Task 调度机制外，还需要监控 Task 的执行状态，与外部通信的是 SchedulerBackend。</p><p><strong>Task 被提交到 Executor 启动执行后，Executor 会将执行状态上报给 SchedulerBackend， SchedulerBackend 则通知该 Task 对应的 TaskSetManager，TaskSetManager 获取得知 Task 的执行状态，对于失败的 Task，TaskSetManager 会记录失败次数，如果失败次数还没有超过最大重试次数，则把该 Task 放回待调度的 Task 池子中，否则整个 Application 失败。</strong></p><p>在记录 Task 失败次数过程中，会记录其上一次失败所在的 ExecutorId 和 Host，下次调度该 Task 时，会使用黑名单机制，避免再次被调度到上一次失败的节点上，起到一定的容错作用。</p><p><strong>黑名单记录 Task 上一次失败所在的 ExecutorId 和 Host，以及其对应的 “拉黑时间”.</strong></p><p><strong>“拉黑时间”是指这段时间内不要再往这个节点上调度这个 Task 了。</strong></p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark Shuffle 机制</title>
      <link href="2019/11/28/Spark%20Shuffle/"/>
      <url>2019/11/28/Spark%20Shuffle/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>shuffle 的性能高低直接影响了整个程序的性能和吞吐量。因为在分布式情况下，reduce task 需要跨节点去拉取其它节点上的 map task 结果。这一过程将会产生网络资源消耗和内存，磁盘 IO 的消耗。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a><strong>概述</strong></h2><p>Shuffle 描述着数据从 map task 输出到 reduce task 输入的这段过程。</p><p>Shuffle 是连接 Map 和 Reduce 之间的桥梁， Map 的输出要用到 Reduce 中必须经过 shuffle 这个环节.</p><p>shuffle 的性能高低直接影响了整个程序的性能和吞吐量。因为在分布式情况下，reduce task 需要跨节点去拉取其它节点上的 map task 结果。这一过程将会产生网络资源消耗和内存，磁盘 IO 的消耗。</p><p>通常 shuffle 分为两部分：Map阶段的数据准备和  Reduce 阶段的数据拷贝处理。</p><p>一般将在 map 端的 shuffle 称之为 Shuffle Write， 在Reduce 端的 Shuffle 称之为 Shuffle Read</p><h2 id="导致-Shuffle-操作算子"><a href="#导致-Shuffle-操作算子" class="headerlink" title="导致 Shuffle 操作算子"></a><strong>导致 Shuffle 操作算子</strong></h2><h3 id="重分区类的操作"><a href="#重分区类的操作" class="headerlink" title="重分区类的操作"></a><strong>重分区类的操作</strong></h3><p>重分区类算子一般会 shuffle，因为需要在整个集群中，对之前所有的分区的数据进行随机，均匀的打乱，然后把数据放入下游新的指定数量的分区内。</p><p>比如 repartition、repartitionAndSortWithinPartitions等</p><h3 id="byKey-类的操作"><a href="#byKey-类的操作" class="headerlink" title="byKey 类的操作"></a><strong>byKey 类的操作</strong></h3><p>比如 reduceByKey、groupByKey、sortByKey 等，对一个 key 进行聚合操作时要保证集群中，所有节点上相同的 key 分配到同一个节点上进行处理</p><h3 id="Join-类的操作"><a href="#Join-类的操作" class="headerlink" title="Join 类的操作"></a><strong>Join 类的操作</strong></h3><p>比如 join、cogroup 等。两个 rdd 进行 join，就必须将相同 key 的数据，shuffle 到同一个节点上，然后进行相同 key 的两个 rdd 数据操作。</p><h2 id="Shuffle-原理"><a href="#Shuffle-原理" class="headerlink" title="Shuffle 原理"></a><strong>Shuffle 原理</strong></h2><p><strong>ShuffleMapStage 的结束伴随着 shuffle 文件的写磁盘</strong></p><p><strong>ResultStage基本上对应代码中的 action 算子， 即将一个函数应用在 RDD 的各个 partition 的数据集上，意味着一个 job 的运行结束</strong></p><p>在划分 stage 时， 最后一个 stage 称为 finalStage， 它本质上是一个 ResultStage</p><h3 id="HashShuffle"><a href="#HashShuffle" class="headerlink" title="HashShuffle"></a><strong>HashShuffle</strong></h3><p>通常 shuffle 分为两部分：write 阶段的数据准备和 read 阶段的数据拷贝处理。</p><h4 id="shuffle-write"><a href="#shuffle-write" class="headerlink" title="shuffle write"></a>shuffle write</h4><blockquote><p>shuffle write 阶段，ShuffleMapStage 结束后，每一个 task 中的数据按照 key 进行分类，根据 <strong>hash 算法</strong>，<strong>将相同的 key 写入到一个磁盘文件中，而每一个磁盘文件都只属于下游 stage 的一个 task。在将数据写入磁盘之前，会先将数据写入到内存缓冲，当内存缓冲填满之后，溢写到磁盘文件中。</strong></p></blockquote><h4 id="shuffle-read"><a href="#shuffle-read" class="headerlink" title="shuffle read"></a>shuffle read</h4><blockquote><p>shuffle read，通常就是一个 stage 刚开始时要做的事情。此时该 stage 的每一个 task 需要将上一个 stage 的计算结果中的所有相同 key，从各个节点上通过网络都拉取到自己所在的节点上，然后进行 key 的聚合或连接等操作。由于 shuffle write 的过程中，task 给下游 stage 的每个 task 都创建了一个磁盘文件，因此 shuffle read 的过程中，每个 task 只要从上游 stage 的所有 task 所在节点上，拉取属于自己的那一个磁盘文件即可.</p></blockquote><blockquote><p>shuffle read 的拉取过程是一边拉取一边进行聚合的。每个 shuffle read task 都会有一个自己的buffer 缓冲，每次都只能拉取与 buffer 缓冲相同大小的数据，然后通过内存中的一个 Map 进行聚合等操作。聚合完一批数据后，再拉取下一批数据，并放到 buffer 缓冲中进行聚合操作。以此类推，直到最后将所有数据到拉取完，并得到最终的结果。</p></blockquote><p>这种策略的不足在于，<strong>下游有几个 task，上游的每一个 task 都就都需要创建几个临时文件</strong>，每个文件中只存储 key 取 hash 之后相同的数据，导致了当下游的 task 任务过多的时候，上游会堆积大量的小文件.</p><p><img src="../images/spark/2.png" alt="屏幕快照 2020-02-21 下午8.24.28"></p><ol><li>Shuffle 前在磁盘上会产生海量的小文件，此时会产生大量耗时低效的 IO 操作</li><li>内存不够用，由于内存中需要保存海量文件操作信息和临时信息，如果数据处理的规模比较庞大的话，内存不可承受，会出现 OOM 等问题。</li></ol><h3 id="优化之后的-HashShuffle"><a href="#优化之后的-HashShuffle" class="headerlink" title="优化之后的 HashShuffle"></a>优化之后的 HashShuffle</h3><p>这里说的优化，是指我们可以设置一个参数，spark.shuffle.consolidateFiles。该参数默认值为false，将其设置为 true 即可开启优化机制。通常来说，如果我们使用HashShuffleManager，那么都建议开启这个选项。</p><p>开启这个机制之后，在 shuffle write 过程中，task 就不是为下游 stage 的每个 task 创建一个磁盘文件。出现 shuffleFileGroup 的概念。一个 Executor 上有多少个 CPU core ，就可以并行执行多少个 task。第一批并行执行的每个 task 都会创建一个 shuffleFileGroup，并将数据写入对应的磁盘文件内。<strong>当 Executor 的 CPU core 接着执行下一批 task 时，下一批 task 就会复用之前已有的 shuffleFileGroup ，包括其中的磁盘文件。</strong>而不会写入新的磁盘文件中。</p><p>consolidate 机制允许不同的 task 复用同一批磁盘文件，这样就可以有效将多个 task 的磁盘文件进行一定程度上的合并，从而大幅度减少磁盘文件的数量，进而提升 shuffle write 的性能。</p><img src="../images/spark/3.png" alt="" style="zoom:50%;" /><h2 id="SortShuffle"><a href="#SortShuffle" class="headerlink" title="SortShuffle"></a><strong>SortShuffle</strong></h2><p>SortShuffleManager 的运行机制主要分成两种，一种是普通运行机制，另一种是 bypass 运 行 机 制 。 当 shuffle read task 的 数量小于等于 spark.shuffle.sort.bypassMergeThreshold 参数的值时[默认为 200 ]， 就会启用 bypass 机制。</p><h3 id="普通-SortShuffle"><a href="#普通-SortShuffle" class="headerlink" title="普通 SortShuffle"></a><strong>普通 SortShuffle</strong></h3><p>Task 将数据会先写入一个内存数据结构。</p><p><font color='blue'>[根据不同的 shuffle 算子，可能选用不同的数据结构。如果是 reduceByKey 这种聚合类的 shuffle 算子，那么会选用 Map 数据结构，一边通过 Map 进行聚合，一边写入内存；如果是 join 这种普通的 shuffle 算子，那么会选用 Array 数据结构，直接写入内存。]</font></p><p>每写一条数据进入内存数据结构之后，就会判断是否达到了某个临界值,<strong>如果达到了临界值的话，就会尝试的将内存数据结构中的数据溢写到磁盘</strong>,然后清空内存数据结构。</p><p>注：此时的临界值为动态变化的，并非固定值</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeSpill</span></span>(collection: <span class="type">C</span>, currentMemory: <span class="type">Long</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> shouldSpill = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (elementsRead % <span class="number">32</span> == <span class="number">0</span> &amp;&amp; currentMemory &gt;= myMemoryThreshold) &#123;</span><br><span class="line">    <span class="comment">// Claim up to double our current memory from the shuffle memory pool</span></span><br><span class="line">    <span class="keyword">val</span> amountToRequest = <span class="number">2</span> * currentMemory - myMemoryThreshold</span><br><span class="line">    <span class="keyword">val</span> granted = acquireMemory(amountToRequest)</span><br><span class="line">    myMemoryThreshold += granted</span><br><span class="line">    <span class="comment">// If we were granted too little memory to grow further (either tryToAcquire returned 0,</span></span><br><span class="line">    <span class="comment">// or we already had more memory than myMemoryThreshold), spill the current collection</span></span><br><span class="line">    shouldSpill = currentMemory &gt;= myMemoryThreshold</span><br><span class="line">  &#125;</span><br><span class="line">  shouldSpill = shouldSpill || _elementsRead &gt; numElementsForceSpillThreshold</span><br><span class="line">  <span class="comment">// Actually spill</span></span><br><span class="line">  <span class="keyword">if</span> (shouldSpill) &#123;</span><br><span class="line">    _spillCount += <span class="number">1</span></span><br><span class="line">    logSpillage(currentMemory)</span><br><span class="line">    spill(collection)</span><br><span class="line">    _elementsRead = <span class="number">0</span></span><br><span class="line">    _memoryBytesSpilled += currentMemory</span><br><span class="line">    releaseMemory()</span><br><span class="line">  &#125;</span><br><span class="line">  shouldSpill</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>在溢写到磁盘文件之前，会先根据 key 对内存数据结构中已有的数据进行排序</strong>，排序之后，会分批将数据写入磁盘文件。</p><p><font color='grey'>默认的 batch 数量是 10000 条，也就是说，排序好的数据，会以每批次 1 万条数据的形式分批写入磁盘文件，写入磁盘文件是通过Java 的 BufferedOutputStream 实现的。BufferedOutputStream 是 Java 的缓冲输出流，首先会将数据缓冲在内存中，当内存缓冲满溢之后再一次写入磁盘文件中，这样可以减少磁盘IO次数，提升性能。</font></p><p>一个 Task 将所有数据写入内存数据结构的过程中，会发生多次磁盘溢写，产生多个临时文件，最后会将之前所有的临时文件都进行合并，最后会合并成为一个大文件。<strong>最终只剩下两个文件，一个是合并之后的数据文件，一个是索引文件</strong>,索引文件标识了下游各个 Task 的数据在文件中的 start offset 与 end offset。最终再由下游的 task 根据索引文件读取相应的数据文件。</p><img src="../images/spark/5.png" alt="" style="zoom:50%;" /><p><font color = 'blue'> <strong>SortShuffleManager 由于有一个磁盘文件 merge 的过程，因此大大减少了文件数量。 比如第一个 stage 有 50 个 task ， 总共有 10 个 Executor ， 每个 Executor 执行 5个 task ，而第二个 stage 有 100 个 task 。由于每个 task 最终只有一个磁盘 文件，因此 此时每个 Executor 上只有 5 个磁盘文件， 所有 Executor 只有 50 个磁盘文件。</strong></font></p><h3 id="bypassSortShuffle"><a href="#bypassSortShuffle" class="headerlink" title="bypassSortShuffle"></a>bypassSortShuffle</h3><p>此时 Task 会为每个下游 Task 都创建一个临时磁盘文件，并将数据按 key 进行 hash 然后根据 key 的hash 值，将 key 写入对应的磁盘文件之中。当然，写入磁盘文件时也是先写入内存缓冲，缓冲写满之后再溢写到磁盘文件的。最后，同样会将所有临时磁盘文件都合并成一个磁盘文件，并创建一个单独的索引文件。</p><p>该过程的磁盘写机制其实跟未经优化的 HashShuffleManager 是一模一样的,因为都要创建数量惊人的磁盘文件， 只是在最后会做一个磁盘文件的合并而已,因此产生少量的最终磁盘文件,也让该机制相对未经优化的 HashShuffleManager 来说，shuffle read 的性能会更好。</p><p>而该机制与普通 SortShuffleManager 运行机制的不同在于</p><ol><li>磁盘写机制不同 </li><li>不会进行排序 </li></ol><p>也就是说,启用该机制的最大好处在于,shuffle write 过程中,不需要进行数据的排序操作,也就节省掉了这部分的性能开销。</p><p><strong>触发条件</strong></p><ol><li><p>shuffle map task 的数量小于 spark.shuffle.sort.bypassMergeThreshold 参数的值[默认200]</p></li><li><p>不是聚合类的shuffle 算子[比如groupByKey]</p></li></ol><h2 id="Spark-Shuffle-vs-MR-Shuffle"><a href="#Spark-Shuffle-vs-MR-Shuffle" class="headerlink" title="Spark Shuffle vs MR Shuffle"></a>Spark Shuffle vs MR Shuffle</h2><h3 id="Shuffle-管理器"><a href="#Shuffle-管理器" class="headerlink" title="Shuffle 管理器"></a>Shuffle 管理器</h3><p>Hadoop 2.7.x Shuffle 过程是 sort-based 过程，在 shuffle 过程中会发生排序行为</p><p>Spark 2.2.x Spark ShuffleManager 分为HashShuffleManager和 SortShuffleManager。Spark 1.2 后 默认为SortShuffleManager，在普通模式下，shuffle 过程中会发生排序行为；Spark 可以根据业务场景需要进行ShuffleManager 选择Hash Shuffle Manager / Sort ShuffleManager[普通模式和bypass模式]。</p><h3 id="Shuffle-过程排序次数"><a href="#Shuffle-过程排序次数" class="headerlink" title="Shuffle 过程排序次数"></a>Shuffle 过程排序次数</h3><ul><li>Hadoop Shuffle 过程总共会发生 3 次排序行为，详细分别如下：<ul><li>第一次排序行为：在 map 阶段，由环形缓冲区溢出到磁盘上时，落地磁盘的文件会按照 key 进行分区和排序，属于分区内有序，排序算法为快速排序</li><li>第二次排序行为：在 map 阶段，对溢出的文件进行 combiner合并过程中，需要对溢出的小文件进行归并排序、合并，排序算法为归并排序；</li><li>第三次排序行为：在 reduce 阶段，reduce task 将不同 maptask 端文件拉去到同一个reduce 分区后，对文件进行合并，归并排序，排序算法为归并排序；</li></ul></li><li>Spark Shuffle 过程在满足Shuffle Manager 为 SortShuffleManager ，且运行模式为普通模式的情况下才会发生排序行为，排序行为发生在数据结构中保存数据内存达到阈值，在溢出磁盘文件之前会对内存数据结构中数据进行排序；<ul><li>Spark 中 Sorted-Based Shuffle 在 Mapper 端是进行排序的，包括 partition 的排序和每个partition 内部元素进行排序。但是在 Reducer 端没有进行排序，所以 job 的结果默认情况下不是排序的。</li><li>Sorted-Based Shuffle  采用 Tim-Sort 排序算法，好处是可以极为高效的使用 Mapper 端的排序成果完成全局排序。</li></ul></li></ul><h3 id="Shuffle-逻辑流划分"><a href="#Shuffle-逻辑流划分" class="headerlink" title="Shuffle 逻辑流划分"></a>Shuffle 逻辑流划分</h3><ul><li><p>Hadoop Shuffle 过程可以划分为：map()，spill，merge，shuffle，sort，reduce()等，是按照流程顺次执行的，属于Push类型；</p></li><li><p>Spark Shuffle过程是由算子进行驱动，由于Spark的算子懒加载特性，属于Pull类型，整个Shuffle过程可以划分为Shuffle Write 和Shuffle Read两个阶段；</p></li></ul><h3 id="数据结构不同"><a href="#数据结构不同" class="headerlink" title="数据结构不同"></a>数据结构不同</h3><ul><li>Hadoop 是基于文件的数据结构</li><li>Spark是基于RDD的数据结构，计算性能要比 Hadoop 要高</li></ul><h3 id="Shuffle-Fetch-后数据存放位置"><a href="#Shuffle-Fetch-后数据存放位置" class="headerlink" title="Shuffle Fetch 后数据存放位置"></a>Shuffle Fetch 后数据存放位置</h3><ul><li>Hadoop reduce 端将 map task 的文件拉去到同一个 reduce 分区，是将文件进行归并排序、合并，将文件直接保存在磁盘上</li><li>Spark Shuffle Read 拉取来的数据首先肯定是放在 Reducer 端的内存缓存区中的，实现是内存+磁盘的方式，当然也可以通过 Spark.shuffle.spill=false 来设置只能使用内存。使用 ExternalAppendOnlyMap的方式时候如果内存使用达到一定临界值，会首先尝试在内存中扩大 ExternalAppendOnlyMap，如果不能扩容的话才会spill到磁盘。</li></ul><h3 id="Fetch-操作与数据计算粒度"><a href="#Fetch-操作与数据计算粒度" class="headerlink" title="Fetch 操作与数据计算粒度"></a>Fetch 操作与数据计算粒度</h3><ul><li>Hadoop 的 MapReduce 是粗粒度的，Hadoop Shuffle Reducer Fetch到的数据 record先暂时被存放到Buffer 中，当 Buffer 快满时才进行 combine() 操作</li><li>Spark 的 Shuffle Fetch 是细粒度的，Reducer 是对 Map 端数据 Record 边拉去边聚合</li></ul><h2 id="Spark-Shuffle-调优"><a href="#Spark-Shuffle-调优" class="headerlink" title="Spark Shuffle 调优"></a>Spark Shuffle 调优</h2><p>大多数 Spark 作业的性能主要就是消耗在了 shuffle 环节，因为该环节包含了大量的磁盘IO、序列化、网络数据传输等操作。因此，如果要让作业的性能更上一层楼，就有必要对 shuffle 过程进行调优。</p><h3 id="shuffle-相关参数调优"><a href="#shuffle-相关参数调优" class="headerlink" title="shuffle 相关参数调优"></a>shuffle 相关参数调优</h3><ol><li><p><strong>spark.shuffle.file.buffer</strong></p><p>默认值：32k</p><p>参数说明：该参数用于设置 shuffle write task 的 BufferedOutputStream 的 buffer 缓冲大小。将数据写到磁盘文件之前，会先写入 buffer 缓冲中，待缓冲写满之后，才会溢写到磁盘。<br>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如64k），从而减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</p></li><li><p><strong>spark.reducer.maxSizeInFlight</strong></p><p>默认值：48m<br>参数说明：该参数用于设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据。<br>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。</p></li><li><p><strong>spark.shuffle.io.maxRetries</strong></p><p>默认值：3<br>参数说明：shuffle read task 从 shuffle write task 所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取还是没有成功，就可能会导致作业执行失败。<br>调优建议：对于那些包含了特别耗时的 shuffle 操作的作业，建议增加重试最大次数（比如60次），以避免由于 JVM 的 full gc 或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的 shuffle 过程，调节该参数可以大幅度提升稳定性。</p></li><li><p><strong>spark.shuffle.io.retryWait</strong></p><p>默认值：5s<br>参数说明：该参数代表了每次重试拉取数据的等待间隔，默认是 5s。<br>调优建议：建议加大间隔时长（比如60s），以增加 shuffle 操作的稳定性。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark 数据倾斜</title>
      <link href="2019/11/23/Spark%20%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/"/>
      <url>2019/11/23/Spark%20%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Spark 中的数据倾斜问题主要指 shuffle 过程中由于不同的 key 对应的数据量不同导致的不同 task 所处理的数据量不同的问题。</p><a id="more"></a><h2 id="表现"><a href="#表现" class="headerlink" title="表现"></a>表现</h2><ol><li>Spark 作业的大部分 task 都执行迅速，只有有限的几个 task 执行的非常慢，此时可能出现了数据倾斜，作业可以运行，但是运行的非常慢。</li><li>原本能够正常执行的 Spark 作业，突然出现 OOM[内存溢出] 异常</li></ol><h2 id="定位数据倾斜"><a href="#定位数据倾斜" class="headerlink" title="定位数据倾斜"></a>定位数据倾斜</h2><p>在 Spark 中，同一个 Stage 的不同 Partition 可以并行处理，而具有依赖关系的不同 Stage 之间是串行处理的。假设某个 Spark Job 分为 Stage 0 和 Stage 1 两个 Stage，且 Stage 1 依赖于 Stage 0，那 Stage 0 完全处理结束之前不会处理 Stage 1。而 Stage 0 可能包含 N 个Task，这 N 个Task可以并行进行。如果其中 N-1 个 Task 都在10秒内完成，而另外一个 Task 却耗时1分钟，那该 Stage 的总时间至少为1分钟。换句话说，一个 Stage 所耗费的时间，主要由最慢的那个 Task 决定。<br>由于同一个 Stage 内的所有 Task 执行相同的计算，在排除不同计算节点计算能力差异的前提下，不同Task之间耗时的差异主要由该 Task 所处理的数据量决定。<br>Stage 的数据来源主要分为如下两类</p><ol><li>从数据源直接读取。如读取 HDFS，Kafka</li><li>读取上一个 Stage 的 Shuffle 数据</li></ol><p>常用并且可能会触发 shuffle 操作的算子有：distinct，groupByKey，reduceByKey，aggregateByKey，join 等。出现数据倾斜，很有可能就是使用了这些算子中的某一个导致的。</p><ol><li><p>如果我们是 yarn-client 模式提交，我们可以在本地直接查看 log，在 log 中定位到当前运行到了哪个 stage</p></li><li><p>如果用的 yarn-cluster 模式提交的话，我们可以通过 spark web UI 来查看当前运行到了哪个 stage。</p></li></ol><p>无论用的哪种模式我们都可以在 Spark web UI 上面查看到当前这个 stage 的各个 task 的数据量和运行时间，从而能够进一步确定是不是 task 的数据分配不均导致的数据倾斜。</p><p>当确定了发生数据倾斜的 stage 后，我们可以找出会触发 shuffle 的算子，推算出发生倾斜的那个 stage 对应代码。触发 shuffle 操作的除了上面提到的那些算子外，还要注意使用 spark sql 的某些 sql 语句，比如 group by 等。</p><h2 id="解决策略"><a href="#解决策略" class="headerlink" title="解决策略"></a>解决策略</h2><h4 id="数据源的数据倾斜"><a href="#数据源的数据倾斜" class="headerlink" title="数据源的数据倾斜"></a>数据源的数据倾斜</h4><p>尽量避免数据源的数据倾斜，以 Spark Stream 通过 DirectStream 方式读取 Kafka 数据为例。由于Kafka 的每一个 Partition 对应 Spark 的一个 Task（Partition），所以 Kafka 内相关 Topic 的各 Partition 之间数据是否平衡，直接决定 Spark 处理该数据时是否会产生数据倾斜。</p><p>Kafka 某一 Topic 内消息在不同 Partition 之间的分布，主要由 Producer 端所使用的 Partition 实现类决定。如果使用随机 Partitioner，则每条消息会随机发送到一个 Partition 中，从而从概率上来讲，各 Partition 间的数据会达到平衡。此时源直接读取 Kafka 数据的 Stage 不会产生数据倾斜。<br>但很多时候，业务场景可能会要求将具备同一特征的数据顺序消费，此时就需要将具有相同特征的数据放于同一个Partition中。一个典型的场景是，需要将同一个用户相关的 PV 信息置于同一个 Partition 中。此时，如果产生了数据倾斜，则需要通过其它方式处理。</p><h4 id="过滤异常数据"><a href="#过滤异常数据" class="headerlink" title="过滤异常数据"></a><strong>过滤异常数据</strong></h4><p>如果导致数据倾斜的 key 是异常数据，那么简单的过滤掉就可以了。</p><p>首先要对 key 进行分析，判断是哪些 key 造成数据倾斜。然后对这些 key 对应的记录进行分析:</p><ol><li>空值或者异常值之类的，大多是这个原因引起</li><li>无效数据，大量重复的测试数据或是对结果影响不大的有效数据</li><li>有效数据，业务导致的正常数据分布</li></ol><p>解决方案</p><p>对于第 1，2 种情况，直接对数据进行过滤即可。第3种情况则需要特殊的处理，具体我们下面详细介绍</p><h3 id="调整并行度分散同一个-Task-的不同-Key"><a href="#调整并行度分散同一个-Task-的不同-Key" class="headerlink" title="调整并行度分散同一个 Task 的不同 Key"></a>调整并行度分散同一个 Task 的不同 Key</h3><p>Spark 在做 Shuffle 时，默认使用 HashPartitioner 对数据进行分区。如果并行度设置的不合适，可能造成大量不相同的 Key 对应的数据被分配到了同一个 Task 上，造成该 Task 所处理的数据远大于其它 Task，从而造成数据倾斜。<br>如果调整 Shuffle 时的并行度，使得原本被分配到同一 Task 的不同 Key 发配到不同 Task 上处理，则可降低原 Task 所需处理的数据量，从而缓解数据倾斜问题造成的短板效应。</p><p><strong>优势</strong><br>实现简单，可在需要 Shuffle 的操作算子上直接设置并行度或者使用<code>spark.default.parallelism</code>设置。如果是Spark SQL，还可通过<code>SET spark.sql.shuffle.partitions=[num_tasks]</code>设置并行度。可用最小的代价解决问题。一般如果出现数据倾斜，都可以通过这种方法先试验几次，如果问题未解决，再尝试其它方法。</p><p><img src="https://www.iteblog.com/pic/spark/changeparallelism.png" alt="spark change parallelism"></p><p><strong>劣势</strong><br>适用场景少，只能将分配到同一Task 的不同 Key 分散开，但对于同一 Key 倾斜严重的情况该方法并不适用。并且该方法一般只能缓解数据倾斜，没有彻底消除问题。从实践经验来看，其效果一般。</p><p><strong>方案实践经验</strong></p><p>该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。所以这种方案只能说是在发现数据倾斜时尝试使用的第一种手段，尝试去用嘴简单的方法缓解数据倾斜而已，或者是和其他方案结合起来使用。</p><h3 id="自定义-Partitioner"><a href="#自定义-Partitioner" class="headerlink" title="自定义 Partitioner"></a>自定义 Partitioner</h3><p><strong>适用场景</strong><br>大量不同的 Key 被分配到了相同的 Task 造成该 Task 数据量过大。</p><p><strong>解决方案</strong><br>使用自定义的 Partitioner 实现类代替默认的 HashPartitioner，尽量将所有不同的 Key 均匀分配到不同的Task中。</p><p><strong>优势</strong><br>不影响原有的并行度设计。如果改变并行度，后续 Stage 的并行度也会默认改变，可能会影响后续 Stage。</p><p><strong>劣势</strong><br>适用场景有限，只能将不同 Key 分散开，对于同一 Key 对应数据集非常大的场景不适用。效果与调整并行度类似，只能缓解数据倾斜而不能完全消除数据倾斜。而且需要根据数据特点自定义专用的 Partitioner，不够灵活。</p><h3 id="两阶段聚合（局部聚合-全局聚合）"><a href="#两阶段聚合（局部聚合-全局聚合）" class="headerlink" title="两阶段聚合（局部聚合+全局聚合）"></a>两阶段聚合（局部聚合+全局聚合）</h3><p>在 Spark 中使用 groupByKey 和 reduceByKey 这两个算子会进行 shuffle 操作。这时候如果 map 端的文件每个 key 的数据量偏差很大，很容易会造成数据倾斜。</p><p>我们可以先对需要操作的数据中的 key 拼接上随机数进行打散分组，这样原来是一个 key 的数据可能会被分到多个 key 上，然后进行一次聚合，聚合完之后将原来拼在 key 上的随机数去掉，再进行聚合，这样对数据倾斜会有比较好的效果。</p><p>这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个 key 都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行 reduceByKey 等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</p><p><strong>方案缺点：</strong>仅仅适用于聚合类的 shuffle 操作，适用范围相对较窄。如果是 join 类的 shuffle 操作，还得用其他的解决方案。</p><h3 id="将-reduce-join-转换为-map-join"><a href="#将-reduce-join-转换为-map-join" class="headerlink" title="将 reduce join 转换为 map join"></a>将 reduce join 转换为 map join</h3><p>通过 Spark 的 Broadcast 机制，将 Reduce 侧 Join 转化为 Map 侧 Join，避免 Shuffle 从而完全消除 Shuffle 带来的数据倾斜。</p><p>两个 RDD 在进行 join 时会有 shuffle 操作，如果每个 key 对应的数据分布不均匀也会有数据倾斜发生。</p><p>这种情况下，如果两个 RDD 中某个 RDD 的数据量不大，可以将该 RDD 的数据提取出来，然后做成广播变量，将数据量大的那个 RDD 做 map 算子操作，然后在 map 算子内和广播变量进行 join，这样可以避免了 join 过程中的 shuffle，也就避免了 shuffle 过程中可能会出现的数据倾斜现象。</p><p><strong>适用场景</strong><br>参与 Join 的一边数据集足够小，可被加载进 Driver 并通过 Broadcast 方法广播到各个 Executor 中。</p><p><strong>解决方案</strong><br>在 Java/Scala 代码中将小数据集数据拉取到 Driver，然后通过 broadcast 方案将小数据集的数据广播到各 Executor。或者在使用 SQL 前，将 broadcast 的阈值调整得足够多，从而使用 broadcast 生效。进而将 Reduce 侧 Join 替换为 Map 侧 Join。</p><p><a href="https://www.iteblog.com/pic/spark/mapjoin.png"><img src="https://www.iteblog.com/pic/spark/mapjoin.png" alt="spark map join"></a></p><h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><p><strong>优势</strong><br>避免了 Shuffle，彻底消除了数据倾斜产生的条件，可极大提升性能。</p><p><strong>劣势</strong><br>要求参与 Join 的一侧数据集足够小，并且主要适用于 Join 的场景，不适合聚合的场景，适用条件有限。</p><h3 id="为-skew-的-key-增加随机前-后缀，拆分-join-再-union"><a href="#为-skew-的-key-增加随机前-后缀，拆分-join-再-union" class="headerlink" title="为 skew 的 key 增加随机前/后缀，拆分 join 再 union"></a>为 skew 的 key 增加随机前/后缀，<strong>拆分 join 再 union</strong></h3><p>为数据量特别大的 Key 增加随机前/后缀，使得原来 Key 相同的数据变为 Key 不相同的数据，从而使倾斜的数据集分散到不同的 Task 中，彻底解决数据倾斜问题。Join 另一则的数据中，与倾斜 Key 对应的部分数据，与随机前缀集作笛卡尔乘积，从而保证无论数据倾斜侧倾斜Key如何加前缀，都能与之正常 Join。</p><p><strong>适用场景</strong><br>两张表都比较大，无法使用Map则Join。其中一个RDD有少数几个Key的数据量过大，另外一个RDD的Key分布较为均匀。</p><p><strong>解决方案</strong><br>将有数据倾斜的RDD中倾斜Key对应的数据集单独抽取出来加上随机前缀，另外一个RDD每条数据分别与随机前缀结合形成新的RDD（相当于将其数据增到到原来的N倍，N即为随机前缀的总个数），然后将二者Join并去掉前缀。然后将不包含倾斜Key的剩余数据进行Join。最后将两次Join的结果集通过union合并，即可得到全部Join结果。</p><p><img src="https://www.iteblog.com/pic/spark/randomprefix.png" alt="spark random prefix"></p><p><strong>优势</strong><br>相对于 Map 则Join，更能适应大数据集的 Join。如果资源充足，倾斜部分数据集与非倾斜部分数据集可并行进行，效率提升明显。且只针对倾斜部分的数据做数据扩展，增加的资源消耗有限。</p><p><strong>劣势</strong><br>如果倾斜 Key 非常多，则另一侧数据膨胀非常大，此方案不适用。而且此时对倾斜Key与非倾斜Key分开处理，需要扫描数据集两遍，增加了开销。</p><h3 id="大表-key-加盐，小表扩大-N-倍-join"><a href="#大表-key-加盐，小表扩大-N-倍-join" class="headerlink" title="大表 key 加盐，小表扩大 N 倍 join"></a><strong>大表 key 加盐，小表扩大 N 倍 join</strong></h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>如果出现数据倾斜的 Key 比较多，上一种方法将这些大量的倾斜 Key 分拆出来，意义不大。此时更适合直接对存在数据倾斜的数据集全部加上随机前缀，然后对另外一个不存在严重数据倾斜的数据集整体与随机前缀集作笛卡尔乘积（即将数据量扩大N倍）。</p><p><img src="https://www.iteblog.com/pic/spark/randomprefixandenlargesmalltable.png" alt="spark random prefix"></p><p><strong>适用场景</strong><br>一个数据集存在的倾斜Key比较多，另外一个数据集数据分布比较均匀。</p><p><strong>优势</strong><br>对大部分场景都适用，效果不错。</p><p><strong>劣势</strong><br>需要将一个数据集整体扩大N倍，会增加资源消耗。</p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 数据转换算子</title>
      <link href="2019/11/23/Flink%E7%AE%97%E5%AD%90(Operator)%E7%AE%80%E4%BB%8B/"/>
      <url>2019/11/23/Flink%E7%AE%97%E5%AD%90(Operator)%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 Flink 应用程序中，无论你的应用程序是批程序，还是流程序，都是上图这种模型，有数据源（source），有数据下游（sink）</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在 Flink 应用程序中，无论你的应用程序是批程序，还是流程序，都是上图这种模型，有数据源（source），有数据下游（sink）</p><ol><li><p><strong>Source</strong>:</p><p>数据源，Flink 在流处理和批处理上的 source 大概有 4 类</p><ul><li><p>基于本地集合的 source</p></li><li><p>基于文件的 source</p></li><li><p>基于网络套接字的 source</p></li><li><p>自定义的 source</p></li></ul></li><li><p><strong>Transformation</strong></p><p>数据转换的各种操作，有 Map / FlatMap / Filter / KeyBy / Reduce / Fold / Aggregations / Window / WindowAll / Union / Window join / Split / Select / Project 等，操作很多。</p></li><li><p><strong>Sink</strong>: 接收器，Sink 是指 Flink 将转换计算后的数据发送的地点。Flink 常见的 Sink 大概有如下几类：写入文件、打印出来、写入 Socket 、自定义的 Sink 。</p><p>自定义的 sink 常见的有 Apache kafka、RabbitMQ、MySQL、ElasticSearch、Hadoop FileSystem 等，同理也可以定义自己的 Sink。</p></li></ol><h1 id="常用算子"><a href="#常用算子" class="headerlink" title="常用算子"></a>常用算子</h1><h4 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h4><p>Map 算子的输入流是 DataStream，经过 Map 算子后返回的数据格式是 SingleOutputStreamOperator 类型，获取一个元素并生成一个元素</p><h4 id="FlatMap"><a href="#FlatMap" class="headerlink" title="FlatMap"></a>FlatMap</h4><p>FlatMap 算子的输入流是 DataStream，经过 FlatMap 算子后返回的数据格式是 SingleOutputStreamOperator 类型，获取一个元素并生成零个、一个或多个元素</p><h4 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h4><p>对每个元素都进行判断，返回为 true 的元素，如果为 false 则丢弃数据</p><h4 id="KeyBy"><a href="#KeyBy" class="headerlink" title="KeyBy"></a>KeyBy</h4><p>KeyBy 在逻辑上是基于 key 对流进行分区，相同的 Key 会被分到一个分区（这里分区指的就是下游算子多个并行节点的其中一个）。在内部，它使用 hash 函数对流进行分区。它返回 KeyedDataStream 数据流</p><img src="/Users/joker/Documents/chen_blog/images/截屏2021-01-20 上午9.17.14.png" alt="截屏2021-01-20 上午9.17.14" style="zoom:50%;" /><h4 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h4><p>Reduce 返回单个的结果值，并且 reduce 操作每处理一个元素总是创建一个新值。常用的方法有 average、sum、min、max、count</p><h4 id="Aggregations"><a href="#Aggregations" class="headerlink" title="Aggregations"></a>Aggregations</h4><p>DataStream API 支持各种聚合，例如 min、max、sum 等。 这些函数可以应用于 KeyedStream 以获得 Aggregations 聚合</p><h4 id="Union"><a href="#Union" class="headerlink" title="Union"></a>Union</h4><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-06-30-061732.jpg" alt="img"></p><p>Union 函数将两个或多个数据流结合在一起。 这样后面在使用的时候就只需使用一个数据流就行了。 如果我们将一个流与自身组合，那么组合后的数据流会有两份同样的数据。</p><h4 id="Select"><a href="#Select" class="headerlink" title="Select"></a>Select</h4><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-06-30-062535.jpg" alt="img"></p><p>上面用 Split 算子将数据流拆分成两个数据流（奇数、偶数），接下来你可能想从拆分流中选择特定流，那么就得搭配使用 Select 算子（一般这两者都是搭配在一起使用的）</p><h4 id="Split"><a href="#Split" class="headerlink" title="Split"></a>Split</h4><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-06-30-062027.jpg" alt="img"></p><p>此功能根据条件将流拆分为两个或多个流。 当你获得混合流然后你可能希望单独处理每个数据流时，可以使用此方法</p>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> F </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark Shuffle</title>
      <link href="2019/11/23/HDFS%E6%A6%82%E8%BF%B0/"/>
      <url>2019/11/23/HDFS%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-产生背景"><a href="#1-产生背景" class="headerlink" title="1.产生背景"></a>1.产生背景</h1><h1 id="2-HDFS-优缺点"><a href="#2-HDFS-优缺点" class="headerlink" title="2.HDFS 优缺点"></a>2.<code>HDFS</code> 优缺点</h1><h2 id="2-1-HDFS-的优点"><a href="#2-1-HDFS-的优点" class="headerlink" title="2.1.HDFS 的优点"></a>2.1.<code>HDFS</code> 的优点</h2><h3 id="2-1-1-处理超大文件"><a href="#2-1-1-处理超大文件" class="headerlink" title="2.1.1. 处理超大文件"></a>2.1.1. 处理超大文件</h3><p>超大文件通常是指百<code>MB</code>、甚至数百<code>TB</code>大小的文件。目前在实际应用中，HDFS 已经能用来存储管理 PB 级的数据了。</p><h3 id="2-1-2-流式的访问数据"><a href="#2-1-2-流式的访问数据" class="headerlink" title="2.1.2. 流式的访问数据"></a>2.1.2. 流式的访问数据</h3><p><code>HDFS</code> 的设计建立在 **”一次写入、多次读写”**任务的基础上。这意味着一个数据集一旦由数据源生成，就会被复制分发到不同的存储节点中，然后响应各种各样的数据分析任务请求。</p><h3 id="2-1-3-运行于廉价的商用机器集群上"><a href="#2-1-3-运行于廉价的商用机器集群上" class="headerlink" title="2.1.3. 运行于廉价的商用机器集群上"></a>2.1.3. 运行于廉价的商用机器集群上</h3><p>只须运行在低廉的商用硬件集群上，而无需在昂贵的高可用性机器上</p><h2 id="2-2-HDFS-的缺点"><a href="#2-2-HDFS-的缺点" class="headerlink" title="2.2. HDFS 的缺点"></a>2.2. <code>HDFS</code> 的缺点</h2><h3 id="2-2-1-不适合低延迟数据访问"><a href="#2-2-1-不适合低延迟数据访问" class="headerlink" title="2.2.1. 不适合低延迟数据访问"></a>2.2.1. 不适合低延迟数据访问</h3><p>如果要处理一些用户要求时间比较短的低延迟应用请求，则HDFS不适合。HDFS是为了处理大型数据集分析任务的，主要是为达到高的数据吞吐量而设计的，这就可能要求以高延迟作为代价。对于那些有低延时要求的应用程序，HBase是一个更好的选择。</p><h3 id="2-2-2-无法高效存储大量的小文件"><a href="#2-2-2-无法高效存储大量的小文件" class="headerlink" title="2.2.2. 无法高效存储大量的小文件"></a>2.2.2. 无法高效存储大量的小文件</h3><p>因为NameNode把文件系统的元数据放置在内存中，所有文件系统所能容纳的文件数目是由NameNode的内存大小来决定。还有一个问题就是，因为MapTask的数量是由Splits来决定的，所以用MR处理大量的小文件时，就会产生过多的MapTask，线程管理开销将会增加作业时间。当Hadoop处理很多小文件(文件大小小于HDFS中Block大小)的时候，由于FileInputFormat不会对小文件进行划分，所以每一个小文件都会被当做一个Split并分配一个Map任务，导致效率底下。</p><h3 id="2-2-3-不支持多用户写入及任意修改文件"><a href="#2-2-3-不支持多用户写入及任意修改文件" class="headerlink" title="2.2.3. 不支持多用户写入及任意修改文件"></a>2.2.3. 不支持多用户写入及任意修改文件</h3><p>在HDFS的一个文件中只有一个写入者，而且写操作只能在文件末尾完成，即只能执行追加操作，目前HDFS还不支持多个户对同一文件的写操作，以及在文件任意位置进行修改。但是支持文件追加</p><h1 id="3-HDFS-架构"><a href="#3-HDFS-架构" class="headerlink" title="3. HDFS 架构"></a>3. <code>HDFS</code> 架构</h1><h2 id="3-1-Hadoop1-x"><a href="#3-1-Hadoop1-x" class="headerlink" title="3.1. Hadoop1.x"></a>3.1. <code>Hadoop1.x</code></h2><h3 id="3-1-1-NameNode"><a href="#3-1-1-NameNode" class="headerlink" title="3.1.1. NameNode"></a>3.1.1. <code>NameNode</code></h3><p>NameNode又称为名称节点，是负责管理分布式文件系统的命名空间，保存了两个核心的数据结构，即FsImage 和EditLog 。你可以把它理解成大管家，它不负责存储具体的数据。</p><p>HDFS也是文件系统，它也有metadata；由NameNode**<strong>储存在其内存</strong></p><p>文件、block、目录占用大概150Byte字节的元数据；所以HDFS适合储存大文件，不适合储存小文件</p><h3 id="3-1-2-Secondary-NameNode"><a href="#3-1-2-Secondary-NameNode" class="headerlink" title="3.1.2. Secondary NameNode"></a>3.1.2. <code>Secondary NameNode</code></h3><blockquote><p>它出现在 <code>Hadoop1.x</code> 版本中，又称辅助<code>NameNode</code>，在 <code>Hadoop2.x</code> 以后的版本中此角色消失。如果充当<code>Datanode</code> 节点的一台机器宕机或者损害，其数据不会丢失，因为备份数据还存在于其他的 <code>Datanode</code> 中。但是，如果充当 <code>Namenode</code> 节点的机器宕机或损害导致文件系统无法使用，那么文件系统上的所有文件将会丢失，因为我们不知道如何根据 <code>Datanode</code> 的块重建文件。因此，对 <code>NameNode</code> 实现容错非常重要。<code>Hadoop</code> 提供了两种机制实现高容错性。</p></blockquote><blockquote><ul><li><p>辅助 <code>NameNode</code> 工作，分担其工作量。比如定期合并 <code>FsImage</code> 和 <code>Edits</code> ，防止编辑日志文件过大，并且能保证其信息与 <code>NameNode</code> 信息保持一致，并推送给<code>NameNode</code>。</p></li><li><p>紧急情况下，可以辅助恢复 <code>NameNode</code>。</p></li></ul></blockquote><blockquote><p><strong><code>SecondaryNameNode</code> 一般在另一台单独的物理计算机上运行，因为它需要占用大量 <code>CPU</code> 时间来与<code>namenode</code> 进行合并操作，一般情况是单独开一个线程来执行操作过程。但是，<code>SecondaryNameNode</code> 保存的信息永远是滞后于<code>NameNode</code>，所以在 <code>NameNode</code> 失效时，难免会丢失部分数据。</strong></p></blockquote><blockquote><p>在这种情况下，一般把存储在 <code>NFS</code> 上的 <code>Namenode</code> 元数据复制到 <code>SecondaryNameNode</code> 并作为新的 <code>NameNode</code>。<code>SecondaryNameNode</code> 不是 <code>NameNode</code> 的备份，可以作为备份。<code>SecondaryNameNode</code> 主要工作是帮助 <code>NameNode</code> 合并 <code>edits</code> 和<code>fsimag</code>e，减少 <code>Namenode</code> 的启动时间</p></blockquote><blockquote><p><strong><code>SecondaryNameNode</code> 执行合并的时机决定于</strong>：</p><ul><li>配置文件设置的时间间隔 **<code>fs.checkpoint.period</code>**，默认为 <code>3600</code> 秒。</li><li>配置文件设置 <code>edits log</code> 大小**<code>fs.checkpoint.size</code>**,规定 <code>edits</code> 文件的最大值默认是<code>64MB</code>。</li></ul></blockquote><ul><li><p>第一阶段：<code>NameNode</code> 启动</p><ul><li>第一次启动 <code>NameNode</code> 格式化后，创建 <code>FsImage</code> 和 <code>Edits</code> 文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</li><li>客户端对元数据进行增删改的请求</li><li><code>NameNode</code> 记录操作日志，更新滚动日志。</li><li><code>NameNode</code> 在内存中对数据进行增删改查</li></ul></li><li><p>第二阶段：<code>Secondary NameNode</code>工作</p><ul><li><strong><code>Secondary NameNode</code> 请求  <code>NameNode</code> 是否需要  <code>checkpoint</code>。直接带回<code>NameNode</code>是否需要检查结果。</strong>[<code>checkpoint</code> 触发条件：定时时间和 <code>Edits</code> 数据已满]</li><li><code>Secondary NameNode</code> 请求执行 <code>checkpoint</code>。</li><li><code>NameNode</code> 滚动正在写的 <code>Edits</code> 日志</li><li>将滚动前的编辑日志和镜像文件拷贝到 <code>Secondary NameNode</code></li><li><code>SecondaryNameNode</code>加载编辑日志和镜像文件到内存，并合并。生成新的镜像文件<code>fsimage.chkpoint</code></li><li>拷贝 <code>fsimage.chkpoint</code> 到 <code>NameNode</code></li><li><code>NameNode</code> 将 <code>fsimage.chkpoint</code> 重新命名成 `fsimage``</li></ul></li></ul><h3 id="3-1-3-DataNode"><a href="#3-1-3-DataNode" class="headerlink" title="3.1.3. DataNode"></a>3.1.3. <code>DataNode</code></h3><blockquote><p><code>Datanode</code> 用来具体的存储文件，维护了<code>blockId</code> 与 <code>datanode</code> 本地文件的映射。 需要不断的与<code>namenode</code> 节点通信，来告知其自己的信息，方便 <code>namenode</code> 来管控整个系统。</p></blockquote><h3 id="3-1-4-Client"><a href="#3-1-4-Client" class="headerlink" title="3.1.4. Client"></a>3.1.4. <code>Client</code></h3><blockquote><p>客户端是用户和 <code>HDFS</code> 进行交互的手段，<code>HDFS</code> 提供了各种各样的客户端，包括命令行接口、<code>Java API</code> <code>Thrift</code>接口等。</p></blockquote><ul><li><p>职责</p><ul><li><p>文件切分。文件上传 <code>HDFS</code> 的时候，<code>client</code> 将文件切分成一个一个的 <code>Block</code>，然后进行上传。</p></li><li><p>和 <code>NameNode</code> 进行交互，获取文件的位置信息。</p></li><li><p>和 <code>DataNode</code> 进行交互，读取或写入文件</p></li><li><p>提供一些命令来管理 <code>HDFS</code>，如 <code>NameNode</code>格式化</p></li><li><p>提供一些命令来访问<code>HDFS</code>，如 <code>NameNode</code> 增删改查操作。</p></li></ul></li></ul><h2 id="3-2-Hadoop2-x"><a href="#3-2-Hadoop2-x" class="headerlink" title="3.2. Hadoop2.x"></a>3.2. <code>Hadoop2.x</code></h2><h3 id="3-2-1-Active-NameNode"><a href="#3-2-1-Active-NameNode" class="headerlink" title="3.2.1. Active NameNode"></a>3.2.1. <code>Active NameNode</code></h3><h3 id="3-2-2-StandBy-NameNode"><a href="#3-2-2-StandBy-NameNode" class="headerlink" title="3.2.2. StandBy NameNode"></a>3.2.2. <code>StandBy NameNode</code></h3>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark Shuffle</title>
      <link href="2019/11/23/Hadoop%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%5B3%5D-NameNode%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"/>
      <url>2019/11/23/Hadoop%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%5B3%5D-NameNode%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>详细讲述 HDFS NameNode 启动流程</p><a id="more"></a><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Namenode 实体在代码实现中主要对应于三个类</p><ol><li><p>NameNode</p><p>NameNode 类负责管理 Namenode 配置，RPC 接口以及 HTTP 接口等，</p></li><li><p>NameNodeRpcServer</p><p>用于接收和处理所有的 RPC 请求</p></li><li><p>FSNamesystem</p><p>负责实现 Namenode 的所有逻辑</p></li></ol><p>Namenode 的启动操作是在 NameNode 类中执行的，main() 方法首先调用 createNameNode() 创建一个NameNode 对象，创建成功后调用 NameNode.join() 方法等待 RPC 服务结束。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String argv[])</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (DFSUtil.parseHelpArgument(argv, NameNode.USAGE, System.out, <span class="keyword">true</span>)) &#123;</span><br><span class="line">    System.exit(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    StringUtils.startupShutdownMessage(NameNode.class, argv, LOG);</span><br><span class="line">    <span class="comment">//TODO</span></span><br><span class="line">    NameNode namenode = createNameNode(argv, <span class="keyword">null</span>);</span><br><span class="line">    <span class="keyword">if</span> (namenode != <span class="keyword">null</span>) &#123;</span><br><span class="line">      namenode.join();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">    LOG.error(<span class="string">&quot;Failed to start namenode.&quot;</span>, e);</span><br><span class="line">    terminate(<span class="number">1</span>, e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>createNameNode() 方法会根据启动 Namenode 时传入的启动选项，调用对应的方法执行操<br>作。</p><ul><li>FORMAT:格式化当前 Namenode,调用 format() 方法执行格式化操作。</li><li>FINALIZE:提交上一次升级，目前 Namenode 命令不再支持“－finalize”选项，建<br>议用户使用“hdfs dfsadmin-finalizeUpgrade”命令进行提交操作。</li><li>ROLLBACK:回滚上一次升级，调用 doRollback0方法执行回滚操作</li><li>BOOTSTRAPSTANDBY:拷贝 Active Namenode 的最新命名空间数据到 Standby<br>Namenode,调用 BootstrapStandby.run方法执行操作。</li><li>INITIALIZESHAREDEDITS:初始化editlog 的共享存储空间，并从Active Namenode<br>中拷贝足够的 editlog 数据，使得Standby 节点能够顺利启动。 这里调用了静态方法<br>initializeSharedEdits() 执行操作。</li><li>BACKUP:启动 backup节点，这里直接构造一个BackupNode对象并返回。</li><li>CHECKPOINT:启动 checkpoint 节点，也是直接构造BackupNode 对象并返回。</li><li>RECOVER:恢复损坏的元数据以及文件系统，这里调用了 doRecoveryO方法执行操作。</li><li>默认：正常启动NameNode</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//正常启动NameNode</span></span><br><span class="line"><span class="keyword">default</span>: &#123;</span><br><span class="line">  <span class="comment">//初始化 metric 系统</span></span><br><span class="line">  DefaultMetricsSystem.initialize(<span class="string">&quot;NameNode&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> NameNode(conf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="正常启动-NameNode"><a href="#正常启动-NameNode" class="headerlink" title="正常启动 NameNode"></a>正常启动 NameNode</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="title">NameNode</span><span class="params">(Configuration conf, NamenodeRole role)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">this</span>.conf = conf;</span><br><span class="line">  <span class="keyword">this</span>.role = role;</span><br><span class="line">  setClientNamenodeAddress(conf);<span class="comment">//RPC地址</span></span><br><span class="line">  String nsId = getNameServiceId(conf);<span class="comment">//命名空间的id</span></span><br><span class="line">  String namenodeId = HAUtil.getNameNodeId(conf, nsId);</span><br><span class="line">  <span class="keyword">this</span>.haEnabled = HAUtil.isHAEnabled(conf, nsId);</span><br><span class="line">  state = createHAState(getStartupOption(conf));</span><br><span class="line">  <span class="keyword">this</span>.allowStaleStandbyReads = HAUtil.shouldAllowStandbyReads(conf);</span><br><span class="line">  <span class="keyword">this</span>.haContext = createHAContext();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">//初始化联邦一些配置</span></span><br><span class="line">    initializeGenericKeys(conf, nsId, namenodeId);</span><br><span class="line">    <span class="comment">//TODO 初始化 namenode</span></span><br><span class="line">    initialize(conf);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      haContext.writeLock();</span><br><span class="line">      state.prepareToEnterState(haContext);</span><br><span class="line">      <span class="comment">//TODO active \ standBy</span></span><br><span class="line">      state.enterState(haContext);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      haContext.writeUnlock();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    <span class="keyword">this</span>.stop();</span><br><span class="line">    <span class="keyword">throw</span> e;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (HadoopIllegalArgumentException e) &#123;</span><br><span class="line">    <span class="keyword">this</span>.stop();</span><br><span class="line">    <span class="keyword">throw</span> e;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">this</span>.started.set(<span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="初始化成员变量"><a href="#初始化成员变量" class="headerlink" title="初始化成员变量"></a>初始化成员变量</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.conf = conf;</span><br><span class="line"><span class="keyword">this</span>.role = role;</span><br><span class="line">setClientNamenodeAddress(conf);<span class="comment">//RPC地址</span></span><br><span class="line">String nsId = getNameServiceId(conf);<span class="comment">//命名空间的id</span></span><br><span class="line">String namenodeId = HAUtil.getNameNodeId(conf, nsId);</span><br><span class="line"><span class="keyword">this</span>.haEnabled = HAUtil.isHAEnabled(conf, nsId);</span><br><span class="line">state = createHAState(getStartupOption(conf));</span><br><span class="line"><span class="keyword">this</span>.allowStaleStandbyReads = HAUtil.shouldAllowStandbyReads(conf);</span><br><span class="line"><span class="keyword">this</span>.haContext = createHAContext();</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//NameNode核心成员变量用来管理元数据（实现对DataNode、Block的管理以及读写日志）</span></span><br><span class="line"><span class="keyword">protected</span> FSNamesystem namesystem;</span><br><span class="line"><span class="comment">//保存配置文件的信息</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> Configuration conf;</span><br><span class="line"><span class="comment">//保存NameNode的角色信息</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> NamenodeRole role;</span><br><span class="line"></span><br><span class="line"><span class="comment">//保存NameNode的状态（HA）</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> HAState state;</span><br><span class="line"><span class="comment">//是否开启了高可用(HA)</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> haEnabled;</span><br><span class="line"><span class="comment">//高可用上下文</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> HAContext haContext;</span><br><span class="line"><span class="comment">//NameNode核心成员变量提供RPC服务（提供RPC服务是DataNode和NameNode通信和外部命令管理NameNode的窗口）</span></span><br><span class="line"><span class="keyword">private</span> NameNodeRpcServer rpcServer;</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">boolean</span> allowStaleStandbyReads;</span><br><span class="line"><span class="keyword">private</span> AtomicBoolean started = <span class="keyword">new</span> AtomicBoolean(<span class="keyword">false</span>); </span><br></pre></td></tr></table></figure><h4 id="初始化联邦"><a href="#初始化联邦" class="headerlink" title="初始化联邦"></a>初始化联邦</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//初始化联邦一些配置</span></span><br><span class="line">initializeGenericKeys(conf, nsId, namenodeId);</span><br></pre></td></tr></table></figure><h4 id="初始化-NameNode"><a href="#初始化-NameNode" class="headerlink" title="初始化 NameNode"></a>初始化 NameNode</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始化 namenode</span></span><br><span class="line">initialize(conf);</span><br></pre></td></tr></table></figure><p>NameNode.initialize()构造 HTTP 服务器，构造 RPC 服务器，初始化<br>FSNamesystem 对象，最后调用 startCommonServices() 启动 HTTP 服务器、RPC服务器。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">(Configuration conf)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">//设置metrics的监控间隔</span></span><br><span class="line">  <span class="keyword">if</span> (conf.get(HADOOP_USER_GROUP_METRICS_PERCENTILES_INTERVALS) == <span class="keyword">null</span>) &#123;</span><br><span class="line">    String intervals = conf.get(DFS_METRICS_PERCENTILES_INTERVALS_KEY);</span><br><span class="line">    <span class="keyword">if</span> (intervals != <span class="keyword">null</span>) &#123;</span><br><span class="line">      conf.set(HADOOP_USER_GROUP_METRICS_PERCENTILES_INTERVALS,</span><br><span class="line">        intervals);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//设置权限，根据 hadoop.security.authentication 获取认证方式及规则</span></span><br><span class="line">  UserGroupInformation.setConfiguration(conf);</span><br><span class="line">  <span class="comment">//用户安全登录</span></span><br><span class="line">  loginAsNameNodeUser(conf);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//初始化度量系统，用于度量namenode服务状态</span></span><br><span class="line">  NameNode.initMetrics(conf, <span class="keyword">this</span>.getRole());</span><br><span class="line">  StartupProgressMetrics.register(startupProgress);</span><br><span class="line">  <span class="keyword">if</span> (NamenodeRole.NAMENODE == role) &#123;</span><br><span class="line">    <span class="comment">//TODO 1. 启动 httpServer 对外发布50070</span></span><br><span class="line">    startHttpServer(conf);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">this</span>.spanReceiverHost = SpanReceiverHost.getInstance(conf);</span><br><span class="line">  <span class="comment">//TODO 2. 加载元数据</span></span><br><span class="line">  loadNamesystem(conf);</span><br><span class="line">  <span class="comment">//TODO 2. 启动 RPC</span></span><br><span class="line">  rpcServer = createRpcServer(conf);</span><br><span class="line">  <span class="comment">//如果RPC的地址是null，那么创建一个RPC的地址</span></span><br><span class="line">  <span class="keyword">if</span> (clientNamenodeAddress == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// This is expected for MiniDFSCluster. Set it now using </span></span><br><span class="line">    <span class="comment">// the RPC server&#x27;s bind address.</span></span><br><span class="line">    clientNamenodeAddress = </span><br><span class="line">        NetUtils.getHostPortString(rpcServer.getRpcAddress());</span><br><span class="line">    LOG.info(<span class="string">&quot;Clients are to use &quot;</span> + clientNamenodeAddress + <span class="string">&quot; to access&quot;</span></span><br><span class="line">        + <span class="string">&quot; this namenode/service.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (NamenodeRole.NAMENODE == role) &#123;</span><br><span class="line">    httpServer.setNameNodeAddress(getNameNodeAddress());<span class="comment">//给httpServer设置RPC的地址</span></span><br><span class="line">    httpServer.setFSImage(getFSImage());<span class="comment">//设置FSImage快照</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  pauseMonitor = <span class="keyword">new</span> JvmPauseMonitor(conf);</span><br><span class="line">  pauseMonitor.start();</span><br><span class="line">  metrics.getJvmMetrics().setPauseMonitor(pauseMonitor);</span><br><span class="line">  <span class="comment">//TODO 4. 启动一些公共服务[最重要]</span></span><br><span class="line">  startCommonServices(conf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="启动-HttpServer"><a href="#启动-HttpServer" class="headerlink" title="启动 HttpServer"></a>启动 HttpServer</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (NamenodeRole.NAMENODE == role) &#123;</span><br><span class="line">  <span class="comment">//TODO 启动 httpServer 对外发布50070</span></span><br><span class="line">  startHttpServer(conf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startHttpServer</span><span class="params">(<span class="keyword">final</span> Configuration conf)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  httpServer = <span class="keyword">new</span> NameNodeHttpServer(conf, <span class="keyword">this</span>, getHttpServerBindAddress(conf));</span><br><span class="line">  httpServer.start();</span><br><span class="line">  httpServer.setStartupProgress(startupProgress);</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">//HTTP_ONLY</span></span><br><span class="line">    HttpConfig.Policy policy = DFSUtil.getHttpPolicy(conf);</span><br><span class="line">    <span class="comment">//localhost | 0.0.0.0</span></span><br><span class="line">    <span class="keyword">final</span> String infoHost = bindAddress.getHostName();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//得到 namenode 的 web 端地址 localhost:50070</span></span><br><span class="line">    <span class="keyword">final</span> InetSocketAddress httpAddr = bindAddress;</span><br><span class="line">    <span class="comment">//得到https的服务地址：localhost:50470</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> String httpsAddrString = conf.getTrimmed(</span><br><span class="line">        DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_KEY,</span><br><span class="line">        DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_DEFAULT);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//把https的地址封装成InetSocketAddress</span></span><br><span class="line">    InetSocketAddress httpsAddr = NetUtils.createSocketAddr(httpsAddrString);</span><br><span class="line">    <span class="comment">//构造https的地址</span></span><br><span class="line">    <span class="keyword">if</span> (httpsAddr != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">//TODO</span></span><br><span class="line"><span class="comment">//      final String bindHost =</span></span><br><span class="line"><span class="comment">//      conf.getTrimmed(DFSConfigKeys.DFS_NAMENODE_HTTPS_BIND_HOST_KEY);</span></span><br><span class="line">      <span class="keyword">final</span> String bindHost = <span class="string">&quot;localhost&quot;</span>;</span><br><span class="line">      <span class="keyword">if</span> (bindHost != <span class="keyword">null</span> &amp;&amp; !bindHost.isEmpty()) &#123;</span><br><span class="line">        httpsAddr = <span class="keyword">new</span> InetSocketAddress(bindHost, httpsAddr.getPort());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    HttpServer2.Builder builder = DFSUtil.httpServerTemplateForNNAndJN(conf,</span><br><span class="line">        httpAddr, httpsAddr, <span class="string">&quot;hdfs&quot;</span>,</span><br><span class="line">        DFSConfigKeys.DFS_NAMENODE_KERBEROS_INTERNAL_SPNEGO_PRINCIPAL_KEY,</span><br><span class="line">        DFSConfigKeys.DFS_NAMENODE_KEYTAB_FILE_KEY);</span><br><span class="line"></span><br><span class="line">    httpServer = builder.build();</span><br><span class="line">    <span class="keyword">if</span> (policy.isHttpsEnabled()) &#123;</span><br><span class="line">      <span class="comment">// 构建datanode的https服务的端口</span></span><br><span class="line">      InetSocketAddress datanodeSslPort = NetUtils.createSocketAddr(conf.getTrimmed(</span><br><span class="line">          DFSConfigKeys.DFS_DATANODE_HTTPS_ADDRESS_KEY, infoHost + <span class="string">&quot;:&quot;</span></span><br><span class="line">              + DFSConfigKeys.DFS_DATANODE_HTTPS_DEFAULT_PORT));</span><br><span class="line">      httpServer.setAttribute(DFSConfigKeys.DFS_DATANODE_HTTPS_PORT_KEY,</span><br><span class="line">          datanodeSslPort.getPort());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    initWebHdfs(conf);</span><br><span class="line">    <span class="comment">//绑定属性</span></span><br><span class="line">    httpServer.setAttribute(NAMENODE_ATTRIBUTE_KEY, nn);</span><br><span class="line">    httpServer.setAttribute(JspHelper.CURRENT_CONF, conf);</span><br><span class="line">    <span class="comment">//TODO 在这里绑定很多功能</span></span><br><span class="line">    setupServlets(httpServer, conf);</span><br><span class="line">    httpServer.start();<span class="comment">//启动对外发布50070</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> connIdx = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (policy.isHttpEnabled()) &#123;</span><br><span class="line">      httpAddress = httpServer.getConnectorAddress(connIdx++);</span><br><span class="line">      conf.set(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY,</span><br><span class="line">          NetUtils.getHostPortString(httpAddress));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (policy.isHttpsEnabled()) &#123;</span><br><span class="line">      httpsAddress = httpServer.getConnectorAddress(connIdx);</span><br><span class="line">      conf.set(DFSConfigKeys.DFS_NAMENODE_HTTPS_ADDRESS_KEY,</span><br><span class="line">          NetUtils.getHostPortString(httpsAddress));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><img src="/Users/zxc/Documents/hexo/source/_posts/Hadoop源码学习[3]-NameNode启动流程.assets/hdfs3.png" alt="hdfs3" style="zoom:50%;" /><h3 id="绑定功能属性"><a href="#绑定功能属性" class="headerlink" title="绑定功能属性"></a>绑定功能属性</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">initWebHdfs(conf);</span><br><span class="line"><span class="comment">//绑定属性</span></span><br><span class="line">httpServer.setAttribute(NAMENODE_ATTRIBUTE_KEY, nn);</span><br><span class="line">httpServer.setAttribute(JspHelper.CURRENT_CONF, conf);</span><br><span class="line"><span class="comment">//TODO 在这里绑定很多功能</span></span><br><span class="line">setupServlets(httpServer, conf);</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setupServlets</span><span class="params">(HttpServer2 httpServer, Configuration conf)</span> </span>&#123;</span><br><span class="line">  httpServer.addInternalServlet(<span class="string">&quot;startupProgress&quot;</span>,</span><br><span class="line">      StartupProgressServlet.PATH_SPEC, StartupProgressServlet.class);</span><br><span class="line">  httpServer.addInternalServlet(<span class="string">&quot;getDelegationToken&quot;</span>,</span><br><span class="line">      GetDelegationTokenServlet.PATH_SPEC, </span><br><span class="line">      GetDelegationTokenServlet.class, <span class="keyword">true</span>);</span><br><span class="line">  httpServer.addInternalServlet(<span class="string">&quot;renewDelegationToken&quot;</span>, </span><br><span class="line">      RenewDelegationTokenServlet.PATH_SPEC, </span><br><span class="line">      RenewDelegationTokenServlet.class, <span class="keyword">true</span>);</span><br><span class="line">  httpServer.addInternalServlet(<span class="string">&quot;cancelDelegationToken&quot;</span>, </span><br><span class="line">      CancelDelegationTokenServlet.PATH_SPEC, </span><br><span class="line">      CancelDelegationTokenServlet.class, <span class="keyword">true</span>);</span><br><span class="line">  httpServer.addInternalServlet(<span class="string">&quot;fsck&quot;</span>, <span class="string">&quot;/fsck&quot;</span>, FsckServlet.class,</span><br><span class="line">      <span class="keyword">true</span>);</span><br><span class="line">  httpServer.addInternalServlet(<span class="string">&quot;imagetransfer&quot;</span>, ImageServlet.PATH_SPEC,</span><br><span class="line">      ImageServlet.class, <span class="keyword">true</span>);</span><br><span class="line">  httpServer.addInternalServlet(<span class="string">&quot;listPaths&quot;</span>, <span class="string">&quot;/listPaths/*&quot;</span>,</span><br><span class="line">      ListPathsServlet.class, <span class="keyword">false</span>);</span><br><span class="line">  httpServer.addInternalServlet(<span class="string">&quot;data&quot;</span>, <span class="string">&quot;/data/*&quot;</span>,</span><br><span class="line">      FileDataServlet.class, <span class="keyword">false</span>);</span><br><span class="line">  httpServer.addInternalServlet(<span class="string">&quot;checksum&quot;</span>, <span class="string">&quot;/fileChecksum/*&quot;</span>,</span><br><span class="line">      FileChecksumServlets.RedirectServlet.class, <span class="keyword">false</span>);</span><br><span class="line">  httpServer.addInternalServlet(<span class="string">&quot;contentSummary&quot;</span>, <span class="string">&quot;/contentSummary/*&quot;</span>,</span><br><span class="line">      ContentSummaryServlet.class, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="/Users/zxc/Documents/hexo/source/_posts/Hadoop源码学习[3]-NameNode启动流程.assets/hdfs5.png" alt="hdfs5" style="zoom:60%;" /><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//NameNode核心成员变量用来管理元数据（实现对DataNode、Block的管理以及读写日志）</span></span><br><span class="line"><span class="keyword">protected</span> FSNamesystem namesystem;</span><br><span class="line"><span class="comment">//保存配置文件的信息</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> Configuration conf;</span><br><span class="line"><span class="comment">//保存NameNode的角色信息</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> NamenodeRole role;</span><br><span class="line"></span><br><span class="line"><span class="comment">//保存NameNode的状态（HA）</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> HAState state;</span><br><span class="line"><span class="comment">//是否开启了高可用(HA)</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> haEnabled;</span><br><span class="line"><span class="comment">//高可用上下文</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> HAContext haContext;</span><br><span class="line"><span class="comment">//NameNode核心成员变量提供RPC服务（提供RPC服务是DataNode和NameNode通信和外部命令管理NameNode的窗口）</span></span><br><span class="line"><span class="keyword">private</span> NameNodeRpcServer rpcServer;</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">boolean</span> allowStaleStandbyReads;</span><br><span class="line"><span class="keyword">private</span> AtomicBoolean started = <span class="keyword">new</span> AtomicBoolean(<span class="keyword">false</span>); </span><br></pre></td></tr></table></figure><h1 id="3-加载元数据"><a href="#3-加载元数据" class="headerlink" title="3.加载元数据"></a>3.加载元数据</h1><p><img src="/Users/zxc/Documents/hexo/source/_posts/Hadoop%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%5B3%5D-NameNode%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B.assets/hdfs6-2540565.png" alt="hdfs6"></p><h1 id="4-创建-RPC"><a href="#4-创建-RPC" class="headerlink" title="4.创建 RPC"></a>4.创建 RPC</h1><h3 id="4-1-注册-RPC，然后给引擎注册协议-Protocol"><a href="#4-1-注册-RPC，然后给引擎注册协议-Protocol" class="headerlink" title="4.1.注册 RPC，然后给引擎注册协议 Protocol"></a>4.1.<strong>注册 RPC，然后给引擎注册协议 Protocol</strong></h3><h3 id="4-2-分别实例化-ServiceRpcServer-和-ClientRpcServer"><a href="#4-2-分别实例化-ServiceRpcServer-和-ClientRpcServer" class="headerlink" title="4.2.分别实例化 ServiceRpcServer 和 ClientRpcServer"></a>4.2.<strong>分别实例化 ServiceRpcServer 和 ClientRpcServer</strong></h3><h3 id="4-2-1-ServiceRpcServer"><a href="#4-2-1-ServiceRpcServer" class="headerlink" title="4.2.1.ServiceRpcServer"></a>4.2.1.ServiceRpcServer</h3><p>用来 NameNode 和 DataNode 之间的通信（注册、心跳、握手、数据块的汇报）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.serviceRpcServer = <span class="keyword">new</span> RPC.Builder(conf)</span><br><span class="line">    .setProtocol(</span><br><span class="line">        org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB.class)</span><br><span class="line">    .setInstance(clientNNPbService)</span><br><span class="line">    .setBindAddress(bindHost)</span><br><span class="line">    .setPort(serviceRpcAddr.getPort()).setNumHandlers(serviceHandlerCount)</span><br><span class="line">    .setVerbose(<span class="keyword">false</span>)</span><br><span class="line">    .setSecretManager(namesystem.getDelegationTokenSecretManager())</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><h3 id="4-2-2-ClientRpcServer"><a href="#4-2-2-ClientRpcServer" class="headerlink" title="4.2.2.ClientRpcServer"></a>4.2.2.ClientRpcServer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.clientRpcServer = <span class="keyword">new</span> RPC.Builder(conf)</span><br><span class="line">    .setProtocol(</span><br><span class="line">        org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB.class)</span><br><span class="line">    .setInstance(clientNNPbService).setBindAddress(bindHost)</span><br><span class="line">    .setPort(rpcAddr.getPort()).setNumHandlers(handlerCount)</span><br><span class="line">    .setVerbose(<span class="keyword">false</span>)</span><br><span class="line">    .setSecretManager(namesystem.getDelegationTokenSecretManager()).build();</span><br></pre></td></tr></table></figure><h1 id="5-启动公共服务"><a href="#5-启动公共服务" class="headerlink" title="5.启动公共服务"></a>5.启动公共服务</h1><h2 id="5-1-进行资源检查的前期准备"><a href="#5-1-进行资源检查的前期准备" class="headerlink" title="5.1.进行资源检查的前期准备"></a>5.1.进行资源检查的前期准备</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Create a NameNodeResourceChecker, which will check the edits dirs and any</span></span><br><span class="line"><span class="comment"> * additional dirs to check set in &lt;code&gt;conf&lt;/code&gt;.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">NameNodeResourceChecker</span><span class="params">(Configuration conf)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.conf = conf;</span><br><span class="line">  <span class="comment">//volumes 存放待检查的路径</span></span><br><span class="line">  volumes = <span class="keyword">new</span> HashMap&lt;String, CheckedVolume&gt;();</span><br><span class="line">  <span class="comment">//100M</span></span><br><span class="line">  duReserved = conf.getLong(DFSConfigKeys.DFS_NAMENODE_DU_RESERVED_KEY,</span><br><span class="line">      DFSConfigKeys.DFS_NAMENODE_DU_RESERVED_DEFAULT);</span><br><span class="line">  <span class="comment">//获取本地目录列表</span></span><br><span class="line">  Collection&lt;URI&gt; extraCheckedVolumes = Util.stringCollectionAsURIs(</span><br><span class="line">          conf.getTrimmedStringCollection(DFSConfigKeys.DFS_NAMENODE_CHECKED_VOLUMES_KEY));</span><br><span class="line"></span><br><span class="line">  <span class="comment">//获取共享目录列表dfs.namenode.shared.edits.dir（HA场景下的journalNode的目录列表）</span></span><br><span class="line">  Collection&lt;URI&gt; localEditDirs = Collections2.filter(</span><br><span class="line">      FSNamesystem.getNamespaceEditsDirs(conf),<span class="comment">//拿到edits的目录</span></span><br><span class="line">      <span class="keyword">new</span> Predicate&lt;URI&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">apply</span><span class="params">(URI input)</span> </span>&#123;</span><br><span class="line">          <span class="keyword">if</span> (input.getScheme().equals(NNStorage.LOCAL_URI_SCHEME)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Add all the local edits dirs, marking some as required if they are</span></span><br><span class="line">  <span class="comment">// configured as such.</span></span><br><span class="line">  <span class="keyword">for</span> (URI editsDirToCheck : localEditDirs) &#123;</span><br><span class="line">    addDirToCheck(editsDirToCheck,</span><br><span class="line">        FSNamesystem.getRequiredNamespaceEditsDirs(conf).contains(</span><br><span class="line">            editsDirToCheck));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// All extra checked volumes are marked &quot;required&quot;</span></span><br><span class="line">  <span class="keyword">for</span> (URI extraDirToCheck : extraCheckedVolumes) &#123;</span><br><span class="line">    addDirToCheck(extraDirToCheck, <span class="keyword">true</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//返回配置的目录空间，最小可用的容忍度，模式1</span></span><br><span class="line">  minimumRedundantVolumes = conf.getInt(</span><br><span class="line">      DFSConfigKeys.DFS_NAMENODE_CHECKED_VOLUMES_MINIMUM_KEY,</span><br><span class="line">      DFSConfigKeys.DFS_NAMENODE_CHECKED_VOLUMES_MINIMUM_DEFAULT);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="5-2-检查可用资源是否足够：如果不够，日志打印警告信息，然后进入安全模式"><a href="#5-2-检查可用资源是否足够：如果不够，日志打印警告信息，然后进入安全模式" class="headerlink" title="5.2.检查可用资源是否足够：如果不够，日志打印警告信息，然后进入安全模式"></a>5.2.检查可用资源是否足够：如果不够，日志打印警告信息，然后进入安全模式</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * Start services common to both active and standby states</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">startCommonServices</span><span class="params">(Configuration conf, HAContext haContext)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.registerMBean(); <span class="comment">// register the MBean for the FSNamesystemState</span></span><br><span class="line">  writeLock();</span><br><span class="line">  <span class="keyword">this</span>.haContext = haContext;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">//TODO 1 进行资源检查的前期准备</span></span><br><span class="line">    nnResourceChecker = <span class="keyword">new</span> NameNodeResourceChecker(conf);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 2 检查可用资源是否足够：如果不够，日志打印警告信息，然后进入安全模式</span></span><br><span class="line">    checkAvailableResources();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> safeMode != <span class="keyword">null</span> &amp;&amp; !isPopulatingReplQueues();</span><br><span class="line"></span><br><span class="line">    StartupProgress prog = NameNode.getStartupProgress();</span><br><span class="line">    <span class="comment">// 目前NameNode启动，进入到safemode阶段，处于一个等待汇报blocks的状态</span></span><br><span class="line">    prog.beginPhase(Phase.SAFEMODE);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 处于一个等待汇报blocks的状态</span></span><br><span class="line">    prog.setTotal(Phase.SAFEMODE, STEP_AWAITING_REPORTED_BLOCKS,</span><br><span class="line">      getCompleteBlocksTotal());</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 3 设置所有的block，用于后面判断是否进入安全模式</span></span><br><span class="line">    setBlockTotal();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 4 激活BlockManager</span></span><br><span class="line">    blockManager.activate(conf);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    writeUnlock();</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  registerMXBean();</span><br><span class="line">  DefaultMetricsSystem.instance().register(<span class="keyword">this</span>);</span><br><span class="line">  <span class="keyword">if</span> (inodeAttributeProvider != <span class="keyword">null</span>) &#123;</span><br><span class="line">    inodeAttributeProvider.start();</span><br><span class="line">    dir.setINodeAttributeProvider(inodeAttributeProvider);</span><br><span class="line">  &#125;</span><br><span class="line">  snapshotManager.registerMXBean();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="5-2-安全模式"><a href="#5-2-安全模式" class="headerlink" title="5.2.安全模式"></a>5.2.安全模式</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * There is no need to enter safe mode </span></span><br><span class="line"><span class="comment"> * if DFS is empty or &#123;<span class="doctag">@link</span> #threshold&#125; == 0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">needEnter</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 1: threshold=0.999f 这个不为null &amp;&amp; 汇报过来的数据块数 &lt; 安全阈值(1000=999)</span></span><br><span class="line"><span class="comment">   * 2: 存活的 datanode 数量如果&lt;=0</span></span><br><span class="line"><span class="comment">   * 3: 如果磁盘空间&lt;100m</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * */</span></span><br><span class="line">  <span class="keyword">return</span> (threshold != <span class="number">0</span> &amp;&amp; blockSafe &lt; blockThreshold) ||</span><br><span class="line">    (datanodeThreshold != <span class="number">0</span> &amp;&amp; getNumLiveDataNodes() &lt; datanodeThreshold) ||</span><br><span class="line">    (!nameNodeHasResourcesAvailable());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h1><p><img src="/Users/zxc/Documents/hexo/source/_posts/Hadoop%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%5B3%5D-NameNode%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B.assets/hdfs1.png" alt="hdfs1"></p><h2 id="1-2-简介"><a href="#1-2-简介" class="headerlink" title="1.2. 简介"></a>1.2. 简介</h2><p>安全模式是HDFS的一种工作状态，处于安全模式的状态下，只向客户端提供文件的只读视图，不接受对命名空间的修改；同时NameNode节点也不会进行数据块的复制或者删除，如：副本的数量小于正常水平。</p><h2 id="1-3-相关命令"><a href="#1-3-相关命令" class="headerlink" title="1.3. 相关命令"></a>1.3. 相关命令</h2><ul><li><p><code>hadoop dfsadmin -safemode leave</code></p><blockquote><p>强制 <code>NameNode</code> 退出安全模式</p></blockquote></li><li><p><code>hadoop dfsadmin -safemode enter</code>  </p><blockquote><p> 进入安全模式</p></blockquote></li><li><p><code>hadoop dfsadmin -safemode get</code>   </p><blockquote><p> 查看安全模式状态</p></blockquote></li><li><p><code>hadoop dfsadmin -safemode wait </code></p><blockquote><p>等待一直到安全模式结束</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> Hadoop 源码阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> Hadoop 源码阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark 存储模块</title>
      <link href="2019/11/22/Spark%20%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/"/>
      <url>2019/11/22/Spark%20%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业[Job]，并将作业转化为计算任务[Task]，在各个 Executor 进程间协调任务的调度；后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver， 同时为需要持久化的 RDD 提供存储功能。由于 Driver 的内存管理相对来说较为简单，本节主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。</p><a id="more"></a><h2 id="Execuor-内存模型"><a href="#Execuor-内存模型" class="headerlink" title="Execuor 内存模型"></a>Execuor 内存模型</h2><h3 id="堆内和堆外内存"><a href="#堆内和堆外内存" class="headerlink" title="堆内和堆外内存"></a>堆内和堆外内存</h3><p>作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内 [On-heap]空间进行了更为详细的分配，以充分利用内存。</p><p>同时，Spark 引入了堆外[Off-heap]内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。</p><p><strong>堆内内存受到 JVM 统一管理，堆外内存是直接向操作系统进行内存的申请和释放。</strong></p><h3 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h3><p>堆内内存的大小，由 Spark 应用程序启动时的 –executor-memory 或 spark.executor.memory 参数配置。 </p><p>Executor 内运行的并发任务共享 JVM 堆内内存， 这些任务在缓存 RDD 数据和广播 Broadcast 数据时占用的内存被规划为存储 [Storage] 内存， 而这些任务在执行 Shuffle 时占用的内存被规划为执行 [Execution] 内存，剩余的部分不做特殊规划，Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间 。不同的管理模式下， 这三部分占用的空间大小各不相同 </p><h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>JVM 对于内存的清理无法准确指定时间点，因此无法实现精确的释放。<strong>为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了堆外[Off-heap]内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。</strong>由于内存的申请和释放不再通过 JVM 机制，而是直接向操作系统申请，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说，堆外内存可以被精确地申请和释放，降低了管理的难度，也降低了误差 </p><p>在默认情况下堆外内存并不启用，可通过配置 spark.memory.offHeap.enabled 参数启用，并由 spark.memory.offHeap.size 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存 。</p><h2 id="内存空间分配"><a href="#内存空间分配" class="headerlink" title="内存空间分配"></a>内存空间分配</h2><h3 id="静态内存管理"><a href="#静态内存管理" class="headerlink" title="静态内存管理"></a>静态内存管理</h3><p>在 Spark 最初采用的静态内存管理机制下，**[存储内存]<strong>、</strong>[执行内存]<strong>和</strong>[其他内存]**的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置。</p><img src="/images/spark/009.png" alt="" style="zoom:90%;" /><ul><li><p>可用的存储内存</p><p> systemMaxMemory * spark.storage.memoryFraction * spark.storage.safetyFraction</p></li><li><p>可用的执行内存</p><p>systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction</p></li></ul><p>其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。 </p><p>上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 [1-safetyFraction] 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险。</p><p>值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和”其它内存”一样交给了 JVM 去管理。</p><p><strong>Storage 内存和 Execution 内存都有预留空间，目的是防止 OOM ，因为 Spark 堆内内存大小的记录是不准确的，需要留出保险区域。</strong></p><p>堆外的空间分配较为简单，只有存储内存和执行内存。可用的执行内存和存储内存占用的空间大小直接由参数 spark.memory.storageFraction 决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域 </p><img src="/images/spark/12.png" alt="" style="zoom:90%;" /><p>静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。</p><h3 id="统一内存管理"><a href="#统一内存管理" class="headerlink" title="统一内存管理"></a>统一内存管理</h3><p><strong>Spark1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于<font color='blue'>存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域</font></strong> </p><img src="/images/spark/10.png" alt="" style="zoom:90%;" /><p>其中最重要的优化在于动态占用机制， 其规则如下：</p><img src="/images/spark/20.png" alt="" style="zoom:90%;" /><ul><li><p>设定基本的存储内存和执行内存区域（spark.storage.storageFraction参数），该设定确定了双方各自拥有的空间的范围；</p></li><li><p>双方的空间都不足时，则存储到硬盘</p><p>若己方空间不足而对方空余时，可借用对方的空间; [注：存储空间不足是指不足以放下一个完整的Block]</p></li><li><p>执行内存的空间被对方占用后，可让对方将占用的部分转存到磁盘，然后”归还”借用的空间；</p></li><li><p>存储内存的空间被对方占用后，无法让对方 “归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。</p></li></ul><h2 id="存储内存管理"><a href="#存储内存管理" class="headerlink" title="存储内存管理"></a>存储内存管理</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Storage 管理着 Spark 应用在运行过程中产生的各种数据。比如 RDD 缓存，shuffle 过程中缓存及写入磁盘的数据，广播变量等。</p><p>Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block。Driver 端 BlockManager 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Executor 端的 BlockManager 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令， 例如新增或删除一个 RDD。</p><ul><li><p>BlockManager</p><blockquote><p>BlockManager 是 整个 Spark 底层负责数据存储与管理的一个组件 ， Driver 和 Executor 的所有数据都由对应的 BlockManager 进行管理。</p><p>Driver 上有 BlockManager Master ，负责对各个节点上的 BlockManager 内部管理的数据的元数据进行维护， 比如 block 的增删改等操作， 都会在这里维护好元数据 的变更。</p><p>每个节点都有一个 BlockManager，每个 BlockManager 创建之后， 第一件事即使去向 BlockManag erMaster 进行注册。</p></blockquote></li><li><p>CacheManager</p><blockquote><p>CacheManager 管理 spark 的缓存，而缓存可以基于内存的缓存，也可以是基于磁盘的缓存；<br>CacheManager 需要通过 BlockManager 来操作数据</p></blockquote></li></ul><h3 id="RDD-的持久化机制"><a href="#RDD-的持久化机制" class="headerlink" title="RDD 的持久化机制"></a>RDD 的持久化机制</h3><p>弹性分布式数据集 RDD 作为 Spark 最根本的数据抽象，是只读的分区记录的集合，基于在稳定物理存储中的数据集上创建，或者在其他已有的 RDD 上执行转换[Transformation]操作产生一个新的 RDD。转换后的 RDD 与 原始的 RDD 之间产生的依赖关系构成了血统[Lineag]。凭借血统，Spark 保证了每一个 RDD 都可以被重新恢复。</p><p>Task 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 要执行多次 action 操作， 可以在第一次 action 操作中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。</p><blockquote><p>其中 cache 这个方法是个 Tranformation ,当第一次遇到 action 算子的时才会进行持久化</p><p>cache 内部调用了 persist(StorageLevel.MEMORY_ONLY)方法，所以执行 cache 算子其实就是执行了 persist 算子且持久化级别为 MEMORY_ONLY。 故缓存是一种特殊的持久化。堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理。</p></blockquote><p>RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。 </p><p>在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY 、MEMORY_AND_DISK 等 7 种不同的存储级别 ， 而存储级别是以下 5 个变量的组合：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StorageLevel</span> <span class="title">private</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useDisk: <span class="type">Boolean</span>, //磁盘</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useMemory: <span class="type">Boolean</span>, //这里其实是指堆内内存</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useOffHeap: <span class="type">Boolean</span>, //堆外内存</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _deserialized: <span class="type">Boolean</span>, //是否为非序列化</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _replication: <span class="type">Int</span> = 1 //副本个数</span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>存储级别</th><th>含义</th></tr></thead><tbody><tr><td>MEMORY_ONLY</td><td>以非序列化的 Java 对象的方式持久化在 JVM 内存中。如果内存无法完全存储 RDD 所有的 partition，那么那些没有持久化的 partition 就会在下一次需要使用它们的时候，重新被计算</td></tr><tr><td>MEMORY_AND_DISK</td><td>同上，但是当 RDD 某些 partition 无法存储在内存中时，会持久化到磁盘中。下次需要使用这些 partition 时，需要从磁盘上读取</td></tr><tr><td>MEMORY_ONLY_SER</td><td>同 MEMORY_ONLY，但是会使用 Java 序列化方式，将 Java 对象序列化后进行持久化。可以减少内存开销，但是需要进行反序列化，因此会加大 CPU 开销</td></tr><tr><td>MEMORY_AND_DISK_SER</td><td>同 MEMORY_AND_DISK，但是使用序列化方式持久化 Java 对象</td></tr><tr><td>DISK_ONLY</td><td>使用非序列化 Java 对象的方式持久化，完全存储到磁盘上</td></tr><tr><td>MEMORY_ONLY_2  MEMORY_AND_DISK_2</td><td>如果是尾部加了 2 的持久化级别，表示将持久化数据复用一份，保存到其他节点，从而在数据丢失时，不需要再次计算，只需要使用备份数据即可</td></tr></tbody></table><h3 id="RDD的缓存过程"><a href="#RDD的缓存过程" class="headerlink" title="RDD的缓存过程"></a>RDD的缓存过程</h3><p>RDD 在缓存到存储内存之前，数据项 [Record]的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一 Partition 的不同数据项的存储空间并不连续。</p><p>缓存到存储内存之后， Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为”展开” [Unroll] </p><p>Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别。非序列化的 Block 用一个数组存储所有的对象实例<strong>，序列化的 Block 则用字节缓冲区 ByteBuffer 来存储二进制数据。</strong></p><p>每个 Executor 的 Storage 模块用一个 LinkedHashMap 来管理堆内和堆外存储内存中所有的 Block ，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放。</p><p>因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。在静态内存管理时，Spark 在存储内存中专门划分了一块 Unroll 空间，其大小是固定的，统一内存管理时则没有对 Unroll 空间进行特别区分，对于序列化的 Partition ，其所需的 Unroll 空间可以直接累加计算，一次申请。</p><blockquote><p>对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。</p></blockquote><blockquote><p>对于非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。</p></blockquote><p>如果最终 Unroll 成功， 当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间 </p><img src="/images/spark/30.png" alt="" style="zoom:90%;" /><h3 id="淘汰与落盘"><a href="#淘汰与落盘" class="headerlink" title="淘汰与落盘"></a>淘汰与落盘</h3><p><strong>由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中 的旧 Block 进行淘汰，而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘，否则直接删除该 Block。</strong></p><ul><li>被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存</li><li>新旧 Block 不能属于同一个RDD，避免循环淘汰</li><li>旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题</li><li>遍历 LinkedHashMap中 Block，按照最近最少使用 LRU 的顺序淘汰，直到满足新 Block 所需的空间。 其中 LRU 是 LinkedHashMap 的特性。</li></ul><h3 id="执行内存管理"><a href="#执行内存管理" class="headerlink" title="执行内存管理"></a>执行内存管理</h3><p>执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程， Shuffle 的 Write 和 Read 两阶段对执行内存的使用.</p><h3 id="Shuffle-Write"><a href="#Shuffle-Write" class="headerlink" title="Shuffle Write"></a>Shuffle Write</h3><p>在 map 端会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。</p><h3 id="Shuffle-Read"><a href="#Shuffle-Read" class="headerlink" title="Shuffle Read"></a>Shuffle Read</h3><ul><li>在对 reduce端的数据进行聚合时， 要将数据交给 Aggregator处理， 在内存中存储数据时占用堆内执行空间。</li><li>如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter处理，占用堆内执行空间</li></ul><p>在 ExternalSorter 和 Aggregator 中， Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据 ， 但在 Shuffle 过程中所有数据并不能都保存到该哈希表中， 当这个哈希表占用的内存会进行周期性地采样估算， 当其大到一定程度， 无法再从 MemoryManager 申请到新的执行内存时， Spark 就会将其全部内容存储到磁盘文件中， 这 个过程被称为溢存 [Spill] ， 溢存到磁盘的文件最后会被归 并 [Merge] </p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Spark 的存储内存和执行内存有着截然不同的管理方式</p><ul><li><p>对于存储内存来说，<strong>Spark</strong> 用一个 **LinkedHashMap **来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；</p></li><li><p>对于执行内存，Spark 用 <strong>AppendOnlyMap</strong> 来存储 Shuffle 过程中的数据， 在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制 。</p></li></ul><h2 id="Spark-Shuffle-内存使用"><a href="#Spark-Shuffle-内存使用" class="headerlink" title="Spark Shuffle 内存使用"></a>Spark Shuffle 内存使用</h2><p>在使用 Spark 进行计算时，我们经常会碰到作业 (Job) Out Of Memory(OOM) 的情况，而且很大一部分情况是发生在 Shuffle 阶段。那么在 Spark Shuffle 中具体是哪些地方会使用比较多的内存而有可能导致 OOM 呢？ 为此，本文将围绕以上问题梳理 Spark 内存管理和 Shuffle 过程中与内存使用相关的知识；然后，简要分析下在 Spark Shuffle 中有可能导致 OOM 的原因。</p><h2 id="OOM"><a href="#OOM" class="headerlink" title="OOM"></a>OOM</h2><p>内存不够，数据太多就会抛出 OOM的 Exeception，主要有driver OOM和 executor OOM两种</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">java</span><span class="selector-class">.lang</span><span class="selector-class">.OutOfMemoryError</span>: <span class="selector-tag">Java</span> <span class="selector-tag">heap</span> <span class="selector-tag">space</span></span><br></pre></td></tr></table></figure><h3 id="driver-OOM"><a href="#driver-OOM" class="headerlink" title="driver OOM"></a><strong>driver OOM</strong></h3><ul><li><strong>用户在 Driver 端口生成大对象, 比如创建了一个大的集合数据结构</strong></li><li><strong>使用了collect 等操作，将所有 executor 的数据聚合到 driver 导致</strong></li></ul><p>一般是使用了collect 等操作，将所有 executor 的数据聚合到 driver 导致。尽量不要使用 collect操作即可。</p><h3 id="executor-OOM"><a href="#executor-OOM" class="headerlink" title="executor OOM"></a><strong>executor OOM</strong></h3><h3 id="数据倾斜导致内存溢出"><a href="#数据倾斜导致内存溢出" class="headerlink" title="数据倾斜导致内存溢出"></a><strong>数据倾斜导致内存溢出</strong></h3><p>数据不平衡除了有可能导致内存溢出外，也有可能导致性能的问题，调用 repartition 重新分区</p><h3 id="Reduce-OOM"><a href="#Reduce-OOM" class="headerlink" title="Reduce OOM"></a>Reduce OOM</h3><p>reduce task 去 map 端获取数据，reduce一边拉取数据一边聚合，reduce端有一块聚合内存[executor memory * 0.2],也就是这块内存不够<br><strong>解决方法</strong></p><ul><li>增加 reduce 聚合操作的内存的比例</li><li>增加 Executor memory 的大小 <strong>–executor-memory 5G</strong></li><li>减少 reduce task 每次拉取的数据量 设置 spak.reducer.maxSizeInFlight 24m, 拉取的次数就多了，因此建立连接的次数增多，有可能会连接不上[正好赶上 map task 端进行GC]</li></ul><h3 id="shuffle-后内存溢出"><a href="#shuffle-后内存溢出" class="headerlink" title="shuffle 后内存溢出"></a><strong>shuffle 后内存溢出</strong></h3><p> shuffle 后单个文件过大导致内存溢出。在 Spark 中，join，reduceByKey 这一类型的过程，都会有shuffle的过程，在shuffle的使用，需要传入一个partitioner，大部分 Spark 中的 shuffle 操作，默认的 partitioner 都是 HashPatitioner，默认值是父 RDD 中最大的分区数,这个参数通过spark.default.parallelism 控制 [在spark-sql中用spark.sql.shuffle.partitions] </p><p>spark.default.parallelism 参数只对 HashPartitioner 有效，所以如果是别的 Partitioner 或者自己实现的 Partitioner 就不能使用 spark.default.parallelism 这个参数来控制 shuffle 的并发量了。如果是别的partitioner 导致的 shuffle 内存溢出，就需要从 partitioner 的代码增加 partitions 的数量</p><h3 id="coalesce-调用导致内存溢出"><a href="#coalesce-调用导致内存溢出" class="headerlink" title="coalesce 调用导致内存溢出"></a><strong>coalesce 调用导致内存溢出</strong></h3><p>因为 hdfs 中不适合存小问题，所以 Spark 计算后如果产生的文件太小，调用 coalesce 合并文件再存入 hdfs中。但会导致一个问题，例如在 coalesce 之前有100个文件，这也意味着能够有100个 Task，现在调用coalesce(10)，最后只产生10个文件，因为 coalesce 并不是 shuffle 操作，这意味着 coalesce并不是先执行100个 Task，再将 Task 的执行结果合并成10个，而是从头到位只有10个 Task 在执行，原本100个文件是分开执行的，现在每个 Task 同时一次读取10个文件，使用的内存是原来的10倍，这导致了OOM。</p><p>解决这个问题的方法是令程序按照我们想的先执行100个 Task 再将结果合并成10个文件，这个问题同样可以通过repartition 解决，调用 repartition(10)</p><h3 id="standalone-模式下资源分配不均匀导致内存溢出"><a href="#standalone-模式下资源分配不均匀导致内存溢出" class="headerlink" title="standalone 模式下资源分配不均匀导致内存溢出"></a><strong>standalone 模式下资源分配不均匀导致内存溢出</strong></h3><p>在 standalone 的模式下如果配置了 –total-executor-cores 和 –executor-memory 这两个参数，但是没有配置 –executor-cores 参数，有可能导致，每个 Executor 的 memory 是一样的，但是 cores 的数量不同，那么在 cores 数量多的 Executor 中，由于能够同时执行多个Task，就容易导致内存溢出的情况。</p><p>这种情况的解决方法就是同时配置–executor-cores或者spark.executor.cores参数，确保Executor资源分配均匀。</p><h3 id="map-过程产生大量对象导致内存溢出"><a href="#map-过程产生大量对象导致内存溢出" class="headerlink" title="map 过程产生大量对象导致内存溢出"></a><strong>map 过程产生大量对象导致内存溢出</strong></h3><p>这种溢出的原因是在单个 map 中产生了大量的对象导致的</p><p>例如：rdd.map(x=&gt;for(i &lt;- 1 to 10000) yield i.toString)，这个操作在rdd中，每个对象都产生了10000 个对象，这肯定很容易产生内存溢出的问题。</p><p>针对这种问题，在不增加内存的情况下，可以通过减少每个 Task 的大小，以便达到每个 Task 即使产生大量的对象 Executor 的内存也能够装得下。具体做法可以在会产生大量对象的 map 操作之前调用 repartition方法，分区成更小的块传入map。</p><p>例如：rdd.repartition(10000).map(x=&gt;for(i &lt;- 1 to 10000) yield i.toString)</p><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a><strong>参数</strong></h2><h3 id="spark-driver-memory"><a href="#spark-driver-memory" class="headerlink" title="spark.driver.memory"></a>spark.driver.memory</h3><p>用来设置 Driver 的内存。在 Spark 程序中，SparkContext，DAGScheduler 都是运行在Driver端的。对应Stage 切分也是在 Driver 端运行，如果用户自己写的程序有过多的步骤，切分出过多的 Stage，这部分信息消耗的是 Driver 的内存，这个时候就需要调大 Driver 的内存</p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark 存储模块</title>
      <link href="2019/11/22/Spark%20%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97/"/>
      <url>2019/11/22/Spark%20%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业[Job]，并将作业转化为计算任务[Task]，在各个 Executor 进程间协调任务的调度；后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver， 同时为需要持久化的 RDD 提供存储功能。由于 Driver 的内存管理相对来说较为简单，本节主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。</p><a id="more"></a><h2 id="Execuor-内存模型"><a href="#Execuor-内存模型" class="headerlink" title="Execuor 内存模型"></a>Execuor 内存模型</h2><h3 id="堆内和堆外内存"><a href="#堆内和堆外内存" class="headerlink" title="堆内和堆外内存"></a>堆内和堆外内存</h3><p>作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内 [On-heap]空间进行了更为详细的分配，以充分利用内存。</p><p>同时，Spark 引入了堆外[Off-heap]内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。</p><p><strong>堆内内存受到 JVM 统一管理，堆外内存是直接向操作系统进行内存的申请和释放。</strong></p><h3 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h3><p>堆内内存的大小，由 Spark 应用程序启动时的 –executor-memory 或 spark.executor.memory 参数配置。 </p><p>Executor 内运行的并发任务共享 JVM 堆内内存， Spark 对堆内内存的管理是一种逻辑上的“规划式”的管理，Executor 端的堆内内存区域在逻辑上被划分为以下四个区域。</p><ol><li><p>执行内存 (Execution Memory) : 主要用于存放 Shuffle、Join、Sort、Aggregation 等计算过程中的临时数据</p></li><li><p>存储内存 (Storage Memory) : 主要用于存储 spark 的 cache 数据，例如 RDD 的缓存、unroll 数据</p><p>主要用于存储 spark 的 cache 数据，例如 RDD 的缓存、广播（Broadcast）数据、和 unroll 数据。内存占比为 UsableMemory * spark.memory.fraction * spark.memory.storageFraction，Spark 2+ 中，默认初始状态下 Storage Memory 和 Execution Memory 均约占系统总内存的30%（1 * 0.6 * 0.5 = 0.3）。</p></li><li><p>用户内存（User Memory）: 主要用于存储 RDD 转换操作所需要的数据，例如 RDD 依赖等信息；</p></li><li><p>预留内存（Reserved Memory）: 系统预留内存，会用来存储 Spark 内部对象。</p><p>系统预留内存，用来存储 Spark 内部对象。其大小在代码中是写死的，其值等于 300MB，这个值是不能修改的</p></li></ol><h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>Spark 对于堆内内存的清理无法准确指定时间点，因此无法实现精确的释放。<strong>为了进一步优化内存的使用 Spark 引入了堆外内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。</strong>由于内存的申请和释放不再通过 JVM 机制，而是直接向操作系统申请，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说，堆外内存可以被精降低了管理的难度，也降低了误差。 </p><p>在默认情况下堆外内存并不启用，可通过配置 spark.memory.offHeap.enabled 参数启用，并由 spark.memory.offHeap.size 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。</p><h2 id="内存空间分配"><a href="#内存空间分配" class="headerlink" title="内存空间分配"></a>内存空间分配</h2><h3 id="静态内存管理"><a href="#静态内存管理" class="headerlink" title="静态内存管理"></a>静态内存管理</h3><p>在 Spark 最初采用的静态内存管理机制下，**[存储内存]<strong>、</strong>[执行内存]<strong>和</strong>[其他内存]**的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置。</p><img src="../images/spark/009.png" alt="" style="zoom:90%;" /><ul><li><p>可用的存储内存</p><p> systemMaxMemory * spark.storage.memoryFraction * spark.storage.safetyFraction</p></li><li><p>可用的执行内存</p><p>systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction</p></li></ul><p>其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。 </p><p>上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 [1-safetyFraction] 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险。</p><p>值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和”其它内存”一样交给了 JVM 去管理。</p><p><strong>Storage 内存和 Execution 内存都有预留空间，目的是防止 OOM ，因为 Spark 堆内内存大小的记录是不准确的，需要留出保险区域。</strong></p><p>堆外的空间分配较为简单，只有存储内存和执行内存。可用的执行内存和存储内存占用的空间大小直接由参数 spark.memory.storageFraction 决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域 </p><img src="../images/spark/12.png" alt="" style="zoom:90%;" /><p>静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。</p><h3 id="统一内存管理"><a href="#统一内存管理" class="headerlink" title="统一内存管理"></a>统一内存管理</h3><p><strong>Spark1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于<font color='blue'>存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域</font></strong> </p><img src="../images/spark/10.png" alt="" style="zoom:90%;" /><p>其中最重要的优化在于动态占用机制， 其规则如下：</p><img src="../images/spark/20.png" alt="" style="zoom:90%;" /><ul><li><p>设定基本的存储内存和执行内存区域（spark.storage.storageFraction参数），该设定确定了双方各自拥有的空间的范围；</p></li><li><p>双方的空间都不足时，则存储到硬盘</p><p>若己方空间不足而对方空余时，可借用对方的空间; [注：存储空间不足是指不足以放下一个完整的Block]</p></li><li><p>执行内存的空间被对方占用后，可让对方将占用的部分转存到磁盘，然后”归还”借用的空间；</p></li><li><p>存储内存的空间被对方占用后，无法让对方 “归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。</p><p>Storage 内存的空间被对方占用后，目前的实现是无法让对方”归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂；而且 Shuffle 过程产生的文件在后面一定会被使用到，而 Cache 在内存的数据不一定在后面使用。在 <a href="http://www.linuxprobe.com/wp-content/uploads/2017/04/unified-memory-management-spark-10000.pdf">Unified Memory Management in Spark 1.6</a> 中详细讲解了为何选择这种策略，简单总结如下:</p><ul><li>数据清除的开销 : 驱逐 storage 内存的开销取决于 storage level，MEMORY_ONLY 可能是最昂贵的，因为需要重新计算，MEMORY_AND_DISK_SER 正好相反，只涉及到磁盘IO。溢写 execution 内存到磁盘的开销并不昂贵，因为 execution 存储的数据格式紧凑(compact format)，序列化开销低。并且，清除的 storage 内存可能不会被用到，但是，可以预见的是，驱逐的 execution 内存是必然会再被读到内存的，频繁的驱除重读 execution 内存将导致昂贵的开销。</li><li>实现的复杂度 : storage 内存的驱逐是容易实现的，只需要使用已有的方法，drop 掉 block。execution 则复杂的多，首先，execution 以 page 为单位管理这部分内存，并且确保相应的操作至少有 one page ，如果把这 one page 内存驱逐了，对应的操作就会处于饥饿状态。此外，还需要考虑 execution 内存被驱逐的情况下，等待 cache 的 block 如何处理。</li></ul></li></ul><h2 id="存储内存管理"><a href="#存储内存管理" class="headerlink" title="存储内存管理"></a>存储内存管理</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block。</p><p>BlockManager 是 整个 Spark 底层负责数据存储与管理的一个组件 ， Driver 和 Executor 的所有数据都由对应的 BlockManager 进行管理。</p><p>Driver 端 BlockManager 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Executor 端的 BlockManager 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令， 例如新增或删除一个 RDD。</p><h3 id="RDD-的持久化机制"><a href="#RDD-的持久化机制" class="headerlink" title="RDD 的持久化机制"></a>RDD 的持久化机制</h3><p>Task 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 要执行多次 action 操作， 可以在第一次 action 操作中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。</p><blockquote><p>其中 cache 这个方法是个 Tranformation ,当第一次遇到 action 算子的时才会进行持久化</p><p>cache 内部调用了 persist(StorageLevel.MEMORY_ONLY)方法，所以执行 cache 算子其实就是执行了 persist 算子且持久化级别为 MEMORY_ONLY。 故缓存是一种特殊的持久化。堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理。</p></blockquote><p>RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。 </p><p>在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY 、MEMORY_AND_DISK 等 7 种不同的存储级别 ， 而存储级别是以下 5 个变量的组合：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StorageLevel</span> <span class="title">private</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useDisk: <span class="type">Boolean</span>, //磁盘</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useMemory: <span class="type">Boolean</span>, //这里其实是指堆内内存</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useOffHeap: <span class="type">Boolean</span>, //堆外内存</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _deserialized: <span class="type">Boolean</span>, //是否为非序列化</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _replication: <span class="type">Int</span> = 1 //副本个数</span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>存储级别</th><th>含义</th></tr></thead><tbody><tr><td>MEMORY_ONLY</td><td>以非序列化的 Java 对象的方式持久化在 JVM 内存中。如果内存无法完全存储 RDD 所有的 partition，那么那些没有持久化的 partition 就会在下一次需要使用它们的时候，重新被计算</td></tr><tr><td>MEMORY_AND_DISK</td><td>同上，但是当 RDD 某些 partition 无法存储在内存中时，会持久化到磁盘中。下次需要使用这些 partition 时，需要从磁盘上读取</td></tr><tr><td>MEMORY_ONLY_SER</td><td>同 MEMORY_ONLY，但是会使用 Java 序列化方式，将 Java 对象序列化后进行持久化。可以减少内存开销，但是需要进行反序列化，因此会加大 CPU 开销</td></tr><tr><td>MEMORY_AND_DISK_SER</td><td>同 MEMORY_AND_DISK，但是使用序列化方式持久化 Java 对象</td></tr><tr><td>DISK_ONLY</td><td>使用非序列化 Java 对象的方式持久化，完全存储到磁盘上</td></tr><tr><td>MEMORY_ONLY_2  MEMORY_AND_DISK_2</td><td>如果是尾部加了 2 的持久化级别，表示将持久化数据复用一份，保存到其他节点，从而在数据丢失时，不需要再次计算，只需要使用备份数据即可</td></tr></tbody></table><h3 id="RDD的缓存过程"><a href="#RDD的缓存过程" class="headerlink" title="RDD的缓存过程"></a>RDD的缓存过程</h3><p>RDD 在缓存之前，数据项 [Record]的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一Partition 的不同数据项的存储空间并不连续。缓存到存储内存之后， Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为”展开” [Unroll] </p><p>Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别。非序列化的 Block 用一个数组存储所有的对象实例<strong>，序列化的 Block 则用字节缓冲区 ByteBuffer 来存储二进制数据。</strong></p><p>每个 Executor 的 Storage 模块用一个 LinkedHashMap 来管理堆内和堆外存储内存中所有的 Block ，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放。</p><p>因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。在静态内存管理时，Spark 在存储内存中专门划分了一块 Unroll 空间，其大小是固定的，统一内存管理时则没有对 Unroll 空间进行特别区分，对于序列化的 Partition ，其所需的 Unroll 空间可以直接累加计算，一次申请。</p><blockquote><p>对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。</p></blockquote><blockquote><p>对于非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。</p></blockquote><p>如果最终 Unroll 成功， 当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间 </p><img src="../images/spark/30.png" alt="" style="zoom:50%;" /><h3 id="淘汰与落盘"><a href="#淘汰与落盘" class="headerlink" title="淘汰与落盘"></a>淘汰与落盘</h3><p><strong>由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中 的旧 Block 进行淘汰，而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘，否则直接删除该 Block。</strong></p><ul><li>被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存</li><li>新旧 Block 不能属于同一个RDD，避免循环淘汰</li><li>旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题</li><li>遍历 LinkedHashMap中 Block，按照最近最少使用 LRU 的顺序淘汰，直到满足新 Block 所需的空间。 其中 LRU 是 LinkedHashMap 的特性。</li></ul><h3 id="执行内存管理"><a href="#执行内存管理" class="headerlink" title="执行内存管理"></a>执行内存管理</h3><p>执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程， Shuffle 的 Write 和 Read 两阶段对执行内存的使用.</p><h3 id="Shuffle-Write"><a href="#Shuffle-Write" class="headerlink" title="Shuffle Write"></a>Shuffle Write</h3><p>在 map 端会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。</p><h3 id="Shuffle-Read"><a href="#Shuffle-Read" class="headerlink" title="Shuffle Read"></a>Shuffle Read</h3><ul><li>在对 reduce端的数据进行聚合时， 要将数据交给 Aggregator处理， 在内存中存储数据时占用堆内执行空间。</li><li>如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter处理，占用堆内执行空间</li></ul><p>在 ExternalSorter 和 Aggregator 中， Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据 ， 但在 Shuffle 过程中所有数据并不能都保存到该哈希表中， 当这个哈希表占用的内存会进行周期性地采样估算， 当其大到一定程度， 无法再从 MemoryManager 申请到新的执行内存时， Spark 就会将其全部内容存储到磁盘文件中， 这 个过程被称为溢存 [Spill] ， 溢存到磁盘的文件最后会被归 并 [Merge] </p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Spark 的存储内存和执行内存有着截然不同的管理方式</p><ul><li><p>对于存储内存来说，<strong>Spark</strong> 用一个 **LinkedHashMap **来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；</p></li><li><p>对于执行内存，Spark 用 <strong>AppendOnlyMap</strong> 来存储 Shuffle 过程中的数据， 在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制 。</p></li></ul><h2 id="Spark-Shuffle-内存使用"><a href="#Spark-Shuffle-内存使用" class="headerlink" title="Spark Shuffle 内存使用"></a>Spark Shuffle 内存使用</h2><p>在使用 Spark 进行计算时，我们经常会碰到作业 (Job) Out Of Memory(OOM) 的情况，而且很大一部分情况是发生在 Shuffle 阶段。那么在 Spark Shuffle 中具体是哪些地方会使用比较多的内存而有可能导致 OOM 呢？ 为此，本文将围绕以上问题梳理 Spark 内存管理和 Shuffle 过程中与内存使用相关的知识；然后，简要分析下在 Spark Shuffle 中有可能导致 OOM 的原因。</p><h2 id="OOM"><a href="#OOM" class="headerlink" title="OOM"></a>OOM</h2><p>内存不够，数据太多就会抛出 OOM 的 Exeception，主要有 driver OOM 和 executor OOM两种</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">java</span><span class="selector-class">.lang</span><span class="selector-class">.OutOfMemoryError</span>: <span class="selector-tag">Java</span> <span class="selector-tag">heap</span> <span class="selector-tag">space</span></span><br></pre></td></tr></table></figure><h3 id="driver-OOM"><a href="#driver-OOM" class="headerlink" title="driver OOM"></a><strong>driver OOM</strong></h3><ul><li><strong>用户在 Driver 端口生成大对象, 比如创建了一个大的集合数据结构</strong></li><li><strong>使用了collect 等操作，将所有 executor 的数据聚合到 driver 导致</strong></li></ul><p>一般是使用了collect 等操作，将所有 executor 的数据聚合到 driver 导致。尽量不要使用 collect 操作即可。</p><h3 id="executor-OOM"><a href="#executor-OOM" class="headerlink" title="executor OOM"></a><strong>executor OOM</strong></h3><h3 id="数据倾斜导致内存溢出"><a href="#数据倾斜导致内存溢出" class="headerlink" title="数据倾斜导致内存溢出"></a><strong>数据倾斜导致内存溢出</strong></h3><p>数据不平衡除了有可能导致内存溢出外，也有可能导致性能的问题，调用 repartition 重新分区</p><h3 id="Reduce-OOM"><a href="#Reduce-OOM" class="headerlink" title="Reduce OOM"></a>Reduce OOM</h3><p>reduce task 去 map 端获取数据，reduce一边拉取数据一边聚合，reduce端有一块聚合内存[executor memory * 0.2],也就是这块内存不够<br><strong>解决方法</strong></p><ul><li>增加 reduce 聚合操作的内存的比例</li><li>增加 Executor memory 的大小 <strong>–executor-memory 5G</strong></li><li>减少 reduce task 每次拉取的数据量 设置 spak.reducer.maxSizeInFlight 24m, 拉取的次数就多了，因此建立连接的次数增多，有可能会连接不上[正好赶上 map task 端进行GC]</li></ul><h3 id="shuffle-后内存溢出"><a href="#shuffle-后内存溢出" class="headerlink" title="shuffle 后内存溢出"></a><strong>shuffle 后内存溢出</strong></h3><p>shuffle 后单个文件过大导致内存溢出。在 Spark 中，join，reduceByKey 这一类型的过程，都会有shuffle 的过程，在 shuffle 的使用，需要传入一个 partitioner，大部分 Spark 中的 shuffle 操作，默认的 partitioner 都是 HashPatitioner，默认值是父 RDD 中最大的分区数,这个参数通过spark.default.parallelism 控制 [在spark-sql中用spark.sql.shuffle.partitions] </p><p>spark.default.parallelism 参数只对 HashPartitioner 有效，所以如果是别的 Partitioner 或者自己实现的 Partitioner 就不能使用 spark.default.parallelism 这个参数来控制 shuffle 的并发量了。如果是别的partitioner 导致的 shuffle 内存溢出，就需要从 partitioner 的代码增加 partitions 的数量</p><h3 id="coalesce-调用导致内存溢出"><a href="#coalesce-调用导致内存溢出" class="headerlink" title="coalesce 调用导致内存溢出"></a><strong>coalesce 调用导致内存溢出</strong></h3><p>因为 hdfs 中不适合存小问题，所以 Spark 计算后如果产生的文件太小，调用 coalesce 合并文件再存入 hdfs中。但会导致一个问题，例如在 coalesce 之前有100个文件，这也意味着能够有100个 Task，现在调用coalesce(10)，最后只产生10个文件，因为 coalesce 并不是 shuffle 操作，这意味着 coalesce并不是先执行100个 Task，再将 Task 的执行结果合并成10个，而是从头到位只有10个 Task 在执行，原本100个文件是分开执行的，现在每个 Task 同时一次读取10个文件，使用的内存是原来的10倍，这导致了OOM。</p><p>解决这个问题的方法是令程序按照我们想的先执行100个 Task 再将结果合并成10个文件，这个问题同样可以通过repartition 解决，调用 repartition(10)</p><h3 id="standalone-模式下资源分配不均匀导致内存溢出"><a href="#standalone-模式下资源分配不均匀导致内存溢出" class="headerlink" title="standalone 模式下资源分配不均匀导致内存溢出"></a><strong>standalone 模式下资源分配不均匀导致内存溢出</strong></h3><p>在 standalone 的模式下如果配置了 –total-executor-cores 和 –executor-memory 这两个参数，但是没有配置 –executor-cores 参数，有可能导致，每个 Executor 的 memory 是一样的，但是 cores 的数量不同，那么在 cores 数量多的 Executor 中，由于能够同时执行多个Task，就容易导致内存溢出的情况。</p><p>这种情况的解决方法就是同时配置–executor-cores或者spark.executor.cores参数，确保Executor资源分配均匀。</p><h3 id="map-过程产生大量对象导致内存溢出"><a href="#map-过程产生大量对象导致内存溢出" class="headerlink" title="map 过程产生大量对象导致内存溢出"></a><strong>map 过程产生大量对象导致内存溢出</strong></h3><p>这种溢出的原因是在单个 map 中产生了大量的对象导致的</p><p>例如：rdd.map(x=&gt;for(i &lt;- 1 to 10000) yield i.toString)，这个操作在rdd中，每个对象都产生了10000 个对象，这肯定很容易产生内存溢出的问题。</p><p>针对这种问题，在不增加内存的情况下，可以通过减少每个 Task 的大小，以便达到每个 Task 即使产生大量的对象 Executor 的内存也能够装得下。具体做法可以在会产生大量对象的 map 操作之前调用 repartition方法，分区成更小的块传入map。</p><p>例如：rdd.repartition(10000).map(x=&gt;for(i &lt;- 1 to 10000) yield i.toString)</p><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a><strong>参数</strong></h2><h3 id="spark-driver-memory"><a href="#spark-driver-memory" class="headerlink" title="spark.driver.memory"></a>spark.driver.memory</h3><p>用来设置 Driver 的内存。在 Spark 程序中，SparkContext，DAGScheduler 都是运行在Driver端的。对应Stage 切分也是在 Driver 端运行，如果用户自己写的程序有过多的步骤，切分出过多的 Stage，这部分信息消耗的是 Driver 的内存，这个时候就需要调大 Driver 的内存</p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark 存储模块</title>
      <link href="2019/11/22/Spark%20%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6/"/>
      <url>2019/11/22/Spark%20%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业[Job]，并将作业转化为计算任务[Task]，在各个 Executor 进程间协调任务的调度；后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver， 同时为需要持久化的 RDD 提供存储功能。由于 Driver 的内存管理相对来说较为简单，本节主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。</p><a id="more"></a><h2 id="Execuor-内存模型"><a href="#Execuor-内存模型" class="headerlink" title="Execuor 内存模型"></a>Execuor 内存模型</h2><h3 id="堆内和堆外内存"><a href="#堆内和堆外内存" class="headerlink" title="堆内和堆外内存"></a>堆内和堆外内存</h3><p>作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内 [On-heap]空间进行了更为详细的分配，以充分利用内存。</p><p>同时，Spark 引入了堆外[Off-heap]内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。</p><p><strong>堆内内存受到 JVM 统一管理，堆外内存是直接向操作系统进行内存的申请和释放。</strong></p><h3 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h3><p>堆内内存的大小，由 Spark 应用程序启动时的 –executor-memory 或 spark.executor.memory 参数配置。 </p><p>Executor 内运行的并发任务共享 JVM 堆内内存， 这些任务在缓存 RDD 数据和广播 Broadcast 数据时占用的内存被规划为存储 [Storage] 内存， 而这些任务在执行 Shuffle 时占用的内存被规划为执行 [Execution] 内存，剩余的部分不做特殊规划，Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间 。不同的管理模式下， 这三部分占用的空间大小各不相同 </p><h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>JVM 对于内存的清理无法准确指定时间点，因此无法实现精确的释放。<strong>为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了堆外[Off-heap]内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。</strong>由于内存的申请和释放不再通过 JVM 机制，而是直接向操作系统申请，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说，堆外内存可以被精确地申请和释放，降低了管理的难度，也降低了误差 </p><p>在默认情况下堆外内存并不启用，可通过配置 spark.memory.offHeap.enabled 参数启用，并由 spark.memory.offHeap.size 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存 。</p><h2 id="内存空间分配"><a href="#内存空间分配" class="headerlink" title="内存空间分配"></a>内存空间分配</h2><h3 id="静态内存管理"><a href="#静态内存管理" class="headerlink" title="静态内存管理"></a>静态内存管理</h3><p>在 Spark 最初采用的静态内存管理机制下，**[存储内存]<strong>、</strong>[执行内存]<strong>和</strong>[其他内存]**的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置。</p><img src="/images/spark/009.png" alt="" style="zoom:90%;" /><ul><li><p>可用的存储内存</p><p> systemMaxMemory * spark.storage.memoryFraction * spark.storage.safetyFraction</p></li><li><p>可用的执行内存</p><p>systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction</p></li></ul><p>其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。 </p><p>上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 [1-safetyFraction] 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险。</p><p>值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和”其它内存”一样交给了 JVM 去管理。</p><p><strong>Storage 内存和 Execution 内存都有预留空间，目的是防止 OOM ，因为 Spark 堆内内存大小的记录是不准确的，需要留出保险区域。</strong></p><p>堆外的空间分配较为简单，只有存储内存和执行内存。可用的执行内存和存储内存占用的空间大小直接由参数 spark.memory.storageFraction 决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域 </p><img src="/images/spark/12.png" alt="" style="zoom:90%;" /><p>静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。</p><h3 id="统一内存管理"><a href="#统一内存管理" class="headerlink" title="统一内存管理"></a>统一内存管理</h3><p><strong>Spark1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于<font color='blue'>存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域</font></strong> </p><img src="/images/spark/10.png" alt="" style="zoom:90%;" /><p>其中最重要的优化在于动态占用机制， 其规则如下：</p><img src="/images/spark/20.png" alt="" style="zoom:90%;" /><ul><li><p>设定基本的存储内存和执行内存区域（spark.storage.storageFraction参数），该设定确定了双方各自拥有的空间的范围；</p></li><li><p>双方的空间都不足时，则存储到硬盘</p><p>若己方空间不足而对方空余时，可借用对方的空间; [注：存储空间不足是指不足以放下一个完整的Block]</p></li><li><p>执行内存的空间被对方占用后，可让对方将占用的部分转存到磁盘，然后”归还”借用的空间；</p></li><li><p>存储内存的空间被对方占用后，无法让对方 “归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。</p></li></ul><h2 id="存储内存管理"><a href="#存储内存管理" class="headerlink" title="存储内存管理"></a>存储内存管理</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Storage 管理着 Spark 应用在运行过程中产生的各种数据。比如 RDD 缓存，shuffle 过程中缓存及写入磁盘的数据，广播变量等。</p><p>Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block。Driver 端 BlockManager 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Executor 端的 BlockManager 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令， 例如新增或删除一个 RDD。</p><ul><li><p>BlockManager</p><blockquote><p>BlockManager 是 整个 Spark 底层负责数据存储与管理的一个组件 ， Driver 和 Executor 的所有数据都由对应的 BlockManager 进行管理。</p><p>Driver 上有 BlockManager Master ，负责对各个节点上的 BlockManager 内部管理的数据的元数据进行维护， 比如 block 的增删改等操作， 都会在这里维护好元数据 的变更。</p><p>每个节点都有一个 BlockManager，每个 BlockManager 创建之后， 第一件事即使去向 BlockManag erMaster 进行注册。</p></blockquote></li><li><p>CacheManager</p><blockquote><p>CacheManager 管理 spark 的缓存，而缓存可以基于内存的缓存，也可以是基于磁盘的缓存；<br>CacheManager 需要通过 BlockManager 来操作数据</p></blockquote></li></ul><h3 id="RDD-的持久化机制"><a href="#RDD-的持久化机制" class="headerlink" title="RDD 的持久化机制"></a>RDD 的持久化机制</h3><p>弹性分布式数据集 RDD 作为 Spark 最根本的数据抽象，是只读的分区记录的集合，基于在稳定物理存储中的数据集上创建，或者在其他已有的 RDD 上执行转换[Transformation]操作产生一个新的 RDD。转换后的 RDD 与 原始的 RDD 之间产生的依赖关系构成了血统[Lineag]。凭借血统，Spark 保证了每一个 RDD 都可以被重新恢复。</p><p>Task 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 要执行多次 action 操作， 可以在第一次 action 操作中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。</p><blockquote><p>其中 cache 这个方法是个 Tranformation ,当第一次遇到 action 算子的时才会进行持久化</p><p>cache 内部调用了 persist(StorageLevel.MEMORY_ONLY)方法，所以执行 cache 算子其实就是执行了 persist 算子且持久化级别为 MEMORY_ONLY。 故缓存是一种特殊的持久化。堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理。</p></blockquote><p>RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。 </p><p>在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY 、MEMORY_AND_DISK 等 7 种不同的存储级别 ， 而存储级别是以下 5 个变量的组合：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StorageLevel</span> <span class="title">private</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useDisk: <span class="type">Boolean</span>, //磁盘</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useMemory: <span class="type">Boolean</span>, //这里其实是指堆内内存</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useOffHeap: <span class="type">Boolean</span>, //堆外内存</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _deserialized: <span class="type">Boolean</span>, //是否为非序列化</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _replication: <span class="type">Int</span> = 1 //副本个数</span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>存储级别</th><th>含义</th></tr></thead><tbody><tr><td>MEMORY_ONLY</td><td>以非序列化的 Java 对象的方式持久化在 JVM 内存中。如果内存无法完全存储 RDD 所有的 partition，那么那些没有持久化的 partition 就会在下一次需要使用它们的时候，重新被计算</td></tr><tr><td>MEMORY_AND_DISK</td><td>同上，但是当 RDD 某些 partition 无法存储在内存中时，会持久化到磁盘中。下次需要使用这些 partition 时，需要从磁盘上读取</td></tr><tr><td>MEMORY_ONLY_SER</td><td>同 MEMORY_ONLY，但是会使用 Java 序列化方式，将 Java 对象序列化后进行持久化。可以减少内存开销，但是需要进行反序列化，因此会加大 CPU 开销</td></tr><tr><td>MEMORY_AND_DISK_SER</td><td>同 MEMORY_AND_DISK，但是使用序列化方式持久化 Java 对象</td></tr><tr><td>DISK_ONLY</td><td>使用非序列化 Java 对象的方式持久化，完全存储到磁盘上</td></tr><tr><td>MEMORY_ONLY_2  MEMORY_AND_DISK_2</td><td>如果是尾部加了 2 的持久化级别，表示将持久化数据复用一份，保存到其他节点，从而在数据丢失时，不需要再次计算，只需要使用备份数据即可</td></tr></tbody></table><h3 id="RDD的缓存过程"><a href="#RDD的缓存过程" class="headerlink" title="RDD的缓存过程"></a>RDD的缓存过程</h3><p>RDD 在缓存到存储内存之前，数据项 [Record]的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一 Partition 的不同数据项的存储空间并不连续。</p><p>缓存到存储内存之后， Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为”展开” [Unroll] </p><p>Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别。非序列化的 Block 用一个数组存储所有的对象实例<strong>，序列化的 Block 则用字节缓冲区 ByteBuffer 来存储二进制数据。</strong></p><p>每个 Executor 的 Storage 模块用一个 LinkedHashMap 来管理堆内和堆外存储内存中所有的 Block ，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放。</p><p>因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。在静态内存管理时，Spark 在存储内存中专门划分了一块 Unroll 空间，其大小是固定的，统一内存管理时则没有对 Unroll 空间进行特别区分，对于序列化的 Partition ，其所需的 Unroll 空间可以直接累加计算，一次申请。</p><blockquote><p>对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。</p></blockquote><blockquote><p>对于非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。</p></blockquote><p>如果最终 Unroll 成功， 当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间 </p><img src="/images/spark/30.png" alt="" style="zoom:90%;" /><h3 id="淘汰与落盘"><a href="#淘汰与落盘" class="headerlink" title="淘汰与落盘"></a>淘汰与落盘</h3><p><strong>由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中 的旧 Block 进行淘汰，而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘，否则直接删除该 Block。</strong></p><ul><li>被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存</li><li>新旧 Block 不能属于同一个RDD，避免循环淘汰</li><li>旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题</li><li>遍历 LinkedHashMap中 Block，按照最近最少使用 LRU 的顺序淘汰，直到满足新 Block 所需的空间。 其中 LRU 是 LinkedHashMap 的特性。</li></ul><h3 id="执行内存管理"><a href="#执行内存管理" class="headerlink" title="执行内存管理"></a>执行内存管理</h3><p>执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程， Shuffle 的 Write 和 Read 两阶段对执行内存的使用.</p><h3 id="Shuffle-Write"><a href="#Shuffle-Write" class="headerlink" title="Shuffle Write"></a>Shuffle Write</h3><p>在 map 端会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。</p><h3 id="Shuffle-Read"><a href="#Shuffle-Read" class="headerlink" title="Shuffle Read"></a>Shuffle Read</h3><ul><li>在对 reduce端的数据进行聚合时， 要将数据交给 Aggregator处理， 在内存中存储数据时占用堆内执行空间。</li><li>如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter处理，占用堆内执行空间</li></ul><p>在 ExternalSorter 和 Aggregator 中， Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据 ， 但在 Shuffle 过程中所有数据并不能都保存到该哈希表中， 当这个哈希表占用的内存会进行周期性地采样估算， 当其大到一定程度， 无法再从 MemoryManager 申请到新的执行内存时， Spark 就会将其全部内容存储到磁盘文件中， 这 个过程被称为溢存 [Spill] ， 溢存到磁盘的文件最后会被归 并 [Merge] </p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Spark 的存储内存和执行内存有着截然不同的管理方式</p><ul><li><p>对于存储内存来说，<strong>Spark</strong> 用一个 **LinkedHashMap **来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；</p></li><li><p>对于执行内存，Spark 用 <strong>AppendOnlyMap</strong> 来存储 Shuffle 过程中的数据， 在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制 。</p></li></ul><h2 id="Spark-Shuffle-内存使用"><a href="#Spark-Shuffle-内存使用" class="headerlink" title="Spark Shuffle 内存使用"></a>Spark Shuffle 内存使用</h2><p>在使用 Spark 进行计算时，我们经常会碰到作业 (Job) Out Of Memory(OOM) 的情况，而且很大一部分情况是发生在 Shuffle 阶段。那么在 Spark Shuffle 中具体是哪些地方会使用比较多的内存而有可能导致 OOM 呢？ 为此，本文将围绕以上问题梳理 Spark 内存管理和 Shuffle 过程中与内存使用相关的知识；然后，简要分析下在 Spark Shuffle 中有可能导致 OOM 的原因。</p><h2 id="OOM"><a href="#OOM" class="headerlink" title="OOM"></a>OOM</h2><p>内存不够，数据太多就会抛出 OOM的 Exeception，主要有driver OOM和 executor OOM两种</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">java</span><span class="selector-class">.lang</span><span class="selector-class">.OutOfMemoryError</span>: <span class="selector-tag">Java</span> <span class="selector-tag">heap</span> <span class="selector-tag">space</span></span><br></pre></td></tr></table></figure><h3 id="driver-OOM"><a href="#driver-OOM" class="headerlink" title="driver OOM"></a><strong>driver OOM</strong></h3><ul><li><strong>用户在 Driver 端口生成大对象, 比如创建了一个大的集合数据结构</strong></li><li><strong>使用了collect 等操作，将所有 executor 的数据聚合到 driver 导致</strong></li></ul><p>一般是使用了collect 等操作，将所有 executor 的数据聚合到 driver 导致。尽量不要使用 collect操作即可。</p><h3 id="executor-OOM"><a href="#executor-OOM" class="headerlink" title="executor OOM"></a><strong>executor OOM</strong></h3><h3 id="数据倾斜导致内存溢出"><a href="#数据倾斜导致内存溢出" class="headerlink" title="数据倾斜导致内存溢出"></a><strong>数据倾斜导致内存溢出</strong></h3><p>数据不平衡除了有可能导致内存溢出外，也有可能导致性能的问题，调用 repartition 重新分区</p><h3 id="Reduce-OOM"><a href="#Reduce-OOM" class="headerlink" title="Reduce OOM"></a>Reduce OOM</h3><p>reduce task 去 map 端获取数据，reduce一边拉取数据一边聚合，reduce端有一块聚合内存[executor memory * 0.2],也就是这块内存不够<br><strong>解决方法</strong></p><ul><li>增加 reduce 聚合操作的内存的比例</li><li>增加 Executor memory 的大小 <strong>–executor-memory 5G</strong></li><li>减少 reduce task 每次拉取的数据量 设置 spak.reducer.maxSizeInFlight 24m, 拉取的次数就多了，因此建立连接的次数增多，有可能会连接不上[正好赶上 map task 端进行GC]</li></ul><h3 id="shuffle-后内存溢出"><a href="#shuffle-后内存溢出" class="headerlink" title="shuffle 后内存溢出"></a><strong>shuffle 后内存溢出</strong></h3><p> shuffle 后单个文件过大导致内存溢出。在 Spark 中，join，reduceByKey 这一类型的过程，都会有shuffle的过程，在shuffle的使用，需要传入一个partitioner，大部分 Spark 中的 shuffle 操作，默认的 partitioner 都是 HashPatitioner，默认值是父 RDD 中最大的分区数,这个参数通过spark.default.parallelism 控制 [在spark-sql中用spark.sql.shuffle.partitions] </p><p>spark.default.parallelism 参数只对 HashPartitioner 有效，所以如果是别的 Partitioner 或者自己实现的 Partitioner 就不能使用 spark.default.parallelism 这个参数来控制 shuffle 的并发量了。如果是别的partitioner 导致的 shuffle 内存溢出，就需要从 partitioner 的代码增加 partitions 的数量</p><h3 id="coalesce-调用导致内存溢出"><a href="#coalesce-调用导致内存溢出" class="headerlink" title="coalesce 调用导致内存溢出"></a><strong>coalesce 调用导致内存溢出</strong></h3><p>因为 hdfs 中不适合存小问题，所以 Spark 计算后如果产生的文件太小，调用 coalesce 合并文件再存入 hdfs中。但会导致一个问题，例如在 coalesce 之前有100个文件，这也意味着能够有100个 Task，现在调用coalesce(10)，最后只产生10个文件，因为 coalesce 并不是 shuffle 操作，这意味着 coalesce并不是先执行100个 Task，再将 Task 的执行结果合并成10个，而是从头到位只有10个 Task 在执行，原本100个文件是分开执行的，现在每个 Task 同时一次读取10个文件，使用的内存是原来的10倍，这导致了OOM。</p><p>解决这个问题的方法是令程序按照我们想的先执行100个 Task 再将结果合并成10个文件，这个问题同样可以通过repartition 解决，调用 repartition(10)</p><h3 id="standalone-模式下资源分配不均匀导致内存溢出"><a href="#standalone-模式下资源分配不均匀导致内存溢出" class="headerlink" title="standalone 模式下资源分配不均匀导致内存溢出"></a><strong>standalone 模式下资源分配不均匀导致内存溢出</strong></h3><p>在 standalone 的模式下如果配置了 –total-executor-cores 和 –executor-memory 这两个参数，但是没有配置 –executor-cores 参数，有可能导致，每个 Executor 的 memory 是一样的，但是 cores 的数量不同，那么在 cores 数量多的 Executor 中，由于能够同时执行多个Task，就容易导致内存溢出的情况。</p><p>这种情况的解决方法就是同时配置–executor-cores或者spark.executor.cores参数，确保Executor资源分配均匀。</p><h3 id="map-过程产生大量对象导致内存溢出"><a href="#map-过程产生大量对象导致内存溢出" class="headerlink" title="map 过程产生大量对象导致内存溢出"></a><strong>map 过程产生大量对象导致内存溢出</strong></h3><p>这种溢出的原因是在单个 map 中产生了大量的对象导致的</p><p>例如：rdd.map(x=&gt;for(i &lt;- 1 to 10000) yield i.toString)，这个操作在rdd中，每个对象都产生了10000 个对象，这肯定很容易产生内存溢出的问题。</p><p>针对这种问题，在不增加内存的情况下，可以通过减少每个 Task 的大小，以便达到每个 Task 即使产生大量的对象 Executor 的内存也能够装得下。具体做法可以在会产生大量对象的 map 操作之前调用 repartition方法，分区成更小的块传入map。</p><p>例如：rdd.repartition(10000).map(x=&gt;for(i &lt;- 1 to 10000) yield i.toString)</p><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a><strong>参数</strong></h2><h3 id="spark-driver-memory"><a href="#spark-driver-memory" class="headerlink" title="spark.driver.memory"></a>spark.driver.memory</h3><p>用来设置 Driver 的内存。在 Spark 程序中，SparkContext，DAGScheduler 都是运行在Driver端的。对应Stage 切分也是在 Driver 端运行，如果用户自己写的程序有过多的步骤，切分出过多的 Stage，这部分信息消耗的是 Driver 的内存，这个时候就需要调大 Driver 的内存</p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark Shuffle</title>
      <link href="2019/11/20/Hadoop%E5%B0%8F%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/"/>
      <url>2019/11/20/Hadoop%E5%B0%8F%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HDFS上每个文件都要在 NameNode 上建立一个索引，这个索引的大小约为 <strong>150byte</strong>，这样当小文件比较多的时候，就会产生很多的索引文件，一方面会大量占用 **NameNode **的内存空间，另一方面就是索引文件过大使得索引速度变慢。</p><a id="more"></a><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="小文件"><a href="#小文件" class="headerlink" title="小文件"></a>小文件</h2><blockquote></blockquote><h2 id="小文件弊端"><a href="#小文件弊端" class="headerlink" title="小文件弊端"></a>小文件弊端</h2><p>HDFS上每个文件都要在 NameNode 上建立一个索引，这个索引的大小约为 <strong>150byte</strong>，这样当小文件比较多的时候，就会产生很多的索引文件，一方面会大量占用 **NameNode **的内存空间，另一方面就是索引文件过大使得索引速度变慢。</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><h2 id="Hadoop-Archive"><a href="#Hadoop-Archive" class="headerlink" title="Hadoop Archive"></a>Hadoop Archive</h2><h2 id="Sequence-File"><a href="#Sequence-File" class="headerlink" title="Sequence File"></a>Sequence File</h2><h2 id="CombineFileInputFormat"><a href="#CombineFileInputFormat" class="headerlink" title="CombineFileInputFormat"></a>CombineFileInputFormat</h2><h2 id="开启-JVM-重用"><a href="#开启-JVM-重用" class="headerlink" title="开启 JVM 重用"></a>开启 JVM 重用</h2><p>Hadoop的默认配置通常是使用派生JVM来执行map和Reduce任务的。这时JVM的启动过程可能会造成相当大的开销，尤其是执行的job包含有成百上千task任务的情况。JVM重用可以使得JVM实例在同一个job中重新使用N次</p>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark 调优</title>
      <link href="2019/11/19/Spark%20%E4%BC%98%E5%8C%96/"/>
      <url>2019/11/19/Spark%20%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在执行 Spark 的应用程序时，Spark集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业[Job]，并将作业转化为计算任务[Task]，在各个 Executor 进程间协调任务的调度；后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver， 同时为需要持久化的 RDD 提供存储功能。由于 Driver 的内存管理相对来说较为简单，本节主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。</p><a id="more"></a><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>智慧出行服务体系建设的开发之订单和轨迹监控</title>
      <link href="2019/11/13/%E6%99%BA%E6%85%A7%E5%87%BA%E8%A1%8C%E6%9C%8D%E5%8A%A1%E4%BD%93%E7%B3%BB%E5%BB%BA%E8%AE%BE%E7%9A%84%E5%BC%80%E5%8F%91%E4%B9%8B%E8%AE%A2%E5%8D%95%E5%92%8C%E8%BD%A8%E8%BF%B9%E7%9B%91%E6%8E%A7/"/>
      <url>2019/11/13/%E6%99%BA%E6%85%A7%E5%87%BA%E8%A1%8C%E6%9C%8D%E5%8A%A1%E4%BD%93%E7%B3%BB%E5%BB%BA%E8%AE%BE%E7%9A%84%E5%BC%80%E5%8F%91%E4%B9%8B%E8%AE%A2%E5%8D%95%E5%92%8C%E8%BD%A8%E8%BF%B9%E7%9B%91%E6%8E%A7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1、实时订单统计"><a href="#1、实时订单统计" class="headerlink" title="1、实时订单统计"></a>1、实时订单统计</h2><p>订单数据处理流程:</p><p>1.shell播放脚本读取订单数据到指定订单文件中.</p><p>2.使用flume监听订单文件，实时将订单数据发送到Kafka.</p><p>3.使用Spark streaming处理统计订单数据和乘车人数保存到redis中.</p><p>4.页面请求Java中台相应restful接口，restful接口查询redis中的数据返回页面，然后页面渲染显示.</p><p><img src="/images/didi/1571121383981.png" alt="1571121383981"></p><h3 id="1-1-订单数据回放"><a href="#1-1-订单数据回放" class="headerlink" title="1.1 订单数据回放"></a>1.1 订单数据回放</h3><p> 1.安装配置 Flume</p><p>flume agent配置:</p><p>代理名称：配置如下:a1(按照业务功能自定义一个名称即可)</p><p><img src="/images/didi/1571053796134.png" alt="1571053796134"></p><p>配置文件内容如下:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">a1.sources=r1</span><br><span class="line">a1.sinks=k1</span><br><span class="line">a1.channels=c1</span><br><span class="line">a1.sources.r1.type=exec</span><br><span class="line"><span class="meta">#</span><span class="bash">先使用tail -F的方式，随后做优化</span></span><br><span class="line">a1.sources.r1.command=tail -F /root/order/order</span><br><span class="line">a1.sources.r1.fileHeader=true</span><br><span class="line">a1.sinks.k1.type=org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">a1.sinks.k1.topic=hai_kou_order_topic</span><br><span class="line">a1.sinks.k1.brokerList=cdh-node01:9092,cdh-node02:9092,cdh-node03:9092</span><br><span class="line">a1.sinks.k1.batchSize=20</span><br><span class="line">a1.sinks.k1.requiredAcks=1</span><br><span class="line">a1.sinks.k1.producer.linger.ms=1</span><br><span class="line">a1.sinks.k1.producer.compression.type=snappy</span><br><span class="line">a1.channels.c1.type=memory</span><br><span class="line">a1.channels.c1.capacity=1000</span><br><span class="line">a1.channels.c1.transactionCapacity=100</span><br><span class="line">a1.sources.r1.channels=c1</span><br><span class="line">a1.sinks.k1.channel=c1</span><br></pre></td></tr></table></figure><p>2.kafka manager工具安装</p><p>此工具主要用作kafka主题消息的监控，主题增加，删除等操作.</p><p>3.消费kafka中的订单数据数据代码实现.</p><h3 id="1-2-数据回放的断点续传解决方案"><a href="#1-2-数据回放的断点续传解决方案" class="headerlink" title="1.2 数据回放的断点续传解决方案"></a>1.2 数据回放的断点续传解决方案</h3><p>问题背景:</p><p> 通常我们使用flume和kafka集成，都是使用flume监控文件,会在配置source时的命令，例如:tail -F 文件名,这种方式依然会存在一个问题，但flume的agent进程由于各种原因挂掉一段时间之后，</p><p>解决方案:</p><p>1.第一种方案,是在使用tail -F命令的地方修改</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r2.command=</span><br><span class="line">tail  -n +$(tail -n1 /root/log) -F /root/data/nginx.log | awk &#x27;ARGIND==1&#123;i=$0;next&#125;&#123;i++;if($0~/^tail/)&#123;i=0&#125;;print $0;print i &gt;&gt; &quot;/root/log&quot;;fflush(&quot;&quot;)&#125;&#x27; /root/log</span><br></pre></td></tr></table></figure><p>2.第二种方案,高版本的flume可以使用tailDir Souce</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.s1.type = TAILDIR</span><br><span class="line">a1.sources.s1.positionFile = /home/dev/flume/flume-1.8.0/log/taildir_position.json</span><br><span class="line">a1.sources.s1.filegroups = f1</span><br><span class="line">a1.sources.s1.filegroups.f1 = /home/dev/log/moercredit/logstash.log</span><br><span class="line">a1.sources.s1.headers.f1.headerKey1 = aaa</span><br><span class="line">a1.sources.s1.fileHeader = true</span><br></pre></td></tr></table></figure><h3 id="1-3-实时订单数据统计（订单情况、乘车人数情况）"><a href="#1-3-实时订单数据统计（订单情况、乘车人数情况）" class="headerlink" title="1.3 实时订单数据统计（订单情况、乘车人数情况）"></a>1.3 实时订单数据统计（订单情况、乘车人数情况）</h3><p>OrderStreamingProcessor类</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.cartravel.spark</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.cartravel.common.&#123;<span class="type">Constants</span>, <span class="type">TopicName</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.<span class="type">StringDeserializer</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka010.<span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.<span class="type">Level</span></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.<span class="type">Logger</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>._</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 订单数据流处理程</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OrderStreamingProcessor</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Order</span>(<span class="params">oderId: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">object</span> <span class="title">OrderStreamingProcessor</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.streaming._</span><br><span class="line">    <span class="comment">//设置Spark程序在控制台中的日志打印级别</span></span><br><span class="line">    <span class="type">Logger</span>.getLogger(<span class="string">&quot;org&quot;</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</span><br><span class="line">    <span class="comment">//local[*]使用本地模式运行，*表示内部会自动计算CPU核数，也可以直接指定运行线程数比如2，就是local[2]</span></span><br><span class="line">    <span class="comment">//表示使用两个线程来模拟spark集群</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;OrderMonitor&quot;</span>).setMaster(<span class="string">&quot;local[1]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//初始化Spark Streaming环境</span></span><br><span class="line">    <span class="keyword">val</span> streamingContext = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置检查点</span></span><br><span class="line">    streamingContext.checkpoint(<span class="string">&quot;/sparkapp/tmp&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//&quot;auto.offset.reset&quot; -&gt; &quot;earliest&quot;</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Object</span>](</span><br><span class="line"><span class="comment">//      &quot;bootstrap.servers&quot; -&gt; &quot;192.168.21.173:6667,192.168.21.174:6667,192.168.21.175:6667&quot;,</span></span><br><span class="line">      <span class="string">&quot;bootstrap.servers&quot;</span> -&gt; <span class="type">Constants</span>.<span class="type">KAFKA_BOOTSTRAP_SERVERS</span>,</span><br><span class="line">      <span class="string">&quot;key.deserializer&quot;</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">      <span class="string">&quot;value.deserializer&quot;</span> -&gt; classOf[<span class="type">StringDeserializer</span>],</span><br><span class="line">      <span class="string">&quot;group.id&quot;</span> -&gt; <span class="string">&quot;test0001&quot;</span>,</span><br><span class="line">      <span class="string">&quot;auto.offset.reset&quot;</span> -&gt; <span class="string">&quot;latest&quot;</span>,</span><br><span class="line">      <span class="string">&quot;enable.auto.commit&quot;</span> -&gt; (<span class="literal">false</span>: java.lang.<span class="type">Boolean</span>)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> topics = <span class="type">Array</span>(</span><br><span class="line">      <span class="type">TopicName</span>.<span class="type">HAI_KOU_ORDER_TOPIC</span>.getTopicName,</span><br><span class="line">      <span class="type">TopicName</span>.<span class="type">CHENG_DU_ORDER_TOPIC</span>.getTopicName,</span><br><span class="line">      <span class="type">TopicName</span>.<span class="type">XI_AN_ORDER_TOPIC</span>.getTopicName</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    topics.foreach(println(_))</span><br><span class="line">    println(<span class="string">&quot;topics:&quot;</span> + topics)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stream = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>](</span><br><span class="line">      streamingContext,</span><br><span class="line">      <span class="type">PreferConsistent</span>,</span><br><span class="line">      <span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](topics, kafkaParams)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    stream.count().print();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//实时统计订单总数</span></span><br><span class="line">    <span class="keyword">val</span> ordersDs = stream.map(record =&gt; &#123;</span><br><span class="line">      <span class="comment">//主题名称</span></span><br><span class="line">      <span class="keyword">val</span> topicName = record.topic()</span><br><span class="line">      <span class="keyword">val</span> orderInfo = record.value()</span><br><span class="line"></span><br><span class="line">      <span class="comment">//订单信息解析器</span></span><br><span class="line">      <span class="keyword">var</span> orderParser: <span class="type">OrderParser</span> = <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//不同主题的订单进行不同的处理</span></span><br><span class="line">      topicName <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&quot;hai_kou_order_topic&quot;</span> =&gt; &#123;</span><br><span class="line">          orderParser = <span class="keyword">new</span> <span class="type">HaiKouOrderParser</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&quot;cheng_du_order_topic&quot;</span> =&gt; &#123;</span><br><span class="line">          orderParser = <span class="keyword">new</span> <span class="type">ChengDuOrderParser</span>()</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&quot;xi_an_order_topic&quot;</span> =&gt; &#123;</span><br><span class="line">          orderParser = <span class="keyword">new</span> <span class="type">XiAnOrderParser</span>()</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">case</span> _ =&gt; &#123;</span><br><span class="line">          orderParser = <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      println(<span class="string">&quot;orderParser:&quot;</span> + orderParser)</span><br><span class="line">      <span class="keyword">if</span> (<span class="literal">null</span> != orderParser) &#123;</span><br><span class="line">        <span class="keyword">val</span> order = orderParser.parser(orderInfo)</span><br><span class="line">        println(<span class="string">&quot;parser order:&quot;</span> + order)</span><br><span class="line">        order</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="literal">null</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//订单计数,对于每个订单出现一次计数1</span></span><br><span class="line">    <span class="keyword">val</span> orderCountRest = ordersDs.map(order =&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="literal">null</span> == order) &#123;</span><br><span class="line">        (<span class="string">&quot;&quot;</span>, <span class="number">0</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (order.getClass == classOf[<span class="type">ChengDuTravelOrder</span>]) &#123;</span><br><span class="line">        (<span class="type">Constants</span>.<span class="type">CITY_CODE_CHENG_DU</span> + <span class="string">&quot;_&quot;</span> + order.createDay, <span class="number">1</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (order.getClass == classOf[<span class="type">XiAnTravelOrder</span>]) &#123;</span><br><span class="line">        (<span class="type">Constants</span>.<span class="type">CITY_CODE_XI_AN</span> + <span class="string">&quot;_&quot;</span> + order.createDay, <span class="number">1</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (order.getClass == classOf[<span class="type">HaiKouTravelOrder</span>]) &#123;</span><br><span class="line">        (<span class="type">Constants</span>.<span class="type">CITY_CODE_HAI_KOU</span> + <span class="string">&quot;_&quot;</span> + order.createDay, <span class="number">1</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        (<span class="string">&quot;&quot;</span>, <span class="number">0</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;).updateStateByKey((currValues: <span class="type">Seq</span>[<span class="type">Int</span>], state: <span class="type">Option</span>[<span class="type">Int</span>]) =&gt; &#123;</span><br><span class="line">      <span class="keyword">var</span> count = currValues.sum + state.getOrElse(<span class="number">0</span>);</span><br><span class="line">      <span class="type">Some</span>(count)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 乘车人数统计</span></span><br><span class="line"><span class="comment">      * 如果是成都或者西安的订单，数据中没有乘车人数字段，所有按照默认一单一人的方式进行统计</span></span><br><span class="line"><span class="comment">      * 海口的订单数据中有乘车人数字段，就按照具体数进行统计</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">    <span class="keyword">val</span> passengerCountRest = ordersDs.map(order =&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="literal">null</span> == order) &#123;</span><br><span class="line">        (<span class="string">&quot;&quot;</span>, <span class="number">0</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (order.getClass == classOf[<span class="type">ChengDuTravelOrder</span>]) &#123;</span><br><span class="line">        (<span class="type">Constants</span>.<span class="type">CITY_CODE_CHENG_DU</span> + <span class="string">&quot;_&quot;</span> + order.createDay, <span class="number">1</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (order.getClass == classOf[<span class="type">XiAnTravelOrder</span>]) &#123;</span><br><span class="line">        (<span class="type">Constants</span>.<span class="type">CITY_CODE_XI_AN</span> + <span class="string">&quot;_&quot;</span> + order.createDay, <span class="number">1</span>)</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (order.getClass == classOf[<span class="type">HaiKouTravelOrder</span>]) &#123;</span><br><span class="line">        <span class="keyword">var</span> passengerCount = order.asInstanceOf[<span class="type">HaiKouTravelOrder</span>].passengerCount.toInt</span><br><span class="line">        <span class="comment">//scala不支持类似java中的三目运算符，可以使用下面的操作方式</span></span><br><span class="line">        passengerCount = <span class="keyword">if</span>(passengerCount&gt;<span class="number">0</span>) passengerCount <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        (<span class="type">Constants</span>.<span class="type">CITY_CODE_HAI_KOU</span> + <span class="string">&quot;_&quot;</span> + order.createDay,passengerCount)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        (<span class="string">&quot;&quot;</span>, <span class="number">0</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;).updateStateByKey((currValues: <span class="type">Seq</span>[<span class="type">Int</span>], state: <span class="type">Option</span>[<span class="type">Int</span>]) =&gt; &#123;</span><br><span class="line">      <span class="keyword">var</span> count = currValues.sum + state.getOrElse(<span class="number">0</span>);</span><br><span class="line">      <span class="type">Some</span>(count)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    orderCountRest.foreachRDD(orderCountRDD=&gt;&#123;</span><br><span class="line">      <span class="keyword">import</span> com.cartravel.util.<span class="type">JedisUtil</span></span><br><span class="line">      <span class="keyword">val</span> jedisUtil = <span class="type">JedisUtil</span>.getInstance()</span><br><span class="line">      <span class="keyword">val</span> jedis = jedisUtil.getJedis</span><br><span class="line">      <span class="keyword">val</span> orderCountRest = orderCountRDD.collect()</span><br><span class="line">      println(<span class="string">&quot;orderCountRest:&quot;</span>+orderCountRest)</span><br><span class="line">      orderCountRest.foreach(countrest=&gt;&#123;</span><br><span class="line">        println(<span class="string">&quot;countrest:&quot;</span>+countrest._1+<span class="string">&quot;,&quot;</span>+countrest._2)</span><br><span class="line">        <span class="keyword">if</span>(<span class="literal">null</span>!=countrest)&#123;</span><br><span class="line">          jedis.hset(<span class="type">Constants</span>.<span class="type">ORDER_COUNT</span>, countrest._1, countrest._2 + <span class="string">&quot;&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;)</span><br><span class="line">      jedisUtil.returnJedis(jedis)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    passengerCountRest.foreachRDD(passengerCountRdd=&gt;&#123;</span><br><span class="line">      <span class="keyword">import</span> com.cartravel.util.<span class="type">JedisUtil</span></span><br><span class="line">      <span class="keyword">val</span> jedisUtil = <span class="type">JedisUtil</span>.getInstance()</span><br><span class="line">      <span class="keyword">val</span> jedis = jedisUtil.getJedis</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> passengerCountRest = passengerCountRdd.collect()</span><br><span class="line">      passengerCountRest.foreach(countrest=&gt;&#123;</span><br><span class="line">        jedis.hset(<span class="type">Constants</span>.<span class="type">PASSENGER_COUNT</span>, countrest._1, countrest._2 + <span class="string">&quot;&quot;</span>)</span><br><span class="line">      &#125;)</span><br><span class="line">      jedisUtil.returnJedis(jedis)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//启动sparkstreaming程序</span></span><br><span class="line">    streamingContext.start();</span><br><span class="line">    streamingContext.awaitTermination();</span><br><span class="line">    streamingContext.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2、全域订单轨迹监控"><a href="#2、全域订单轨迹监控" class="headerlink" title="2、全域订单轨迹监控"></a>2、全域订单轨迹监控</h2><h3 id="2-1-实时订单轨迹监控"><a href="#2-1-实时订单轨迹监控" class="headerlink" title="2.1 实时订单轨迹监控"></a>2.1 实时订单轨迹监控</h3><p>​    盖亚数据计划开放的开源数据集中是已经生成的订单轨迹数据所以是不知道订单什么时候结束，真实的业务场景中是有开始和技术的标志位，但是我们可以在数据中认为的设置开始和技术标记，可以这么做在数据的开始开可以设置start字符串在数据的技术可以设置end技术的字符串，使用start和end字符串作为订单轨迹数据的开始和结束.</p><p>实现流程:</p><p><img src="/images/didi/1571215041738.png" alt="1571215041738"></p><p>消费轨迹数据</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br></pre></td><td class="code"><pre><span class="line">com.cartravel.kafka.<span class="keyword">package</span> com.cartravel.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.cartravel.common.Constants;</span><br><span class="line"><span class="keyword">import</span> com.cartravel.common.Order;</span><br><span class="line"><span class="keyword">import</span> com.cartravel.common.TopicName;</span><br><span class="line"><span class="keyword">import</span> com.cartravel.util.HBaseUtil;</span><br><span class="line"><span class="keyword">import</span> com.cartravel.util.JedisUtil;</span><br><span class="line"><span class="keyword">import</span> com.cartravel.util.ObjUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.Consumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Level;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.Logger;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.BufferedOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.PrintWriter;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GpsConsumer</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Logger log = Logger.getLogger(GpsConsumer.class);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span>  KafkaConsumer&lt;String, String&gt; consumer;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">    <span class="comment">//计数消费到的消息条数</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> FileOutputStream file = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> BufferedOutputStream out = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> PrintWriter printWriter = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> String lineSeparator = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> batchNum = <span class="number">0</span>;</span><br><span class="line">    JedisUtil instance = <span class="keyword">null</span>;</span><br><span class="line">    Jedis jedis = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String cityCode = <span class="string">&quot;&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, String&gt; gpsMap = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">    SimpleDateFormat sdf = <span class="keyword">new</span> SimpleDateFormat(<span class="string">&quot;yyyy-MM-dd HH:mm:ss&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GpsConsumer</span><span class="params">(String topic, String groupId)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (topic.equalsIgnoreCase(TopicName.CHENG_DU_GPS_TOPIC.getTopicName())) &#123;</span><br><span class="line">            cityCode = Constants.CITY_CODE_CHENG_DU;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (topic.equalsIgnoreCase(TopicName.XI_AN_GPS_TOPIC.getTopicName())) &#123;</span><br><span class="line">            cityCode = Constants.CITY_CODE_XI_AN;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (topic.equalsIgnoreCase(TopicName.HAI_KOU_ORDER_TOPIC.getTopicName())) &#123;</span><br><span class="line">            cityCode = Constants.CITY_CODE_HAI_KOU;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(topic+<span class="string">&quot;,主题名称不合法!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//dev-hdp</span></span><br><span class="line"><span class="comment">//        props.put(&quot;bootstrap.servers&quot;, &quot;192.168.21.173:6667,192.168.21.174:6667,192.168.21.175:6667&quot;);</span></span><br><span class="line">        <span class="comment">//dev-cdh</span></span><br><span class="line"><span class="comment">//        props.put(&quot;bootstrap.servers&quot;, &quot;192.168.21.177:9092,192.168.21.178:9092,192.168.21.179:9092&quot;);</span></span><br><span class="line">        <span class="comment">//pro-cdh</span></span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, Constants.KAFKA_BOOTSTRAP_SERVERS);</span><br><span class="line"></span><br><span class="line"><span class="comment">//        props.put(&quot;bootstrap.servers&quot;, &quot;192.168.21.178:9092&quot;);</span></span><br><span class="line"></span><br><span class="line">        props.put(<span class="string">&quot;group.id&quot;</span>, groupId);</span><br><span class="line">        props.put(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;auto.offset.reset&quot;</span>, <span class="string">&quot;earliest&quot;</span>);</span><br><span class="line"><span class="comment">//        props.put(&quot;auto.offset.reset&quot;, &quot;latest&quot;);</span></span><br><span class="line">        props.put(<span class="string">&quot;session.timeout.ms&quot;</span>, <span class="string">&quot;30000&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        consumer = <span class="keyword">new</span> KafkaConsumer&lt;String,String&gt;(props);</span><br><span class="line">        <span class="keyword">this</span>.topic = topic;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                doWork();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        batchNum++;</span><br><span class="line">        consumer.subscribe(Collections.singletonList(<span class="keyword">this</span>.topic));</span><br><span class="line">        ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">1000</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;第&quot;</span> + batchNum + <span class="string">&quot;批次,&quot;</span> + records.count());</span><br><span class="line">        <span class="comment">//司机ID</span></span><br><span class="line">        String driverId = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="comment">//订单ID</span></span><br><span class="line">        String orderId = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="comment">//经度</span></span><br><span class="line">        String lng = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="comment">//维度</span></span><br><span class="line">        String lat = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="comment">//时间戳</span></span><br><span class="line">        String timestamp = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        Order order = <span class="keyword">null</span>;</span><br><span class="line">        Order startEndTimeOrder = <span class="keyword">null</span>;</span><br><span class="line">        Object tmpOrderObj = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (records.count() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            Table table = HBaseUtil.getTable(Constants.HTAB_GPS);</span><br><span class="line">            JedisUtil instance = JedisUtil.getInstance();</span><br><span class="line">            jedis = instance.getJedis();</span><br><span class="line">            List&lt;Put&gt; puts = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            String rowkey = <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (gpsMap.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                gpsMap.clear();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//表不存在时创建表</span></span><br><span class="line">            <span class="keyword">if</span> (!HBaseUtil.tableExists(Constants.HTAB_GPS)) &#123;</span><br><span class="line">                HBaseUtil.createTable(HBaseUtil.getConnection(), Constants.HTAB_GPS, Constants.DEFAULT_FAMILY);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                count++;</span><br><span class="line">                log.warn(<span class="string">&quot;Received message: (&quot;</span> + record.key() + <span class="string">&quot;, &quot;</span> + record.value() + <span class="string">&quot;) at offset &quot;</span> +</span><br><span class="line">                        record.offset() + <span class="string">&quot;,count:&quot;</span> + count);</span><br><span class="line">                String value = record.value();</span><br><span class="line">                <span class="keyword">if</span> (value.contains(<span class="string">&quot;,&quot;</span>)) &#123;</span><br><span class="line">                    order = <span class="keyword">new</span> Order();</span><br><span class="line">                    String[] split = value.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                    driverId = split[<span class="number">0</span>];</span><br><span class="line">                    orderId = split[<span class="number">1</span>];</span><br><span class="line">                    timestamp = split[<span class="number">2</span>];</span><br><span class="line">                    lng = split[<span class="number">3</span>];</span><br><span class="line">                    lat = split[<span class="number">4</span>];</span><br><span class="line"></span><br><span class="line">                    rowkey = orderId + <span class="string">&quot;_&quot;</span> + timestamp;</span><br><span class="line">                    gpsMap.put(<span class="string">&quot;CITYCODE&quot;</span>, cityCode);</span><br><span class="line">                    gpsMap.put(<span class="string">&quot;DRIVERID&quot;</span>, driverId);</span><br><span class="line">                    gpsMap.put(<span class="string">&quot;ORDERID&quot;</span>, orderId);</span><br><span class="line">                    gpsMap.put(<span class="string">&quot;TIMESTAMP&quot;</span>, timestamp + <span class="string">&quot;&quot;</span>);</span><br><span class="line">                    gpsMap.put(<span class="string">&quot;TIME&quot;</span>, sdf.format(<span class="keyword">new</span> Date(Long.parseLong(timestamp+<span class="string">&quot;000&quot;</span>))));</span><br><span class="line">                    gpsMap.put(<span class="string">&quot;LNG&quot;</span>, lng);</span><br><span class="line">                    gpsMap.put(<span class="string">&quot;LAT&quot;</span>, lat);</span><br><span class="line"></span><br><span class="line">                    order.setOrderId(orderId);</span><br><span class="line"></span><br><span class="line">                    puts.add(HBaseUtil.createPut(rowkey, Constants.DEFAULT_FAMILY.getBytes(), gpsMap));</span><br><span class="line"></span><br><span class="line">                    <span class="comment">//1.存入实时订单单号</span></span><br><span class="line">                    jedis.sadd(Constants.REALTIME_ORDERS, cityCode + <span class="string">&quot;_&quot;</span> + orderId);</span><br><span class="line">                    <span class="comment">//2.存入实时订单的经纬度信息</span></span><br><span class="line">                    jedis.lpush(cityCode + <span class="string">&quot;_&quot;</span> + orderId, lng + <span class="string">&quot;,&quot;</span> + lat);</span><br><span class="line">                    <span class="comment">//3.存入订单的开始结束时间信息</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">byte</span>[] orderBytes = jedis.hget(Constants.ORDER_START_ENT_TIME.getBytes()</span><br><span class="line">                            , orderId.getBytes());</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (orderBytes != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        tmpOrderObj = ObjUtil.deserialize(orderBytes);</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (<span class="keyword">null</span> != tmpOrderObj) &#123;</span><br><span class="line">                        startEndTimeOrder = (Order) tmpOrderObj;</span><br><span class="line">                        startEndTimeOrder.setEndTime(Long.parseLong(timestamp+<span class="string">&quot;000&quot;</span>));</span><br><span class="line">                        jedis.hset(Constants.ORDER_START_ENT_TIME.getBytes(), orderId.getBytes(),</span><br><span class="line">                                ObjUtil.serialize(startEndTimeOrder));</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">//第一次写入订单的开始时间,开始时间和结束时间一样</span></span><br><span class="line">                        order.setStartTime(Long.parseLong(timestamp));</span><br><span class="line">                        order.setEndTime(Long.parseLong(timestamp));</span><br><span class="line">                        jedis.hset(Constants.ORDER_START_ENT_TIME.getBytes(), orderId.getBytes(),</span><br><span class="line">                                ObjUtil.serialize(order));</span><br><span class="line">                    &#125;</span><br><span class="line">                    hourOrderInfoGather(jedis,gpsMap);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (value.contains(<span class="string">&quot;end&quot;</span>)) &#123;</span><br><span class="line">                    jedis.lpush(cityCode + <span class="string">&quot;_&quot;</span> + orderId, value);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            table.put(puts);</span><br><span class="line">            instance.returnJedis(jedis);</span><br><span class="line">        &#125;</span><br><span class="line">        log.warn(<span class="string">&quot;正常结束...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计城市的每小时的订单信息和订单数</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span>  <span class="keyword">void</span> <span class="title">hourOrderInfoGather</span><span class="params">(Jedis jedis,Map&lt;String, String&gt; gpsMap)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        String time = gpsMap.get(<span class="string">&quot;TIME&quot;</span>);</span><br><span class="line">        String orderId = gpsMap.get(<span class="string">&quot;ORDERID&quot;</span>);</span><br><span class="line">        String day = time.substring(<span class="number">0</span>,time.indexOf(<span class="string">&quot; &quot;</span>));</span><br><span class="line">        String hour = time.split(<span class="string">&quot; &quot;</span>)[<span class="number">1</span>].substring(<span class="number">0</span>,<span class="number">2</span>);</span><br><span class="line">        <span class="comment">//redis表名,小时订单统计</span></span><br><span class="line">        String hourOrderCountTab = cityCode+<span class="string">&quot;_&quot;</span>+day+<span class="string">&quot;_hour_order_count&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//redis表名,小时订单ID</span></span><br><span class="line">        String hourOrderField = cityCode+<span class="string">&quot;_&quot;</span>+day+<span class="string">&quot;_&quot;</span>+hour;</span><br><span class="line">        String hourOrder = cityCode+<span class="string">&quot;_order&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> hourOrderCount = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//redis set集合中存放每小时内的所有订单id</span></span><br><span class="line">        <span class="keyword">if</span>(!jedis.sismember(hourOrder,orderId))&#123;</span><br><span class="line">            <span class="comment">//使用set存储小时订单id</span></span><br><span class="line">            jedis.sadd(hourOrder,orderId);</span><br><span class="line">            String hourOrdernum = jedis.hget(hourOrderCountTab, hourOrderField);</span><br><span class="line">            <span class="keyword">if</span>(StringUtils.isEmpty(hourOrdernum))&#123;</span><br><span class="line">                hourOrderCount = <span class="number">1</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                hourOrderCount = Integer.parseInt(hourOrdernum)+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//HashMap 存储每个小时的订单总数</span></span><br><span class="line">            jedis.hset(hourOrderCountTab,hourOrderField,hourOrderCount+<span class="string">&quot;&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Logger.getLogger(<span class="string">&quot;org.apache.kafka&quot;</span>).setLevel(Level.INFO);</span><br><span class="line">        <span class="comment">//kafka主题</span></span><br><span class="line">        String topic = <span class="string">&quot;cheng_du_gps_topic&quot;</span>;</span><br><span class="line">        <span class="comment">//消费组id</span></span><br><span class="line">        String groupId = <span class="string">&quot;cheng_du_gps_consumer_01&quot;</span>;</span><br><span class="line"></span><br><span class="line">        GpsConsumer gpsConsumer = <span class="keyword">new</span> GpsConsumer(topic, groupId);</span><br><span class="line">        Thread start = <span class="keyword">new</span> Thread(gpsConsumer);</span><br><span class="line">        start.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-2-历史订单轨迹回放"><a href="#2-2-历史订单轨迹回放" class="headerlink" title="2.2 历史订单轨迹回放"></a>2.2 历史订单轨迹回放</h3><p><a href="https://lbs.amap.com/api/javascript-api/example/marker/replaying-historical-running-data">高德轨迹回放示例</a></p><p>功能实现流程:</p><p><img src="/images/didi/1571216562760.png" alt="1571216562760"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">com.cartravel.ordermonitor.TrackMonitorController</span><br><span class="line"></span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 查询订单历史轨迹点</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> wrapper</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@PostMapping(&quot;/historyTrackPoints&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> ResultModel&lt;List&lt;TrackPoint&gt;&gt; historyTrackPoints(<span class="meta">@RequestBody</span> QueryWrapper wrapper) &#123;</span><br><span class="line">        <span class="keyword">long</span> startTime = System.currentTimeMillis();</span><br><span class="line">        logger.info(<span class="string">&quot;【查询图形(点线面)】&quot;</span>);</span><br><span class="line">        ResultModel&lt;List&lt;TrackPoint&gt;&gt; result = <span class="keyword">new</span> ResultModel&lt;List&lt;TrackPoint&gt;&gt;();</span><br><span class="line">        Object tmpOrderObj = <span class="keyword">null</span>;</span><br><span class="line">        Order startEndTimeOrder = <span class="keyword">null</span>;</span><br><span class="line">        List&lt;TrackPoint&gt; list = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            String orderId = wrapper.getOrderId();</span><br><span class="line">            JedisUtil instance = JedisUtil.getInstance();</span><br><span class="line">            Jedis jedis = instance.getJedis();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">byte</span>[] orderBytes = jedis.hget(Constants.ORDER_START_ENT_TIME.getBytes()</span><br><span class="line">                    , orderId.getBytes());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (orderBytes != <span class="keyword">null</span>) &#123;</span><br><span class="line">                tmpOrderObj = ObjUtil.deserialize(orderBytes);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">null</span> != tmpOrderObj) &#123;</span><br><span class="line">                startEndTimeOrder = (Order) tmpOrderObj;</span><br><span class="line">                String starttime = startEndTimeOrder.getStartTime() + <span class="string">&quot;&quot;</span>;</span><br><span class="line">                String enttime = startEndTimeOrder.getEndTime() + <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line">                String tableName = Constants.HTAB_GPS;</span><br><span class="line">                list = HBaseUtil.getRest(tableName, wrapper.getOrderId(),</span><br><span class="line">                        starttime, enttime, TrackPoint.class);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            result.setSuccess(<span class="keyword">true</span>);</span><br><span class="line">            result.setData(list);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            result.setMsg(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">        logger.info(<span class="string">&quot;【查询订单历史轨迹点】msg:&#123;&#125;,time:&#123;&#125;&quot;</span>, result.getMsg(),</span><br><span class="line">                System.currentTimeMillis() - startTime);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
      
      
      <categories>
          
          <category> 滴滴智慧出行 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 滴滴智慧出行 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HDFS HA 机制解析</title>
      <link href="2019/11/12/HDFS%20HA%E6%9C%BA%E5%88%B6%E8%A7%A3%E6%9E%90/"/>
      <url>2019/11/12/HDFS%20HA%E6%9C%BA%E5%88%B6%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><code>Hadoop</code>的高可用是 <code>Hadoop 2.X</code> 版本及以上的特性</p><p><code>Hadoop HA</code> 通过 <code>zookeeper</code> 来实现 <code>namenode</code> 的高可用</p><a id="more"></a><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h1><blockquote><p><code>Hadoop</code>的高可用是 <code>Hadoop 2.X</code> 版本及以上的特性</p><p><code>Hadoop HA</code> 通过 <code>zookeeper</code> 来实现 <code>namenode</code> 的高可用</p></blockquote><h1 id="2-关键技术"><a href="#2-关键技术" class="headerlink" title="2. 关键技术"></a>2. 关键技术</h1><p>保持主和备 <code>NameNode</code> 的状态同步</p><blockquote><p>并让 <code>Standby</code> 在 <code>Active</code> 挂掉后迅速提供服务 <code>Namenode</code> 启动比较耗时，包括加载<code>fsimage</code> 和 <code>editlog</code>[获取<code>file to block</code>信息]、处理所有 <code>datanode</code> 第一次<code>blockreport</code> [获取 <code>block to datanode</code> 信息]，保持 <code>NN</code> 的状态同步，需要这两部分信息同步。</p></blockquote><p>脑裂 <code>split-brain</code></p><blockquote><p>指在一个高可用系统中，当联系着的两个节点断开联系时，本来为一个整体的系统，分裂为两个独立节点，这时两个节点开始争抢共享资源，结果会导致系统混乱，数据损坏。</p></blockquote><p><code>NameNode</code> 切换对外透明</p><blockquote><p>主 <code>Namenode</code> 切换到另外一台机器时，不应该导致正在连接的客户端失败，主要包括 <code>Client</code>，<code>Datanode</code>与<code>NameNode</code> 的连接</p></blockquote><h1 id="3-架构"><a href="#3-架构" class="headerlink" title="3. 架构"></a>3. 架构</h1><h2 id="3-1-主备NameNode"><a href="#3-1-主备NameNode" class="headerlink" title="3.1. 主备NameNode"></a>3.1. 主备<code>NameNode</code></h2><blockquote><p><strong>解决单点问题，主 <code>NameNode</code> 对外提供服务，<code>StandBy NameNode</code> 同步``Active NameNode<code> 元数据，以待切换；所有</code>DataNode<code>同时向两个</code>NameNode` 汇报数据块信息</strong></p></blockquote><blockquote><p>两种切换选择</p><ul><li>手动切换:通过命令实现主备之间的切换，可以用 <code>HDFS</code> 升级等场合</li><li>自由切换:基于 <code>Zookeeper</code> 实现；<code>Zookeeper FailOver Controller</code> ：监控 <code>NameNode</code> 健康状态并向<code>Zookeeper</code> 注册 <code>NameNode</code> ，<code>NameNode</code> 挂掉后，<code>ZKFC </code>为 <code>NameNode</code> 竞争锁，获得<code>ZKFC</code>锁的<code>NameNode</code> 变为 <code>active</code></li></ul></blockquote><h2 id="3-2-Journal-Node-集群"><a href="#3-2-Journal-Node-集群" class="headerlink" title="3.2. Journal Node 集群"></a>3.2. <code>Journal Node</code> 集群</h2><blockquote><p><strong><code>Journal node</code> 是根据 <code>paxos</code> 思想来设计的，只有写到一半以上返回成功，就算本次写成功。所以 <code>Journal </code>需要部署 <code>3 </code>台组成一个集群，核心思想是过半 <code>Quorum</code>，异步写到多个<code> Journal Node</code>。</strong></p></blockquote><h1 id="4-机制"><a href="#4-机制" class="headerlink" title="4. 机制"></a>4. 机制</h1><blockquote><p> <code>Active Namenode</code> 每接收到事务请求时，都会先写日志</p></blockquote><p>批量刷磁盘</p><p>这个应该说是写日志的通用做法，如果每来一条日志都刷磁盘，效率很低，如果批量刷盘，就能合并很多小 <code>IO</code></p><p>双缓冲区切换</p><p>bufCurrent 日志写入缓冲区 </p><p>bufReady 即将刷磁盘的缓冲区</p><p>如果没有双缓冲区，我们写日志缓冲区满了，就要强制刷磁盘，我们知道刷磁盘不仅是写到操作系统内核缓冲区，还要刷到磁盘设备上，这是相当费时的操作，引入双缓冲区，在刷磁盘操作和写日志操作可以并发执行，大大提高了Namenode的吞吐量。</p>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HDFS 读写机制</title>
      <link href="2019/11/10/HDFS%E8%AF%BB%E5%86%99%E5%8F%8A%E5%85%B6%E7%9B%B8%E5%85%B3%E6%9C%BA%E5%88%B6/"/>
      <url>2019/11/10/HDFS%E8%AF%BB%E5%86%99%E5%8F%8A%E5%85%B6%E7%9B%B8%E5%85%B3%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 HDFS中可能同时有多个客户端在同一时刻写文件，如果不进行控制的话，有可能多个客户端会并发的写一个文件，所以需要进行控制，一般的想法是用一个互斥锁，在某一时刻只有一个客户端进行写操作，但是在分布式系统中有如下问题：</p><a id="more"></a><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="HDFS-租约机制"><a href="#HDFS-租约机制" class="headerlink" title="HDFS 租约机制"></a>HDFS 租约机制</h2><p>在 HDFS中可能同时有多个客户端在同一时刻写文件，如果不进行控制的话，有可能多个客户端会并发的写一个文件，所以需要进行控制，一般的想法是用一个互斥锁，在某一时刻只有一个客户端进行写操作，但是在分布式系统中有如下问题：</p><ul><li>每次写文件前，客户端需要向 master获取锁情况，他们之间的网络通讯太频繁。</li><li>当某个客户端获取锁之后和 master 失去联系，这个锁一直被该客户端占据，master和其他客户端不能获得锁，后续操作中断。</li></ul><p>在 HDFS 中使用了租约解决上面的问题：</p><ul><li>当写一个文件时，客户端向 NameNode 请求一个租约，租约有个时间期限，在时间期限内客户端可以写租约中管理的文件，一个文件只可能在一个租约内，所以只可能有一个客户端写。</li><li>在租约的有效时间内，客户端不需要向 NameNode 询问是否有写文件的权限，客户端会一直持有，当客户端一直正常的时候，客户端在租约过期的时候会续约。</li><li>当客户端在持有租约期间如果发生异常，和 NameNode 失去联系，在租约期满以后 NameNode 会发现客户端异常，新的租约会赋给其他正常的客户端，当异常客户端已经写了一部分数据， HDFS 为了分辨这些无用的数据，每次写的时候会增加版本号，异常客户端写的数据版本号过低，可以安全的删除掉。</li></ul><h2 id="CRC-校验"><a href="#CRC-校验" class="headerlink" title="CRC 校验"></a>CRC 校验</h2><h1 id="写数据流程"><a href="#写数据流程" class="headerlink" title="写数据流程"></a>写数据流程</h1><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><ul><li><p>客户端向 NameNode 请求上传文件，NameNode 判断、检查目标文件是否已存在、判断 client 是否有权限、父目录是否存在。</p></li><li><p>NameNode 返回是否可以上传。</p></li><li><p>客户端请求第一个 block 上传到哪几个 DataNode 服务器上。</p></li><li><p>NameNode 返回给客户端存储块文件的 DataNode 列表。</p><p><font color='grey'>NameNode 会根据客户端的配置来查询 DataNode 信息，如果使用默认配置，那么最终结果会返回同一个机架的两个 DataNode 和另一个机架的 DataNode。这称为 <font color='blue'><strong>“机架感知”</strong> </font>策略。如：NameNode 返回3个 DataNode 节点，分别为 dn1、dn2、dn3。</font></p><p><font color='grey'><strong>在大多数情况下，副本系数是 3，HDFS 的存放策略是将一个副本存放在本机架的本节点上，一个副本放在同一机架的另一个节点上，最后一个副本放在不同机架的节点上。</strong></font></p><p><font color='grey'>这种策略减少了机架间的数据传输，这就提高了写操作的效率。机架的错误远远比节点的错误少，所以这个策略不会影响到数据的可靠性和可用性。同时，因为数据块只放在两个 [不是三个] 不同的机架上，所以此策略减少了读取数据时需要的网络传输总带宽。</font></p><p><font color='grey'>在这种策略下，副本并不是均匀分布在不同的机架上。三分之一的副本在一个节点上，三分之二的副本在一个机架上，其他副本均匀分布在剩下的机架中，这一策略在不损害数据可靠性和读取性能的情况下改进了写的性能。</font></p></li><li><p>客户端发出请求建立 pipeline。客户端请求 dn1 上传数据，dn1 收到请求会继续调用 dn2，然后 dn2调用dn3，将这个通信管道建立完成</p></li><li><p>客户端先将数据写入数据块 chunk 中（512Byte），当写满 chunk 之后会计算当前 chunk 的校验值checksums [4Byte]，同时将 checksums 写入chunk[chunk总大小为512Byte+4Byte],将chunk写入数据包 package</p><p><font color='grey'>客户端在开始传输数据块之前会把数据缓存在本地，当缓存大小超过了一个数据块的大小，会在客户端和第一个 datanode 建立连接开始流式的传输数据，这个 datanode 会一小部分一小部分[4K]的接收数据然后写入本地仓库，同时会把这些数据传输到第二个datanode，第二个 datanode 也同样一小部分一小部分的接收数据并写入本地仓库，同时传输给第三个 datanode (在流式复制时，逐级传输和响应采用响应队列来等待传输结果。队列响应完成后返回给客户端)，依次类推。这样逐级调用和返回之后，待这个数据块传输完成客户端后告诉 namenode 数据块传输完成，这时候 namenode 才会更新元数据信息记录操作日志。</font></p></li><li><p>第一个数据块传输完成后会使用同样的方式传输下面的数据块直到整个文件上传完成。</p></li></ul><h1 id="读数据"><a href="#读数据" class="headerlink" title="读数据"></a>读数据</h1><h2 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h2><ul><li>客户端向 NameNode 请求下载文件，NameNode 通过查询元数据，找到文件块所在的 DataNode 地址。</li><li>挑选一台 DataNode[就近原则，然后随机]服务器，请求读取数据。如果第一个 DataNode 无法连接，客户端将自动连接下一个 DataNode</li><li>DataNode 开始传输数据给客户端 [从磁盘里面读取数据放入流，以packet为单位来做校验]</li><li>客户端以 packet 为单位接收，先在本地缓存，然后写入目标文件。</li></ul><h1 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h1><h2 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h2><h3 id="HDFS-从客户端写入到-DataNode-时，ACK是否三个备份都写成功之后再确认成功操作？"><a href="#HDFS-从客户端写入到-DataNode-时，ACK是否三个备份都写成功之后再确认成功操作？" class="headerlink" title="HDFS 从客户端写入到  DataNode 时，ACK是否三个备份都写成功之后再确认成功操作？"></a>HDFS 从客户端写入到  DataNode 时，ACK是否三个备份都写成功之后再确认成功操作？</h3><p>不是，只要成功写入的节点数量达到 <strong>dfs.replication.min</strong>[默认为1]，那么就任务是写成功的</p><p>正常情况下</p><ul><li><p>在进行写操作的时候[以默认备份 3 份为例]，DataNode_1 接受数据后，首先将数据写入  buffer ，再将数据写入 DataNode_2，写入成功后将 buffer 中的数据写入本地磁盘，并等待 ACK 信息</p></li><li><p>重复上一个步骤，DataNode_2 写入本地磁盘后，等待 ACK 信息</p></li><li><p>如果 ACK 都成功返回后，发送给 Client，本次写入成功</p></li><li><p>如果一个节点或多个节点写入失败：</p></li></ul><p>只要成功写入的节点数量达到 dfs.replication.min [默认为1]，那么就任务是写成功的。然后 NameNode 会通过异步的方式将 block 复制到其他节点，使数据副本达到dfs.replication 参数配置的个数</p>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop 序列化机制</title>
      <link href="2019/10/17/Hadoop%E5%BA%8F%E5%88%97%E5%8C%96%E6%9C%BA%E5%88%B6/"/>
      <url>2019/10/17/Hadoop%E5%BA%8F%E5%88%97%E5%8C%96%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>对象序列化**是一个用于将内存中对象状态转换为字节流的过程，可以将其保存到磁盘文件中或通过网络发送到任何其他程序</p><p>从字节流创建对象的相反的过程称为<strong>反序列化</strong>。而创建的字节流是与平台无关的，在一个平台上序列化的对象可以在不同的平台上反序列化。</p><a id="more"></a><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><h2 id="1-1-什么是序列化-？"><a href="#1-1-什么是序列化-？" class="headerlink" title="1.1. 什么是序列化 ？"></a>1.1. 什么是序列化 ？</h2><blockquote><p><strong>对象序列化</strong>是一个用于将内存中对象状态转换为字节流的过程，可以将其保存到磁盘文件中或通过网络发送到任何其他程序</p></blockquote><blockquote><p>从字节流创建对象的相反的过程称为<strong>反序列化</strong>。而创建的字节流是与平台无关的，在一个平台上序列化的对象可以在不同的平台上反序列化。</p></blockquote><h2 id="1-2-为什么要序列化-？"><a href="#1-2-为什么要序列化-？" class="headerlink" title="1.2. 为什么要序列化 ？"></a>1.2. 为什么要序列化 ？</h2><h2 id="1-3-Java-序列化实现"><a href="#1-3-Java-序列化实现" class="headerlink" title="1.3. Java 序列化实现"></a>1.3. <code>Java</code> 序列化实现</h2><h2 id="1-4-Hadoop-序列化"><a href="#1-4-Hadoop-序列化" class="headerlink" title="1.4. Hadoop 序列化"></a>1.4. <code>Hadoop</code> 序列化</h2><blockquote><p><code>Java</code> 的序列化机制的缺点就是计算量开销大，且序列化的结果体积大，有时能达到对象大小的数倍乃至十倍。</p><p>它的引用机制也会导致大文件不能分割的问题。这些缺点使得 <code>Java</code> 的序列化机制对<code>Hadoop</code>来说是不合适的。于是<code>Hadoop</code>设计了自己的序列化机制。</p></blockquote><blockquote><p><code>hadoop</code> 提供了 <code>Writable</code> 接口实现序列化。<code>Hadoop2.x</code> 里面包含了<code>avro</code> 和<code>protocol buffer</code>。</p><p><code>Hadoop</code> 序列化没有提供比较功能，所以和 <code>Java</code> 中的<code>Comparable</code>接口合并，提供一个接口<code>WritableComparable</code>。[自定义比较]</p></blockquote><h2 id="1-5-Hadoop-序列化特点"><a href="#1-5-Hadoop-序列化特点" class="headerlink" title="1.5. Hadoop 序列化特点"></a>1.5. <code>Hadoop</code> 序列化特点</h2><h1 id="2-自定义序列化"><a href="#2-自定义序列化" class="headerlink" title="2. 自定义序列化"></a>2. 自定义序列化</h1><h2 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1. 概述"></a>2.1. 概述</h2><h2 id="2-2-步骤"><a href="#2-2-步骤" class="headerlink" title="2.2. 步骤"></a>2.2. 步骤</h2><ul><li><p>必须实现 **<code>Writable</code> ** 接口</p></li><li><p>反序列化的时候，需要反射调用空参构造函数，必须有空参构造函数</p></li><li><p>重写序列化方法</p></li><li><p>重写反序列化方法</p><blockquote><p> 注意: 反序列化的顺序和序列化的顺序必须一致</p></blockquote></li><li><p>如果要想把结果显示在文件中，需要重写 <code>toString()</code>,可用<code>\t</code>分开，方便后续使用</p></li><li><p>如果需要自定义的 <code>bean</code> 放在 <code>key</code> 中传输，则还需要实现 <code>Comparable</code> 接口，因为 <code>MapReduce</code> 框架中的 <code>shuffle</code> 过程要求对 <code>key</code> 必须能排序 </p></li></ul><h2 id="2-3-案例"><a href="#2-3-案例" class="headerlink" title="2.3. 案例"></a>2.3. 案例</h2><h1 id="3-序列化框架"><a href="#3-序列化框架" class="headerlink" title="3. 序列化框架"></a>3. 序列化框架</h1>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop Federation</title>
      <link href="2019/10/15/Federation%20/"/>
      <url>2019/10/15/Federation%20/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HDFS Federation 是解决 NameNode 内存瓶颈问题的水平横向扩展方案。</p><a id="more"></a><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>HDFS 主要有两大模块：</p><blockquote><ul><li><strong>Namespace</strong></li></ul><blockquote><p>包括目录、文件和块。</p></blockquote><blockquote><p>它支持所有和命名空间相关的文件操作，如创建、删除、修改，查看所有文件和目录。</p></blockquote><ul><li><p>**Block Storage Service ** **[块存储服务]**包括两部分</p><ul><li><p>在 namenode 中的块的管理</p><ul><li>提供 datanode 集群的注册、心跳检测等功能。</li><li>处理块的报告信息和维护块的位置信息。</li><li>支持块相关的操作，如创建、删除、修改、获取块的位置信息。</li><li>管理块的冗余信息、创建副本、删除多余的副本等。</li></ul></li><li><p>存储</p><blockquote><p>datanode 提供本地文件系统上块的存储、读写、访问等。</p></blockquote></li></ul></li></ul><p>以前的 HDFS 框架整个集群只允许有一个namenode，一个 namenode管理所有的命名空间，HDFS 联邦通过增加多个 namenode 来打破这种限制。</p><p>单 NameNode 的架构使得 HDFS 在集群扩展性和性能上都有潜在的问题。当集群大到一定程度后，NameNode 进程使用的内存可能会达到上百 G，NameNode 成为了性能的瓶颈。因而提出了 namenode 水平扩展方案– Federation</p><p>hdfs federation 即 hdfs 的联邦，可以简单理解为多个 hdfs 集群聚合到一起，更准确的理解是有多个namenode节点的 hdfs 集群</p></blockquote><h1 id="2-架构"><a href="#2-架构" class="headerlink" title="2. 架构"></a>2. 架构</h1><h2 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1. 概述"></a>2.1. 概述</h2><p>HDFS Federation 是解决 NameNode 内存瓶颈问题的水平横向扩展方案。</p><p>NameNode 之间相互独立，各自管理自己的区域，且不需要互相协调，一个 NameNode 挂掉了不会影响其他的 NameNode</p><p>DataNode 被用作通用的数据存储设备，每个 DataNode 要向集群中所有的 NameNode注册，且周期性的向所有NameNode 发送心跳和报告，并执行来自所有 NameNode 的命令.</p><p>一个Block Pool由属于同一个 NameSpace 的数据块组成，每个 DataNode 可能会存储集群中所有 Block Pool 数据块，每个Block Pool内部自治，各自管理各自的Block，不会与其他 Block Pool交流<br>NameNode 和 Block Pool 一起被称作 Namespace Volume，它是管理的基本单位，当一个 namespace 被删除后，所有 datanode 上与其对应的 block pool 也会被删除。当集群升级时，每个 namespace volume 作为一个基本单元进行升级</p><h2 id="2-2-Block-Pool"><a href="#2-2-Block-Pool" class="headerlink" title="2.2.  Block Pool"></a>2.2.  Block Pool</h2><p>一个块池就是属于一个namespace的一组块。datanodes存储集群中所有的块池，它独立于其它块池进行管理。这允许namespace在不与其它namespace交互的情况下生成块的ID，有故障的namenode不影响datanode继续为集群中的其它namenode服务。一个namespace和它的blockpool一起叫做namespace volume，这是一个自己的管理单位，当一个namenode被删除，那么在datanode上的相应的block pool也会被删除。在集群进行升级的时候，每一个namespace volume独立的进行升级。</p><h2 id="2-3-ClusterID"><a href="#2-3-ClusterID" class="headerlink" title="2.3. ClusterID"></a>2.3. ClusterID</h2><p>增加一个新的ClusterID标识来在集群中所有的节点。当一个namenode被格式化的时候，这个标识被指定或自动生成，这个ID会用于格式化集群中的其它namenode。</p><h2 id="2-5-不足"><a href="#2-5-不足" class="headerlink" title="2.5. 不足"></a>2.5. 不足</h2><p>HDFS Federation 并没有完全解决单点故障问题。虽然 NameNode 存在多个，但是从单个NameNode 看，仍然存在单点故障：<br>如果某个 NameNode 挂掉了，其管理的相应的文件便不可以访问。 Federation 中每个NameNode 仍然像之前 HDFS 上实现一样，配有一个 Secondary NameNode，以便主 NameNode 挂掉，用于还原元数据信息。<br>所以一般集群规模很大的时，会采用 HA+Federation 的部署方案</p><h1 id="3-配置"><a href="#3-配置" class="headerlink" title="3. 配置"></a>3. 配置</h1>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark 架构设计</title>
      <link href="2019/10/10/Spark%E6%9E%B6%E6%9E%84/"/>
      <url>2019/10/10/Spark%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="Spark-核心组件"><a href="#Spark-核心组件" class="headerlink" title="Spark 核心组件"></a>Spark 核心组件</h1><h3 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h3><p>Spark 驱动器节点，用于执行 Spark 任务中的 main 方法， 负责实际代码的执行工作。Driver 在 Spark 作业执行时主要负责：</p><ol><li><p>将用户程序转化为任务[job]</p></li><li><p>Executor 之间调度任务task</p></li><li><p>跟踪 Executor 的执行情况；</p></li><li><p>通过 UI 展示查询运行情况</p></li></ol><h3 id="Executor"><a href="#Executor" class="headerlink" title="Executor"></a>Executor</h3><p>Spark Executor 节点是一个 JVM 进程，负责在 Spark 作业中运行 具体 任务，任 务 彼此之 间相互独立。 Spark 应用启动时， Executor 节点被同时启动， 并且 始终伴 随着整个 Spark 应用的生命周期而存在。 如果有 Executor 节点发生了故障或崩溃 ， Spark 应用也可以继续执行， 会将出错节点上的任务调度到其他 Executor 节点上继 续运行。</p><p>Executor 有两个核心功能：</p><ol><li><p>负责运行组成 Spark 应用的任务，并将结果返回给 Driver 进程；</p></li><li><p>它们通过自身的块管理器（ Block Manager ）为用户程序中要求缓存的 RDD</p></li></ol><h2 id="运行流程概述"><a href="#运行流程概述" class="headerlink" title="运行流程概述"></a>运行流程概述</h2><p>![image-20200131155431461](/Users/zxc/Library/Application Support/typora-user-images/image-20200131155431461.png)</p><h2 id="Spark-部署模式"><a href="#Spark-部署模式" class="headerlink" title="Spark 部署模式"></a>Spark 部署模式</h2><h3 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h3><p>Local[N] 模式，用单机的多个线程来模拟 Spark 分布式计算，直接运行在本地，便于调试，通常用来验证开发出来的应用程序逻辑上有没有问题。</p><p>其中 N 代表可以使用 N 个线程，每个线程拥有一个 core。如果不指定 N，则默认是1个线程，该线程有1个core。</p><ul><li>local 只启动一个 executor</li><li>local[k] 启动 k 个executor</li><li>local[*] 启动 和 cpu 数目相同的 executor</li></ul><h3 id="Standalone-模式"><a href="#Standalone-模式" class="headerlink" title="Standalone 模式"></a>Standalone 模式</h3><p>独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。</p><h3 id="Spark-On-Mesos-模式"><a href="#Spark-On-Mesos-模式" class="headerlink" title="Spark On Mesos 模式"></a>Spark On Mesos 模式</h3><p>Spark 运行在 Mesos 上会比运行在 YARN 上更加灵活，更加自然。目前在 Spark On Mesos 环境中，用户可选择两种调度模式之一运行自己的应用程序。 </p><ul><li><p>粗粒度模式</p><blockquote><p>每个应用程序的运行环境由一个 Dirver 和若干个 Executor 组成，其中，每个 Executor 占用若干资源，内部可运行多个Task。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中要一直占用这些资源，即使不用，最后程序运行结束后，回收这些资源。</p></blockquote></li><li><p>细粒度模式</p><blockquote><p>鉴于粗粒度模式会造成大量资源浪费，Spark On Mesos 还提供了另外一种调度模式：细粒度模式，这种模式类似于现在的云计算，思想是按需分配。与粗粒度模式一样，应用程序启动时，先会启动executor，但每个 executor 占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos 会为每个 executor 动态分配资源，每分配一些，便可以运行一个新任务，单个 Task 运行完之后可以马上释放对应的资源。每个 Task 会汇报状态给 Mesos slave 和 Mesos Master ，便于更加细粒度管理和容错，这种调度模式类似于 MapReduce 调度模式，每个 Task 完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。</p></blockquote></li></ul><h3 id="Spark-On-YARN-模式"><a href="#Spark-On-YARN-模式" class="headerlink" title="Spark On YARN 模式"></a>Spark On YARN 模式</h3><p>目前仅支持粗粒度模式。这是由于 YARN 上的 Container 资源是不可以动态伸缩的，一旦 Container 启动之后，可使用的资源不能再发生变化，不过这个已经在 YARN 计划中了。 </p><p>spark on yarn 的支持两种模式： </p><ol><li>yarn-cluster：适用于生产环境； </li><li>yarn-client：适用于交互、调试，希望立即看到 app 的输出 </li></ol><p>yarn-cluster 和 yarn-client 的区别在于 yarn appMaster，每个 yarn app 实例有一个 appMaster进程，是为 app 启动的第一个 container</p><p>负责从 ResourceManager 请求资源，获取到资源后，告诉 NodeManager 为其启动 container。</p><h2 id="运行机制"><a href="#运行机制" class="headerlink" title="运行机制"></a>运行机制</h2><h3 id="Standalone-模式运行机制"><a href="#Standalone-模式运行机制" class="headerlink" title="Standalone 模式运行机制"></a>Standalone 模式运行机制</h3><p>在 Standalone Client 模式下，Driver 在任务提交的本地机器上运行，Driver 启动后向 Master 注册应用程序，Master 根据 submit 脚本的资源需求找到内部资源至少可以启动一个 Executor 的所有 Worker ，然后在这些 Worker 之间分配 Executor ，Worker 上的 Executor 启动后会向 Driver 反向注册，所有的 Executor 注册完成后，Driver 开 始执行 main 函数， 之后执行到 Action 算子时 ， 开始划分 stage ， 每个 stage 生成对 应 的 taskSet ， 之后将task 分发到各个 Executor 上执行。</p><h3 id="YARN-模式运行机制"><a href="#YARN-模式运行机制" class="headerlink" title="YARN 模式运行机制"></a>YARN 模式运行机制</h3><h5 id="YARN-Client-模式"><a href="#YARN-Client-模式" class="headerlink" title="YARN  Client 模式"></a><font color='blue'>YARN  Client 模式</font></h5><p>在 YARN Client 模式下， Driver 在任务提交的本地机器上运行， Driver 启动后会和 ResourceManager 通讯申请启动 Application Master，随后 ResourceManager 分配 container ， 在合适的 NodeManager 上启动 ApplicationMaster，此时的 ApplicationMaster 的功能相当于一个 Executor Laucher，只 负责向 ResourceManager 申请 Executor 内存 。</p><p>ResourceManager 接到 ApplicationMaster 的资源申请后会分配 container，然后 ApplicationMaster 在资源分配指定的 NodeManager 上启动 Executor 进程， Executor 进程启动后会向 Driver 反向注册， Executor 全部注册完成后 Driver 开始执行 main 函数，之后执行到 Action 算子时， 触发一个job，并根据宽依赖开始划分 stage ， 每个 stage 生成对应的 taskSet，之后将 task 分发到各个 Executor 上执行 。</p><p>![屏幕快照 2020-03-23 上午12.33.41](/Users/zxc/Documents/hexo/source/_posts/Spark架构.assets/屏幕快照 2020-03-23 上午12.33.41.png)</p><p><font color='blue'><strong>YARN Cluster模式</strong></font></p><p>在 Yarn-Cluster 模式中，当用户向 Yarn 中提交一个应用程序后， Yarn 将分两个阶段运行该应用程序：第一个阶段是把 Spark 的 Driver 作为一个 ApplicationMaster 在 Yarn 集群中先启动；第二个阶段是由 ApplicationMaster 创建应用程序，然后为它向 ResourceManager 申请资源，并启动 Executor 来运行 Task，同时监控它的整个运行过程，直到运行完成。</p><p>![屏幕快照 2020-03-23 上午12.27.59](/Users/zxc/Documents/hexo/source/_posts/Spark架构.assets/屏幕快照 2020-03-23 上午12.27.59.png)</p><p>在 YARNCluster 模式下，任务提交后会和 ResourceManager 通讯申请启动 Application Master ， 随后 ResourceManager 分配 container， 在合适的 NodeManager 上启动 ApplicationMaster ， 此时的 ApplicationMaster 就是 Driver 。</p><p>Driver 启动后 向 ResourceManager 申请 Executor 内存， ResourceManager 接到 ApplicationMaster 的资源申请后会分配 container， 然后在合适的 NodeManager 上启动 Executor 进程， Executor 进程启动后会向 Driver 反向注册， Executor 全部注册完 成后 Driver 开始执行 main 函数，之后执行到 Action 算子时，触发一个 job ，并根据 宽依赖 开始划分 stage ， 每个 stage 生成对应 的 taskSet ， 之后将 task 分发到各个 Executor 上执行。</p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>对扩展开放&amp;对修改关闭</title>
      <link href="2019/10/09/%E5%AF%B9%E6%89%A9%E5%B1%95%E5%BC%80%E6%94%BE&amp;%E4%BF%AE%E6%94%B9%E5%85%B3%E9%97%AD/"/>
      <url>2019/10/09/%E5%AF%B9%E6%89%A9%E5%B1%95%E5%BC%80%E6%94%BE&amp;%E4%BF%AE%E6%94%B9%E5%85%B3%E9%97%AD/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>开闭原则的英文全称是 <code>Open Closed Principle</code>，简写为 OCP。英文描述是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">software entities (modules, classes, functions, etc.) should be open for extension , but closed for modification。</span><br></pre></td></tr></table></figure><p>翻译成中文就是：软件实体（模块、类、方法等）应该 “对扩展开放、对修改关闭”。</p><a id="more"></a><p>添加一个新的功能应该是，在已有代码基础上扩展代码（新增模块、类、方法等），而非修改已有代码（修改模块、类、方法等）。</p><p>这是一段 API 接口监控告警的代码。</p><ol><li><code>AlertRule</code> 存储告警规则，可以自由设置。</li><li><code>Notification</code> 是告警通知类，支持邮件、短信、微信、手机等多种通知渠道。</li><li><code>NotificationEmergencyLevel</code> 表示通知的紧急程度，包括 SEVERE（严重）、URGENCY（紧急）、NORMAL（普通）、TRIVIAL（无关紧要），不同的紧急程度对应不同的发送渠道。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Alert</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> AlertRule rule;</span><br><span class="line">  <span class="keyword">private</span> Notification notification;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Alert</span><span class="params">(AlertRule rule, Notification notification)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.rule = rule;</span><br><span class="line">    <span class="keyword">this</span>.notification = notification;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">check</span><span class="params">(String api, <span class="keyword">long</span> requestCount, <span class="keyword">long</span> errorCount, <span class="keyword">long</span> durationOfSeconds)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> tps = requestCount / durationOfSeconds;</span><br><span class="line">    <span class="keyword">if</span> (tps &gt; rule.getMatchedRule(api).getMaxTps()) &#123;</span><br><span class="line">      notification.notify(NotificationEmergencyLevel.URGENCY, <span class="string">&quot;...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (errorCount &gt; rule.getMatchedRule(api).getMaxErrorCount()) &#123;</span><br><span class="line">      notification.notify(NotificationEmergencyLevel.SEVERE, <span class="string">&quot;...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单一职责原则</title>
      <link href="2019/10/09/%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3%E5%8E%9F%E5%88%99/"/>
      <url>2019/10/09/%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>单一职责原则 <code>Single Responsibility Principle</code>，缩写为 SRP。这个原则的英文描述是这样的</p><p><code>A class or module should have a single responsibility</code> 翻译成中文就是：一个类或者模块只负责完成一个职责（或者功能）。</p><a id="more"></a><p><code>A class or module should have a single responsibility</code> 原则描述的对象包含两个，一个是类（class），一个是模块（module）。有两种理解方式。</p><ol><li>一种理解是: 把模块看作比类更加抽象的概念，类也可以看作模块。</li><li>另一种理解是: 把模块看作比类更加粗粒度的代码块，模块中包含多个类，多个类组成一个模块。</li></ol><p>单一职责原则: 一个类只负责完成一个职责或者功能。也就是说，不要设计大而全的类，要设计粒度小、功能单一的类。换个角度来讲就是，一个类包含了两个或者两个以上业务不相干的功能，就说它职责不够单一，应该将它拆分成多个功能更加单一、粒度更细的类。</p><h1 id="如何判断类的职责是否足够单一？"><a href="#如何判断类的职责是否足够单一？" class="headerlink" title="如何判断类的职责是否足够单一？"></a>如何判断类的职责是否足够单一？</h1><p>在一个社交产品中，我们用下面的 UserInfo 类来记录用户的信息。UserInfo 类的设计是否满足单一职责原则呢？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserInfo</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> userId;</span><br><span class="line">  <span class="keyword">private</span> String username;</span><br><span class="line">  <span class="keyword">private</span> String email;</span><br><span class="line">  <span class="keyword">private</span> String telephone;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> createTime;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> lastLoginTime;</span><br><span class="line">  <span class="keyword">private</span> String avatarUrl;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">private</span> String provinceOfAddress; <span class="comment">// 省</span></span><br><span class="line">  <span class="keyword">private</span> String cityOfAddress; <span class="comment">// 市</span></span><br><span class="line">  <span class="keyword">private</span> String regionOfAddress; <span class="comment">// 区 </span></span><br><span class="line">  <span class="keyword">private</span> String detailedAddress; <span class="comment">// 详细地址</span></span><br><span class="line">  <span class="comment">// ...省略其他属性和方法...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有两种不同的观点。</p><ol><li>一种观点是，UserInfo 类包含的都是跟用户相关的信息，所有的属性和方法都隶属于用户这样一个业务模型，满足单一职责原则；</li><li>另一种观点是，地址信息在 UserInfo 类中，所占的比重比较高，可以继续拆分成独立的 UserAddress 类，UserInfo 只保留除 Address 之外的其他信息，拆分之后的两个类的职责更加单一。</li></ol><p><strong>哪种观点更对呢 ？</strong></p><blockquote><p>实际上，要从中做出选择，不能脱离具体的应用场景。如果在这个社交产品中，用户的地址信息跟其他信息一样，只是单纯地用来展示，那 <code>UserInfo</code> 现在的设计就是合理的。但是，如果这个社交产品发展得比较好，之后又在产品中添加了电商的模块，用户的地址信息还会用在电商物流中，那最好将地址信息从 <code>UserInfo</code> 中拆分出来，独立成用户物流信息（或者叫地址信息、收货信息等）。</p></blockquote><p>再进一步延伸一下。如果做这个社交产品的公司发展得越来越好，公司内部又开发出了很多其他产品。公司希望支持统一账号系统，也就是用户一个账号可以在公司内部的所有产品中登录。这个时候，我们就需要继续对 <code>UserInfo</code> 进行拆分，将跟身份认证相关的信息（比如，email、telephone 等）抽取成独立的类。</p><p>不同的应用场景、不同阶段的需求背景下，对同一个类的职责是否单一的判定，可能都是不一样的。在某种应用场景或者当下的需求背景下，一个类的设计可能已经满足单一职责原则了，但如果换个应用场景或着在未来的某个需求背景下，可能就不满足了，需要继续拆分成粒度更细的类。</p><p>除此之外，从不同的业务层面去看待同一个类的设计，对类是否职责单一，也会有不同的认识。比如，例子中的 <code>UserInfo</code> 类。如果从 “用户” 这个业务层面来看，<code>UserInfo</code> 包含的信息都属于用户，满足职责单一原则。如果我们从更加细分的 “用户展示信息” “地址信息” “登录认证信息” 等等这些更细粒度的业务层面来看，那 <code>UserInfo</code> 就应该继续拆分。</p><h1 id="类的职责是否设计得越单一越好-？"><a href="#类的职责是否设计得越单一越好-？" class="headerlink" title="类的职责是否设计得越单一越好 ？"></a>类的职责是否设计得越单一越好 ？</h1><p>为了满足单一职责原则，是不是把类拆得越细就越好呢？答案是否定的。通过一个例子来解释一下。Serialization 类实现了一个简单协议的序列化和反序列功能，具体代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> * Protocol format: identifier-string;&#123;gson string&#125;</span></span><br><span class="line"><span class="comment"> * For example: UEUEUE;&#123;&quot;a&quot;:&quot;A&quot;,&quot;b&quot;:&quot;B&quot;&#125;</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">   <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Serialization</span> </span>&#123;</span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String IDENTIFIER_STRING = <span class="string">&quot;UEUEUE;&quot;</span>;</span><br><span class="line">     <span class="keyword">private</span> Gson gson;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Serialization</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.gson = <span class="keyword">new</span> Gson();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">serialize</span><span class="params">(Map&lt;String, String&gt; object)</span> </span>&#123;</span><br><span class="line">    StringBuilder textBuilder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    textBuilder.append(IDENTIFIER_STRING);</span><br><span class="line">    textBuilder.append(gson.toJson(object));</span><br><span class="line">    <span class="keyword">return</span> textBuilder.toString();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Map&lt;String, String&gt; <span class="title">deserialize</span><span class="params">(String text)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!text.startsWith(IDENTIFIER_STRING)) &#123;</span><br><span class="line">        <span class="keyword">return</span> Collections.emptyMap();</span><br><span class="line">    &#125;</span><br><span class="line">    String gsonStr = text.substring(IDENTIFIER_STRING.length());</span><br><span class="line">    <span class="keyword">return</span> gson.fromJson(gsonStr, Map.class);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果想让类的职责更加单一，对 <code>Serialization</code> 类进一步拆分，拆分成一个只负责序列化工作的 <code>Serializer</code> 类和另一个只负责反序列化工作的 <code>Deserializer</code> 类。拆分后的具体代码如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Serializer</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String IDENTIFIER_STRING = <span class="string">&quot;UEUEUE;&quot;</span>;</span><br><span class="line">  <span class="keyword">private</span> Gson gson;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Serializer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.gson = <span class="keyword">new</span> Gson();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">serialize</span><span class="params">(Map&lt;String, String&gt; object)</span> </span>&#123;</span><br><span class="line">    StringBuilder textBuilder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    textBuilder.append(IDENTIFIER_STRING);</span><br><span class="line">    textBuilder.append(gson.toJson(object));</span><br><span class="line">    <span class="keyword">return</span> textBuilder.toString();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Deserializer</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String IDENTIFIER_STRING = <span class="string">&quot;UEUEUE;&quot;</span>;</span><br><span class="line">  <span class="keyword">private</span> Gson gson;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">Deserializer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.gson = <span class="keyword">new</span> Gson();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Map&lt;String, String&gt; <span class="title">deserialize</span><span class="params">(String text)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!text.startsWith(IDENTIFIER_STRING)) &#123;</span><br><span class="line">        <span class="keyword">return</span> Collections.emptyMap();</span><br><span class="line">    &#125;</span><br><span class="line">    String gsonStr = text.substring(IDENTIFIER_STRING.length());</span><br><span class="line">    <span class="keyword">return</span> gson.fromJson(gsonStr, Map.class);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然经过拆分之后，<code>Serializer</code> 类和 <code>Deserializer</code> 类的职责更加单一了，但也随之带来了新的问题。如果修改了协议的格式，数据标识从 <code>UEUEUE</code> 改为 <code>DFDFDF</code>，或者序列化方式从 JSON 改为了 XML，那 Serializer 类和 Deserializer 类都需要做相应的修改，代码的内聚性显然没有原来 Serialization 高了。而且，如果仅仅对 Serializer 类做了协议修改，而忘记了修改 Deserializer 类的代码，那就会导致序列化、反序列化不匹配，程序运行出错，也就是说，拆分之后，代码的可维护性变差了。</p><p>不管是应用设计原则还是设计模式，最终的目的还是提高代码的可读性、可扩展性、复用性、可维护性等。在考虑应用某一个设计原则是否合理的时候，也可以以此作为最终的考量标准。</p>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello 设计模式</title>
      <link href="2019/10/08/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>2019/10/08/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。</p><a id="more"></a><h2 id="原则"><a href="#原则" class="headerlink" title="原则"></a>原则</h2><ol><li><p><strong>单一职责原则</strong>（Single Responsibility Principle）</p><p>单一职责原则指的是应该有且仅有一个原因引起类的变更</p><p>分清职责，接口一定要做到单一职责，方法也要做到，类尽量做到</p><p>对于一个类/接口/方式而言之负责一个职责或职能。比如说A类负责两个不同的职责，职责1和职责2，当职责1发生需求变更而修改时，有可能会造成职责2执行错误，这是后需要将A类拆分为A1和A2两个。这样做的有点：1.降低了类的复杂性。2.提高了类的可读性，因为一个类只负责一个职责，看起来比较有目的性。3.提高系统的可维护性，降低了当需求变更时修改程序带来的风险。但是，如果一位的最求单一职责原则，有时候可能会造成类爆炸的问题，所以使用时需要谨慎的看待这一点，不过，接口和方法必须要遵守这一原则。</p></li><li><p><strong>开闭原则</strong></p><p>开闭原则的意思是：<strong>对扩展开放，对修改关闭</strong>。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类</p><p>一个软件实体如类、模块和函数应该对扩展开放，对修改关闭</p></li><li><p><strong>依赖倒转原则</strong>（Dependence Inversion Principle）</p><p>针对接口编程，依赖与抽象而不是具体类</p></li><li><p><strong>里氏代换原则</strong>（Liskov Substitution Principle）</p><p>里氏代换原则是面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。</p></li><li><p><strong>接口隔离原则</strong></p><p>把一个臃肿的接口变更为两个独立的接口所依赖的原则就是接口隔离原则</p></li><li><p><strong>迪米特法则</strong></p><p>一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立</p></li><li><p><strong>合成复用原则</strong></p><p>尽量使用合成/聚合的方式，而不是使用继承</p></li></ol><h2 id="设计模式的类型"><a href="#设计模式的类型" class="headerlink" title="设计模式的类型"></a>设计模式的类型</h2><h3 id="创建型"><a href="#创建型" class="headerlink" title="创建型"></a>创建型</h3><p>创建型模式的主要关注点是”怎样创建对象？”，它的主要特点是“将对象的创建与使用分离”。这样可以降低系统的耦合度，使用者不需要关注对象的创建细节，对象的创建由相关的工厂来完成。</p><ol><li>单例模式</li><li>工厂方法模式（工厂模式）</li><li>抽象工厂模式</li><li>建造者模式（生成器模式）</li><li>原型模式</li></ol><p>以上 5 种创建型模式，除了工厂方法模式属于类创建型模式，其他的全部属于对象创建型模式，</p><h3 id="结构型模式："><a href="#结构型模式：" class="headerlink" title="结构型模式："></a>结构型模式：</h3><ol><li>适配器模式（变压器模式/包装模式）</li><li>桥接模式（桥梁模式）</li><li>组合模式（合成模式/部分-整体模式）</li><li>装饰模式（装饰器模式）</li><li>外观模式（门面模式）</li><li>享元模式</li><li>代理模式（委托模式）</li></ol><h3 id="行为型模式："><a href="#行为型模式：" class="headerlink" title="行为型模式："></a>行为型模式：</h3><ol><li>观察者模式（发布订阅模式）</li><li>模板方法模式</li><li>命令模式</li><li>状态模式</li><li>职责链模式（责任链模式）</li><li>解释器模式</li><li>中介者模式</li><li>访问者模式</li><li>策略模式</li><li>备忘录模式</li><li>迭代器模式</li></ol>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2019/09/04/Hadoop%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E7%BC%96%E8%AF%91/"/>
      <url>2019/09/04/Hadoop%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E7%BC%96%E8%AF%91/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="Hadoop源码环境搭建及编译"><a href="#Hadoop源码环境搭建及编译" class="headerlink" title="Hadoop源码环境搭建及编译"></a>Hadoop源码环境搭建及编译</h1><h2 id="一、课前准备"><a href="#一、课前准备" class="headerlink" title="一、课前准备"></a>一、课前准备</h2><ol><li>下载hadoop2.7.0源代码</li></ol><h2 id="二、课堂主题"><a href="#二、课堂主题" class="headerlink" title="二、课堂主题"></a>二、课堂主题</h2><ol><li>围绕Hadoop源码环境搭建及编译讲解</li></ol><h2 id="三、课堂目标"><a href="#三、课堂目标" class="headerlink" title="三、课堂目标"></a>三、课堂目标</h2><ol><li>搭建Hadoop源码阅读环境</li><li>学会如何编译Hadoop源码</li></ol><h2 id="四、知识要点"><a href="#四、知识要点" class="headerlink" title="四、知识要点"></a>四、知识要点</h2><h3 id="1-搭建windows下Hadoop源码阅读环境"><a href="#1-搭建windows下Hadoop源码阅读环境" class="headerlink" title="1. 搭建windows下Hadoop源码阅读环境"></a>1. 搭建windows下Hadoop源码阅读环境</h3><blockquote><p>以windows下为例（linux下的类似）</p></blockquote><h4 id="1-1-下载对应版本的Hadoop源码包"><a href="#1-1-下载对应版本的Hadoop源码包" class="headerlink" title="1.1 下载对应版本的Hadoop源码包"></a>1.1 下载对应版本的Hadoop源码包</h4><ol><li><p>此处以Hadoop-2.7.0为例</p></li><li><p>进入Hadoop官网 <a href="https://hadoop.apache.org/">https://hadoop.apache.org/</a>  按图操作</p></li></ol><p><img src="assets/Image201907241207.png"></p><ol start="3"><li><p>![](assets/Image201907241207 (2).png)</p></li><li><p>下载Hadoop 2.7.0源代码</p></li></ol><p><img src="assets/Image201907241208.png"></p><h4 id="1-2-源码导入IDEA"><a href="#1-2-源码导入IDEA" class="headerlink" title="1.2 源码导入IDEA"></a>1.2 源码导入IDEA</h4><ol><li>将源代码解压到本地路径</li><li>将源代码导入IDEA中；打开IDEA，并导入源码</li></ol><p><img src="assets/1563941707252.png" alt="1563941707252"></p><ol start="3"><li>选择本地解压后的hadoop源码包；依次按图中步骤操作</li></ol><p><img src="assets/Image201907241216.png"></p><p><img src="assets/Image201907241217.png"></p><p><img src="assets/Image201907241219.png"></p><p><img src="assets/Image201907241221.png"></p><p><img src="assets/Image201907241222.png"></p><p><img src="assets/Image201907241223.png"></p><p><img src="assets/Image201907241224.png"></p><ol start="4"><li>正在resolving dependencies 解决依赖</li></ol><p><img src="assets/Image2019072412241.png"></p><p><img src="assets/Image201907241226.png"></p><ol start="5"><li>源码导入成功</li></ol><p><img src="assets/Image201907241231.png"></p><h3 id="2-编译Hadoop源码"><a href="#2-编译Hadoop源码" class="headerlink" title="2. 编译Hadoop源码"></a>2. 编译Hadoop源码</h3><blockquote><p>编译源码最好是在linux平台，此处用CentOS 7.4平台编译源码</p><p>使用<strong>root用户</strong>编译</p><p>所有软件压缩包，放到**/opt/apps**目录</p></blockquote><h4 id="2-1-查看编译说明文件"><a href="#2-1-查看编译说明文件" class="headerlink" title="2.1 查看编译说明文件"></a>2.1 查看编译说明文件</h4><p>将hadoop-2.7.0-src.tar.gz源码包放到/opt目录下</p><p>将源码包解压到/opt目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 opt]# cd /opt/</span><br><span class="line">[root@node-01 opt]# tar -xzvf hadoop-2.7.0-src.tar.gz</span><br></pre></td></tr></table></figure><p>进入解压出来的目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 opt]# cd hadoop-2.7.0-src/</span><br><span class="line">[root@node-01 hadoop-2.7.0-src]# ls</span><br></pre></td></tr></table></figure><p><img src="assets/Image201907241342.png"></p><p>BUILDING.txt文件是编译hadoop源码的说明文件；打开文件，列出了编译hadoop源码时，要求软件及对应版本要求</p><p><img src="assets/Image201907241346.png"></p><p>要求在Unix系统下编译</p><h4 id="2-2-安装JDK"><a href="#2-2-安装JDK" class="headerlink" title="2.2 安装JDK"></a>2.2 安装JDK</h4><p>要求版本：JDK1.7+</p><p>确定JDK是否已经安装，要求JDK1.7或以上版本</p><p><strong>若已经安装非系统自带的openjdk且是版本符合要求，则略过步骤“安装JDK”</strong>；运行下边命令进行确认</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 jdk1.8.0_201]# java -version</span><br><span class="line">java version &quot;1.8.0_201&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_201-b09)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)</span><br></pre></td></tr></table></figure><p>（使用root用户）卸载系统自带的openjdk</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 ~]# rpm -qa |grep java</span><br><span class="line">python-javapackages-3.4.1-11.el7.noarch</span><br><span class="line">java-1.8.0-openjdk-headless-1.8.0.161-2.b14.el7.x86_64</span><br><span class="line">tzdata-java-2018c-1.el7.noarch</span><br><span class="line">java-1.7.0-openjdk-1.7.0.171-2.6.13.2.el7.x86_64</span><br><span class="line">java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64</span><br><span class="line">javapackages-tools-3.4.1-11.el7.noarch</span><br><span class="line">java-1.7.0-openjdk-headless-1.7.0.171-2.6.13.2.el7.x86_64</span><br></pre></td></tr></table></figure><p>忽略依赖卸载查询到的openjdk相关包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rpm -e --nodeps python-javapackages-3.4.1-11.el7.noarch</span><br><span class="line">rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.161-2.b14.el7.x86_64</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>上传自己的jdk解压，并配置环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf /opt/apps/jdk-8u201-linux-x64.tar.gz -C /opt/</span><br></pre></td></tr></table></figure><p>打开<code>/etc/profile</code>文件添加以下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/jdk1.8.0_201</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br></pre></td></tr></table></figure><p>检测是否安装成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 jdk1.8.0_201]# source /etc/profile</span><br><span class="line">[root@node-01 jdk1.8.0_201]# java -version</span><br><span class="line">java version &quot;1.8.0_201&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_201-b09)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)</span><br></pre></td></tr></table></figure><h4 id="2-3-安装依赖包"><a href="#2-3-安装依赖包" class="headerlink" title="2.3 安装依赖包"></a>2.3 安装依赖包</h4><p>根据编译说明文件BUILDING.txt，安装相关依赖程序包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 jdk1.8.0_201]# yum -y install gcc-c++ build-essential autoconf automake libtool cmake zlib1g-dev pkg-config libssl-devua svn openssl-devel ncurses-devel</span><br></pre></td></tr></table></figure><p>说明：</p><p>gcc-c++ -&gt; liunx环境中的c/c++编译器</p><p>build-essential -&gt; linux操作系统上面开发程序，光有了gcc是不行的；它还需要一个build-essential软件包；作用是提供编译程序必须软件包的列表信息</p><p><img src="assets/Image201907241443.png"></p><p>如果运行过程中，出现一下类似情况，说明需要更换yum源（如何更换，自行百度）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.neusoft.edu.cn</span><br><span class="line"> * extras: mirrors.tuna.tsinghua.edu.cn</span><br><span class="line"> * updates: mirrors.neusoft.edu.cn</span><br><span class="line">base                                                                     | 3.6 kB  00:00:00     </span><br><span class="line">extras                                                                   | 3.4 kB  00:00:00     </span><br><span class="line">updates                                                                  | 3.4 kB  00:00:00     </span><br><span class="line">updates/7/x86_64/primary_db                                              | 6.5 MB  00:00:01     </span><br><span class="line">No package build-essential available.</span><br><span class="line">No package zlib1g-dev available.</span><br><span class="line">No package pkg-config available.</span><br><span class="line">No package libssl-devua available.</span><br><span class="line">Resolving Dependencies</span><br><span class="line"><span class="meta">--&gt;</span><span class="bash"> Running transaction check</span></span><br></pre></td></tr></table></figure><p>或参考下边四种情况的解决方案</p><p><img src="assets/Image201907281128.png"></p><p>情况一：No package build-essential available.解决方案</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum groupinstall &#x27;Development Tools&#x27;</span><br></pre></td></tr></table></figure><p>情况二：No package zlib1g-dev available.解决方案</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install zlib</span><br><span class="line">yum install zlib-devel</span><br></pre></td></tr></table></figure><p>情况三：No package pkg-config available.解决方案</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install pkgconfig</span><br></pre></td></tr></table></figure><p>情况四：No package libssl-devua available.解决方案</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install openssl</span><br><span class="line">yum install openssl-devel</span><br></pre></td></tr></table></figure><h4 id="2-4-安装Maven"><a href="#2-4-安装Maven" class="headerlink" title="2.4 安装Maven"></a>2.4 安装Maven</h4><p>版本要求：Maven 3.0或以后版本均可</p><blockquote><p><font color='red'>坑</font>：由于apache-maven-3.5.0及以后的版本，在编译hadoop-2.7.0源码时，容易出错；本文档使用<font color='red'><strong>apache-maven-3.5.0</strong></font></p></blockquote><p><img src="assets/Image201907280230.png"></p><p>先确认一下，是否已经安装了符合要求的maven；</p><p>若已安装<font color='red'><strong>apache-maven-3.5.0</strong></font>，则<strong>略过“安装maven”步骤</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 opt]# mvn -v</span><br></pre></td></tr></table></figure><p><img src="assets/Image201907281207.png"></p><p>否则安装<font color='red'><strong>apache-maven-3.5.0</strong></font></p><p>安装软件：apache-maven-3.5.0-bin.tar.gz</p><p>解压maven压缩包到/opt目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 apps]# ls</span><br><span class="line">apache-maven-3.5.0-bin.tar.gz</span><br><span class="line">[root@node-01 apps]# tar -xzvf apache-maven-3.5.0-bin.tar.gz -C /opt/</span><br></pre></td></tr></table></figure><p>配置mvn的环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 ~]# vim /etc/profile</span><br></pre></td></tr></table></figure><p>添加如下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export M2_HOME=/opt/apache-maven-3.5.0</span><br><span class="line">export PATH=$PATH:$M2_HOME/bin</span><br></pre></td></tr></table></figure><p>测试是否安装完成</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 ~]# source .bash_profile</span><br><span class="line">[root@node-01 ~]# mvn -v</span><br></pre></td></tr></table></figure><p><img src="assets/Image201907281207.png"></p><p>默认使用中央仓库下载即可</p><h4 id="2-5-安装Findbugs"><a href="#2-5-安装Findbugs" class="headerlink" title="2.5 安装Findbugs"></a>2.5 安装Findbugs</h4><p>版本要求：Findbugs 1.3.9</p><p>安装软件：findbugs-3.0.1.tar.gz</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 apps]# ls</span><br><span class="line">findbugs-3.0.1.tar</span><br><span class="line">[root@node-01 apps]# tar -xvf findbugs-3.0.1.tar.gz -C /opt</span><br></pre></td></tr></table></figure><p>配置Findbugs环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 apps]# vim &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure><p>添加如下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export FINDBUGS_HOME=/opt/findbugs-3.0.1</span><br><span class="line">export PATH=$PATH:$FINDBUGS_HOME/bin</span><br></pre></td></tr></table></figure><p>测试是否安装完成</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 apps]# source /etc/profile</span><br><span class="line">[root@node-01 apps]# findbugs -version</span><br><span class="line">3.0.1</span><br></pre></td></tr></table></figure><h4 id="2-6-安装ProtocolBuffer"><a href="#2-6-安装ProtocolBuffer" class="headerlink" title="2.6 安装ProtocolBuffer"></a>2.6 安装ProtocolBuffer</h4><p>版本要求：ProtocolBuffer 2.5.0</p><p>安装软件：protobuf-2.5.0.tar，不建议用其它版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 apps]# ls</span><br><span class="line">protobuf-2.5.0.tar</span><br><span class="line">[root@node-01 apps]# tar -xvf protobuf-2.5.0.tar</span><br><span class="line">[root@node-01 apps]# mv protobuf-2.5.0 ../</span><br><span class="line">[root@node-01 apps]# cd /opt/protobuf-2.5.0/</span><br><span class="line">[root@node-01 protobuf-2.5.0]# ./configure </span><br><span class="line">[root@node-01 protobuf-2.5.0]# make -j 4  # 干货，-j以4核同时编译；根据实际情况修改</span><br><span class="line">[root@node-01 protobuf-2.5.0]# make install</span><br></pre></td></tr></table></figure><p>测试是否安装完成</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 protobuf-2.5.0]# protoc --version</span><br><span class="line">libprotoc 2.5.0</span><br></pre></td></tr></table></figure><h4 id="2-7-安装Snappy"><a href="#2-7-安装Snappy" class="headerlink" title="2.7 安装Snappy"></a>2.7 安装Snappy</h4><p>若想让hadoop支持snappy压缩，得先安装snappy；</p><p><strong>若不需要，跳过此步骤</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 apps]# ls</span><br><span class="line">snappy-1.1.3.tar.gz</span><br></pre></td></tr></table></figure><p>解压</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 opt]# tar -xzvf snappy-1.1.3.tar.gz -C /opt/</span><br></pre></td></tr></table></figure><p>安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 opt]# cd /opt/snappy-1.1.3/</span><br><span class="line">[root@node-01 snappy-1.1.3]# ./configure</span><br><span class="line">[root@node-01 snappy-1.1.3]# make -j 4</span><br><span class="line">[root@node-01 snappy-1.1.3]# make install</span><br></pre></td></tr></table></figure><p>查看snappy文件库</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 snappy-1.1.3]# ls -lh /usr/local/lib | grep snappy</span><br><span class="line">-rw-r--r--. 1 root root 510K 4月  12 14:14 libsnappy.a</span><br><span class="line">-rwxr-xr-x. 1 root root  955 4月  12 14:14 libsnappy.la</span><br><span class="line">lrwxrwxrwx. 1 root root   18 4月  12 14:14 libsnappy.so -&gt; libsnappy.so.1.3.0</span><br><span class="line">lrwxrwxrwx. 1 root root   18 4月  12 14:14 libsnappy.so.1 -&gt; libsnappy.so.1.3.0</span><br><span class="line">-rwxr-xr-x. 1 root root 253K 4月  12 14:14 libsnappy.so.1.3.0</span><br><span class="line">[root@node-01 snappy-1.1.3]# </span><br></pre></td></tr></table></figure><p><img src="assets/Image201907241650.png"></p><h4 id="2-8-安装Jansson"><a href="#2-8-安装Jansson" class="headerlink" title="2.8 安装Jansson"></a>2.8 安装Jansson</h4><p>首先确保已经安装wget，若没有，先安装（自行百度）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 snappy-1.1.3]# cd /opt/apps/</span><br><span class="line">[root@node-01 opt]# wget http://www.digip.org/jansson/releases/jansson-2.5.tar.gz</span><br><span class="line">[root@node-01 opt]# tar -zxvf jansson-2.5.tar.gz -C /opt</span><br><span class="line">[root@node-01 opt]# cd /opt/jansson-2.5</span><br><span class="line">[root@node-01 jansson-2.5]# ./configure  &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h4 id="2-9-编译hadoop"><a href="#2-9-编译hadoop" class="headerlink" title="2.9 编译hadoop"></a>2.9 编译hadoop</h4><p>防止编译时java.lang.OutOfMemoryError:Java heap space堆栈内存溢出问题，可以适当调整一下编译用的内存大小</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 opt]# export MAVEN_OPTS=&quot;-Xms256m -Xmx2048m&quot;</span><br></pre></td></tr></table></figure><p>进入源码包下，执行命令进行编译</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node-01 fuse-2.8.4]# cd</span><br><span class="line">[root@node-01 ~]# cd /opt/</span><br><span class="line">[root@node-01 opt]# cd hadoop-2.7.0-src/</span><br><span class="line">[root@node-01 hadoop-2.7.0-src]# mvn package -Pdist,native,docs -DskipTests -Dtar</span><br></pre></td></tr></table></figure><p><img src="assets/Image201907241711.png"></p><p>如果中途编译失败，并且不要文档、hadoop支持snappy、支持openssl的话，请使用这个命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost hadoop-2.7.7-src]# mvn clean package -Pdist,native -DskipTests -Dtar -Drequire.snappy -Dsnappy.lib=/usr/local/lib -Dbundle.snappy -Drequire.openssl</span><br></pre></td></tr></table></figure><p>说明：</p><p>支持snappy（若不需要支持snappy，把这些选项去除即可）：Drequire.snappy -Dsnappy.lib=/usr/local/lib -Dbundle.snappy</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis 适合做消息队列吗？</title>
      <link href="2019/08/25/Redis%20%E9%80%82%E5%90%88%E5%81%9A%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%90%97%EF%BC%9F/"/>
      <url>2019/08/25/Redis%20%E9%80%82%E5%90%88%E5%81%9A%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%90%97%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>消息队列要能支持组件通信消息的快速读写，而 Redis 本身支持数据的高速访问，正好可以满足消息队列的读写性能需求。不过，除了性能，消息队列还有其他的要求: “Redis 适合做消息队列吗？”</p><a id="more"></a><h2 id="1-消息队列的消息存取需求"><a href="#1-消息队列的消息存取需求" class="headerlink" title="1. 消息队列的消息存取需求"></a>1. 消息队列的消息存取需求</h2><p>在分布式系统中，当两个组件要基于消息队列进行通信时，一个组件会把要处理的数据以消息的形式传递给消息队列，然后，这个组件就可以继续执行其他操作了；远端的另一个组件从消息队列中把消息读取出来，再在本地进行处理。</p><p>消息队列在存取消息时，必须要满足三个需求，分别是消息保序、处理重复的消息和保证消息可靠性。</p><h3 id="1-1-消息保序"><a href="#1-1-消息保序" class="headerlink" title="1.1. 消息保序"></a>1.1. 消息保序</h3><p>虽然消费者是异步处理消息，但是，消费者仍然需要按照生产者发送消息的顺序来处理消息，避免后发送的消息被先处理了。对于要求消息保序的场景来说，一旦出现这种消息被乱序处理的情况，就可能会导致业务逻辑被错误执行，从而给业务方造成损失。</p><h3 id="1-2-重复消息处理"><a href="#1-2-重复消息处理" class="headerlink" title="1.2. 重复消息处理"></a>1.2. 重复消息处理</h3><p>消费者从消息队列读取消息时，有时会因为网络堵塞而出现消息重传的情况。此时，消费者可能会收到多条重复的消息。对于重复的消息，消费者如果多次处理的话，就可能造成一个业务逻辑被多次执行，如果业务逻辑正好是要修改数据，那就会出现数据被多次修改的问题了。 </p><h3 id="1-3-消息可靠性保证"><a href="#1-3-消息可靠性保证" class="headerlink" title="1.3. 消息可靠性保证"></a>1.3. 消息可靠性保证</h3><p>消费者在处理消息的时候，还可能出现因为故障或宕机导致消息没有处理完成的情况。此时，消息队列需要能提供消息可靠性的保证，也就是说，当消费者重启后，可以重新读取消息再次进行处理，否则，就会出现消息漏处理的问题了。</p><h2 id="2-基于-List-的消息队列解决方案"><a href="#2-基于-List-的消息队列解决方案" class="headerlink" title="2. 基于 List 的消息队列解决方案"></a>2. 基于 List 的消息队列解决方案</h2><h3 id="2-1-消息保序"><a href="#2-1-消息保序" class="headerlink" title="2.1. 消息保序"></a>2.1. 消息保序</h3><p>List 本身就是按先进先出的顺序对数据进行存取的，使用 List 作为消息队列保存消息,能满足消息保序的需求了。生产者可以使用 LPUSH 命令把要发送的消息依次写入 List，而消费者则可以使用 RPOP 命令，从 List 的另一端按照消息的写入顺序，依次读取消息并进行处理。</p><p>在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 RPOP 命令(比如使用一个 while(1) 循环)。如果有新消息写入，RPOP 命令就会返回结果，否则，RPOP 命令返回空值，再继续循环。</p><p>Redis 提供了 BRPOP 命令。BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。和消费者程序自己不停地调用 RPOP 命令相比，这种方式能节省 CPU 开销。</p><h3 id="2-2-重复消息"><a href="#2-2-重复消息" class="headerlink" title="2.2. 重复消息"></a>2.2. 重复消息</h3><p>消费者程序本身能对重复消息进行判断。一方面，消息队列要能给每一个消息提供全局唯一的 ID 号；另一方面，消费者程序要把已经处理过的消息的 ID 号记录下来。</p><p>List 本身是不会为每个消息生成 ID 号的，所以，消息的全局唯一 ID 号就需要生产者程序在发送消息前自行生成。生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。</p><h3 id="2-3-消息可靠性"><a href="#2-3-消息可靠性" class="headerlink" title="2.3. 消息可靠性"></a>2.3. 消息可靠性</h3><p>当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。为了留存消息，List 类型提供了 <strong><font color='blue'><code>BRPOPLPUSH</code></font></strong> 命令，这个命令的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List(可以叫作备份 List)留存。这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。</p><h3 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4. 总结"></a>2.4. 总结</h3><p>基于 List 类型，可以满足分布式组件对消息队列的三大需求。但是在用 List 做消息队列时，还可能遇到过一个问题：生产者消息发送很快，而消费者处理消息的速度比较慢，这就导致 List 中的消息越积越多，给 Redis 的内存带来很大压力。</p><p>启动多个消费者程序组成一个消费组，一起分担处理 List 中的消息。但是，List 类型并不支持消费组的实现。</p><h2 id="3-基于-Streams-的消息队列解决方案"><a href="#3-基于-Streams-的消息队列解决方案" class="headerlink" title="3. 基于 Streams 的消息队列解决方案"></a>3. 基于 Streams 的消息队列解决方案</h2><p>Streams 是 Redis 专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令。</p><ol><li>XADD: 插入消息，保证有序，可以自动生成全局唯一 ID</li><li>XREAD: 用于读取消息，可以按 ID 读取数据</li><li>XREADGROUP: 按消费组形式读取消息</li><li>XPENDING 和 XACK: XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。</li></ol><h3 id="3-1-XADD"><a href="#3-1-XADD" class="headerlink" title="3.1. XADD"></a>3.1. XADD</h3><p>XADD 命令可以往消息队列中插入新消息，消息的格式是键 - 值对形式。对于插入的每一条消息，Streams 可以自动为其生成一个全局唯一的 ID。</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; xadd mystream * repo 5</span><br><span class="line"><span class="string">&quot;1615186814860-0&quot;</span></span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>向名称为 mqstream 的消息队列中插入一条消息，消息的键是 repo，值是 5。其中，消息队列名称后面的 <code>*</code>，表示让 Redis 为插入的数据自动生成一个全局唯一的 ID，例如”1615186814860-0”。也可以不用 <code>*</code>，直接在消息队列名称后自行设定一个 ID 号，只要保证这个 ID 号是全局唯一的就行。相比自行设定 ID 号，使用 <code>*</code> 会更加方便高效。</p><p>消息的全局唯一 ID 由两部分组成，第一部分 “1615186814860” 是数据插入时，以毫秒为单位计算的当前服务器时间，第二部分表示插入消息在当前毫秒内的消息序号，这是从 0 开始编号的。例如，”1615186814860-0” 就表示在”1615186814860” 毫秒内的第 1 条消息。</p><h3 id="3-2-XREAD"><a href="#3-2-XREAD" class="headerlink" title="3.2. XREAD"></a>3.2. XREAD</h3><p>XREAD 在读取消息时，可以指定一个消息 ID，并从这个消息 ID 的下一条消息开始进行读取。</p><p>消费者也可以在调用 XRAED 时设定 block 配置项，实现类似于 BRPOP 的阻塞读取操作。当消息队列中没有消息时，一旦设置了 block 配置项，XREAD 就会阻塞，阻塞的时长可以在 block 配置项进行设置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; xread block 100 streams mystream 1615186814860-0</span><br><span class="line">1) 1) <span class="string">&quot;mystream&quot;</span></span><br><span class="line">   2) 1) 1) <span class="string">&quot;1615187159424-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo2&quot;</span></span><br><span class="line">            2) <span class="string">&quot;6&quot;</span></span><br><span class="line">      2) 1) <span class="string">&quot;1615187163700-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo3&quot;</span></span><br><span class="line">            2) <span class="string">&quot;7&quot;</span></span><br><span class="line">      3) 1) <span class="string">&quot;1615187168584-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo4&quot;</span></span><br><span class="line">            2) <span class="string">&quot;8&quot;</span></span><br><span class="line">      4) 1) <span class="string">&quot;1615187172451-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo5&quot;</span></span><br><span class="line">            2) <span class="string">&quot;9&quot;</span></span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>消费者也可以在调用 XRAED 时在命令最后设定”$”, “$” 符号表示读取最新的消息，同时，设置 block 10000 的配置项，10000 的单位是毫秒，表明 XREAD 在读取最新消息时，如果没有消息到来，XREAD 将阻塞 10000 毫秒（即 10 秒），然后再返回。下面命令中的 XREAD 执行后，消息队列 mqstream 中一直没有消息，所以，XREAD 在 10 秒后返回空值（nil）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; xread block 100 streams mystream $</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure><h3 id="3-3-XREADGROUP"><a href="#3-3-XREADGROUP" class="headerlink" title="3.3. XREADGROUP"></a>3.3. XREADGROUP</h3><p>Streams 本身可以使用 XGROUP 创建消费组，创建消费组之后，Streams 可以使用 XREADGROUP 命令让消费组内的消费者读取消息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; xgroup create mystream mygroup_0 0</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>让 mygroup_0 消费组里的消费者 consumer0 从 mqstream 中读取所有消息，其中，命令最后的参数 “&gt;”，表示从第一条尚未被消费的消息开始读取。因为在 consumer0 读取消息前，group1 中没有其他消费者读取过消息，所以，consumer1 就得到 mqstream 消息队列中的所有消息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; xreadgroup group mygroup_0 consumer0 streams mystream &gt;</span><br><span class="line">1) 1) <span class="string">&quot;mystream&quot;</span></span><br><span class="line">   2) 1) 1) <span class="string">&quot;1615186814860-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo&quot;</span></span><br><span class="line">            2) <span class="string">&quot;5&quot;</span></span><br><span class="line">      2) 1) <span class="string">&quot;1615187159424-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo2&quot;</span></span><br><span class="line">            2) <span class="string">&quot;6&quot;</span></span><br><span class="line">      3) 1) <span class="string">&quot;1615187163700-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo3&quot;</span></span><br><span class="line">            2) <span class="string">&quot;7&quot;</span></span><br><span class="line">      4) 1) <span class="string">&quot;1615187168584-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo4&quot;</span></span><br><span class="line">            2) <span class="string">&quot;8&quot;</span></span><br><span class="line">      5) 1) <span class="string">&quot;1615187172451-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo5&quot;</span></span><br><span class="line">            2) <span class="string">&quot;9&quot;</span></span><br><span class="line">      6) 1) <span class="string">&quot;1615187382806-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo5&quot;</span></span><br><span class="line">            2) <span class="string">&quot;10&quot;</span></span><br></pre></td></tr></table></figure><p>消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了。比如说，我们执行完刚才的 XREADGROUP 命令后，再执行下面的命令，让 mygroup_0 内的 consumer1 读取消息时，consumer1 读到的就是空值，因为消息已经被 consumer0 读取完了，如下所示：</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">XREADGROUP group group1 consumer2  streams mqstream 0</span><br><span class="line">1) 1) <span class="string">&quot;mqstream&quot;</span></span><br><span class="line">   2) (empty list or <span class="built_in">set</span>)</span><br></pre></td></tr></table></figure><p>使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的。例如，我们执行下列命令，让 group2 中的 consumer1、2、3 各自读取一条消息。</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">XREADGROUP group group2 consumer1 count 1 streams mqstream &gt;</span><br><span class="line">1) 1) <span class="string">&quot;mqstream&quot;</span></span><br><span class="line">   2) 1) 1) <span class="string">&quot;1599203861727-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo&quot;</span></span><br><span class="line">            2) <span class="string">&quot;5&quot;</span></span><br><span class="line"></span><br><span class="line">XREADGROUP group group2 consumer2 count 1 streams mqstream &gt;</span><br><span class="line">1) 1) <span class="string">&quot;mqstream&quot;</span></span><br><span class="line">   2) 1) 1) <span class="string">&quot;1599274912765-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo&quot;</span></span><br><span class="line">            2) <span class="string">&quot;3&quot;</span></span><br><span class="line"></span><br><span class="line">XREADGROUP group group2 consumer3 count 1 streams mqstream &gt;</span><br><span class="line">1) 1) <span class="string">&quot;mqstream&quot;</span></span><br><span class="line">   2) 1) 1) <span class="string">&quot;1599274925823-0&quot;</span></span><br><span class="line">         2) 1) <span class="string">&quot;repo&quot;</span></span><br><span class="line">            2) <span class="string">&quot;2&quot;</span></span><br></pre></td></tr></table></figure><p>为了保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息，Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。</p><p>查看一下 group2 中各个消费者已读取、但尚未确认的消息个数。其中，XPENDING 返回结果的第二、三行分别表示 group2 中所有消费者读取的消息最小 ID 和最大 ID。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">XPENDING mqstream group2</span><br><span class="line">1) (<span class="built_in">integer</span>) 3</span><br><span class="line">2) <span class="string">&quot;1599203861727-0&quot;</span></span><br><span class="line">3) <span class="string">&quot;1599274925823-0&quot;</span></span><br><span class="line">4) 1) 1) <span class="string">&quot;consumer1&quot;</span></span><br><span class="line">      2) <span class="string">&quot;1&quot;</span></span><br><span class="line">   2) 1) <span class="string">&quot;consumer2&quot;</span></span><br><span class="line">      2) <span class="string">&quot;1&quot;</span></span><br><span class="line">   3) 1) <span class="string">&quot;consumer3&quot;</span></span><br><span class="line">      2) <span class="string">&quot;1&quot;</span></span><br></pre></td></tr></table></figure><p>查看某个消费者具体读取了哪些数据</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">XPENDING mqstream group2 - + 10 consumer2</span><br><span class="line">1) 1) <span class="string">&quot;1599274912765-0&quot;</span></span><br><span class="line">   2) <span class="string">&quot;consumer2&quot;</span></span><br><span class="line">   3) (<span class="built_in">integer</span>) 513336</span><br><span class="line">   4) (<span class="built_in">integer</span>) 1</span><br></pre></td></tr></table></figure><p>一旦消息 1599274912765-0 被 consumer2 处理了，consumer2 就可以使用 XACK 命令通知 Streams，然后这条消息就会被删除。当我们再使用 XPENDING 命令查看时，就可以看到，consumer2 已经没有已读取、但尚未确认处理的消息了。 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> XACK mqstream group2 1599274912765-0</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">XPENDING mqstream group2 - + 10 consumer2</span><br><span class="line">(empty list or <span class="built_in">set</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 主从复制</title>
      <link href="2019/08/25/Redis-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
      <url>2019/08/25/Redis-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>和 MySQL 主从复制的原因一样，Redis 虽然读取写入的速度都特别快，但是也会产生读压力特别大的情况。为了分担读压力，Redis 支持主从复制，Redis 的主从结构可以采用一主多从或者级联结构，Redis 主从复制可以根据是否是全量分为全量同步和增量同步。</p><a id="more"></a><h1 id="1-主从复制概述"><a href="#1-主从复制概述" class="headerlink" title="1. 主从复制概述"></a>1. 主从复制概述</h1>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 性能优化_碎片整理</title>
      <link href="2019/08/17/MySQL%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96_%E7%A2%8E%E7%89%87%E6%95%B4%E7%90%86/"/>
      <url>2019/08/17/MySQL%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96_%E7%A2%8E%E7%89%87%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>MySQL 碎片就是 MySQL 数据文件中一些不连续的空白空间，这些空间无法再被全部利用，久而久之越来多，越来越零碎，从而造成物理存储和逻辑存储的位置顺序不一致。</p><a id="more"></a><h2 id="碎片是如何产生的"><a href="#碎片是如何产生的" class="headerlink" title="碎片是如何产生的?"></a>碎片是如何产生的?</h2><p>InnoDB 表的数据存储在页(page)中，每个页可以存放多条记录。这些记录以树形结构组织，这颗树称为B+树索引。表中数据和辅助索引都是使用B+树结构。维护表中所有数据的这颗 B+ 树索引称为聚簇索引，通过主键来组织的。聚簇索引的叶子节点包含行中所有字段的值，辅助索引的叶子节点包含索引列和主键列。</p><h4 id="delete-操作"><a href="#delete-操作" class="headerlink" title="delete 操作"></a><strong>delete 操作</strong></h4><p>在 InnoDB 中，删除一些行，这些行只是被标记为“已删除”，而不是真的从索引中物理删除了，因而空间也没有真的被释放回收。InnoDB 的 Purge 线程会异步的来清理这些没用的索引键和行。但是依然没有把这些释放出来的空间还给操作系统重新使用，因而会导致页面中存在很多空洞。如果表结构中包含动态长度字段，那么这些空洞甚至可能不能被 InnoDB 重新用来存新的行，因为空间空间长度不足</p><p>删除数据就会导致页(page)中出现空白空间，大量随机的 DELETE 操作，必然会在数据文件中造成不连续的空白空间。而当插入数据时,这些空白空间则会被利用起来.于是造成了数据的存储位置不连续。物理存储顺序与逻辑上的排序顺序不同,这种就是数据碎片。</p><p>在 MySQL 中删除数据，在存储中就会产生空白的空间，当有新数据插入时，MySQL 会试着在这些空白空间中保存新数据，但是无法用满这些空白空间。所以日积月累，亦或是一下有大量的 delete 操作，一下就会有大量的空白空间，慢慢的会大到比表的数据使用的空间还大。</p><h4 id="update-操作"><a href="#update-操作" class="headerlink" title="update 操作"></a><strong>update 操作</strong></h4><p>在 MySQL 中更新数据，在可变长度的字段(比如 varchar)中更新数据，innodb 表存储数据的单位是页，update 操作会造成页分裂，分裂以后存储变的不连续，不规则，从而产生碎片。</p><blockquote><p>比如说原始字段长度 varchar(100)，大量的更新数据长度位为 50，这样的话，有 50 的空间被空白了，新入库的数据不能完全利用剩余的 50，这就会产生碎片。</p></blockquote><h2 id="碎片到底产生了什么影响"><a href="#碎片到底产生了什么影响" class="headerlink" title="碎片到底产生了什么影响?"></a>碎片到底产生了什么影响?</h2><p>MySQL 既然产生了碎片，你可能比较豪横说磁盘空间够大，浪费空间也没事，但是这些碎片也会产生性能问题，碎片会有什么影响呢？</p><p><strong>空间浪费</strong></p><p>碎片占用了大量可用空间</p><p><strong>读写性能下降</strong></p><p>由于存在大量碎片，数据从连续规则的存储方式变为随机分散的存储方式，磁盘 IO 会变的繁忙，数据库读写性能就会下降。</p><h2 id="寻找碎片"><a href="#寻找碎片" class="headerlink" title="寻找碎片"></a>寻找碎片</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show table status like &#39;%satcat%&#39;\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">           Name: satcat</span><br><span class="line">         Engine: InnoDB</span><br><span class="line">        Version: 10</span><br><span class="line">     Row_format: Dynamic</span><br><span class="line">           Rows: 42353</span><br><span class="line"> Avg_row_length: 111</span><br><span class="line">    Data_length: 4734976</span><br><span class="line">Max_data_length: 0</span><br><span class="line">   Index_length: 442368</span><br><span class="line">      Data_free: 4194304</span><br><span class="line"> Auto_increment: NULL</span><br><span class="line">    Create_time: 2020-08-07 11:24:38</span><br><span class="line">    Update_time: NULL</span><br><span class="line">     Check_time: NULL</span><br><span class="line">      Collation: utf8_general_ci</span><br><span class="line">       Checksum: NULL</span><br><span class="line"> Create_options:</span><br><span class="line">        Comment:</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p><code>datalength</code> 表数据大小 <code>index length</code> 表索引大小<br><code>data_free</code> 碎片大小</p><p>根据返回信息，我们知道碎片大小为 4194304（单位 B）</p><h2 id="如何清理碎片"><a href="#如何清理碎片" class="headerlink" title="如何清理碎片?"></a>如何清理碎片?</h2><h3 id="1-分析表"><a href="#1-分析表" class="headerlink" title="1. 分析表"></a><strong>1. 分析表</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimize table table_name;</span><br></pre></td></tr></table></figure><p>这个方法主要针对 MyISAM 引擎表使用，因为 MyISAM 表的数据和索引是分离的，optimize 表可以整理数据文件，重新排列索引。</p><p>注意：optimize 会锁表，时间长短依据表数据量的大小。</p><h3 id="2-重建表引擎"><a href="#2-重建表引擎" class="headerlink" title="2. 重建表引擎"></a><strong>2. 重建表引擎</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table table_name engine &#x3D; innodb;</span><br></pre></td></tr></table></figure><p>这个方法主要针对 InnoDB 引擎表使用，该操作会重建表的存储引擎，重组数据和索引的存储。</p><p>刚才我们查到表 <code>satcat</code> 有 4M 的碎片，我们清理一下 <code>satcat</code> 表碎片</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; alter table satcat engine &#x3D; innodb;</span><br></pre></td></tr></table></figure><p>查询一下该表的碎片是否被清理：</p><p>清理表的碎片可以提高 MySQL 性能，在日常工作中我们可以定期执行表碎片整理，从而提高 MySQL 性能。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 存储引擎</title>
      <link href="2019/08/17/MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E2/"/>
      <url>2019/08/17/MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop 数据压缩机制</title>
      <link href="2019/08/09/Hadoop%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/"/>
      <url>2019/08/09/Hadoop%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>压缩技术能够有效减少底层存储系统 [HDFS] 读写字节数。压缩提高了网络带宽和磁盘空间的效率。在 Hadoop 下，尤其是数据规模很大和工作负载密集的情况下，使用数据压缩显得非常重要。在这种情况下， I/O 操作和网络数据传输要花大量的时间。还有， Shuffle与 Merge 过程同样也面临着巨大的 I/O 压力。</p><a id="more"></a><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><blockquote><p>压缩技术能够有效减少底层存储系统 [HDFS] 读写字节数。压缩提高了网络带宽和磁盘空间的效率。在 Hadoop 下，尤其是数据规模很大和工作负载密集的情况下，使用数据压缩显得非常重要。在这种情况下， I/O 操作和网络数据传输要花大量的时间。还有， Shuffle与 Merge 过程同样也面临着巨大的 I/O 压力。</p><p>鉴于磁盘 I/O 和网络带宽是 Hadoop 的宝贵资源，数据压缩对于节省资源、最小化磁盘I/O 和网络传输非常有帮助。不过， 尽管压缩与解压操作的 CPU 开销不高，其性能的提升和资源的节省并非没有代价。</p><p>如果磁盘 I/O 和网络带宽影响了 MapReduce 作业性能，在任意 MapReduce 阶段启用压缩都可以改善端到端处理时间并减少 I/O 和网络流量。</p><p>压缩 Mapreduce 的一种优化策略：通过压缩编码对 Mapper 或者 Reducer 的输出进行压缩，以减少磁盘 IO， 提高 MR 程序运行速度（但相应增加了 cpu 运算负担） 。</p><p>注意： 压缩特性运用得当能提高性能，但运用不当也可能降低性能。<br>基本原则：<br>（1）运算密集型的 job，少用压缩<br>（2） IO 密集型的 job，多用压缩</p></blockquote><h1 id="2-MR-支持的压缩类型"><a href="#2-MR-支持的压缩类型" class="headerlink" title="2.MR 支持的压缩类型"></a>2.<code>MR</code> 支持的压缩类型</h1><h2 id="2-1-Gzip-压缩"><a href="#2-1-Gzip-压缩" class="headerlink" title="2.1. Gzip 压缩"></a>2.1. <code>Gzip</code> 压缩</h2><h3 id="2-1-1-优点"><a href="#2-1-1-优点" class="headerlink" title="2.1.1. 优点"></a>2.1.1. 优点</h3><blockquote><ul><li><p><strong>压缩率比较高，而且压缩/解压速度也比较快</strong></p></li><li><p><code>hadoop</code> 本身支持，在应用中处理 <code>gzip</code>  格式的文件就和直接处理文本一样</p></li><li><p>大部分 <code>linux</code> 系统都自带 <code>gzip</code> 命令，使用方便。</p></li></ul></blockquote><h3 id="2-1-2-缺点"><a href="#2-1-2-缺点" class="headerlink" title="2.1.2. 缺点"></a>2.1.2. 缺点</h3><blockquote><p> 不支持 <strong><code>split</code></strong></p></blockquote><h3 id="2-1-3-应用场景"><a href="#2-1-3-应用场景" class="headerlink" title="2.1.3. 应用场景"></a>2.1.3. 应用场景</h3><blockquote><p> 当每个文件压缩之后在 [**<code>1 * 1.1</code>**个块大小内]，都可以考虑用 <code>gzip</code> 压缩格式。</p><ul><li><p>例如说一天或者一个小时的日志压缩成一个 <code>gzip</code> 文件，运行 <code>mapreduce</code> 程序的时候通过多个 <code>gzip</code> 文件达到并发。 </p></li><li><p><code>hive</code> 程序， <code>streaming</code> 程序，和 <code>java</code> 写的 <code>mapreduce</code> 程序完全和文本处理一样，压缩之后原来的程序不需要做任何修改。</p></li></ul></blockquote><h2 id="2-2-Bzip2-压缩"><a href="#2-2-Bzip2-压缩" class="headerlink" title="2.2. Bzip2 压缩"></a>2.2. <code>Bzip2</code> 压缩</h2><h3 id="2-2-1-优点"><a href="#2-2-1-优点" class="headerlink" title="2.2.1. 优点"></a>2.2.1. 优点</h3><blockquote><ul><li><p>支持 <code>split</code></p></li><li><p>具有很高的压缩率，比 <code>gzip</code> 压缩率都高</p></li><li><p><code>hadoop</code> 本身支持</p></li><li><p>在 <code>linux</code> 系统下自带 <code>bzip2</code> 命令，使用方便。</p></li></ul></blockquote><h3 id="2-2-2-缺点"><a href="#2-2-2-缺点" class="headerlink" title="2.2.2. 缺点"></a>2.2.2. 缺点</h3><blockquote><p>压缩/解压速度慢</p></blockquote><h3 id="2-2-3-应用场景"><a href="#2-2-3-应用场景" class="headerlink" title="2.2.3. 应用场景"></a>2.2.3. 应用场景</h3><blockquote><ul><li>适合对速度要求不高，但需要较高的压缩率的时候，可以作为 <code>mapreduce</code> 作业的输出格式 </li><li>输出之后的数据比较大，处理之后的数据需要压缩存档减少磁盘空间并且以后数据用得比较少的情况</li><li>对单个很大的文本文件想压缩减少存储空间，同时又需要支持 <code>split</code>，而且兼容之前的应用程序的情况。</li></ul></blockquote><h2 id="2-3-Lzo-压缩"><a href="#2-3-Lzo-压缩" class="headerlink" title="2.3. Lzo 压缩"></a>2.3. <code>Lzo</code> 压缩</h2><h3 id="2-3-1-优点"><a href="#2-3-1-优点" class="headerlink" title="2.3.1. 优点"></a>2.3.1. 优点</h3><blockquote><ul><li>压缩/解压速度也比较快，合理的压缩率</li><li>支持 <code>split</code>，是 hadoop 中最流行的压缩格式</li><li>可以在 <code>linux</code>系统下安装 <code>lzop</code> 命令，使用方便。</li></ul></blockquote><h3 id="2-3-2-缺点"><a href="#2-3-2-缺点" class="headerlink" title="2.3.2. 缺点"></a>2.3.2. 缺点</h3><blockquote><ul><li>压缩率比 <code>gzip</code> 要低一些</li><li><code>hadoop</code> 本身不支持，需要安装</li><li>在应用中对 <code>lzo</code> 格式的文件需要做一些特殊处理[为了支持 <code>split</code> 需要建索引，还需要指定 <code>inputformat</code> 为 <code>lzo</code> 格式]。</li></ul></blockquote><h3 id="2-3-3-应用场景"><a href="#2-3-3-应用场景" class="headerlink" title="2.3.3. 应用场景"></a>2.3.3. 应用场景</h3><blockquote><p> 一个很大的文本文件，压缩之后还大于 <code>200M</code> 以上的可以考虑，而且单个文件越大， <code>lzo</code> 优点越越明显。</p></blockquote><h2 id="2-4-Snappy-压缩"><a href="#2-4-Snappy-压缩" class="headerlink" title="2.4. Snappy 压缩"></a>2.4. <code>Snappy</code> 压缩</h2><h3 id="2-4-1-优点"><a href="#2-4-1-优点" class="headerlink" title="2.4.1. 优点"></a>2.4.1. 优点</h3><blockquote><p> 高速压缩速度和合理的压缩率。</p></blockquote><h3 id="2-4-2-缺点"><a href="#2-4-2-缺点" class="headerlink" title="2.4.2. 缺点"></a>2.4.2. 缺点</h3><blockquote><ul><li><p>不支持 <code>split</code></p></li><li><p>压缩率比 <code>gzip</code> 要低</p></li><li><p><code>hadoop</code> 本身不支持，需要安装</p></li></ul></blockquote><h3 id="2-4-3-应用场景"><a href="#2-4-3-应用场景" class="headerlink" title="2.4.3. 应用场景"></a>2.4.3. 应用场景</h3><blockquote><p> 当 <code>Mapreduce</code> 作业的 <code>Map</code> 输出的数据比较大的时候，作为 <code>Map</code>  到 <code>Reduce</code> 的中间数据的压缩格式</p><p>或者作为一个 Mapreduce 作业的输出和另外一个 Mapreduce 作业的输入。</p></blockquote><h1 id="3-位置选择"><a href="#3-位置选择" class="headerlink" title="3. 位置选择"></a>3. 位置选择</h1><h1 id="4-配置参数"><a href="#4-配置参数" class="headerlink" title="4. 配置参数"></a>4. 配置参数</h1><h1 id="5-压缩案例"><a href="#5-压缩案例" class="headerlink" title="5. 压缩案例"></a>5. 压缩案例</h1><h2 id="5-1-数据流的压缩和解压缩"><a href="#5-1-数据流的压缩和解压缩" class="headerlink" title="5.1. 数据流的压缩和解压缩"></a>5.1. 数据流的压缩和解压缩</h2><h2 id="5-2-Map-输出端压缩"><a href="#5-2-Map-输出端压缩" class="headerlink" title="5.2. Map 输出端压缩"></a>5.2. <code>Map</code> 输出端压缩</h2><h2 id="5-3-Reduce-输出端压缩"><a href="#5-3-Reduce-输出端压缩" class="headerlink" title="5.3. Reduce 输出端压缩"></a>5.3. <code>Reduce</code> 输出端压缩</h2>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM 字节码[1]: 数据类型</title>
      <link href="2019/07/27/JVM-%E5%AD%97%E8%8A%82%E7%A0%81-1-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
      <url>2019/07/27/JVM-%E5%AD%97%E8%8A%82%E7%A0%81-1-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Class字节码中有两种数据类型：</p><p>（1）字节数据直接量：这是基本的数据类型。共细分为u1、u2、u4、u8四种，分别代表连续的1个字节、2个字节、4个字节、8个字节组成的整体数据。<br>（2）表/数组：表是由多个基本数据或其他表，按照既定顺序组成的大的数据集合。表是有结构的，它的结构体：组成表的成分所在的位置和顺序都是已经严格定义好的。</p><p>Access Falgs：<br>访问标志信息包括了该class文件是类还是接口，是否被定义成public，是否是abstract，如果是类，是否被定义成final。</p><p><img src="./images/re.png"></p><p><img src="./images/hff.png"></p><ul><li><p>0x0021是0x0020和0x0001的并集，表示ACC_PUBLIC和ACC_SUPER<br>0x0002:private</p></li><li><p>字段表（Fields）：<br>字段表用于描述类和接口中声明的变量。这里的字段包含了类级别变量和实例变量，但是不包括方法内部声明的局部变量。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深入理解 JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis 删除策略</title>
      <link href="2019/07/16/Redis-%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8/"/>
      <url>2019/07/16/Redis-%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 索引</title>
      <link href="2019/07/16/MySQL%20%E7%B4%A2%E5%BC%95/"/>
      <url>2019/07/16/MySQL%20%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>对于 MySQL 数据库而言,数据是存储在文件里的，而为了能够快速定位到某张表里的某条记录进行查询和修改，我们需要将这些数据以一定的数据结构进行存储，这个数据结构就是索引。</p><a id="more"></a><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><h2 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1. 定义"></a>1.1. 定义</h2><blockquote><p><code>MySQL</code> 官方定义为：<strong>索引是帮助 <code>MySQL</code> 高效获取数据的 <font color='red'>数据结构</font></strong></p><p><strong><u>[ 本质：索引是一种数据结构 ]</u></strong></p><p>除数据本身之外，数据库还维护着一个满足特定查找算法的数据结构，这些数据结构一某种方式指向数据，这样就可以在这些数据结构基础上实现高级查找算法，这种数据结构就是索引。</p></blockquote><h2 id="1-2-优点"><a href="#1-2-优点" class="headerlink" title="1.2. 优点"></a>1.2. 优点</h2><p>通过创建索引，可以提高数据检索的效率，降低数据库的 IO 成本</p><p>通过创建索引，降低数据排序的成本，降低了 CPU 的消耗</p><h2 id="1-3-缺点"><a href="#1-3-缺点" class="headerlink" title="1.3. 缺点"></a>1.3. 缺点</h2><p>索引本质也是一张表，保存了主键与索引字段，并指向实体表的记录，所以索引列也占用存储空间</p><p>虽然索引大大提高了查询速度，同时却会降低数据更新效率</p><h2 id="1-4-索引分类"><a href="#1-4-索引分类" class="headerlink" title="1.4. 索引分类"></a>1.4. 索引分类</h2><h3 id="1-4-1-实现方式"><a href="#1-4-1-实现方式" class="headerlink" title="1.4.1. 实现方式"></a>1.4.1. 实现方式</h3><ol><li><p>非聚集索引</p><p><strong>非聚集索引的叶子节点为索引节点，但是有一个指针指向数据节点。</strong></p><p><code>MyISAM</code> 是非聚集索引。</p></li><li><p>聚集索引</p><p><strong>聚集索引叶子节点就是数据节点。</strong></p><p><strong>关于聚集索引，<code>innodb</code> 会按照如下规则进行处理：</strong> </p><p>如果定义主键，则主键作为聚集索引 </p><p>如果没有主键被定义，则该表的第一个唯一非空索引被作为聚集索引 </p><p>如果没有主键也没有合适的唯一索引，那么 <code>innodb</code> 内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键是一个6个字节的列，改列的值会随着数据的插入自增。</p></li></ol><p><strong><font color='red'>注意事项</font></strong></p><blockquote><p><code>innodb</code> 的普通索引，唯一索引，联合索引都是辅助索引，采用非聚集索引结构。<code>InnoDB</code> 的所有辅助索引都引用主键作为 <code>data</code> 域。</p></blockquote><blockquote><p>聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 </p></blockquote><h3 id="1-4-2-结构"><a href="#1-4-2-结构" class="headerlink" title="1.4.2. 结构"></a>1.4.2. 结构</h3><ul><li><p><code>Hash</code>索引</p><blockquote><p><code>Hash</code> 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像 <code>B+Tree</code> 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的 <code>IO</code> 访问，所以 <code>Hash</code> 索引的查询效率要远高于 <code>B+Tree</code> 索引。</p><p>虽然 <code>Hash</code> 索引效率高，但是 <code>Hash</code> 索引本身由于其特殊性也带来了 很多限制和弊端，主要有以下这些。</p><ul><li><p><code>Hash</code> 索引仅仅能满足 <code>&quot;=&quot;</code>, <code>&quot;IN&quot;</code> 和 <code>&quot;&lt;=&gt;&quot;</code> 查询，不能使用范围查询。</p><blockquote><p>由于 <code>Hash</code> 索引比较的是进行 <code>Hash</code> 运算之后的 <code>Hash</code> 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 <code>Hash</code> 算法处理之后的 <code>Hash</code> 值的大小关系，并不能保证和 <code>Hash</code> 运算前完全一样</p></blockquote></li><li><p><code>Hash</code> 索引无法被用来避免数据的排序操作</p><blockquote><p>由于 <code>Hash</code> 索引中存放的是经过 <code>Hash</code> 计算之后的 <code>Hash</code> 值，而且 <code>Hash</code> 值的大小关系并不一定和 <code>Hash</code> 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算</p></blockquote></li><li><p><code>Hash</code> 索引不能利用部分索引键查询</p><blockquote><p>对于组合索引，<code>Hash</code> 索引在计算 <code>Hash</code> 值的时候是组合索引键合并后再一起计算 <code>Hash</code> 值，而不是单独计算 <code>Hash</code> 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，<code>Hash</code> 索引也无法被利用。</p></blockquote></li><li><p><code>Hash</code> 索引在任何时候都不能避免表扫描</p><blockquote><p>前面已经知道，<code>Hash</code> 索引是将索引键通过 <code>Hash</code> 运算之后，将 <code>Hash</code>运算结果的 <code>Hash</code> 值和所对应的行指针信息存放于一个 <code>Hash</code> 表中，由于不同索引键存在相同 <code>Hash</code> 值，所以即使取满足某个<code> Hash</code> 键值的数据的记录条数，也无法从 <code>Hash</code> 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。</p></blockquote></li><li><p><code>Hash</code> 索引遇到大量 <code>Hash</code> 值相等的情况后性能并不一定就会比 <code>B+Tree</code> 索引高</p><blockquote><p>对于选择性比较低的索引键，如果创建 <code>Hash</code> 索引，那么将会存在大量记录指针信息存于同一个 <code>Hash</code> 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下</p></blockquote></li></ul></blockquote></li><li><p><code>B+Tree</code></p><blockquote><p><code>B+Tree</code> 索引是 <code>MySQL</code> 数据库中使用最为频繁的索引类型，除了 <code>Archive</code> 存储引擎之外的其他所有的存储引擎都支持 <code>B+Tree</code> 索引。不仅仅在 <code>MySQL</code> 中是如此，实际上在其他的很多数据库管理系统中 <code>B+Tree</code>  索引也同样是作为最主要的索引类型，这主要是因为 <code>B+Tree</code> 索引的存储结构在数据库的数据检索中有非常优异的表现。</p></blockquote></li></ul><h2 id="1-5-适用场景"><a href="#1-5-适用场景" class="headerlink" title="1.5. 适用场景"></a>1.5. 适用场景</h2><ul><li><p>频繁作为查询条件的字段应该创建索引</p></li><li><p>主键列</p></li><li><p>连接列</p></li><li><p>范围搜索列，因为索引进行了排序</p></li><li><p><code>where</code> 子句列</p></li></ul><h2 id="1-6-注意"><a href="#1-6-注意" class="headerlink" title="1.6. 注意"></a>1.6. 注意</h2><ul><li><p>查询很少的列不创建索引</p></li><li><p>列值较少（性别）的列不创建索引，并不是所有索引对查询都有效</p><blockquote><p><code>SQL</code> 是根据表中数据来进行查询优化的，当索引列有大量数据重复时，<code>SQL</code> 查询可能不会去利用索引，如一表中有字段<code>sex</code>，<code>male</code>、<code>female</code> 几乎各一半，那么即使在 <code>sex</code> 上建了索引也对查询效率起不了作用。</p></blockquote></li><li><p><code>image</code>，<code>bit</code> 数据类型的列不创建索引</p></li><li><p>修改性能远远大于索引性能的列</p><blockquote><p>索引会提高检索性能但会降低修改性能。索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。</p></blockquote></li><li><p>只要列中包含有 <code>NULL</code> 值都将不会被包含在索引中，所以我们在数据库设计时不要让字段的默认值为 NULL。</p></li><li><p>对字符串列进行索引，如果可能应该指定一个前缀长度。</p><blockquote><p>例如，如果有一个CHAR(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。</p></blockquote></li><li><p><code>like&quot;%aaa%&quot;</code>不会使用索引而  <code>like&quot;aaa%&quot;</code> 可以使用索引,以 <code>%</code> 开头不会利用到索引，结尾可以。</p></li><li><p>不要在索引列上进行运算,</p><blockquote><p> 我们可以吧 <code>id - 2 = 1</code>改成 <code>id = 1 + 2</code> 的形式</p></blockquote></li><li><p>不使用NOT IN和&lt;&gt;操作</p></li><li><p>符合最左前缀原则</p></li></ul><img src="/Users/joker/Documents/MySQL/img/截屏2021-02-05 下午3.35.53.png" alt="截屏2021-02-05 下午3.35.53" style="zoom:50%;" /><h1 id="2-结构"><a href="#2-结构" class="headerlink" title="2. 结构"></a>2. 结构</h1><h2 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1. 概述"></a>2.1. 概述</h2><blockquote><p> 一般来说， MySQL 中的 B-Tree 索引的物理文件大多都是以 Balance Tree 的结构来存储的，也就是所有实际需要的数据都存放于 Tree 的 Leaf Node ，而且到任何一个 Leaf Node 的最短路径的长度都是完全相同的，所以我们大家都称之为 B-Tree 索引。</p><p>当然，可能各种数据库（或 MySQL 的各种存储引擎）在存放自己的 B-Tree 索引的时候会对存储结构稍作改造。如 Innodb 存储引擎的 B-Tree 索引实际使用的存储结构实际上是 B+Tree ，也就是在 B-Tree 数据结构的基础上做了很小的改造，在每一个 Leaf Node 上面出了存放索引键的相关信息之外，还存储了指向与该 Leaf Node 相邻的后一个 LeafNode 的指针信息，这主要是为了加快检索多个相邻 Leaf Node 的效率考虑。</p></blockquote><h2 id="2-2-Innodb"><a href="#2-2-Innodb" class="headerlink" title="2.2. Innodb"></a>2.2. <code>Innodb</code></h2><h3 id="2-2-1-概述"><a href="#2-2-1-概述" class="headerlink" title="2.2.1. 概述"></a>2.2.1. 概述</h3><blockquote><p>在 Innodb 存储引擎中，存在两种不同形式的索引，一种是 Cluster 形式的主键索引（ Primary Key ），另外一种则是和其他存储引擎（如 MyISAM 存储引擎）存放形式基本相同的普通 B-Tree 索引，这种索引在 Innodb 存储引擎中被称为 Secondary Index 。</p><p>在 Prim中， Leaf Nodes 存放的是表的实际数据，不仅仅包括主键字段的数据，还包括其他字段的数据据以主键值有序的排列。而 Secondary Index 则和其他普通的 B-Tree 索引没有太大的差异，Leaf Nodes 除了存放索引键 的相关信息外，还存放了 Innodb 的主键值。</p><p>所以，在 Innodb 中如果通过主键来访问数据效率是非常高的，而如果是通过 Secondary Index 来访问数据的话， Innodb 首先通过 Secondary Index 的相关信息，通过相应的索引键检索到 Leaf Node之后，需要再通过 Leaf Node 中存放的主键值再通过主键索引来获取相应的数据行。</p></blockquote><h2 id="2-3-MyISAM"><a href="#2-3-MyISAM" class="headerlink" title="2.3. MyISAM"></a>2.3. <code>MyISAM</code></h2><h3 id="2-3-1-概述"><a href="#2-3-1-概述" class="headerlink" title="2.3.1. 概述"></a>2.3.1. 概述</h3><blockquote><p>MyISAM 存储引擎的主键索引和非主键索引差别很小，只不过是主键索引的索引键是一个唯一且非空 的键而已。而且 MyISAM 存储引擎的索引和 Innodb 的 Secondary Index 的存储结构也基本相同，主要的区别只是 MyISAM 存储引擎在 Leaf Nodes 上面除了存放索引键信息之外，再存放能直接定位到 MyISAM 数据文件中相应的数据行的信息（如 Row Number ），但并不会存放主键的键值信息。</p></blockquote><h2 id="2-3-B"><a href="#2-3-B" class="headerlink" title="2.3. B+"></a>2.3. B+</h2><blockquote><p><code>B+</code> 树是应文件系统所需而产生的一种 <code>B</code> 树的变形树 , 类似文件的目录一级一级索引，只有最底层的叶子节点[文件]保存数据，非叶子节点只保存索引，不保存实际的数据，数据都保存在叶子节点中,所有的非叶子节点都可以看成索引的一部分。</p></blockquote><ul><li><p><code>B+</code> 树的磁盘读写代价更低</p><blockquote><p><code>B+</code> 树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对 <code>B</code> 树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。</p></blockquote></li><li><p>B+树的查询效率更加稳定</p><blockquote><p>由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。</p></blockquote></li><li><p>方便</p><blockquote><p>由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。</p></blockquote></li></ul><h1 id="3-索引失效"><a href="#3-索引失效" class="headerlink" title="3. 索引失效"></a>3. 索引失效</h1><h4 id="3-1-索引进行表达式计算，则会失效"><a href="#3-1-索引进行表达式计算，则会失效" class="headerlink" title="3.1. 索引进行表达式计算，则会失效"></a>3.1. 索引进行表达式计算，则会失效</h4><h4 id="3-2-索引使用函数，也会造成失效"><a href="#3-2-索引使用函数，也会造成失效" class="headerlink" title="3.2. 索引使用函数，也会造成失效"></a>3.2. 索引使用函数，也会造成失效</h4><h4 id="3-3-在-WHERE-子句中，如果在-OR-前的条件列进行了索引，而在-OR-后的条件列没有进行索引，那么索引会失效。"><a href="#3-3-在-WHERE-子句中，如果在-OR-前的条件列进行了索引，而在-OR-后的条件列没有进行索引，那么索引会失效。" class="headerlink" title="3.3. 在 WHERE 子句中，如果在 OR 前的条件列进行了索引，而在 OR 后的条件列没有进行索引，那么索引会失效。"></a>3.3. 在 WHERE 子句中，如果在 OR 前的条件列进行了索引，而在 OR 后的条件列没有进行索引，那么索引会失效。</h4><h4 id="3-4-使用-LIKE-进行模糊查询的时候-‘-’"><a href="#3-4-使用-LIKE-进行模糊查询的时候-‘-’" class="headerlink" title="3.4. 使用 LIKE 进行模糊查询的时候 ‘%***’"></a>3.4. 使用 LIKE 进行模糊查询的时候 ‘%***’</h4><h4 id="3-5-索引列尽量设置为-NOT-NULL-约束"><a href="#3-5-索引列尽量设置为-NOT-NULL-约束" class="headerlink" title="3.5. 索引列尽量设置为 NOT NULL 约束"></a>3.5. 索引列尽量设置为 NOT NULL 约束</h4><p>MySQL 官方文档建议尽量将数据表的字段设置为 NOT NULL 约束，这样可以更好地使用索引，节省空间，甚至加速 SQL 的运行。判断索引列是否为 NOT NULL，往往需要走全表扫描，因此最好在设计数据表的时候就将字段设置为 NOT NULL 约束,可以将 INT 类型的字段，默认值设置为 0。将字符类型的默认值设置为空字符串 (‘’)</p><h4 id="3-6-在使用联合索引的时候要注意最左原则"><a href="#3-6-在使用联合索引的时候要注意最左原则" class="headerlink" title="3.6. 在使用联合索引的时候要注意最左原则"></a>3.6. 在使用联合索引的时候要注意最左原则</h4><h2 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h2><h2 id="3-如何创建高性能索引？"><a href="#3-如何创建高性能索引？" class="headerlink" title="3. 如何创建高性能索引？"></a>3. 如何创建高性能索引？</h2><h3 id="3-1-最左前缀匹配原则"><a href="#3-1-最左前缀匹配原则" class="headerlink" title="3.1. 最左前缀匹配原则"></a>3.1. <strong>最左前缀匹配原则</strong></h3>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 索引</title>
      <link href="2019/07/16/MySQL_MVCC/"/>
      <url>2019/07/16/MySQL_MVCC/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>对于 MySQL 数据库而言,数据是存储在文件里的，而为了能够快速定位到某张表里的某条记录进行查询和修改，我们需要将这些数据以一定的数据结构进行存储，这个数据结构就是索引。</p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>MVCC (Multi-Version Concurrency Control) (与 MVCC 相对的，是基于锁的并发控制，Lock-Based Concurrency Control)是一种基于多版本的并发控制协议，只有在 InnoDB 引擎下存在。MVCC 是为了实现事务的隔离性，通过版本号，避免同一数据在不同事务间的竞争，可以把它当成基于多版本号的一种乐观锁。当然，这种乐观锁只在事务级别未提交锁和已提交锁时才会生效。MVCC 最大的好处: 读不加锁，读写不冲突。在读多写少的 OLTP 应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能。</p><h2 id="2-实现机制"><a href="#2-实现机制" class="headerlink" title="2. 实现机制"></a>2. 实现机制</h2><p>在 InnoDB 中，每一行都有 2 个隐藏列 <code>DATA_TRX_ID</code> 和 <code>DATA_ROLL_PTR</code> (如果没有定义主键，则还有个隐藏主键列)</p><ol><li>DATA_TRX_ID: 表示最近修改该行数据的事务ID</li><li>DATA_ROLL_PTR: 则表示指向该行回滚段的指针。该行上所有旧的版本，在 undo 中都通过链表的形式组织，而该值指向 undo 中该行的历史记录链表</li></ol><p>整个 MVCC 的关键就是通过 DATA_TRX_ID 和 DATA_ROLL_PTR 这两个隐藏列来实现的。 </p><h2 id="3-事务链表"><a href="#3-事务链表" class="headerlink" title="3. 事务链表"></a>3. 事务链表</h2><p>MySQL 中的事务在开始到提交这段过程中，都会被保存到一个叫 <code>trx_sys</code> 的事务链表中，这是一个基本的链表结构</p><p>事务链表中保存的都是还未提交的事务，事务一旦被提交，则会被从事务链表中摘除。</p><h2 id="4-ReadView"><a href="#4-ReadView" class="headerlink" title="4. ReadView"></a>4. ReadView</h2><p>ReadView 是一个数据结构，在 SQL 开始的时候被创建。这个数据结构中包含了 3 个主要的成员: <code>ReadView&#123;low_trx_id, up_trx_id, trx_ids&#125;</code>，在并发情况下，一个事务在启动时，trx_sys 链表中存在部分还未提交的事务，那么哪些改变对当前事务是可见的，哪些又是不可见的，这个需要通过 ReadView 来进行判定，首先来看下ReadView中的3个成员各自代表的意思：</p><ol><li>low_trx_id: 表示该 SQL 启动时，当前事务链表中最大的事务id编号，也就是最近创建的除自身以外最大事务编号；</li><li>up_trx_id: 表示该SQL启动时，当前事务链表中最小的事务id编号，也就是当前系统中创建最早但还未提交的事务；</li><li>trx_ids 表示所有事务链表中事务的 id 集合。</li></ol><p>根据上图所示，所有数据行上DATA_TRX_ID小于up_trx_id的记录，说明修改该行的事务在当前事务开启之前都已经提交完成，所以对当前事务来说，都是可见的。而对于DATA_TRX_ID大于low_trx_id的记录，说明修改该行记录的事务在当前事务之后，所以对于当前事务来说是不可见的。</p><h2 id="4-1-定义"><a href="#4-1-定义" class="headerlink" title="4.1. 定义"></a>4.1. 定义</h2><blockquote><p><code>MySQL</code> 官方定义为：<strong>索引是帮助 <code>MySQL</code> 高效获取数据的 <font color='red'>数据结构</font></strong></p><p><strong><u>[ 本质：索引是一种数据结构 ]</u></strong></p><p>除数据本身之外，数据库还维护着一个满足特定查找算法的数据结构，这些数据结构一某种方式指向数据，这样就可以在这些数据结构基础上实现高级查找算法，这种数据结构就是索引。</p></blockquote><h2 id="4-2-优点"><a href="#4-2-优点" class="headerlink" title="4.2. 优点"></a>4.2. 优点</h2><p>通过创建索引，可以提高数据检索的效率，降低数据库的 IO 成本</p><p>通过创建索引，降低数据排序的成本，降低了 CPU 的消耗</p><h2 id="4-3-缺点"><a href="#4-3-缺点" class="headerlink" title="4.3. 缺点"></a>4.3. 缺点</h2><p>索引本质也是一张表，保存了主键与索引字段，并指向实体表的记录，所以索引列也占用存储空间</p><p>虽然索引大大提高了查询速度，同时却会降低数据更新效率</p><h2 id="1-4-索引分类"><a href="#1-4-索引分类" class="headerlink" title="1.4. 索引分类"></a>1.4. 索引分类</h2><h3 id="1-4-1-实现方式"><a href="#1-4-1-实现方式" class="headerlink" title="1.4.1. 实现方式"></a>1.4.1. 实现方式</h3><ol><li><p>非聚集索引</p><p><strong>非聚集索引的叶子节点为索引节点，但是有一个指针指向数据节点。</strong></p><p><code>MyISAM</code> 是非聚集索引。</p></li><li><p>聚集索引</p><p><strong>聚集索引叶子节点就是数据节点。</strong></p><p><strong>关于聚集索引，<code>innodb</code> 会按照如下规则进行处理：</strong> </p><p>如果定义主键，则主键作为聚集索引 </p><p>如果没有主键被定义，则该表的第一个唯一非空索引被作为聚集索引 </p><p>如果没有主键也没有合适的唯一索引，那么 <code>innodb</code> 内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键是一个6个字节的列，改列的值会随着数据的插入自增。</p></li></ol><p><strong><font color='red'>注意事项</font></strong></p><blockquote><p><code>innodb</code> 的普通索引，唯一索引，联合索引都是辅助索引，采用非聚集索引结构。<code>InnoDB</code> 的所有辅助索引都引用主键作为 <code>data</code> 域。</p></blockquote><blockquote><p>聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 </p></blockquote><h3 id="1-4-2-结构"><a href="#1-4-2-结构" class="headerlink" title="1.4.2. 结构"></a>1.4.2. 结构</h3><ul><li><p><code>Hash</code>索引</p><blockquote><p><code>Hash</code> 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像 <code>B+Tree</code> 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的 <code>IO</code> 访问，所以 <code>Hash</code> 索引的查询效率要远高于 <code>B+Tree</code> 索引。</p><p>虽然 <code>Hash</code> 索引效率高，但是 <code>Hash</code> 索引本身由于其特殊性也带来了 很多限制和弊端，主要有以下这些。</p><ul><li><p><code>Hash</code> 索引仅仅能满足 <code>&quot;=&quot;</code>, <code>&quot;IN&quot;</code> 和 <code>&quot;&lt;=&gt;&quot;</code> 查询，不能使用范围查询。</p><blockquote><p>由于 <code>Hash</code> 索引比较的是进行 <code>Hash</code> 运算之后的 <code>Hash</code> 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 <code>Hash</code> 算法处理之后的 <code>Hash</code> 值的大小关系，并不能保证和 <code>Hash</code> 运算前完全一样</p></blockquote></li><li><p><code>Hash</code> 索引无法被用来避免数据的排序操作</p><blockquote><p>由于 <code>Hash</code> 索引中存放的是经过 <code>Hash</code> 计算之后的 <code>Hash</code> 值，而且 <code>Hash</code> 值的大小关系并不一定和 <code>Hash</code> 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算</p></blockquote></li><li><p><code>Hash</code> 索引不能利用部分索引键查询</p><blockquote><p>对于组合索引，<code>Hash</code> 索引在计算 <code>Hash</code> 值的时候是组合索引键合并后再一起计算 <code>Hash</code> 值，而不是单独计算 <code>Hash</code> 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，<code>Hash</code> 索引也无法被利用。</p></blockquote></li><li><p><code>Hash</code> 索引在任何时候都不能避免表扫描</p><blockquote><p>前面已经知道，<code>Hash</code> 索引是将索引键通过 <code>Hash</code> 运算之后，将 <code>Hash</code>运算结果的 <code>Hash</code> 值和所对应的行指针信息存放于一个 <code>Hash</code> 表中，由于不同索引键存在相同 <code>Hash</code> 值，所以即使取满足某个<code> Hash</code> 键值的数据的记录条数，也无法从 <code>Hash</code> 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。</p></blockquote></li><li><p><code>Hash</code> 索引遇到大量 <code>Hash</code> 值相等的情况后性能并不一定就会比 <code>B+Tree</code> 索引高</p><blockquote><p>对于选择性比较低的索引键，如果创建 <code>Hash</code> 索引，那么将会存在大量记录指针信息存于同一个 <code>Hash</code> 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下</p></blockquote></li></ul></blockquote></li><li><p><code>B+Tree</code></p><blockquote><p><code>B+Tree</code> 索引是 <code>MySQL</code> 数据库中使用最为频繁的索引类型，除了 <code>Archive</code> 存储引擎之外的其他所有的存储引擎都支持 <code>B+Tree</code> 索引。不仅仅在 <code>MySQL</code> 中是如此，实际上在其他的很多数据库管理系统中 <code>B+Tree</code>  索引也同样是作为最主要的索引类型，这主要是因为 <code>B+Tree</code> 索引的存储结构在数据库的数据检索中有非常优异的表现。</p></blockquote></li></ul><h2 id="1-5-适用场景"><a href="#1-5-适用场景" class="headerlink" title="1.5. 适用场景"></a>1.5. 适用场景</h2><ul><li><p>频繁作为查询条件的字段应该创建索引</p></li><li><p>主键列</p></li><li><p>连接列</p></li><li><p>范围搜索列，因为索引进行了排序</p></li><li><p><code>where</code> 子句列</p></li></ul><h2 id="1-6-注意"><a href="#1-6-注意" class="headerlink" title="1.6. 注意"></a>1.6. 注意</h2><ul><li><p>查询很少的列不创建索引</p></li><li><p>列值较少（性别）的列不创建索引，并不是所有索引对查询都有效</p><blockquote><p><code>SQL</code> 是根据表中数据来进行查询优化的，当索引列有大量数据重复时，<code>SQL</code> 查询可能不会去利用索引，如一表中有字段<code>sex</code>，<code>male</code>、<code>female</code> 几乎各一半，那么即使在 <code>sex</code> 上建了索引也对查询效率起不了作用。</p></blockquote></li><li><p><code>image</code>，<code>bit</code> 数据类型的列不创建索引</p></li><li><p>修改性能远远大于索引性能的列</p><blockquote><p>索引会提高检索性能但会降低修改性能。索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。</p></blockquote></li><li><p>只要列中包含有 <code>NULL</code> 值都将不会被包含在索引中，所以我们在数据库设计时不要让字段的默认值为 NULL。</p></li><li><p>对字符串列进行索引，如果可能应该指定一个前缀长度。</p><blockquote><p>例如，如果有一个CHAR(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。</p></blockquote></li><li><p><code>like&quot;%aaa%&quot;</code>不会使用索引而  <code>like&quot;aaa%&quot;</code> 可以使用索引,以 <code>%</code> 开头不会利用到索引，结尾可以。</p></li><li><p>不要在索引列上进行运算,</p><blockquote><p> 我们可以吧 <code>id - 2 = 1</code>改成 <code>id = 1 + 2</code> 的形式</p></blockquote></li><li><p>不使用NOT IN和&lt;&gt;操作</p></li><li><p>符合最左前缀原则</p></li></ul><img src="/Users/joker/Documents/MySQL/img/截屏2021-02-05 下午3.35.53.png" alt="截屏2021-02-05 下午3.35.53" style="zoom:50%;" /><h1 id="2-结构"><a href="#2-结构" class="headerlink" title="2. 结构"></a>2. 结构</h1><h2 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1. 概述"></a>2.1. 概述</h2><blockquote><p> 一般来说， MySQL 中的 B-Tree 索引的物理文件大多都是以 Balance Tree 的结构来存储的，也就是所有实际需要的数据都存放于 Tree 的 Leaf Node ，而且到任何一个 Leaf Node 的最短路径的长度都是完全相同的，所以我们大家都称之为 B-Tree 索引。</p><p>当然，可能各种数据库（或 MySQL 的各种存储引擎）在存放自己的 B-Tree 索引的时候会对存储结构稍作改造。如 Innodb 存储引擎的 B-Tree 索引实际使用的存储结构实际上是 B+Tree ，也就是在 B-Tree 数据结构的基础上做了很小的改造，在每一个 Leaf Node 上面出了存放索引键的相关信息之外，还存储了指向与该 Leaf Node 相邻的后一个 LeafNode 的指针信息，这主要是为了加快检索多个相邻 Leaf Node 的效率考虑。</p></blockquote><h2 id="2-2-Innodb"><a href="#2-2-Innodb" class="headerlink" title="2.2. Innodb"></a>2.2. <code>Innodb</code></h2><h3 id="2-2-1-概述"><a href="#2-2-1-概述" class="headerlink" title="2.2.1. 概述"></a>2.2.1. 概述</h3><blockquote><p>在 Innodb 存储引擎中，存在两种不同形式的索引，一种是 Cluster 形式的主键索引（ Primary Key ），另外一种则是和其他存储引擎（如 MyISAM 存储引擎）存放形式基本相同的普通 B-Tree 索引，这种索引在 Innodb 存储引擎中被称为 Secondary Index 。</p><p>在 Prim中， Leaf Nodes 存放的是表的实际数据，不仅仅包括主键字段的数据，还包括其他字段的数据据以主键值有序的排列。而 Secondary Index 则和其他普通的 B-Tree 索引没有太大的差异，Leaf Nodes 除了存放索引键 的相关信息外，还存放了 Innodb 的主键值。</p><p>所以，在 Innodb 中如果通过主键来访问数据效率是非常高的，而如果是通过 Secondary Index 来访问数据的话， Innodb 首先通过 Secondary Index 的相关信息，通过相应的索引键检索到 Leaf Node之后，需要再通过 Leaf Node 中存放的主键值再通过主键索引来获取相应的数据行。</p></blockquote><h2 id="2-3-MyISAM"><a href="#2-3-MyISAM" class="headerlink" title="2.3. MyISAM"></a>2.3. <code>MyISAM</code></h2><h3 id="2-3-1-概述"><a href="#2-3-1-概述" class="headerlink" title="2.3.1. 概述"></a>2.3.1. 概述</h3><blockquote><p>MyISAM 存储引擎的主键索引和非主键索引差别很小，只不过是主键索引的索引键是一个唯一且非空 的键而已。而且 MyISAM 存储引擎的索引和 Innodb 的 Secondary Index 的存储结构也基本相同，主要的区别只是 MyISAM 存储引擎在 Leaf Nodes 上面除了存放索引键信息之外，再存放能直接定位到 MyISAM 数据文件中相应的数据行的信息（如 Row Number ），但并不会存放主键的键值信息。</p></blockquote><h2 id="2-3-B"><a href="#2-3-B" class="headerlink" title="2.3. B+"></a>2.3. B+</h2><blockquote><p><code>B+</code> 树是应文件系统所需而产生的一种 <code>B</code> 树的变形树 , 类似文件的目录一级一级索引，只有最底层的叶子节点[文件]保存数据，非叶子节点只保存索引，不保存实际的数据，数据都保存在叶子节点中,所有的非叶子节点都可以看成索引的一部分。</p></blockquote><ul><li><p><code>B+</code> 树的磁盘读写代价更低</p><blockquote><p><code>B+</code> 树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对 <code>B</code> 树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。</p></blockquote></li><li><p>B+树的查询效率更加稳定</p><blockquote><p>由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。</p></blockquote></li><li><p>方便</p><blockquote><p>由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。</p></blockquote></li></ul><h1 id="3-索引失效"><a href="#3-索引失效" class="headerlink" title="3. 索引失效"></a>3. 索引失效</h1><h4 id="3-1-索引进行表达式计算，则会失效"><a href="#3-1-索引进行表达式计算，则会失效" class="headerlink" title="3.1. 索引进行表达式计算，则会失效"></a>3.1. 索引进行表达式计算，则会失效</h4><h4 id="3-2-索引使用函数，也会造成失效"><a href="#3-2-索引使用函数，也会造成失效" class="headerlink" title="3.2. 索引使用函数，也会造成失效"></a>3.2. 索引使用函数，也会造成失效</h4><h4 id="3-3-在-WHERE-子句中，如果在-OR-前的条件列进行了索引，而在-OR-后的条件列没有进行索引，那么索引会失效。"><a href="#3-3-在-WHERE-子句中，如果在-OR-前的条件列进行了索引，而在-OR-后的条件列没有进行索引，那么索引会失效。" class="headerlink" title="3.3. 在 WHERE 子句中，如果在 OR 前的条件列进行了索引，而在 OR 后的条件列没有进行索引，那么索引会失效。"></a>3.3. 在 WHERE 子句中，如果在 OR 前的条件列进行了索引，而在 OR 后的条件列没有进行索引，那么索引会失效。</h4><h4 id="3-4-使用-LIKE-进行模糊查询的时候-‘-’"><a href="#3-4-使用-LIKE-进行模糊查询的时候-‘-’" class="headerlink" title="3.4. 使用 LIKE 进行模糊查询的时候 ‘%***’"></a>3.4. 使用 LIKE 进行模糊查询的时候 ‘%***’</h4><h4 id="3-5-索引列尽量设置为-NOT-NULL-约束"><a href="#3-5-索引列尽量设置为-NOT-NULL-约束" class="headerlink" title="3.5. 索引列尽量设置为 NOT NULL 约束"></a>3.5. 索引列尽量设置为 NOT NULL 约束</h4><p>MySQL 官方文档建议尽量将数据表的字段设置为 NOT NULL 约束，这样可以更好地使用索引，节省空间，甚至加速 SQL 的运行。判断索引列是否为 NOT NULL，往往需要走全表扫描，因此最好在设计数据表的时候就将字段设置为 NOT NULL 约束,可以将 INT 类型的字段，默认值设置为 0。将字符类型的默认值设置为空字符串 (‘’)</p><h4 id="3-6-在使用联合索引的时候要注意最左原则"><a href="#3-6-在使用联合索引的时候要注意最左原则" class="headerlink" title="3.6. 在使用联合索引的时候要注意最左原则"></a>3.6. 在使用联合索引的时候要注意最左原则</h4><h2 id="3-如何创建高性能索引？"><a href="#3-如何创建高性能索引？" class="headerlink" title="3. 如何创建高性能索引？"></a>3. 如何创建高性能索引？</h2><h3 id="3-1-最左前缀匹配原则"><a href="#3-1-最左前缀匹配原则" class="headerlink" title="3.1. 最左前缀匹配原则"></a>3.1. <strong>最左前缀匹配原则</strong></h3>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis 事件</title>
      <link href="2019/07/15/Redis-%E4%BA%8B%E4%BB%B6/"/>
      <url>2019/07/15/Redis-%E4%BA%8B%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 Redis 中存在两种方式的备份：一种是快照恢复(RDB)，通过快照（snapshotting）实现，它是备份当前瞬间 Redis 在内存中的数据记录。</p><p>另一种是只追加文件（Append-Only File，AOF），其作用就是当 Redis 执行写命令后，在一定的条件下将执行过的写命令依次保存在 Redis 的文件中，将来就可以依次执行那些保存的命令恢复 Redis 的数据了。</p><a id="more"></a><p>虽然跟 AOF 相比, 快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销，</p><p>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。</p><p>快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p><img src="../images/hello.jpg" alt="hello" style="zoom:150%;" />]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 持久化</title>
      <link href="2019/07/15/Redis-%E6%8C%81%E4%B9%85%E5%8C%96-%E6%B7%B7%E5%90%88%E5%A4%87%E4%BB%BD/"/>
      <url>2019/07/15/Redis-%E6%8C%81%E4%B9%85%E5%8C%96-%E6%B7%B7%E5%90%88%E5%A4%87%E4%BB%BD/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 Redis 中存在两种方式的备份：一种是快照恢复(RDB)，通过快照（snapshotting）实现，它是备份当前瞬间 Redis 在内存中的数据记录。</p><p>另一种是只追加文件（Append-Only File，AOF），其作用就是当 Redis 执行写命令后，在一定的条件下将执行过的写命令依次保存在 Redis 的文件中，将来就可以依次执行那些保存的命令恢复 Redis 的数据了。</p><a id="more"></a><p>虽然跟 AOF 相比, 快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销，</p><p>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。</p><p>快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 持久化</title>
      <link href="2019/07/15/Redis-%E6%8C%81%E4%B9%85%E5%8C%96AOF/"/>
      <url>2019/07/15/Redis-%E6%8C%81%E4%B9%85%E5%8C%96AOF/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 Redis 中存在两种方式的备份：一种是快照恢复(RDB)，通过快照（snapshotting）实现，它是备份当前瞬间 Redis 在内存中的数据记录。</p><p>另一种是只追加文件（Append-Only File，AOF），其作用就是当 Redis 执行写命令后，在一定的条件下将执行过的写命令依次保存在 Redis 的文件中，将来就可以依次执行那些保存的命令恢复 Redis 的数据了。</p><a id="more"></a><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>如果数据很重要无法承受任何损失，可以考虑使用 AOF 方式进行持久化，默认 Redis 没有开启AOF(append only file)方式的全持久化模式。</p><p>数据库的写前日志(Write Ahead Log, WAL) 在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。AOF 日志相反, 是写后日志，Redis 是先执行命令，把数据写入内存，然后才记录日志。</p><blockquote><p> AOF 为什么要先执行命令再记日志呢？</p></blockquote><p>为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。不过，AOF 也有两个潜在的风险。首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。</p><h1 id="2-原理"><a href="#2-原理" class="headerlink" title="2. 原理"></a>2. 原理</h1><p>在启动时 Redis 会逐个执行 AOF 文件中的命令来将硬盘中的数据载入到内存中，载入的速度相较RDB会慢一些，开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改该名称。</p><p>Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。此时重新启动Redis后Redis会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少，可以在redis.conf中通过appendonly参数开启Redis AOF全持久化模式</p><p>主要有两种方式触发：有写操作就写、每秒定时写（也会丢数据）。</p><p>因为AOF采用追加的方式，所以文件会越来越大，针对这个问题，新增了重写机制，就是当日志文件大到一定程度的时候，会fork出一条新进程来遍历进程内存中的数据，每条记录对应一条set语句，写到临时文件中，然后再替换到旧的日志文件（类似rdb的操作方式）。默认触发是当aof文件大小是上次重写后大小的一倍且文件大于64M时触发。</p><p>当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。一般情况下，只要使用默认开启的RDB即可，因为相对于AOF，RDB便于进行数据库备份，并且恢复数据集的速度也要快很多。</p><p>开启持久化缓存机制，对性能会有一定的影响，特别是当设置的内存满了的时候，更是下降到几百reqs/s。所以如果只是用来做缓存的话，可以关掉持久化。</p><h1 id="3-写回策略"><a href="#3-写回策略" class="headerlink" title="3.写回策略"></a>3.写回策略</h1><ol><li>Always: 同步写回：每个写命令执行完，立马同步地将日志写回磁盘</li><li>Everysec: 每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘</li><li>No: 操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li></ol><p>针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美</p><ol><li><p>同步写回可</p><p>以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能；</p></li><li><p>操作系统控制的写回</p><p>在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了；</p></li><li><p>每秒写回</p><p>采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。</p></li></ol><p>想要获得高性能，就选择 No 策略；如果想要得到高可靠性保证，就选择 Always 策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略</p><h1 id="4-重写机制"><a href="#4-重写机制" class="headerlink" title="4. 重写机制"></a>4. 重写机制</h1><p>AOF 是以文件的形式在记录接收到的所有写命令。随着接收的写命令越来越多，AOF 文件会越来越大，文件过大会带来的性能问题。</p><p>性能问题主要在于以下三个方面</p><ol><li>文件系统本身对文件大小有限制，无法保存过大的文件</li><li>如果文件太大，之后再往里面追加命令记录的话，效率也会变低</li><li>如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，会影响到 Redis 的正常使用</li></ol><p>AOF 文件是以追加的方式，逐一记录接收到的写命令的。当一个键值对被多条写命令反复修改时，AOF 文件会记录相应的多条命令。但是，在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用一条命令就行了，而且，在日志恢复时，只用执行这条命令，就可以直接完成这个键值对的写入</p><p>虽然 AOF 重写后，日志文件会缩小，但是，要把整个数据库的最新数据的操作日志都写回磁盘，仍然是一个非常耗时的过程。</p><h2 id="4-1-重写实现"><a href="#4-1-重写实现" class="headerlink" title="4.1. 重写实现"></a>4.1. 重写实现</h2><h2 id="4-2-AOF-后台重写"><a href="#4-2-AOF-后台重写" class="headerlink" title="4.2. AOF 后台重写"></a>4.2. AOF 后台重写</h2><h3 id="1-4-AOF-重写会阻塞吗"><a href="#1-4-AOF-重写会阻塞吗" class="headerlink" title="1.4. AOF 重写会阻塞吗?"></a>1.4. AOF 重写会阻塞吗?</h3><p>和 AOF 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。</p><p>重写的过程总结为**<font color='blue'>“一个拷贝，两处日志”</font>**。</p><ol><li><p><strong>一个拷贝</strong></p><p>是指每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。</p></li><li><p><strong>两处日志</strong></p><p>因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。</p></li></ol><p>每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 持久化</title>
      <link href="2019/07/15/Redis-%E6%8C%81%E4%B9%85%E5%8C%96RDB/"/>
      <url>2019/07/15/Redis-%E6%8C%81%E4%B9%85%E5%8C%96RDB/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 Redis 中存在两种方式的备份：一种是快照恢复(RDB)，通过快照（snapshotting）实现，它是备份当前瞬间 Redis 在内存中的数据记录。</p><p>另一种是只追加文件（Append-Only File，AOF），其作用就是当 Redis 执行写命令后，在一定的条件下将执行过的写命令依次保存在 Redis 的文件中，将来就可以依次执行那些保存的命令恢复 Redis 的数据了。</p><a id="more"></a><p>AOF 因为记录的是操作命令，而不是实际的数据，所以，用 AOF 方法进行故障恢复的时候，需要逐一把操作日志都执行一遍。如果操作日志非常多，Redis 就会恢复得很缓慢。</p><p>把某一时刻的状态以文件的形式写到磁盘上，也就是快照。这样一来，即使宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。这个快照文件就称为 RDB 文件，其中，RDB 就是 Redis DataBase 的缩写.</p><p>和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复。</p><h2 id="1-备份时机"><a href="#1-备份时机" class="headerlink" title="1. 备份时机"></a>1. 备份时机</h2><p>半持久化 RDB 模式是 Redis 备份默认方式，是通过快照(snapshotting)完成的，当符合在 Redis.conf 配置文件中设置的条件时 Redis 会自动将内存中的所有数据进行快照并存储在硬盘上，完成数据备份。</p><p>Redis进行 RDB 快照的条件由用户在配置文件中自定义，由两个参数构成: <strong><font color='blue'>[时间]</font>**和</strong><font color='blue'>[改动的键的个数]</font>**。当在指定的时间内被更改的键的个数大于指定的数值时就会进行快照。</p><h2 id="2-原理"><a href="#2-原理" class="headerlink" title="2. 原理"></a>2. 原理</h2><p>Redis 实现快照的过程, Redis 使用 fork 函数复制一份当前进程(父进程)的副本(子进程), 父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件，当子进程写入完所有数据后会用该临时文件替换旧的 RDB 文件，至此一次快照操作完成。</p><blockquote><p>执行 fork 的时操作系统会使用写时复制(copy-on-write)策略，即 fork 函数发生的一刻父子进程共享同一内存数据，当父进程要更改其中某片数据时, 操作系统会将该片数据复制一份以保证子进程的数据不受影响, 所以新的RDB文件存储的是执行 fork 一刻的内存数据。</p></blockquote><p>Redis 在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。这使得我们可以通过定时备份RDB文件来实 现Redis数据库备份。</p><p>RDB 文件是经过压缩(可以配置 rdbcompression 参数以禁用压缩节省 CPU 占用) 的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。</p><p>除了自动快照，还可以手动发送 SAVE 和 BGSAVE 命令让 Redis 执行快照，两个命令的区别在于，前者是由主进程进行快照操作，会阻塞住其他请求，后者会通过 fork 子进程进行快照操作。</p><blockquote><p>注: 通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。此时需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受的范围。</p></blockquote><h5 id="可以每秒做一次快照吗？"><a href="#可以每秒做一次快照吗？" class="headerlink" title="可以每秒做一次快照吗？"></a><font color='BLUE'><strong>可以每秒做一次快照吗？</strong></font></h5><p>如果频繁地执行全量快照，也会带来两方面的开销。</p><ol><li>频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。</li><li>bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。</li></ol><h3 id="2-4-增量快照"><a href="#2-4-增量快照" class="headerlink" title="2.4. 增量快照"></a>2.4. 增量快照</h3><p>增量快照是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。</p><h2 id="3-混合备份"><a href="#3-混合备份" class="headerlink" title="3. 混合备份"></a>3. 混合备份</h2><p>虽然跟 AOF 相比, 快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销，</p><p>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。</p><p>快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 事件</title>
      <link href="2019/07/15/%E8%84%91%E8%A3%82/"/>
      <url>2019/07/15/%E8%84%91%E8%A3%82/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>脑裂，就是指在主从集群中，同时有两个主节点，它们都能接收写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据。而且，严重的话，脑裂会进一步导致数据丢失。</p><a id="more"></a><h2 id="2-1-为什么会发生脑裂？"><a href="#2-1-为什么会发生脑裂？" class="headerlink" title="2.1. 为什么会发生脑裂？"></a>2.1. 为什么会发生脑裂？</h2>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 故障诊断_如何在日志中轻松定位大事务？</title>
      <link href="2019/07/15/%E5%A6%82%E4%BD%95%E5%9C%A8%E6%97%A5%E5%BF%97%E4%B8%AD%E8%BD%BB%E6%9D%BE%E5%AE%9A%E4%BD%8D%E5%A4%A7%E4%BA%8B%E5%8A%A1/"/>
      <url>2019/07/15/%E5%A6%82%E4%BD%95%E5%9C%A8%E6%97%A5%E5%BF%97%E4%B8%AD%E8%BD%BB%E6%9D%BE%E5%AE%9A%E4%BD%8D%E5%A4%A7%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 MySQL 中，事务是由一条或多条 SQL 组成的单位，在这个单位中所有的 SQL 共存亡，要么全部成功，事务顺利完成；要么只要有一个 SQL 失败就会导致整个事务失败，所有已经做过的操作回退到原始数据状态。</p><a id="more"></a><h2 id="如何分析-MySQL-的日志"><a href="#如何分析-MySQL-的日志" class="headerlink" title="如何分析 MySQL 的日志?"></a>如何分析 MySQL 的日志?</h2><h2 id="定位日志中的大事务"><a href="#定位日志中的大事务" class="headerlink" title="定位日志中的大事务"></a>定位日志中的大事务</h2>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis 事务</title>
      <link href="2019/07/13/Redis-%E4%BA%8B%E5%8A%A1/"/>
      <url>2019/07/13/Redis-%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>和其他大部分的 NoSQL 不同，Redis 是存在事务的，尽管没有关系型数据库强大，但是在那些需要高并发的网站当中，还是很有用。</p><p>MULTI、EXEC、DISCARD 和 WATCH 命令是 Redis 事务功能的基础。Redis 事务允许在一次单独的步骤中执行一组命令。</p><a id="more"></a><p>在 Redis 中，存在多个客户端同时向 Redis 系统发送命令的并发可能性，因此同一个数据，可能在不同的时刻被不同的线程所操纵，这样就出现了并发下的数据一致问题。为了保证数据的安全性，Redis 提供了事务机制。Redis 的事务是使用 <strong>MULTI-EXEC</strong> 的命令组合，使用它可以提供两个重要的保证：</p><ul><li>事务是一个被隔离的操作，事务中的方法都会被 Redis 进行序列化并按顺序执行，事务在执行的过程中不会被其他客户端发生的命令所打断。</li><li>事务是一个原子性的操作，它要么全部执行，要么就什么都不执行。</li></ul><h2 id="2-相关命令"><a href="#2-相关命令" class="headerlink" title="2. 相关命令"></a>2. 相关命令</h2><h2 id="2-1-MULTI"><a href="#2-1-MULTI" class="headerlink" title="2.1. MULTI"></a>2.1. MULTI</h2><p>用于标记事务块的开始。Redis 会将后续的命令逐个放入队列中，然后才能使用 EXEC 命令原子化地执行这个命令序列。</p><p>这个命令的运行格式如下所示：</p><p>MULTI</p><p>这个命令的返回值是一个简单的字符串，总是OK。</p><h2 id="2-2-EXEC"><a href="#2-2-EXEC" class="headerlink" title="2.2. EXEC"></a>2.2. EXEC</h2><p>在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态。</p><p>当使用WATCH命令时，只有当受监控的键没有被修改时，EXEC命令才会执行事务中的命令，这种方式利用了检查再设置（CAS）的机制。</p><p>这个命令的运行格式如下所示：</p><p>EXEC</p><p>这个命令的返回值是一个数组，其中的每个元素分别是原子化事务中的每个命令的返回值。 当使用WATCH命令时，如果事务执行中止，那么EXEC命令就会返回一个Null值。</p><h2 id="2-3-DISCARD"><a href="#2-3-DISCARD" class="headerlink" title="2.3. DISCARD"></a>2.3. DISCARD</h2><p>清除所有先前在一个事务中放入队列的命令，然后恢复正常的连接状态。</p><p>如果使用了WATCH命令，那么DISCARD命令就会将当前连接监控的所有键取消监控。</p><p>这个命令的运行格式如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DISCARD</span><br></pre></td></tr></table></figure><p>这个命令的返回值是一个简单的字符串，总是OK。</p><h2 id="2-4-WATCH"><a href="#2-4-WATCH" class="headerlink" title="2.4. WATCH"></a>2.4. WATCH</h2><p>当某个事务需要按条件执行时，就要使用这个命令将给定的键设置为受监控的。</p><p>这个命令的运行格式如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WATCH key [key ...]</span><br></pre></td></tr></table></figure><p>这个命令的返回值是一个简单的字符串，总是OK。</p><p>对于每个键来说，时间复杂度总是O(1)。</p><h2 id="2-5-UNWATCH"><a href="#2-5-UNWATCH" class="headerlink" title="2.5. UNWATCH"></a>2.5. UNWATCH</h2><p>清除所有先前为一个事务监控的键。</p><p>如果你调用了EXEC或DISCARD命令，那么就不需要手动调用UNWATCH命令。</p><p>这个命令的运行格式如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UNWATCH</span><br></pre></td></tr></table></figure><p>这个命令的返回值是一个简单的字符串，总是OK。</p><p>时间复杂度总是O(1)。</p><h2 id="3-Redis-的事务机制能保证哪些属性？"><a href="#3-Redis-的事务机制能保证哪些属性？" class="headerlink" title="3. Redis 的事务机制能保证哪些属性？"></a>3. Redis 的事务机制能保证哪些属性？</h2><h3 id="3-1-原子性"><a href="#3-1-原子性" class="headerlink" title="3.1. 原子性"></a>3.1. 原子性</h3><p>如果事务正常执行，没有发生任何错误，MULTI 和 EXEC 配合使用，就可以保证多个操作都完成。</p><p>如果事务执行发生错误了，原子性还能保证吗？</p><h4 id="3-1-1-在执行-EXEC-命令前，客户端发送的操作命令本身就有错误"><a href="#3-1-1-在执行-EXEC-命令前，客户端发送的操作命令本身就有错误" class="headerlink" title="3.1.1. 在执行 EXEC 命令前，客户端发送的操作命令本身就有错误"></a>3.1.1. 在执行 EXEC 命令前，客户端发送的操作命令本身就有错误</h4><p>在执行 EXEC 命令前，客户端发送的操作命令本身就有错误(比如语法错误，使用了不存在的命令)，在命令入队时就被 Redis 实例判断出来</p><p>对于这种情况，在命令入队时，Redis 就会报错并且记录下这个错误。此时，客户端还能继续提交命令操作。执行 EXEC 命令之后，Redis 就会拒绝执行所有提交的命令操作，返回事务失败的结果。事务中的所有命令都不会再被执行了，保证了原子性。</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">root@e0defba94e44:/data<span class="comment"># redis-cli</span></span><br><span class="line">127.0.0.1:6379&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> hello world</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; set1</span><br><span class="line">(error) ERR unknown <span class="built_in">command</span> `set1`, with args beginning with:</span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> hello2 redis</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; <span class="built_in">exec</span></span><br><span class="line">(error) EXECABORT Transaction discarded because of previous errors.</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><p>事务里包含了一个 Redis 本身就不支持的 <code>set1</code> 命令，所以，在 <code>set1</code> 命令入队时，Redis 就报错了。虽然，事务里还有一个正确的 set 命令，但是，在最后执行 EXEC 命令后，整个事务被放弃执行了。</p><h4 id="3-1-2-事务操作入队时，命令和操作的数据类型不匹配，但-Redis-实例没有检查出错误。"><a href="#3-1-2-事务操作入队时，命令和操作的数据类型不匹配，但-Redis-实例没有检查出错误。" class="headerlink" title="3.1.2. 事务操作入队时，命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误。"></a>3.1.2. 事务操作入队时，命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误。</h4><p>第一种情况不同的是，事务操作入队时，命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误。但是，在执行完 EXEC 命令以后，Redis 实际执行这些事务操作时，就会报错。不过，需要注意的是，虽然 Redis 会对错误命令报错，但还是会把正确的命令执行完。在这种情况下，事务的原子性就无法得到保证了。</p><p>传统数据库(例如 MySQL)在执行事务时，会提供回滚机制，当事务执行发生错误时，事务中的所有操作都会撤销，已经修改的数据也会被恢复到事务执行前的状态，然而 Redis 中并没有提供回滚机制。虽然 Redis 提供了 DISCARD 命令，但是，这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。</p><h4 id="3-1-3-在执行事务的-EXEC-命令时，Redis-实例发生了故障，导致事务执行失败。"><a href="#3-1-3-在执行事务的-EXEC-命令时，Redis-实例发生了故障，导致事务执行失败。" class="headerlink" title="3.1.3. 在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败。"></a>3.1.3. 在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败。</h4><p>如果 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。使用 <code>redis-check-aof</code> 工具检查 AOF 日志文件，这个工具可以把未完成的事务操作从 AOF 文件中去除。这样使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性。如果 AOF 日志并没有开启，实例重启后，数据也都没法恢复了，此时，也就谈不上原子性了。</p><h4 id="3-1-4-总结"><a href="#3-1-4-总结" class="headerlink" title="3.1.4. 总结"></a>3.1.4. 总结</h4><ol><li>命令入队时就报错，会放弃事务执行，保证原子性</li><li>命令入队时没报错，实际执行时报错，不保证原子性</li><li>EXEC 命令执行时实例故障，如果开启了 AOF 日志，可以保证原子性。</li></ol><h3 id="3-2-一致性"><a href="#3-2-一致性" class="headerlink" title="3.2. 一致性"></a>3.2. 一致性</h3><p>事务的一致性保证会受到错误命令、实例故障的影响。所以，按照命令出错和实例故障的发生时机，分成三种情况来看。</p><h4 id="3-2-1-命令入队时报错"><a href="#3-2-1-命令入队时报错" class="headerlink" title="3.2.1. 命令入队时报错"></a>3.2.1. 命令入队时报错</h4><p>在这种情况下，事务本身就会被放弃执行，所以可以保证数据库的一致性。</p><h4 id="3-2-2-命令入队时没报错，实际执行时报错"><a href="#3-2-2-命令入队时没报错，实际执行时报错" class="headerlink" title="3.2.2. 命令入队时没报错，实际执行时报错"></a>3.2.2. 命令入队时没报错，实际执行时报错</h4><p>在这种情况下，有错误的命令不会被执行，正确的命令可以正常执行，也不会改变数据库的一致性。</p><h4 id="3-2-3-EXEC-命令执行时实例发生故障"><a href="#3-2-3-EXEC-命令执行时实例发生故障" class="headerlink" title="3.2.3. EXEC 命令执行时实例发生故障"></a>3.2.3. EXEC 命令执行时实例发生故障</h4><p>实例故障后会进行重启，根据实例是否开启了 RDB 或 AOF 来分情况讨论下。如果没有开启 RDB 或 AOF，那么，实例故障重启后，数据都没有了，数据库是一致的。如果使用了 RDB 快照，因为 RDB 快照不会在事务执行时执行，所以，事务命令操作的结果不会被保存到 RDB 快照中，使用 RDB 快照进行恢复时，数据库里的数据也是一致的。如果我们使用了 AOF 日志，而事务操作还没有被记录到 AOF 日志时，实例就发生了故障，那么，使用 AOF 日志恢复的数据库数据是一致的。如果只有部分操作被记录到了 AOF 日志，可以使用 redis-check-aof 清除事务中已经完成的操作，数据库恢复后也是一致的。所以，总结来说，在命令执行错误或 Redis 发生故障的情况下，Redis 事务机制对一致性属性是有保证的。</p><h3 id="3-3-隔离性"><a href="#3-3-隔离性" class="headerlink" title="3.3. 隔离性"></a>3.3. 隔离性</h3><p>事务的隔离性保证，会受到和事务一起执行的并发操作的影响。而事务执行又可以分成命令入队(EXEC 命令执行前)和命令实际执行(EXEC 命令执行后)两个阶段，所以，针对这两个阶段，分成两种情况来分析：</p><ol><li>并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证</li><li>并发操作在 EXEC 命令后执行，此时，隔离性可以保证。</li></ol><p>WATCH 机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。</p><h3 id="3-4-持久性"><a href="#3-4-持久性" class="headerlink" title="3.4. 持久性"></a>3.4. 持久性</h3>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 数据类型</title>
      <link href="2019/07/12/Redis-%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/"/>
      <url>2019/07/12/Redis-%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>字符串是 Redis 中最为常见的数据存储类型，其底层实现是简单动态字符串 <strong>sds</strong> (simple dynamic string)，是可以修改的字符串。它类似于Java中的ArrayList，它采用预分配冗余空间的方式来减少内存的频繁分配。</p><p>数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存</p><a id="more"></a><h1 id="缓存的特征"><a href="#缓存的特征" class="headerlink" title="缓存的特征"></a>缓存的特征</h1><p>一个系统中的不同层之间的访问速度不一样，所以我们才需要缓存，这样就可以把一些需要频繁访问的数据放在缓存中，以加快它们的访问速度。</p><p>CPU、内存和磁盘这三层的访问速度从几十 ns 到 100ns，再到几 ms，性能的差异很大。如果每次 CPU 处理数据时，都要从 ms 级别的慢速磁盘中读取数据，然后再进行处理，那么，CPU 只能等磁盘的数据传输完成。这样一来，高速的 CPU 就被慢速的磁盘拖累了，整个计算机系统的运行速度会变得非常慢</p><p>计算机系统中，默认有两种缓存：</p><ol><li>CPU 里面的末级缓存，即 LLC, 用来缓存内存中的数据，避免每次从内存中存取数据</li><li>内存中的高速页缓存，即 page cache, 用来缓存磁盘中的数据，避免每次从磁盘中存取数据</li></ol>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 数据类型</title>
      <link href="2019/07/12/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B(2)_String/"/>
      <url>2019/07/12/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B(2)_String/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>字符串是 Redis 中最为常见的数据存储类型，其底层实现是简单动态字符串 <strong>sds</strong> (simple dynamic string)，是可以修改的字符串。它类似于Java中的ArrayList，它采用预分配冗余空间的方式来减少内存的频繁分配。</p><p>数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存</p><a id="more"></a><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>sds本质分为三部分：<strong>header、buf、null结尾符</strong>，其中header可以认为是整个sds的指引部分，给定了使用的空间大小、最大分配大小等信息</p><h3 id="sds"><a href="#sds" class="headerlink" title="sds"></a>sds</h3><h3 id="sds-的优势"><a href="#sds-的优势" class="headerlink" title="sds 的优势"></a>sds 的优势</h3><ul><li><strong>O(1)获取长度</strong>: C字符串需要遍历而sds中有len可以直接获得；</li><li><strong>防止缓冲区溢出bufferoverflow</strong>: 当sds需要对字符串进行修改时，首先借助于len和alloc检查空间是否满足修改所需的要求，如果空间不够的话，SDS会自动扩展空间，避免了像C字符串操作中的覆盖情况；</li><li><strong>有效降低内存分配次数</strong>：C字符串在涉及增加或者清除操作时会改变底层数组的大小造成重新分配、sds使用了空间预分配和惰性空间释放机制，说白了就是每次在扩展时是成倍的多分配的，在缩容是也是先留着并不正式归还给OS，这两个机制也是比较好理解的；</li><li><strong>二进制安全</strong>：C语言字符串只能保存ascii码，对于图片、音频等信息无法保存，sds是二进制安全的，写入什么读取就是什么，不做任何过滤和限制；</li></ul><h2 id="String-类型内存开销"><a href="#String-类型内存开销" class="headerlink" title="String 类型内存开销"></a>String 类型内存开销</h2><p>String 类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大</p><p>在 SDS 中，buf 保存实际数据，而 len 和 alloc 本身其实是 SDS 结构体的额外开销。另外，对于 String 类型来说，除了 SDS 的额外开销，还有一个来自于 RedisObject 结构体的开销。</p><h3 id="RedisObject"><a href="#RedisObject" class="headerlink" title="RedisObject"></a>RedisObject</h3><p>因为 Redis 的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据。</p><p>一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向 String 类型的 SDS 结构所在的内存地址。</p><p>为了节省内存空间，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。</p><ol><li>一方面，当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。</li><li>另一方面，当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。</li><li>当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。</li></ol><p>Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节，</p><p>jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。</p><blockquote><p>如果申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字节空间，jemalloc 则会分配 32 字节。所以，在我们刚刚说的场景里，dictEntry 结构就占用了 32 字节。</p></blockquote><p>用什么数据结构可以节省内存？</p><h2 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h2><p>Redis 有一种底层数据结构，叫压缩列表（ziplist），这是一种非常节省内存的结构。</p><h3 id="压缩列表构成"><a href="#压缩列表构成" class="headerlink" title="压缩列表构成"></a>压缩列表构成</h3><p>表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表结束。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2019/07/12/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B(1)_%E6%A6%82%E8%BF%B0/"/>
      <url>2019/07/12/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B(1)_%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Redis 是一种基于内存的数据库，并且提供一定的持久化功能，它是一种键值（key-value）数据库，使用 key 作为索引找到当前缓存的数据，并且返回给程序调用者。</p><a id="more"></a><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>目前 Redis 支持 6 种数据类型：字符串（String）、列表（List）、集合（set）、哈希结构（hash）、有序集合（zset）和基数（HyperLogLog）</p><table><thead><tr><th align="center">数据类型</th><th align="center">数据类型存储的值</th><th align="center">说 明</th></tr></thead><tbody><tr><td align="center"><strong>STRING</strong>（字符串）</td><td align="center">可以是保存字符串、整数和浮点数</td><td align="center">可以对字符串进行操作，比如增加字符或者求子串：如果是整数或者浮点数，可以实现计算，比如自增等</td></tr><tr><td align="center"><strong>LIST</strong>（列表）</td><td align="center">它是一个链表，它的每一个节点都包含一个字符串</td><td align="center">Redis 支持从链表的两端插入或者弹出节点，或者通过偏移对它进行裁剪；还可以读取一个或者多个节点，根据条件删除或者查找节点等</td></tr><tr><td align="center"><strong>SET</strong>（集合）</td><td align="center">它是一个收集器，但是是无序的，在它里而每一个元素都是一个字符串，而且是独一无二，各不相同的</td><td align="center">可以新增、读取、删除单个元素：检测一个元素是否在集合中；计算它和其他集合的交集、并集和差集等；随机从集合中读取元素</td></tr><tr><td align="center"><strong>HASH</strong>（哈希表）</td><td align="center">它类似于 Java 语言中的 Map，是一个键值对应的无序列表</td><td align="center">可以増、删、査、改单个键值对，也可以获取所有的键值对</td></tr><tr><td align="center"><strong>ZSET</strong>（有序集合）</td><td align="center">它是一个有序的集合，可以包含字符 串、整数、浮点数、分值（score），元素 的排序是依据分值的大小来决定的</td><td align="center">可以增、删、査、改元素，根据分值的范围或者成员 來获取对应的元索</td></tr><tr><td align="center"><strong>HyperLogLog</strong>（基数）</td><td align="center">它的作用是计算重复的值，以确定存储的数量</td><td align="center">只提供基数的运算，不提供返回的功能</td></tr></tbody></table><h1 id="2-String"><a href="#2-String" class="headerlink" title="2. String"></a>2. <strong>String</strong></h1><h2 id="2-1-基本运算"><a href="#2-1-基本运算" class="headerlink" title="2.1. 基本运算"></a>2.1. 基本运算</h2><table><thead><tr><th>命 令</th><th>说 明</th><th>备 注</th></tr></thead><tbody><tr><td><strong>set</strong> key value</td><td>设置键值对</td><td>最常用的写入命令</td></tr><tr><td><strong>get</strong> key</td><td>通过键获取值</td><td>最常用的读取命令</td></tr><tr><td><strong>del</strong> key</td><td>通过 key，删除键值对</td><td>删除命令，返冋删除数，注意，它是个通用的命令，换句话说在其他数据结构中，也可以使用它</td></tr><tr><td><strong>strlen</strong> key</td><td>求 key 指向字符串的长度</td><td>返回长度</td></tr><tr><td><strong>getset</strong> key value</td><td>修改原来 key 的对应值，并将旧值返回</td><td>如果原来值为空，则返回为空，并设置新值</td></tr><tr><td><strong>getrange</strong> key start end</td><td>获取子串</td><td>记字符串的长度为 len，把字符串看作一个数组，而 Redis 是以 0 开始计数的，所以 start 和 end 的取值范围 为 0 到 len-1</td></tr><tr><td><strong>append</strong> key value</td><td>将新的字符串 value，加入到原来 key 指向的字符串末</td><td>返回 key 指向新字符串的长度</td></tr></tbody></table><p>Redis 除了这些之外还提供了对整数和浮点型数字的功能。如果字符串是数字（整数或者浮点数），那么 Redis 还能支持简单的运算。不过它的运算能力比较弱，目前版本只能支持简单的加减法运算</p><table><thead><tr><th>incr key</th><th>在原字段上加 1</th><th>只能对整数操作</th></tr></thead><tbody><tr><td><strong>incrby</strong> key increment</td><td>在原字段上加上整数（increment）</td><td>只能对整数操作</td></tr><tr><td><strong>decr</strong> key</td><td>在原字段上减 1</td><td>只能对整数操作</td></tr><tr><td><strong>decrby</strong> key decrement</td><td>在原字段上减去整数（decrement）</td><td>只能对整数操作</td></tr><tr><td><strong>incrbyfloat</strong> keyincrement</td><td>在原字段上加上浮点数（increment）</td><td>可以操作浮点数或者整数</td></tr></tbody></table><h2 id="2-2-应用场景"><a href="#2-2-应用场景" class="headerlink" title="2.2. 应用场景"></a>2.2. 应用场景</h2><h3 id="2-2-1-计数功能"><a href="#2-2-1-计数功能" class="headerlink" title="2.2.1. 计数功能"></a>2.2.1. 计数功能</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">incr article:001</span><br><span class="line">get article:001</span><br></pre></td></tr></table></figure><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-17 下午5.40.19.png" alt="截屏2021-03-17 下午5.40.19" style="zoom:50%;" /><h3 id="2-2-2-单机或分布式下的标识号"><a href="#2-2-2-单机或分布式下的标识号" class="headerlink" title="2.2.2. 单机或分布式下的标识号"></a>2.2.2. 单机或分布式下的标识号</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">incrby serialNo 1000</span><br></pre></td></tr></table></figure><h3 id="2-2-3-集群环境下的-session-共享"><a href="#2-2-3-集群环境下的-session-共享" class="headerlink" title="2.2.3. 集群环境下的 session 共享"></a>2.2.3. 集群环境下的 session 共享</h3><h2 id="LIST"><a href="#LIST" class="headerlink" title="LIST"></a><strong>LIST</strong></h2><p>链表结构是 Redis 中一个常用的结构，它可以存储多个字符串，而且它是有序的，能够存储 2<sup>32</sup>-1 个节点</p><p>Redis 链表是双向的，因此即可以从左到右，也可以从右到左遍历它存储的节点，</p><p>由于是双向链表，所以只能够从左到右，或者从右到左地访问和操作链表里面的数据节点。但是使用链表结构就意味着读性能的丧失，所以要在大量数据中找到一个节点的操作性能是不佳的，因为链表只能从一个方向中去遍历所要节点。</p><p>比如从查找节点 10000 开始查询，它需要按照节点 1、节点 2、节点 3……直至节点 10 000，这样的顺序查找，然后把一个个节点和你给出的值比对，才能确定节点所在。如果这个链表很大，如有上百万个节点，可能需要遍历几十万次才能找到所需要的节点，显然查找性能是不佳的。</p><p>而链表结构的优势在于插入和删除的便利，因为链表的数据节点是分配在不同的内存区域的，并不连续，只是根据上一个节点保存下一个节点的顺序来索引而已，无需移动元素。</p><h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><table><thead><tr><th>命  令</th><th>说  明</th><th>备  注</th></tr></thead><tbody><tr><td><strong>lpush</strong> key node1 [node2.]…..</td><td>把节点 node1 加入到链表最左边</td><td>如果是 node1、node2 …nodeN 这样加入， 那么链表开头从左到右的顺序是 noden…node2、node1</td></tr><tr><td><strong>rpush</strong> key node1[node2]……</td><td>把节点 node1 加入到链表的最右边</td><td>如果是 node1、node2….noden 这样加 入，那么链表结尾从左到右的顺序是 node1、node2,node3…noden</td></tr><tr><td><strong>lindex</strong> key index</td><td>读取下标为 index 的节点</td><td>返回节点字符串，从 0 开始算</td></tr><tr><td><strong>llen</strong> key</td><td>求链表的长度</td><td>返回链表节点数</td></tr><tr><td><strong>lpop</strong> key</td><td>删除左边第一个节点，并将其返回</td><td>——</td></tr><tr><td><strong>rpop</strong> key</td><td>删除右边第一个节点，并将其返回</td><td>——</td></tr><tr><td><strong>linsert</strong> key <strong>before|after</strong> pivot node</td><td>插入一个节点 node，并且可以指定在值为pivot 的节点的前面（before）或者后面（after)）</td><td>如果 list 不存在，则报错；如果没有值为对应 pivot 的，也会插入失败返回 -1</td></tr><tr><td><strong>lpushx</strong> list node</td><td>如果存在 key 为 list 的链表，则插入节点 node, 并且作为从左到右的第一个节点</td><td>如果 list 不存在，则失败</td></tr><tr><td><strong>rpushx</strong> list node</td><td>如果存在 key 为 list 的链表，则插入节点 node，并且作为从左到右的最后个节点</td><td>如果 list 不存在，则失败</td></tr><tr><td><strong>lrange</strong> list start end</td><td>获取链表 list 从 start 下标到 end 下标的节点值</td><td>包含 start 和 end 下标的值</td></tr><tr><td><strong>lrem</strong> list count value</td><td>如果 count 为 0，则删除所有值等于 value 的节 点：如果 count 不是 0，则先对 count 取绝对值，假设记为 abs，然后从左到右删除不大于 abs 个等于 value 的节点</td><td>注意，count 为整数，如果是负数，则 Redis 会先求取其绝对值，然后传递到后台操作</td></tr><tr><td><strong>lset</strong> key index node</td><td>设置列表下标为 index 的节点的值为 node</td><td>——</td></tr><tr><td><strong>ltrim</strong> key start stop</td><td>修剪链表，只保留从 start 到 stop 的区间的节点，其余的都删除掉</td><td>包含 start 和 end 的下标的节点会保留</td></tr></tbody></table><p>对于大量数据操作的时候，我们需要考虑插入和删除内容的大小，因为这将是十分消耗性能的命令，会导致 Redis 服务器的卡顿。对于不允许卡顿的一些服务器，可以进行分批次操作，以避免出现卡顿。</p><p>需要指出的是，上面操作链表的命令都是进程不安全的，因为当我们操作这些命令的时候，其他 Redis 的客户端也可能操作同一个链表，这样就会造成并发数据安全和一致性的问题，尤其是当你操作一个数据量不小的链表结构时，常常会遇到这样的问题。</p><p>为了克服这些问题，Redis 提供了链表的阻塞命令，它们在运行的时候，会给链表加锁，以保证操作链表的命令安全性</p><table><thead><tr><th>命  令</th><th>说  明</th><th>备  注</th></tr></thead><tbody><tr><td><strong>blpop</strong> key timeout</td><td>移出并获取列表的第一个元索，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元索为止</td><td>相对于 lpop 命令，它的操作是进程安全的</td></tr><tr><td><strong>brpop</strong> key timeout</td><td>移出并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止</td><td>相对于 rpop 命令，它的操作是进程安全的</td></tr><tr><td><strong>rpoplpush</strong> key src dest</td><td>按从左到右的顺序，将一个链表的最后一个元素移除，并插入到目标链表最左边</td><td>不能设置超时时间</td></tr><tr><td><strong>brpoplpush</strong> key src dest timeout</td><td>按从左到右的顺序，将一个链表的最后一个元素移除，并插入到目标链表最左边，并可以设置超时时间</td><td>可设置超时时间</td></tr></tbody></table><p>当使用这些命令时，Redis 就会对对应的链表加锁，加锁的结果就是其他的进程不能再读取或者写入该链表，只能等待命令结束。加锁的好处可以保证在多线程并发环境中数据的一致性，保证一些重要数据的一致性，比如账户的金额、商品的数量。</p><p>不过在保证这些的同时也要付出其他线程等待、线程环境切换等代价，这将使得系统的并发能力下降</p><h2 id="HASH"><a href="#HASH" class="headerlink" title="HASH"></a>HASH</h2><p>Redis 中哈希结构就如同 Java 的 map 一样，一个对象里面有许多键值对，它是特别适合存储对象的，如果内存足够大，那么一个 Redis 的 hash 结构可以存储 2 的 32 次方减 1 个键值对（40 多亿）。</p><p>一般而言，不会使用到那么大的一个键值对，所以我们认为 Redis 可以存储很多的键值对。在 Redis 中，hash 是一个 String 类型的 field 和 value 的映射表，因此我们存储的数据实际在 Redis 内存中都是一个个字符串而已。</p><table><thead><tr><th>命  令</th><th>说  明</th><th>备  注</th></tr></thead><tbody><tr><td><strong>hdel</strong> key field1[field2……]</td><td>删除 hash 结构中的某个（些）字段</td><td>可以进行多个字段的删除</td></tr><tr><td><strong>hexists</strong> key field</td><td>判断 hash 结构中是否存在 field 字段</td><td>存在返回 1，否则返回 0</td></tr><tr><td><strong>hgetall</strong> key</td><td>获取所有 hash 结构中的键值</td><td>返回键和值</td></tr><tr><td><strong>hincrby</strong> key field increment</td><td>指定给 hash 结构中的某一字段加上一个整数</td><td>要求该字段也是整数字符串</td></tr><tr><td><strong>hincrbyfloat</strong> key field increment</td><td>指定给 hash 结构中的某一字段加上一个浮点数</td><td>要求该字段是数字型字符串</td></tr><tr><td><strong>hkeys</strong> key</td><td>返回 hash 中所有的键</td><td>——</td></tr><tr><td><strong>hlen</strong> key</td><td>返回 hash 中键值对的数量</td><td>——</td></tr><tr><td><strong>hmget</strong> key field1[field2……]</td><td>返回 hash 中指定的键的值，可以是多个</td><td>依次返回值</td></tr><tr><td><strong>hmset</strong> key field1 value1 [field2 field2……]</td><td>hash 结构设置多个键值对</td><td>——</td></tr><tr><td><strong>hset</strong> key filed value</td><td>在 hash 结构中设置键值对</td><td>单个设值</td></tr><tr><td><strong>hsetnx</strong> key field value</td><td>当 hash 结构中不存在对应的键，才设置值</td><td>——</td></tr><tr><td><strong>hvals</strong> key</td><td>获取 hash 结构中所有的值</td><td>——</td></tr></tbody></table><p>哈希结构的大小，如果哈希结构是个很大的键值对，那么使用它要十分注意，尤其是关于 hkeys、hgetall、hvals 等返回所有哈希结构数据的命令，会造成大量数据的读取。这需要考虑性能和读取数据大小对 JVM 内存的影响。</p><p>对于数字的操作命令 hincrby 而言，要求存储的也是整数型的字符串，对于 hincrbyfloat 而言，则要求使用浮点数或者整数，否则命令会失败。</p><h2 id="3-2-应用场景"><a href="#3-2-应用场景" class="headerlink" title="3.2. 应用场景"></a>3.2. 应用场景</h2><h3 id="3-2-1-电商网站购物车设计与实现"><a href="#3-2-1-电商网站购物车设计与实现" class="headerlink" title="3.2.1. 电商网站购物车设计与实现"></a>3.2.1. 电商网站购物车设计与实现</h3><p>每个商品入库的时候即会建立他的静态标签列表如，品牌，尺寸，处理器，内存</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-18 上午9.41.37.png" alt="截屏2021-03-18 上午9.41.37" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-18 上午9.43.52.png" alt="截屏2021-03-18 上午9.43.52" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-18 上午9.44.32.png" alt="截屏2021-03-18 上午9.44.32" style="zoom:50%;" /><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hmset 001 g01 100 g02 200</span><br><span class="line">127.0.0.1:6379&gt; hmset 002 g02 1 g04 7 g05 100</span><br><span class="line">127.0.0.1:6379&gt; hset 001 g03 5</span><br><span class="line">127.0.0.1:6379&gt; hgetall 001</span><br><span class="line">127.0.0.1:6379&gt; hdel 001 g01</span><br></pre></td></tr></table></figure><h3 id="3-2-2-单机或分布式下的标识号"><a href="#3-2-2-单机或分布式下的标识号" class="headerlink" title="3.2.2. 单机或分布式下的标识号"></a>3.2.2. 单机或分布式下的标识号</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">incrby serialNo 1000</span><br></pre></td></tr></table></figure><h2 id="SET"><a href="#SET" class="headerlink" title="SET"></a>SET</h2><p>Redis 的集合不是一个线性结构，而是一个哈希表结构，它的内部会根据 hash 分子来存储和查找数据，理论上一个集合可以存储 2<sup>32</sup>-1 个节点个元素，因为采用哈希表结构，所以对于 Redis 集合的插入、删除和查找的复杂度都是 0（1）</p><ul><li>对于集合而言，它的每一个元素都是不能重复的，当插入相同记录的时候都会失败。</li><li>集合是无序的。</li><li>集合的每一个元素都是 String [数据结构]</li></ul><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>命  令</td><td>说  明</td><td>备  注</td></tr><tr><td><strong>sadd</strong> key member1 [member2 member3……]</td><td>给键为 key 的集合増加成员</td><td>可以同时増加多个</td></tr><tr><td><strong>scard</strong> key</td><td>统计键为 key 的集合成员数</td><td>—</td></tr><tr><td><strong>sdiff</strong> key1 [key2]</td><td>找出两个集合的差集</td><td>参数如果是单key，那么 Redis 就返回这个 key 的所有元素</td></tr><tr><td><strong>sdiffstore</strong> des key1 [key2]</td><td>先按 sdiff 命令的规则，找出 key1 和 key2 两个集合的差集，然后将其保存到 des 集合中。</td><td>—</td></tr><tr><td><strong>sinter</strong> key1 [key2]</td><td>求 key1 和 key2 两个集合的交集。</td><td>参数如果是单 key，那么 Redis 就返冋这个 key 的所有元素</td></tr><tr><td><strong>sinterstore</strong> des key1 key2</td><td>先按 sinter 命令的规则，找出 key1 和 key2 两个集合的交集，然后保存到 des 中</td><td>—</td></tr><tr><td><strong>sismember</strong> key member</td><td>判断 member 是否键为 key 的集合的成员</td><td>如果是返回 1，否则返回 0</td></tr><tr><td><strong>smembers</strong> key</td><td>返回集合所有成员</td><td>如果数据量大，需要考虑迭代遍历的问题</td></tr><tr><td><strong>smove</strong> src des member</td><td>将成员 member 从集合 src 迁移到集合 des 中</td><td>—</td></tr><tr><td><strong>spop</strong> key</td><td>随机弹出集合的一个元素</td><td>注意其随机性，因为集合是无序的</td></tr><tr><td><strong>srandmember</strong> key [count]</td><td>随机返回集合中一个或者多个元素，count 为限制返回总数，如果 count 为负数，则先求其绝对值</td><td>count 为整数，如果不填默认为 1，如果 count 大于等于集合总数，则返回整个集合</td></tr><tr><td><strong>srem</strong> key member1[member2……]</td><td>移除集合中的元素，可以是多个元素</td><td>对于很大的集合可以通过它删除部分元素，避免删除大量数据引发 Redis 停顿</td></tr><tr><td><strong>sunion</strong> key1 [key2]</td><td>求两个集合的并集</td><td>参数如果是单 key，那么 Redis 就返回这个 key 的所有元素</td></tr><tr><td><strong>sunionstore</strong> des key1 key2</td><td>先执行 sunion 命令求出并集，然后保存到键为 des 的集合中</td><td></td></tr></tbody></table><h2 id="4-2-应用场景"><a href="#4-2-应用场景" class="headerlink" title="4.2. 应用场景"></a>4.2. 应用场景</h2><h3 id="4-2-1-电商商品筛选-set"><a href="#4-2-1-电商商品筛选-set" class="headerlink" title="4.2.1. 电商商品筛选(set)"></a>4.2.1. 电商商品筛选(set)</h3><p>每个商品入库的时候即会建立他的静态标签列表如，品牌，尺寸，处理器，内存</p><h3 id="4-2-2-单机或分布式下的标识号"><a href="#4-2-2-单机或分布式下的标识号" class="headerlink" title="4.2.2. 单机或分布式下的标识号"></a>4.2.2. 单机或分布式下的标识号</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">incrby serialNo 1000</span><br></pre></td></tr></table></figure><h3 id="4-2-3-集群环境下的-session-共享"><a href="#4-2-3-集群环境下的-session-共享" class="headerlink" title="4.2.3. 集群环境下的 session 共享"></a>4.2.3. 集群环境下的 session 共享</h3><h2 id="ZSET"><a href="#ZSET" class="headerlink" title="ZSET"></a>ZSET</h2><p>有序集合和集合类似，只是说它是有序的，和无序集合的主要区别在于每一个元素除了值之外，它还会多一个分数。分数是一个浮点数，在 Java 中是使用双精度表示的，根据分数，Redis 就可以支持对分数从小到大或者从大到小的排序。</p><p>这里和无序集合一样，对于每一个元素都是唯一的，但是对于不同元素而言，它的分数可以一样。元素也是 String 数据类型，也是一种基于 hash 的存储结构。</p><p>集合是通过哈希表实现的，所以添加、删除、查找的复杂度都是 0（1）。集合中最大的成员数为 2<sup>32</sup>-1</p><table><thead><tr><th>命  令</th><th>说  明</th><th>备  注</th></tr></thead><tbody><tr><td><strong>zadd</strong> key score1 value1 [score2 value2……]</td><td>向有序集合的 key，增加一个或者多个成员</td><td>如果不存在对应的 key，则创建键为 key 的有序集合</td></tr><tr><td><strong>zcard</strong> key</td><td>获取有序集合的成员数</td><td>—</td></tr><tr><td><strong>zcount</strong> key min max</td><td>根据分数返回对应的成员列表</td><td>min 为最小值，max 为最大值，默认为包含 min 和 max 值，采用数学区间表示的方法，如果需要不包含，则在分数前面加入“(”，注意不支持“[”表示</td></tr><tr><td><strong>zincrby</strong> key increment member</td><td>给有序集合成员值为 member 的分数增加 increment</td><td>—</td></tr><tr><td><strong>zinterstore</strong> desKey numkeys key1 [key2 key3……]</td><td>求多个有序集合的交集，并且将结果保存到 desKey 中</td><td>numkeys 是一个整数，表示多少个有序集合</td></tr><tr><td><strong>zrange</strong> key start stop [withscores]</td><td>按照分值的大小（从小到大）返回成员，加入 start 和 stop 参数可以截取某一段返回。如果输入可选项 withscores，则连同分数一起返回</td><td>这里记集合最人长度为 len，则 Redis 会将集合排序后，形成一个从 0 到 len-1 的下标，然后根据 start 和 stop 控制的下标（包含 start 和 stop）返回</td></tr><tr><td><strong>zrank</strong> key member</td><td>按从小到大求有序集合的排行</td><td>排名第一的为 0，第二的为 1……</td></tr><tr><td><strong>zrangebylex</strong> key min max [limit offset count]</td><td>根据值的大小，从小到大排序，min 为最小值，max 为最大值；limit 选项可选，当 Redis 求出范围集合后，会生产下标 0 到 n，然后根据偏移量 offset 和限定返回数 count，返回对应的成员</td><td>这里范围为 key 的成员值，Redis 借助数学区间的表示方法，“[”表示包含该值，“(”表示不包含该值</td></tr><tr><td><strong>zrangebyscore</strong> key min max [withscores] [limit offset count]</td><td>根据分数大小，从小到大求取范围，选项 withscores 和 limit 请参考 zrange 命令和 zrangebylex 说明</td><td>根据分析求取集合的范围。这里默认包含 min 和 max，如果不想包含，则在参数前加入“(”， 注意不支持“[”表示</td></tr><tr><td><strong>zrevrank</strong> key member</td><td>按从大到小的顺序，求元素的排行</td><td>排名第一位 0，第二位 1……</td></tr><tr><td><strong>zscore</strong> key member</td><td>返回成员的分数值</td><td>返回成员的分数</td></tr><tr><td><strong>zunionstore</strong> desKey numKeys key1 [key2 key3 key4……]</td><td>求多个有序集合的并集，其中 numKeys 是有序集合的个数</td><td>——</td></tr></tbody></table><h2 id="5-2-应用场景"><a href="#5-2-应用场景" class="headerlink" title="5.2. 应用场景"></a>5.2. 应用场景</h2><p>redis 的 zset 天生是用来做排行榜的、好友列表, 去重, 历史记录等业务需求</p><h3 id="5-2-1-排行版-zset"><a href="#5-2-1-排行版-zset" class="headerlink" title="5.2.1. 排行版(zset)"></a>5.2.1. 排行版(zset)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// user1 的用户分数为 10 </span><br><span class="line">zadd ranking 10 user1 </span><br><span class="line">zadd ranking 20 user2 </span><br><span class="line">// 取分数最高的3个用户</span><br><span class="line">zrevrange ranking 0 2 withscores</span><br></pre></td></tr></table></figure><h1 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h1><p>Redis 的基数统计，这个结构可以非常省内存的去统计各种计数，比如注册 IP 数、每日访问 IP 数、页面实时 UV）、在线用户数等。基数的作用是评估大约需要准备多少个存储单元去存储数据，但是基数的算法一般会存在一定的误差，一般是可控的。供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计 UV</p><p>基数是一种算法。如一本英文著作由数百万个单词组成，你的内存却不足以存储它们，那么我们先分析一下业务。</p><p>英文单词本身是有限的，在这本书的几百万个单词中有许许多多重复单词，扣去重复的单词，这本书中也就是几千到一万多个单词而已，那么内存就足够存储它们了。</p><p>比如数字集合 {1,2,5,7,9,1,5,9} 的基数集合为 {1,2,5,7,9} 那么基数（不重复元素）就是 5</p><table><thead><tr><th>命  令</th><th>说  明</th><th>备  注</th></tr></thead><tbody><tr><td><strong>pfadd</strong> key element</td><td>添加指定元素到 HyperLogLog 中</td><td>如果已经存储元索，则返回为 0，添加失败</td></tr><tr><td><strong>pfcount</strong> key</td><td>返回 HyperLogLog 的基数值</td><td>—</td></tr><tr><td><strong>pfmerge</strong> desKey key1 [key2 key3…]</td><td>合并多个 HyperLogLog，并将其保存在 desKey 中</td><td>—</td></tr></tbody></table><h2 id="BitMaps"><a href="#BitMaps" class="headerlink" title="BitMaps"></a>BitMaps</h2><p>通过一个 bit 位来表示某个元素对应的值或者状态,其中的 key 就是对应元素本身。我们知道 8 个 bit 可以组成一个 Byte，所以 bitmap 本身会极大的节省储存空间。</p><h3 id="基本操作-1"><a href="#基本操作-1" class="headerlink" title="基本操作"></a>基本操作</h3><ul><li><strong>setbit</strong> bits </li><li><strong>getbit</strong> bits</li></ul><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><h4 id="用户签到"><a href="#用户签到" class="headerlink" title="用户签到"></a>用户签到</h4><p>很多网站都提供了签到功能(这里不考虑数据落地事宜)，并且需要展示最近一个月的签到情况，使用bitmap<br><strong>根据日期 offset =hash % 365 ； key = 年份#用户id</strong></p><h4 id="用户签到-1"><a href="#用户签到-1" class="headerlink" title="用户签到"></a>用户签到</h4><p>使用时间作为 cacheKey，然后用户 ID 为 offset，如果当日活跃过就设置为 1<br>那么我该如果计算某几天/月/年的活跃用户呢(暂且约定，统计时间内只有有一天在线就称为活跃)<br>命令 <code>BITOP operation destkey key [key ...]</code><br>说明：对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。<br>说明：BITOP 命令支持 AND 、 OR 、 NOT 、 XOR 这四种操作中的任意一种参数</p><p>20190216 活跃用户 【1，2】<br>20190217 活跃用户 【1】<br>统计20190216~20190217 总活跃用户数: 1</p><h3 id="用户在线状态"><a href="#用户在线状态" class="headerlink" title="用户在线状态"></a><strong>用户在线状态</strong></h3><p>查询当前用户是否在线的接口。<br>使用 bitmap 是一个节约空间效率又高的一种方法，只需要一个 key，然后用户 ID 为 offset，如果在线就设置为1，<br>不在线就设置为0，和上面的场景一样，5000W用户只需要 6MB 的空间</p><h2 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h2><p>Redis 的 GEO 特性可以将用户给定的地理位置信息储存起来， 并对这些信息进行操作。</p><h2 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h2><p>Stream 是 Redis 5.0 版本引入的一个新的数据类型，它以更抽象的方式模拟日志数据结构，但日志仍然是完整的：就像一个日志文件，通常实现为以只附加模式打开的文件，Redis流主要是一个仅附加数据结构。至少从概念上来讲，因为Redis流是一种在内存表示的抽象数据类型，他们实现了更加强大的操作，以此来克服日志文件本身的限制。</p><p>Stream是Redis的数据类型中最复杂的，尽管数据类型本身非常简单，它实现了额外的非强制性的特性：提供了一组允许消费者以阻塞的方式等待生产者向Stream中发送的新消息，此外还有一个名为<strong>消费者组</strong>的概念。</p><p>消费者组最早是由名为Kafka（TM）的流行消息系统引入的。Redis用完全不同的术语重新实现了一个相似的概念，但目标是相同的：允许一组客户端相互配合来消费同一个Stream的不同部分的消息。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(2)：事务机制</title>
      <link href="2019/07/12/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(4)%EF%BC%9A%E4%BA%8B%E5%8A%A1/"/>
      <url>2019/07/12/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(4)%EF%BC%9A%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-消息传输保障"><a href="#1-消息传输保障" class="headerlink" title="1. 消息传输保障"></a>1. 消息传输保障</h2><h2 id="2-幂等"><a href="#2-幂等" class="headerlink" title="2. 幂等"></a>2. 幂等</h2>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 JVM(5)_双亲委派机制</title>
      <link href="2019/07/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(5)_%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6/"/>
      <url>2019/07/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(5)_%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Java 虚拟机对 class 文件采用的是<font color=red><strong>按需加载</strong></font>的方式，也就是说当需要使用该类时才会将他的 class 文件加载到内存生成Class对象。而且加载某个类的class文件是=时，Java虚拟机采用的是<font color=red><strong>双亲委派机制</strong></font>，即把请求交由父类处理，它是一种任务委派模式。</p><a id="more"></a><p>类加载器用来把类加载到 Java 虚拟机中。从 JDK1.2 版本开始，类的加载过程采用双亲委托机制，这种机制能更好地保证 Java 平台的安全。在此委托机制中，除了 Java 虚拟机自带的根类加载器以外，其余的类加载器都有且只有一个父加载器。当 Java 程序请求加载器 loader1 加载 Sample 类时，loader1 首先委托自己的父加载器去加载 Sample 类，若父加载器能加载，则有父加载器完成加载任务，否则才由加载器loader1 本身加载 Sample 类。</p><p>在双亲委托机制中，各个加载器按照父子关系形成了树形结构，除了根加载器之外，其余的类加载器都有一个父加载器若有一个类能够成功加载 Test 类，那么这个类加载器被称为<strong>定义类加载器</strong>，所有能成功返回Class对象引用的类加载器（包括定义类加载器）称为<strong>初始类加载器</strong>。</p><h2 id="1-工作过程"><a href="#1-工作过程" class="headerlink" title="1. 工作过程"></a>1. 工作过程</h2><ul><li>如果一个类加载器收到了类加载的请求，他不会自己先去加载这个类，而是把这个请求委派父类加载器去完成。</li><li>如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器</li><li>如果父类加载器可以完成类的加载，就成功返回，倘若父类加载器无法完成加载任务，子加载器才会尝试自己去加载</li></ul><h2 id="2-测试和验证"><a href="#2-测试和验证" class="headerlink" title="2. 测试和验证"></a>2. 测试和验证</h2><blockquote><p>在当前模块下，创建一个java.lang.String类，并使用，会使用我们创建的String吗？</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span> </span>&#123;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="keyword">static</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;我是自定义的String类的静态代码块&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//    // 错误: 在类 java.lang.String 中找不到 main 方法</span></span><br><span class="line"><span class="comment">//    public static void main(String[] args) &#123;</span></span><br><span class="line"><span class="comment">//        System.out.println(&quot;hello,String&quot;);</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用 <code>String</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        java.lang.String str = <span class="keyword">new</span> java.lang.String();</span><br><span class="line">        System.out.println(<span class="string">&quot;hello world&quot;</span>);</span><br><span class="line"></span><br><span class="line">        StringTest test = <span class="keyword">new</span> StringTest();</span><br><span class="line">        System.out.println(test.getClass().getClassLoader());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hello world</span><br><span class="line">sun.misc.Launcher$AppClassLoader@18b4aac2</span><br></pre></td></tr></table></figure><p>从运行的结果看，是不会运行我们自定义的 <code>String</code> 的，原因就是因为双亲委派机制</p><p>自定义 String 类，但是在加载自定义 String 类的时候回率先使用引导类加载器加载，而引导类加载器在加载的过程中会先加载jdk自带的文件（rt.jar包中java\lang\lang\String.class），报错信息说没有main方法，就是因为加载的是rt.jar包中的String类。这样可以保证对java核心源代码的保护，这就是<font color=red><strong>沙箱安全机制</strong></font>。</p><h2 id="3-优点"><a href="#3-优点" class="headerlink" title="3.优点"></a>3.优点</h2><ul><li><p>可以确保 Java 和核心库的安全</p><blockquote><p>所有的 Java 应用都会引用 java.lang 中的类，也就是说在运行期 java.lang 中的类会被加载到虚拟机中，如果这个加载过程如果是由自己的类加载器所加载，那么很可能就会在 JVM 中存在多个版本的 java.lang 中的类，而且这些类是相互不可见的。借助于双亲委托机制，Java 核心类库中的类的加载工作都是由启动根加载器去加载，从而确保了 Java 应用所使用的的都是同一个版本的 Java 核心类库，他们之间是相互兼容的</p></blockquote></li><li><p>确保 Java 核心类库中的类不会被自定义的类所替代</p></li><li><p>不同的类加载器可以为相同名称的类（binary name）创建额外的命名空间。相同名称的类可以并存在Java虚拟机中，只需要用不同的类加载器去加载即可。相当于在 Java 虚拟机内部建立了一个又一个相互隔离的 Java 类空间。</p></li><li><p><strong>避免重复加载</strong>，父类已经加载过的类，子类无需重新加载。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.poplar.classload;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoadTest10</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;ClassLoadTest10&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/*执行结果：由于父类已经初始化过了所以Parent2只输出一次</span></span><br><span class="line"><span class="comment">   * ClassLoadTest10</span></span><br><span class="line"><span class="comment">   * Parent2</span></span><br><span class="line"><span class="comment">   * 2</span></span><br><span class="line"><span class="comment">   * Child2</span></span><br><span class="line"><span class="comment">   * 3</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    Parent2 parent2;</span><br><span class="line">    parent2 = <span class="keyword">new</span> Parent2();</span><br><span class="line">    System.out.println(Parent2.a);</span><br><span class="line">    System.out.println(Child2.b);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parent2</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> a = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Parent2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child2</span> <span class="keyword">extends</span> <span class="title">Parent2</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> b = <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Child2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><hr><h2 id="3-双亲委派模型破坏"><a href="#3-双亲委派模型破坏" class="headerlink" title="3. 双亲委派模型破坏"></a><strong>3. 双亲委派模型破坏</strong></h2><p>双亲委托模型并不是一个强制性的约束模型，而是java设计者推荐给开发者的泪加载器实现方式。但是双亲委托模型存在着缺陷，它虽然解决了各个类加载器的基础类的统一加载的问题。如果基础类又要调用回用户代码，那么在就会使用基础类的类加载器(启动类加载器)去加载用户的代码，而启动类加载器是加载 <code>java_home\lib</code> 目录下的。而用户代码都是保存在<code>classpath下</code>，根本就不可能加载。其中这个方面最典型的就是 jdbc 对于双亲委派模型的破坏。</p><ol><li><h4 id="第一次破坏"><a href="#第一次破坏" class="headerlink" title="第一次破坏"></a><strong>第一次破坏</strong></h4><p>由于双亲委派模型是在JDK1.2之后才被引入的，而类加载器和抽象类java.lang.ClassLoader则在JDK1.0时代就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java设计者引入双亲委派模型时不得不做出一些妥协。在此之前，用户去继承java.lang.ClassLoader的唯一目的就是为了重写loadClass()方法，因为虚拟机在进行类加载的时候会调用加载器的私有方法loadClassInternal()，而这个方法唯一逻辑就是去调用自己的loadClass()。</p></li><li><p><strong>第二次破坏</strong></p><p>双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷所导致的，双亲委派很好地解决了各个类加载器的基础类的同一问题如果基础类又要调用回用户的代码，违背了双亲委派模型的一般性原则，</p></li><li><p><strong>第三次破坏</strong></p><p>双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求导致的，这里所说的“动态性”指的是当前一些非常“热门”的名词：代码热替换、模块热部署等，简答的说就是机器不用重启，只要部署上就能用。<br>OSGi 实现模块化热部署的关键则是它自定义的类加载器机制的实现。每一个程序模块(Bundle)都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle连同类加载器一起换掉以实现代码的热替换。在OSGi幻境下，类加载器不再是双亲委派模型中的树状结构，而是进一步发展为更加复杂的网状结构，当受到类加载请求时，OSGi将按照下面的顺序进行类搜索</p><ul><li><p>将java.＊开头的类委派给父类加载器加载。</p></li><li><p>否则，将委派列表名单内的类委派给父类加载器加载。</p></li><li><p>否则，将Import列表中的类委派给Export这个类的Bundle的类加载器加载。</p></li><li><p>否则，查找当前Bundle的ClassPath，使用自己的类加载器加载。</p></li><li><p>否则，查找类是否在自己的Fragment Bundle中，如果在，则委派给Fragment Bundle的类加载器加载。</p></li><li><p>否则，查找Dynamic Import列表的Bundle，委派给对应Bundle的类加载器加载。</p></li><li><p>否则，类加载器失败。</p></li></ul></li></ol><h3 id="3-2-双亲委派模型破坏实例"><a href="#3-2-双亲委派模型破坏实例" class="headerlink" title="3.2. 双亲委派模型破坏实例"></a>3.2. 双亲委派模型破坏实例</h3><h4 id="3-2-1-JDBC"><a href="#3-2-1-JDBC" class="headerlink" title="3.2.1. JDBC"></a>3.2.1. JDBC</h4><p>原生的 JDBC 中 Driver 驱动本身只是一个接口，并没有具体的实现，具体的实现是由不同数据库类型去实现的。例如，MySQL 的mysql-connector-*.jar 中的 Driver 类具体实现的。 原生的 JDBC 中的类是放在 rt.jar 包的，是由启动类加载器进行类加载的，在 JDBC 中的 Driver 类中需要动态去加载不同数据库类型的 Driver 类，而 mysql-connector-.jar中的 Driver 类是用户自己写的代码，那启动类加载器肯定是不能进行加载的，既然是自己编写的代码，那就需要由应用程序启动类去进行类加载。于是乎，这个时候就引入线程上下文件类加载器(Thread Context ClassLoader)。有了这个东西之后，程序就可以把原本需要由启动类加载器进行加载的类，由应用程序类加载器去进行加载了。</p><h4 id="3-2-2-JNDI-服务"><a href="#3-2-2-JNDI-服务" class="headerlink" title="3.2.2. JNDI 服务"></a>3.2.2. JNDI 服务</h4><p>JNDI 现在已经是 Java 的标准服务，它的代码由启动类加载器去加载，但 JNDI 的目的就是对资源进行集中管理和查找，它需要调用由独立厂商实现并部署在应用程序的ClassPath下的JNDI接口提供者的代码，但启动类加载器不可能“认识”这些代码。</p><p>有了线程上下文加载器，JNDI服务就可以使用它去加载所需要的SPI代码，也就是父类加载器请求子类加载器去完成类加载的动作，这种行为实际上就是打通了双亲委派模型层次结构来逆向使用类加载器，实际上已经违背了双亲委派模型的一般性原则，但这也是无可奈何的事情。Java中所有涉及SPI的加载动作基本上都采用这种方式，例如JNDI、JDBC、JCE、JAXB和JBI等。</p>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>JVM 指令集</title>
      <link href="2019/07/03/JVM-%E6%8C%87%E4%BB%A4%E9%9B%86/"/>
      <url>2019/07/03/JVM-%E6%8C%87%E4%BB%A4%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><table><thead><tr><th align="center"></th><th></th><th></th></tr></thead><tbody><tr><td align="center"><strong>指令码</strong></td><td><strong>助记符</strong></td><td><strong>功能描述</strong></td></tr><tr><td align="center">0x00</td><td>nop</td><td>无操作</td></tr><tr><td align="center">0x01</td><td>aconst_null</td><td>aconst_null 功能描述 null进栈指令执行前指令执行后栈底…… null栈顶     注意：JVM并没有为null指派一个具体的值。</td></tr><tr><td align="center">0x02</td><td>iconst_m1</td><td>int型常量值-1进栈</td></tr><tr><td align="center">0x03</td><td>iconst_0</td><td>int型常量值0进栈</td></tr><tr><td align="center">0x04</td><td>iconst_1</td><td>int型常量值1进栈</td></tr><tr><td align="center">0x05</td><td>iconst_2</td><td>int型常量值2进栈</td></tr><tr><td align="center">0x06</td><td>iconst_3</td><td>int型常量值3进栈</td></tr><tr><td align="center">0x07</td><td>iconst_4</td><td>int型常量值4进栈</td></tr><tr><td align="center">0x08</td><td>iconst_5</td><td>int型常量值5进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x09</td><td>lconst_0</td><td>long型常量值0进栈</td></tr><tr><td align="center">0x0A</td><td>lconst_1</td><td>long型常量值1进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x0B</td><td>fconst_0</td><td>float型常量值0进栈</td></tr><tr><td align="center">0x0C</td><td>fconst_1</td><td>float型常量值1进栈</td></tr><tr><td align="center">0x0D</td><td>fconst_2</td><td>float型常量值2进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x0E</td><td>dconst_0</td><td>double型常量值0进栈</td></tr><tr><td align="center">0x0F</td><td>dconst_1</td><td>double型常量值1进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x10</td><td>bipush</td><td>将一个byte型常量值推送至栈顶</td></tr><tr><td align="center">0x11</td><td>sipush</td><td>将一个short型常量值推送至栈顶</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x12</td><td>ldc</td><td>将int、float或String型常量值从常量池中推送至栈顶</td></tr><tr><td align="center">0x13</td><td>ldc_w</td><td>将int、float或String型常量值从常量池中推送至栈顶（宽索引）</td></tr><tr><td align="center">0x14</td><td>ldc2_w</td><td>将long或double型常量值从常量池中推送至栈顶（宽索引）</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x15</td><td>iload</td><td>指定的int型局部变量进栈</td></tr><tr><td align="center">0x16</td><td>lload</td><td>指定的long型局部变量进栈</td></tr><tr><td align="center">0x17</td><td>fload</td><td>指定的float型局部变量进栈</td></tr><tr><td align="center">0x18</td><td>dload</td><td>指定的double型局部变量进栈</td></tr><tr><td align="center">0x19</td><td>aload</td><td>指令格式： aload index功能描述： 当前frame的局部变量数组中下标为index的引用型局部变量进栈指令执行前指令执行后栈底…… objectref栈顶     index ： 无符号一byte整型。和wide指令联用， 可以使index为两byte</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x1A</td><td>iload_0</td><td>第一个int型局部变量进栈</td></tr><tr><td align="center">0x1B</td><td>iload_1</td><td>第二个int型局部变量进栈</td></tr><tr><td align="center">0x1C</td><td>iload_2</td><td>第三个int型局部变量进栈</td></tr><tr><td align="center">0x1D</td><td>iload_3</td><td>第四个int型局部变量进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x1E</td><td>lload_0</td><td>第一个long型局部变量进栈</td></tr><tr><td align="center">0x1F</td><td>lload_1</td><td>第二个long型局部变量进栈</td></tr><tr><td align="center">0x20</td><td>lload_2</td><td>第三个long型局部变量进栈</td></tr><tr><td align="center">0x21</td><td>lload_3</td><td>第四个long型局部变量进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x22</td><td>fload_0</td><td>第一个float型局部变量进栈</td></tr><tr><td align="center">0x23</td><td>fload_1</td><td>第二个float型局部变量进栈</td></tr><tr><td align="center">0x24</td><td>fload_2</td><td>第三个float型局部变量进栈</td></tr><tr><td align="center">0x25</td><td>fload_3</td><td>第四个float型局部变量进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x26</td><td>dload_0</td><td>第一个double型局部变量进栈</td></tr><tr><td align="center">0x27</td><td>dload_1</td><td>第二个double型局部变量进栈</td></tr><tr><td align="center">0x28</td><td>dload_2</td><td>第三个double型局部变量进栈</td></tr><tr><td align="center">0x29</td><td>dload_3</td><td>第四个double型局部变量进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x2A</td><td>aload_0</td><td>指令格式：aload_0该指令的行为类似于aload指令index为0的情况。</td></tr><tr><td align="center">0x2B</td><td>aload_1</td><td>同上</td></tr><tr><td align="center">0x2C</td><td>aload_2</td><td>同上</td></tr><tr><td align="center">0x2D</td><td>aload_3</td><td>同上</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x2E</td><td>iaload</td><td>指定的int型数组的指定下标处的值进栈</td></tr><tr><td align="center">0x2F</td><td>laload</td><td>指定的long型数组的指定下标处的值进栈</td></tr><tr><td align="center">0x30</td><td>faload</td><td>指定的float型数组的指定下标处的值进栈</td></tr><tr><td align="center">0x31</td><td>daload</td><td>指定的double型数组的指定下标处的值进栈</td></tr><tr><td align="center">0x32</td><td>aaload</td><td>指令格式： aaload 功能描述： 栈顶的数组下标（index）、数组引用（arrayref）出栈，并根据这两个数值取出对应的数组元素值（value）进栈。 抛出异常： 如果arrayref的值为null，会抛出NullPointerException。如果index造成数组越界，会抛出ArrayIndexOutOfBoundsException。指令执行前指令执行后栈底……arrayrefvalueindex 栈顶      index： int类型arrayref： 数组的引用</td></tr><tr><td align="center">0x33</td><td>baload</td><td>指定的boolean或byte型数组的指定下标处的值进栈</td></tr><tr><td align="center">0x34</td><td>caload</td><td>指定的char型数组的指定下标处的值进栈</td></tr><tr><td align="center">0x35</td><td>saload</td><td>指定的short型数组的指定下标处的值进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x36</td><td>istore</td><td>将栈顶int型数值存入指定的局部变量</td></tr><tr><td align="center">0x37</td><td>lstore</td><td>将栈顶long型数值存入指定的局部变量</td></tr><tr><td align="center">0x38</td><td>fstore</td><td>将栈顶float型数值存入指定的局部变量</td></tr><tr><td align="center">0x39</td><td>dstore</td><td>将栈顶double型数值存入指定的局部变量</td></tr><tr><td align="center">0x3A</td><td>astore</td><td>astore index 功能描述： 将栈顶数值（objectref）存入当前frame的局部变量数组中指定下标（index）处的变量中，栈顶数值出栈。指令执行前指令执行后栈底……objectref 栈顶     index ： 无符号一byte整数。该指令和wide联用，index可以为无符号两byte整数</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x3B</td><td>istore_0</td><td>将栈顶int型数值存入第一个局部变量</td></tr><tr><td align="center">0x3C</td><td>istore_1</td><td>将栈顶int型数值存入第二个局部变量</td></tr><tr><td align="center">0x3D</td><td>istore_2</td><td>将栈顶int型数值存入第三个局部变量</td></tr><tr><td align="center">0x3E</td><td>istore_3</td><td>将栈顶int型数值存入第四个局部变量</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x3F</td><td>lstore_0</td><td>将栈顶long型数值存入第一个局部变量</td></tr><tr><td align="center">0x40</td><td>lstore_1</td><td>将栈顶long型数值存入第二个局部变量</td></tr><tr><td align="center">0x41</td><td>lstore_2</td><td>将栈顶long型数值存入第三个局部变量</td></tr><tr><td align="center">0x42</td><td>lstore_3</td><td>将栈顶long型数值存入第四个局部变量</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x43</td><td>fstore_0</td><td>将栈顶float型数值存入第一个局部变量</td></tr><tr><td align="center">0x44</td><td>fstore_1</td><td>将栈顶float型数值存入第二个局部变量</td></tr><tr><td align="center">0x45</td><td>fstore_2</td><td>将栈顶float型数值存入第三个局部变量</td></tr><tr><td align="center">0x46</td><td>fstore_3</td><td>将栈顶float型数值存入第四个局部变量</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x47</td><td>dstore_0</td><td>将栈顶double型数值存入第一个局部变量</td></tr><tr><td align="center">0x48</td><td>dstore_1</td><td>将栈顶double型数值存入第二个局部变量</td></tr><tr><td align="center">0x49</td><td>dstore_2</td><td>将栈顶double型数值存入第三个局部变量</td></tr><tr><td align="center">0x4A</td><td>dstore_3</td><td>将栈顶double型数值存入第四个局部变量</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x4B</td><td>astore_0</td><td>指令格式： astore_0功能描述： 该指令的行为类似于astore指令index为0的情况。</td></tr><tr><td align="center">0x4C</td><td>astore_1</td><td>同上</td></tr><tr><td align="center">0x4D</td><td>astore_2</td><td>同上</td></tr><tr><td align="center">0x4E</td><td>astore_3</td><td>同上</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x4F</td><td>iastore</td><td>将栈顶int型数值存入指定数组的指定下标处</td></tr><tr><td align="center">0x50</td><td>lastore</td><td>将栈顶long型数值存入指定数组的指定下标处</td></tr><tr><td align="center">0x51</td><td>fastore</td><td>将栈顶float型数值存入指定数组的指定下标处</td></tr><tr><td align="center">0x52</td><td>dastore</td><td>将栈顶double型数值存入指定数组的指定下标处</td></tr><tr><td align="center">0x53</td><td>aastore</td><td>指令格式： aastore 功能描述： 根据栈顶的引用型数值（value）、数组下标（index）、数组引用（arrayref）出栈，将数值存入对应的数组元素中抛出异常： 如果value的类型和arrayref所引用的数组的元素类型不兼容，会抛出抛出ArrayStoreException。如果index造成数组越界，会抛出ArrayIndexOutOfBoundsException。 如果arrayref值为null，会抛出NullPointerException。指令执行前指令执行后栈底……arrayref index value 栈顶       arrayref ： 必须是对数组的引用index ： int类型value ： 引用类型</td></tr><tr><td align="center">0x54</td><td>bastore</td><td>将栈顶boolean或byte型数值存入指定数组的指定下标处</td></tr><tr><td align="center">0x55</td><td>castore</td><td>将栈顶char型数值存入指定数组的指定下标处</td></tr><tr><td align="center">0x56</td><td>sastore</td><td>将栈顶short型数值存入指定数组的指定下标处</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x57</td><td>pop</td><td>栈顶数值出栈 (该栈顶数值不能是long或double型)</td></tr><tr><td align="center">0x58</td><td>pop2</td><td>栈顶的一个（如果是long、double型的)或两个（其它类型的）数值出栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x59</td><td>dup</td><td>复制栈顶数值，并且复制值进栈</td></tr><tr><td align="center">0x5A</td><td>dup_x1</td><td>复制栈顶数值，并且复制值进栈2次</td></tr><tr><td align="center">0x5B</td><td>dup_x2</td><td>复制栈顶数值，并且复制值进栈2次或3次</td></tr><tr><td align="center">0x5C</td><td>dup2</td><td>复制栈顶一个（long、double型的)或两个（其它类型的）数值，并且复制值进栈</td></tr><tr><td align="center">0x5D</td><td>dup2_x1</td><td></td></tr><tr><td align="center">0x5E</td><td>dup2_x2</td><td></td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x5F</td><td>swap</td><td>栈顶的两个数值互换(要求栈顶的两个数值不能是long或double型的)</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x60</td><td>iadd</td><td>栈顶两int型数值相加，并且结果进栈</td></tr><tr><td align="center">0x61</td><td>ladd</td><td>栈顶两long型数值相加，并且结果进栈</td></tr><tr><td align="center">0x62</td><td>fadd</td><td>栈顶两float型数值相加，并且结果进栈</td></tr><tr><td align="center">0x63</td><td>dadd</td><td>栈顶两double型数值相加，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x64</td><td>isub</td><td>栈顶两int型数值相减，并且结果进栈</td></tr><tr><td align="center">0x65</td><td>lsub</td><td>栈顶两long型数值相减，并且结果进栈</td></tr><tr><td align="center">0x66</td><td>fsub</td><td>栈顶两float型数值相减，并且结果进栈</td></tr><tr><td align="center">0x67</td><td>dsub</td><td>栈顶两double型数值相减，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x68</td><td>imul</td><td>栈顶两int型数值相乘，并且结果进栈</td></tr><tr><td align="center">0x69</td><td>lmul</td><td>栈顶两long型数值相乘，并且结果进栈</td></tr><tr><td align="center">0x6A</td><td>fmul</td><td>栈顶两float型数值相乘，并且结果进栈</td></tr><tr><td align="center">0x6B</td><td>dmul</td><td>栈顶两double型数值相乘，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x6C</td><td>idiv</td><td>栈顶两int型数值相除，并且结果进栈</td></tr><tr><td align="center">0x6D</td><td>ldiv</td><td>栈顶两long型数值相除，并且结果进栈</td></tr><tr><td align="center">0x6E</td><td>fdiv</td><td>栈顶两float型数值相除，并且结果进栈</td></tr><tr><td align="center">0x6F</td><td>ddiv</td><td>栈顶两double型数值相除，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x70</td><td>irem</td><td>栈顶两int型数值作取模运算，并且结果进栈</td></tr><tr><td align="center">0x71</td><td>lrem</td><td>栈顶两long型数值作取模运算，并且结果进栈</td></tr><tr><td align="center">0x72</td><td>frem</td><td>栈顶两float型数值作取模运算，并且结果进栈</td></tr><tr><td align="center">0x73</td><td>drem</td><td>栈顶两double型数值作取模运算，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x74</td><td>ineg</td><td>栈顶int型数值取负，并且结果进栈</td></tr><tr><td align="center">0x75</td><td>lneg</td><td>栈顶long型数值取负，并且结果进栈</td></tr><tr><td align="center">0x76</td><td>fneg</td><td>栈顶float型数值取负，并且结果进栈</td></tr><tr><td align="center">0x77</td><td>dneg</td><td>栈顶double型数值取负，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x78</td><td>ishl</td><td>int型数值左移指定位数，并且结果进栈</td></tr><tr><td align="center">0x79</td><td>lshl</td><td>long型数值左移指定位数，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x7A</td><td>ishr</td><td>int型数值带符号右移指定位数，并且结果进栈</td></tr><tr><td align="center">0x7B</td><td>lshr</td><td>long型数值带符号右移指定位数，并且结果进栈</td></tr><tr><td align="center">0x7C</td><td>iushr</td><td>int型数值无符号右移指定位数，并且结果进栈</td></tr><tr><td align="center">0x7D</td><td>lushr</td><td>long型数值无符号右移指定位数，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x7E</td><td>iand</td><td>栈顶两int型数值按位与，并且结果进栈</td></tr><tr><td align="center">0x7F</td><td>land</td><td>栈顶两long型数值按位与，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x80</td><td>ior</td><td>栈顶两int型数值按位或，并且结果进栈</td></tr><tr><td align="center">0x81</td><td>lor</td><td>栈顶两long型数值按位或，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x82</td><td>ixor</td><td>栈顶两int型数值按位异或，并且结果进栈</td></tr><tr><td align="center">0x83</td><td>lxor</td><td>栈顶两long型数值按位异或，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x84</td><td>iinc</td><td>指定int型变量增加指定值</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x85</td><td>i2l</td><td>栈顶int值强转long值，并且结果进栈</td></tr><tr><td align="center">0x86</td><td>i2f</td><td>栈顶int值强转float值，并且结果进栈</td></tr><tr><td align="center">0x87</td><td>i2d</td><td>栈顶int值强转double值，并且结果进栈</td></tr><tr><td align="center">0x88</td><td>l2i</td><td>栈顶long值强转int值，并且结果进栈</td></tr><tr><td align="center">0x89</td><td>l2f</td><td>栈顶long值强转float值，并且结果进栈</td></tr><tr><td align="center">0x8A</td><td>l2d</td><td>栈顶long值强转double值，并且结果进栈</td></tr><tr><td align="center">0x8B</td><td>f2i</td><td>栈顶float值强转int值，并且结果进栈</td></tr><tr><td align="center">0x8C</td><td>f2l</td><td>栈顶float值强转long值，并且结果进栈</td></tr><tr><td align="center">0x8D</td><td>f2d</td><td>栈顶float值强转double值，并且结果进栈</td></tr><tr><td align="center">0x8E</td><td>d2i</td><td>栈顶double值强转int值，并且结果进栈</td></tr><tr><td align="center">0x8F</td><td>d2l</td><td>栈顶double值强转long值，并且结果进栈</td></tr><tr><td align="center">0x90</td><td>d2f</td><td>栈顶double值强转float值，并且结果进栈</td></tr><tr><td align="center">0x91</td><td>i2b</td><td>栈顶int值强转byte值，并且结果进栈</td></tr><tr><td align="center">0x92</td><td>i2c</td><td>栈顶int值强转char值，并且结果进栈</td></tr><tr><td align="center">0x93</td><td>i2s</td><td>栈顶int值强转short值，并且结果进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x94</td><td>lcmp</td><td>比较栈顶两long型数值大小，并且结果（1，0，-1）进栈</td></tr><tr><td align="center">0x95</td><td>fcmpl</td><td>比较栈顶两float型数值大小，并且结果（1，0，-1）进栈；当其中一个数值为NaN时， -1进栈</td></tr><tr><td align="center">0x96</td><td>fcmpg</td><td>比较栈顶两float型数值大小，并且结果（1，0，-1）进栈；当其中一个数值为NaN时，1进栈</td></tr><tr><td align="center">0x97</td><td>dcmpl</td><td>比较栈顶两double型数值大小，并且结果（1，0，-1）进栈；当其中一个数值为NaN时，-1进栈</td></tr><tr><td align="center">0x98</td><td>dcmpg</td><td>比较栈顶两double型数值大小，并且结果（1，0，-1）进栈；当其中一个数值为NaN时，1进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0x99</td><td>ifeq</td><td>当栈顶int型数值等于0时跳转</td></tr><tr><td align="center">0x9A</td><td>ifne</td><td>当栈顶int型数值不等于0时跳转</td></tr><tr><td align="center">0x9B</td><td>iflt</td><td>当栈顶int型数值小于0时跳转</td></tr><tr><td align="center">0x9C</td><td>ifge</td><td>当栈顶int型数值大于等于0时跳转</td></tr><tr><td align="center">0x9D</td><td>ifgt</td><td>当栈顶int型数值大于0时跳转</td></tr><tr><td align="center">0x9E</td><td>ifle</td><td>当栈顶int型数值小于等于0时跳转</td></tr><tr><td align="center">0x9F</td><td>if_icmpeq</td><td>比较栈顶两int型数值大小，当结果等于0时跳转</td></tr><tr><td align="center">0xA0</td><td>if_icmpne</td><td>比较栈顶两int型数值大小，当结果不等于0时跳转</td></tr><tr><td align="center">0xA1</td><td>if_icmplt</td><td>比较栈顶两int型数值大小，当结果小于0时跳转</td></tr><tr><td align="center">0xA2</td><td>if_icmpge</td><td>比较栈顶两int型数值大小，当结果大于等于0时跳转</td></tr><tr><td align="center">0xA3</td><td>if_icmpgt</td><td>比较栈顶两int型数值大小，当结果大于0时跳转</td></tr><tr><td align="center">0xA4</td><td>if_icmple</td><td>比较栈顶两int型数值大小，当结果小于等于0时跳转</td></tr><tr><td align="center">0xA5</td><td>if_acmpeq</td><td>比较栈顶两引用型数值，当结果相等时跳转</td></tr><tr><td align="center">0xA6</td><td>if_acmpne</td><td>比较栈顶两引用型数值，当结果不相等时跳转</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xA7</td><td>goto</td><td>无条件跳转</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xA8</td><td>jsr</td><td>跳转至指定16位offset位置，并将jsr下一条指令地址压入栈顶</td></tr><tr><td align="center">0xA9</td><td>ret</td><td>返回至局部变量指定的index的指令位置（通常与jsr、jsr_w联合使用）</td></tr><tr><td align="center">0xAA</td><td>tableswitch</td><td>用于switch条件跳转，case值连续（可变长度指令）</td></tr><tr><td align="center">0xAB</td><td>lookupswitch</td><td>用于switch条件跳转，case值不连续（可变长度指令）</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xAC</td><td>ireturn</td><td>当前方法返回int</td></tr><tr><td align="center">0xAD</td><td>lreturn</td><td>当前方法返回long</td></tr><tr><td align="center">0xAE</td><td>freturn</td><td>当前方法返回float</td></tr><tr><td align="center">0xAF</td><td>dreturn</td><td>当前方法返回double</td></tr><tr><td align="center">0xB0</td><td>areturn</td><td>指令格式： areturn功能描述： 从方法中返回一个对象的引用。抛出异常： 如果当前方法是<code>synchronized</code>方法，并且当前线程不是改方法的锁的拥有者，会抛出IllegalMonitorStateException指令执行前指令执行后栈底… objectref 栈顶     objectref ： 被返回的对象引用</td></tr><tr><td align="center">0xB1</td><td>return</td><td>当前方法返回void</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xB2</td><td>getstatic</td><td>获取指定类的静态域，并将其值压入栈顶</td></tr><tr><td align="center">0xB3</td><td>putstatic</td><td>为指定的类的静态域赋值</td></tr><tr><td align="center">0xB4</td><td>getfield</td><td>获取指定类的实例域，并将其值压入栈顶</td></tr><tr><td align="center">0xB5</td><td>putfield</td><td>为指定的类的实例域赋值</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xB6</td><td>invokevirtual</td><td>调用实例方法</td></tr><tr><td align="center">0xB7</td><td>invokespecial</td><td>调用超类构造方法、实例初始化方法、私有方法</td></tr><tr><td align="center">0xB8</td><td>invokestatic</td><td>调用静态方法</td></tr><tr><td align="center">0xb9</td><td>invokeinterface</td><td>调用接口方法</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xBA</td><td>—</td><td>因为历史原因，该码点为未使用的保留码点</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xBB</td><td>new</td><td>创建一个对象，并且其引用进栈</td></tr><tr><td align="center">0xBC</td><td>newarray</td><td>创建一个基本类型数组，并且其引用进栈</td></tr><tr><td align="center">0xBD</td><td>anewarray</td><td>指令格式： anewarray index1 index2 功能描述： 栈顶数值（count）作为数组长度，创建 一个引用 型数组。栈顶数值出栈，数组引用进栈。 抛出异常： 如果count小于0，会抛出 NegativeArraySizeException指令执行前指令执行后栈底……countarrayref栈顶     count： int类型。arrayref： 对所创建的数组的引用。</td></tr><tr><td align="center">0xBE</td><td>arraylength</td><td>指令格式： arraylength功能描述： 栈顶的数组引用（arrayref）出栈，该 数组的长度进栈。抛出异常： 如果arrayref的值为null，会抛出NullPointerException。指令执行前指令执行后栈底……arrayreflength栈顶     arrayref： 数组引用length： 数组长度</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xBF</td><td>athrow</td><td>指令格式： athrow功能描述： 将栈顶的数值作为异常或错误抛出抛出异常： 如果栈顶数值为null，则使用NullPointerException代替栈顶数值抛出。如果方法是的，则有可能抛出 IllegalMonitorStateException。指令执行前指令执行后栈底…objectrefobjectref 栈顶     objectref： Throwable或其子类的实例的引用。</td></tr><tr><td align="center">0xC0</td><td>checkcast</td><td>类型转换检查，如果该检查未通过将会抛出ClassCastException异常</td></tr><tr><td align="center">0xc1</td><td>instanceof</td><td>检查对象是否是指定的类的实例。如果是，1进栈；否则，0进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xC2</td><td>monitorenter</td><td>获得对象锁</td></tr><tr><td align="center">0xC3</td><td>monitorexit</td><td>释放对象锁</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xC4</td><td>wide</td><td>用于修改其他指令的行为</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xC5</td><td>multianewarray</td><td>创建指定类型和维度的多维数组（执行该指令时，栈中必须包含各维度的长度值），并且其引用值进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xC6</td><td>ifnull</td><td>为null时跳转</td></tr><tr><td align="center">0xC7</td><td>ifnonnull</td><td>不为null时跳转</td></tr><tr><td align="center">0xC8</td><td>goto_w</td><td>无条件跳转（宽索引）</td></tr><tr><td align="center">0xC9</td><td>jsr_w</td><td>跳转至指定32位offset位置，并且jsr_w下一条指令地址进栈</td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xCA</td><td>breakpoint</td><td></td></tr><tr><td align="center"></td><td></td><td></td></tr><tr><td align="center">0xFE</td><td>impdep1</td><td></td></tr><tr><td align="center">0xFF</td><td>impdep2</td><td></td></tr></tbody></table>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解JVM(4)_类加载器</title>
      <link href="2019/07/03/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(4)_%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/"/>
      <url>2019/07/03/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(4)_%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>类的加载由类加载器完成，JVM 提供的类加载器叫做系统类加载器，此外还可以通过继承 ClassLoader 基类来自定义类加载器。</p><a id="more"></a><h2 id="1-类加载器分类"><a href="#1-类加载器分类" class="headerlink" title="1.类加载器分类"></a>1.类加载器分类</h2><p>JVM 支持两种类型的类加载器，分别是<font color=red><strong>引导类加载器（Bootstrap ClassLoader）</strong></font>和<font color=red><strong>自定义类加载器（User-Defined ClassLoader）</strong></font></p><p>从概念上讲，自定义类加载器是指程序中由开发人员自定义的一类加载器，然而Java虚拟机规范却并没有这么定义，而是<font color=red><strong>将所有派生与抽象类 ClassLoader 的类加载器都划分为自定义类加载器</strong></font>。</p><p>无论类加载器的类型如何划分，在程序中我们最常见的类加载器始终只有三个，如下图：</p><img src="images/54.png" alt="img" style="zoom:55%;" /><p>Bootstrap ClassLoader是由C++语言实现的，其余的是由Java语言实现的</p><img src="images/55.png" alt="img" style="zoom:65%;" /><hr><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoaderTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取系统类加载器</span></span><br><span class="line">        ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader();</span><br><span class="line">        System.out.println(systemClassLoader);<span class="comment">//sun.misc.Launcher$AppClassLoader@18b4aac2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取其上层：扩展类加载器</span></span><br><span class="line">        ClassLoader extClassLoader = systemClassLoader.getParent();</span><br><span class="line">        System.out.println(extClassLoader);<span class="comment">//sun.misc.Launcher$ExtClassLoader@1540e19d</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取其上层：获取不到引导类加载器</span></span><br><span class="line">        ClassLoader bootstrapClassLoader = extClassLoader.getParent();</span><br><span class="line">        System.out.println(bootstrapClassLoader);<span class="comment">//null</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//对于用户自定义类来说：默认使用系统类加载器进行加载</span></span><br><span class="line">        ClassLoader classLoader = ClassLoaderTest.class.getClassLoader();</span><br><span class="line">        System.out.println(classLoader);<span class="comment">//sun.misc.Launcher$AppClassLoader@18b4aac2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//String类使用引导类加载器进行加载的。---&gt; Java的核心类库都是使用引导类加载器进行加载的。</span></span><br><span class="line">        ClassLoader classLoader1 = String.class.getClassLoader();</span><br><span class="line">        System.out.println(classLoader1);<span class="comment">//null</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-1-虚拟机自带的加载器"><a href="#1-1-虚拟机自带的加载器" class="headerlink" title="1.1. 虚拟机自带的加载器"></a>1.1. 虚拟机自带的加载器</h3><h4 id="1-1-1-启动类加载器（引导类加载器，Bootstrap-ClassLoader）"><a href="#1-1-1-启动类加载器（引导类加载器，Bootstrap-ClassLoader）" class="headerlink" title="1.1.1. 启动类加载器（引导类加载器，Bootstrap ClassLoader）"></a>1.1.1. 启动类加载器（引导类加载器，Bootstrap ClassLoader）</h4><ul><li>这个类加载使用 <font color=red><strong>C/C++语言实现的</strong></font>，嵌套在 JVM 内部</li><li>它用来加载 Java 核心类库(JAVA_HOME/jre/lib/rt.jar、resources.jar或sun.boot.class.path路径下的内容)，用于提供 JVM 自身需要的类</li><li>并不继承自 <code>java.lang.ClassLoader</code>，没有父加载器</li><li>加载扩展类和应用程序加载器，并指定为他们的父类加载器</li><li>出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类</li></ul><h4 id="1-1-2-扩展类加载器（Extension-ClassLoader）"><a href="#1-1-2-扩展类加载器（Extension-ClassLoader）" class="headerlink" title="1.1.2. 扩展类加载器（Extension ClassLoader）"></a>1.1.2. 扩展类加载器（Extension ClassLoader）</h4><ul><li><p><font color=red><strong>Java语言编写</strong></font>，由 <code>sun.misc.Launcher$ExtClassLoader</code> 实现。</p></li><li><p><font color=red><strong>派生于ClassLoader类</strong></font></p></li><li><p>父类加载器为启动类加载器</p></li><li><p>从java.ext.dirs系统属性所指定的目录加载类库，或从JDK安装目录的jre/lib/ext子目录（扩展目录）下加载类库。<font color=red><strong>如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载</strong></font>。</p></li><li><p>应用程序类加载器（系统类加载器，AppClassLoader）</p><ul><li>java语言编写，由sun.misc.Launcher$AppClassLoader实现。</li><li><font color=red><strong>派生于ClassLoader类</strong></font></li><li>父类加载器为启动类加载器</li><li>它负责加载环境变量classpath或系统属性java.class.path指定路径下的类库</li><li><font color=red><strong>该类加载是程序中默认的类加载器</strong></font>，一般来说，Java应用的类都是由它来完成加载</li><li>通过ClassLoader.getSystemClassLoader()方法可以获取到该类加载器</li></ul></li><li><p>加载器加载内容</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoaderTest1</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;------------启动类加载器------------&quot;</span>);</span><br><span class="line">        <span class="comment">//获取BootstrapClassLoader能够加载的api的路径</span></span><br><span class="line">        URL[] urLs = sun.misc.Launcher.getBootstrapClassPath().getURLs();</span><br><span class="line">        <span class="keyword">for</span> (URL element : urLs) &#123;</span><br><span class="line">            System.out.println(element.toExternalForm());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//从上面的路径中随意选择一个类,来看看他的类加载器是什么:引导类加载器</span></span><br><span class="line">        ClassLoader classLoader = Provider.class.getClassLoader();</span><br><span class="line">        System.out.println(classLoader);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;------------扩展类加载器------------&quot;</span>);</span><br><span class="line">        String extDirs = System.getProperty(<span class="string">&quot;java.ext.dirs&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (String path : extDirs.split(<span class="string">&quot;;&quot;</span>)) &#123;</span><br><span class="line">            System.out.println(path);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//从上面的路径中随意选择一个类,来看看他的类加载器是什么:扩展类加载器</span></span><br><span class="line">        ClassLoader classLoader1 = CurveDB.class.getClassLoader();</span><br><span class="line">        System.out.println(classLoader1);<span class="comment">//sun.misc.Launcher$ExtClassLoader@1540e19d</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p>​            ————启动类加载器————</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/resources.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/rt.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/sunrsasign.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/jsse.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/jce.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/charsets.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/jfr.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/classes</p><p>​            null</p><p>​            ————扩展类加载器————</p><p>​            D:\Java\jdk1.8.0_231\jre\lib\ext</p><p>​            C:\WINDOWS\Sun\Java\lib\ext</p><p>​            sun.misc.Launcher$ExtClassLoader@12a3a380</p></li><li><p>用户自定义类加载器</p><ul><li>在Java日常应用程序开发中，类的加载几乎是由上述3种加载器相互配合执行的，在必要时，我们还可以自定义类加载器，来定制类的加载方式。</li><li>为什么需要自定义类加载器？<ul><li>隔离加载类</li><li>修改类加载的方式</li><li>扩展加载源</li><li>防止源码泄露</li></ul></li><li>用户自定义类加载器实现步骤：<ul><li>开发人员可以通过集成抽象类java.lang.ClassLoader类的方式，实现自己的类加载器，以满足一些特殊的需求</li><li>在JDK1.2之前，在自定义类加载器时，总会去集成ClassLoader类并重写loadClass()方法，从而实现自定义的类加载器，但是在JDK1.2之后已不再建议用户去覆盖loadClass()方法，而是建议把自定义的类加载逻辑卸载findClass()方法中</li><li>在编写自定义的类加载器时，如果没有过于复杂的需求，可以直接继承URLClassLoader类，这样就可以避免自己去编写findClass()方法及获取字节码流的方式，使自定义类加载器编写更加简洁。</li></ul></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomClassLoader</span> <span class="keyword">extends</span> <span class="title">ClassLoader</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> Class&lt;?&gt; findClass(String name) <span class="keyword">throws</span> ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] result = getClassFromCustomPath(name);</span><br><span class="line">            <span class="keyword">if</span>(result == <span class="keyword">null</span>)&#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> FileNotFoundException();</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">return</span> defineClass(name,result,<span class="number">0</span>,result.length);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ClassNotFoundException(name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">byte</span>[] getClassFromCustomPath(String name)&#123;</span><br><span class="line">        <span class="comment">//从自定义路径中加载指定类:细节略</span></span><br><span class="line">        <span class="comment">//如果指定路径的字节码文件进行了加密，则需要在此方法中进行解密操作。</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        CustomClassLoader customClassLoader = <span class="keyword">new</span> CustomClassLoader();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Class&lt;?&gt; clazz = Class.forName(<span class="string">&quot;One&quot;</span>,<span class="keyword">true</span>,customClassLoader);</span><br><span class="line">            Object obj = clazz.newInstance();</span><br><span class="line">            System.out.println(obj.getClass().getClassLoader());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="4-ClassLoader的使用说明"><a href="#4-ClassLoader的使用说明" class="headerlink" title="4 ClassLoader的使用说明"></a>4 ClassLoader的使用说明</h2><ul><li><p>ClassLoader类，它是一个抽象类，其后所有的类加载器都继承自ClassLoader（不包括启动类加载器）</p><p><img src="images/56.png" alt="img"></p><img src="images/55.png" alt="img" style="zoom:65%;" /></li><li><p>获取ClassLoader的途径</p><ul><li>方式一：获取当前类的ClassLoader：class.getClassLoader()</li><li>方式二：获取当前线程上下文的ClassLoader：Thread.current().getContextLoader()</li><li>方式三：获取系统的ClassLoader：ClassLoader.getSystemClassLoader()</li><li>方式四：获取调用者的ClassLoader：DriverManager.getCallerClassLoader()</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoaderTest2</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1.</span></span><br><span class="line">            ClassLoader classLoader = Class.forName(<span class="string">&quot;java.lang.String&quot;</span>).getClassLoader();</span><br><span class="line">            System.out.println(classLoader);</span><br><span class="line">            <span class="comment">//2.</span></span><br><span class="line">            ClassLoader classLoader1 = Thread.currentThread().getContextClassLoader();</span><br><span class="line">            System.out.println(classLoader1);</span><br><span class="line">            <span class="comment">//3.</span></span><br><span class="line">            ClassLoader classLoader2 = ClassLoader.getSystemClassLoader().getParent();</span><br><span class="line">            System.out.println(classLoader2);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p>​            null</p><p>​            sun.misc.Launcher$AppClassLoader@18b4aac2</p><p>​            sun.misc.Launcher$ExtClassLoader@1b6d3586</p></li></ul><h2 id="5-双亲委派机制"><a href="#5-双亲委派机制" class="headerlink" title="5 双亲委派机制"></a>5 双亲委派机制</h2><ul><li><p>Java虚拟机对class文件采用的是<font color=red><strong>按需加载</strong></font>的方式，也就是说当需要使用该类时才会将他的class文件加载到内存生成Class对象。而且加载某个类的class文件是=时，Java虚拟机采用的是<font color=red><strong>双亲委派机制</strong></font>，即把请求交由父类处理，它是一种任务委派模式。</p></li><li><p>一个问题？在当前模块下，创建一个java.lang.String类，并使用，会使用我们创建的String吗？</p><img src="images/57.png" alt="img" style="zoom:85%;" /><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span> </span>&#123;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="keyword">static</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;我是自定义的String类的静态代码块&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//    //错误: 在类 java.lang.String 中找不到 main 方法</span></span><br><span class="line"><span class="comment">//    public static void main(String[] args) &#123;</span></span><br><span class="line"><span class="comment">//        System.out.println(&quot;hello,String&quot;);</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        java.lang.String str = <span class="keyword">new</span> java.lang.String();</span><br><span class="line">        System.out.println(<span class="string">&quot;hello,atguigu.com&quot;</span>);</span><br><span class="line"></span><br><span class="line">        StringTest test = <span class="keyword">new</span> StringTest();</span><br><span class="line">        System.out.println(test.getClass().getClassLoader());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p>​            hello,atguigu.com</p><p>​            sun.misc.Launcher$AppClassLoader@18b4aac2</p><p>从运行的结果看，是不会运行我们自定义的String的，原因就是因为双亲委派机制。</p></li><li><p>双亲委派机制</p><img src="images/58.png" alt="img" style="zoom:65%;" /><img src="images/59.png" alt="img" style="zoom:75%;" /><ul><li><p>优势</p><ul><li><p>避免类的重复加载</p></li><li><p>保护程序安全，防止核心API被随意篡改</p><ul><li><p>自定义类：java.lang.String</p></li><li><p>自定义类：java.lang.ShkStart</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> java.lang;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShkStart</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;hello!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p><img src="images/60.png" alt="img"></p></li></ul></li></ul></li><li><p>沙箱安全机制</p><ul><li>自定义String类，但是在加载自定义String类的时候回率先使用引导类加载器加载，而引导类加载器在加载的过程中会先加载jdk自带的文件（rt.jar包中java\lang\lang\String.class），报错信息说没有main方法，就是因为加载的是rt.jar包中的String类。这样可以保证对java核心源代码的保护，这就是<font color=red><strong>沙箱安全机制</strong></font>。</li></ul></li></ul></li></ul><h2 id="6-其他"><a href="#6-其他" class="headerlink" title="6 其他"></a>6 其他</h2><ul><li><p>在JVM中表示两个class对象是否为同一个类存在两个必要条件：</p><ul><li>类的完整名必须相同，包括包名。</li><li>加载这个类的ClassLoader（指ClassLoader实例对象）必须相同。</li></ul></li><li><p>换句话说，在JVM中，即使两个类对象（class对象）来源于同一个class文件，被同一个虚拟机所加载，但只要加载他们的ClassLoader实例对象不同，那么这两个类对象也是不同的。</p></li><li><p>对加载器的引用</p><ul><li>JVM必须知道一个类型是由启动类加载器加载还是用户类加载器加载的。如果一个类型是由用户类加载器加载的，那么JVM会<font color=red><strong>将这个类加载器的一个引用作为类型信息的一部分保存在方法区中</strong></font>。当解析一个类型到另一个类型的引用的时候，JVN需要保证这两个类型的类加载器时相同的。</li></ul></li><li><p>类的主动使用和被动使用</p><img src="images/61.png" alt="img" style="zoom:70%;" /></li></ul>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MySQL-REDO</title>
      <link href="2019/07/02/MySQL-REDO/"/>
      <url>2019/07/02/MySQL-REDO/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>innodb 事务日志包括 redo log 和 undo log。redo log 是重做日志，提供前滚操作，undo log 是回滚日志，提供回滚操作。</p><p>undo log 不是 redo log 的逆向过程，其实它们都算是用来恢复的日志</p><ol><li><strong>redo log 通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。</strong></li><li>undo 用来回滚行记录到某个版本。undo log 一般是逻辑日志，根据每行记录进行记录。</li></ol>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解JVM(3)_类加载子系统</title>
      <link href="2019/07/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(3)_%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F/"/>
      <url>2019/07/01/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(3)_%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>类的加载指的是将类的 <code>.class</code> 文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在内存区创建一个 <code>java.lang.Class</code> 对象，用来封装类在方法区内的数据结构 </p><p><font color = 'red'> <strong>注意：</strong></font>规范并未说明 <em>Class</em> 对象位于哪里，<em>HotSpot</em> 虚拟机将其放在了方法区内。</p><h2 id="1-类加载时机"><a href="#1-类加载时机" class="headerlink" title="1.类加载时机"></a>1.类加载时机</h2><p>JVM 规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了 <code>.class</code> 文件缺失或存在错误，类加载器必须在<strong>程序首次主动</strong>使用该类才报告错误（LinkageError错误），如果这个类没有被程序主动使用，那么类加载器就不会报告错误。</p><h2 id="2-类加载过程"><a href="#2-类加载过程" class="headerlink" title="2. 类加载过程"></a>2. 类加载过程</h2><h3 id="2-1-加载"><a href="#2-1-加载" class="headerlink" title="2.1.加载"></a>2.1.加载</h3><p>加载是类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情：</p><ul><li>通过一个类的全限定名来获取其定义的二进制字节流。</li><li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</li><li>在 Java 堆中生成一个代表这个类的 <code>java.lang.Class</code> 对象，作为对方法区中这些数据的访问入口。</li></ul><p>相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。</p><p>加载阶段完成后，虚拟机外部的 二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在 Java 堆中也创建一个java.lang.Class 类的对象，这样便可以通过该对象访问方法区中的这些数据。</p><hr><h5 id="加载-class-文件的方式"><a href="#加载-class-文件的方式" class="headerlink" title="加载 .class 文件的方式"></a><strong>加载 .class 文件的方式</strong></h5><ol><li>从本地系统中直接加载</li><li>通过网络下载 .class 文件</li><li>从 zip, jar 等归档文件中加载 .class 文件</li><li>从专有数据库中提取 .class 文件，比较少见</li><li>运行时计算生成: 动态代理</li><li>将 Java 源文件动态编译为 .class 文件</li></ol><hr><h3 id="2-2-连接"><a href="#2-2-连接" class="headerlink" title="2.2. 连接"></a>2.2. 连接</h3><p><strong>类被加载之后，进入连接阶段。连接阶段就是将已经读入到内存的类的二进制数据合并到虚拟机的运行时环境中去。</strong></p><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a><strong><code>验证</code></strong></h4><p>验证是连接阶段的第一步，这一阶段的目的是为了确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作：</p><ol><li><p><strong>文件格式验证</strong></p><p>验证字节流是否符合 Class 文件格式的规范；例如：是否以 <code>0xCAFEBABE</code> 开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。</p></li><li><p><strong>元数据验证</strong></p><p>对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了java.lang.Object之外。</p></li><li><p><strong>字节码验证</strong></p><p>通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。</p></li><li><p><strong>符号引用验证</strong></p><p>确保解析动作能正确执行。</p></li></ol><p>验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone 参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。</p><h4 id="准备"><a href="#准备" class="headerlink" title="准备"></a><code>准备</code></h4><p><strong>在准备阶段，Java 虚拟机为类的静态变量分配内存，并设置默认的初始值。</strong></p><blockquote><p>准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：</p></blockquote><ol><li><p>这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。</p></li><li><p>这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。</p><p>![截屏2020-09-29 下午4.25.03](/Users/joker/Library/Application Support/typora-user-images/截屏2020-09-29 下午4.25.03.png)</p></li></ol><p>假设一个类变量的定义为：public static int value = 3；</p><p>那么变量 value 在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何 Java 方法，而把 value 赋值为3的 putstatic 指令是在程序编译后，存放于类构造器 <clinit>() 方法之中的，所以把 value 赋值为 3 的动作将在初始化阶段才会执行。</p><p>例如对于以下 Sample 类，在准备阶段，将为 int 类型的静态变量 a 分配4个字节的内存空间，并且赋予默认值0，为long类型的静态变量b分配8个字节的内存空间，并且赋予默认值0</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Sample</span></span>&#123;</span><br><span class="line">       <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> a=<span class="number">1</span>;</span><br><span class="line">       <span class="keyword">public</span>  <span class="keyword">static</span> <span class="keyword">long</span> b;</span><br><span class="line">       <span class="keyword">public</span>  <span class="keyword">static</span> <span class="keyword">long</span> c;</span><br><span class="line">       <span class="keyword">static</span> &#123;</span><br><span class="line">           b=<span class="number">2</span>;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="解析"><a href="#解析" class="headerlink" title="解析"></a><code>解析</code></h4><p>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。<strong>符号引用</strong> 就是一组符号来描述目标，可以是任何字面量。</p><p><strong>直接引用</strong>就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。</p><h3 id="2-3-初始化"><a href="#2-3-初始化" class="headerlink" title="2.3. 初始化"></a>2.3. 初始化</h3><p><strong>在初始化阶段，Java 虚拟机执行类的初始化语句，为类的静态变量赋予初始值。</strong>JVM 负责对类进行初始化，主要对类变量进行初始化在程序中，静态变量的初始化有两种途径</p><p>初始化阶段就是执行类构造器方法<clinit>() 的过程</p><img src="/Users/joker/Documents/Learnning/Java/JVM/images/截屏2020-09-29 下午4.30.01.png" alt="截屏2020-09-29 下午4.30.01" style="zoom:50%;" /><ol><li>在静态变量的声明处进行初始化</li><li>在静态代码块中进行初始化。</li></ol><p><strong><font color='blue'>准备阶段即使我们为静态变量赋值为任意的数值，但是该静态变量还是会被初始化为他的默认值，最后的初始化时才会把我们赋予的值设为该静态变量的值</font></strong></p><hr><h4 id="初始化时机"><a href="#初始化时机" class="headerlink" title="初始化时机"></a><code>初始化时机</code></h4><p><strong>Java 虚拟机实现必须在每个类或接口被 Java 程序 “首次主动使用” 时初始化他们</strong></p><ol><li>主动使用<ul><li>创建类的实例</li><li>访问某个类或接口的静态变量，或者对该静态变量赋值</li><li>调用该类的静态方法</li><li>反射</li><li>初始化一个类的子类</li><li>Java虚拟机启动时被标为启动类的类（Java Test）</li></ul></li><li>被动使用</li></ol><hr><h4 id="类的初始化步骤"><a href="#类的初始化步骤" class="headerlink" title="类的初始化步骤"></a><strong><code>类的初始化步骤</code></strong></h4><ol><li>假如这个类还没有被加载和连接，那就先进行加载和连接</li><li>假如类存在直接父类，并且这个父类还没有被初始化，那就先初始化直接父类</li><li>假如类中存在初始化语句，那就依次执行这些初始化语句</li></ol><p>当 Java 虚拟机初始化一个类时，要求它的所有父类都已经被初始化，<strong>但是这条规则不适用于接口</strong>。因此，一个父接口并不会因为它的子接口或者实现类的初始化而初始化。只有当程序首次使用特定的接口的静态变量时，才会导致该接口的初始化。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoadTest9</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;ClassLoadTest9&quot;</span>);</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(Child1.a);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parent1</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> a = <span class="number">9</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Parent1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child1</span> <span class="keyword">extends</span> <span class="title">Parent1</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Child1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 最后输出顺序</span></span><br><span class="line"><span class="comment">// ClassLoadTest9</span></span><br><span class="line"><span class="comment">// Parent1</span></span><br><span class="line"><span class="comment">// 9</span></span><br></pre></td></tr></table></figure><hr><p><strong>接口初始化</strong></p><ol><li>当一个接口在初始化时，并不要求其父接口都完成了初始化只有在真正使用到父接口的时候（如引用接口中定义的常量），才会初始化</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 当一个接口在初始化时，并不要求其父接口都完成了初始化</span></span><br><span class="line"><span class="comment"> * 只有在真正使用到父接口的时候（如引用接口中定义的常量），才会初始化</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoadTest5</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">       System.out.println(MyChild.b);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Student5</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">9</span>; <span class="comment">//前面省了public static final</span></span><br><span class="line">    Thread thread = <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">        &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;thread 初始化了&quot;</span>);<span class="comment">//如果父接口初始化了这句应该输出</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">MyChild</span> <span class="keyword">extends</span> <span class="title">Student5</span> </span>&#123;     <span class="comment">//接口属性默认是 public static final</span></span><br><span class="line">    String b = LocalDateTime.now().toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h2 id="3-截屏2020-09-29-下午4-30-01-Users-joker-Documents-Learnning-Java-JVM-images-截屏2020-09-29-下午4-30-01-png-类加载器"><a href="#3-截屏2020-09-29-下午4-30-01-Users-joker-Documents-Learnning-Java-JVM-images-截屏2020-09-29-下午4-30-01-png-类加载器" class="headerlink" title="3. ![截屏2020-09-29 下午4.30.01](/Users/joker/Documents/Learnning/Java/JVM/images/截屏2020-09-29 下午4.30.01.png )类加载器"></a>3. ![截屏2020-09-29 下午4.30.01](/Users/joker/Documents/Learnning/Java/JVM/images/截屏2020-09-29 下午4.30.01.png )类加载器</h2><p>类的加载由类加载器完成，JVM 提供的类加载器叫做系统类加载器，此外还可以通过继承 ClassLoader 基类来自定义类加载器。</p><h3 id="系统类加载器"><a href="#系统类加载器" class="headerlink" title="系统类加载器"></a>系统类加载器</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.poplar.classload;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoadTest18</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(System.getProperty(<span class="string">&quot;sun.boot.class.path&quot;</span>));<span class="comment">//根加载器路径</span></span><br><span class="line">        System.out.println(System.getProperty(<span class="string">&quot;java.ext.dirs&quot;</span>));<span class="comment">//扩展类加载器路径</span></span><br><span class="line">        System.out.println(System.getProperty(<span class="string">&quot;java.class.path&quot;</span>));<span class="comment">//应用类加载器路径</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p><strong>根类加载器</strong>（Bootstrap）</p><blockquote><p>该加载器没有父加载器，它负责加载虚拟机中的核心类库。根类加载器从系统属性 <code>sun.boot.class.path</code> 所指定的目录中加载类库。类加载器的实现依赖于底层操作系统，属于虚拟机的实现的一部分，它并没有集成<code>java.lang.ClassLoader</code> 类。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.poplar.classload;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoadTest7</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">     <span class="comment">//null 由于String是由根加载器加载，在rt.jar包下</span></span><br><span class="line">     System.out.println(String.class.getClassLoader());</span><br><span class="line">     <span class="comment">//sun.misc.Launcher$AppClassLoader@73d16e93 </span></span><br><span class="line">     System.out.println(C.class.getClassLoader());</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><ul><li><p><strong>扩展类加载器</strong>（Extension）</p><blockquote><p>它的父加载器为根类加载器。它从 <code>java.ext.dirs</code> 系统属性所指定的目录中加载类库，或者从JDK的安装目录的jre\lib\ext子目录（扩展目录）下加载类库，如果把用户创建的jar文件放在这个目录下，也会自动由扩展类加载器加载，扩展类加载器是纯java类，是java.lang.ClassLoader的子类。</p></blockquote></li><li><p><strong>系统应用类加载器</strong>（AppClassLoader/System）</p><blockquote><p>也称为应用类加载器，它的父加载器为扩展类加载器，它从环境变量classpath或者系统属性java.class.path所指定的目录中加载类，他是用户自定义的类加载器的默认父加载器。系统类加载器时纯java类，是java.lang.ClassLoader的子类。</p></blockquote></li></ul><h3 id="用户自定义的类加载器"><a href="#用户自定义的类加载器" class="headerlink" title="用户自定义的类加载器"></a><strong>用户自定义的类加载器</strong></h3><ul><li>java.lang.ClassLoader的子类</li><li>用户可以定制类的加载方式</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.poplar.classload;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**  </span></span><br><span class="line"><span class="comment"> * 自定义类加载器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomClassLoader</span> <span class="keyword">extends</span> <span class="title">ClassLoader</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> String classLoaderName;</span><br><span class="line">  <span class="keyword">private</span> String path;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPath</span><span class="params">(String path)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.path = path;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String filePost = <span class="string">&quot;.class&quot;</span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">CustomClassLoader</span><span class="params">(ClassLoader parent, String classLoaderName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(parent);<span class="comment">//显示指定该类的父类加载器</span></span><br><span class="line">    <span class="keyword">this</span>.classLoaderName = classLoaderName;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">CustomClassLoader</span><span class="params">(String classLoaderName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>();<span class="comment">//将系统类加载器当作该类的父类加载器</span></span><br><span class="line">    <span class="keyword">this</span>.classLoaderName = classLoaderName;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Class <span class="title">findClass</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;findClass,输出这句话说明我们自己的类加载器加载了指定的类&quot;</span>);</span><br><span class="line">    <span class="keyword">byte</span>[] b = loadClassData(name);</span><br><span class="line">    <span class="keyword">return</span> defineClass(name, b, <span class="number">0</span>, b.length);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">byte</span>[] loadClassData(String name) &#123;</span><br><span class="line">    InputStream is = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">byte</span>[] data = <span class="keyword">null</span>;</span><br><span class="line">    ByteArrayOutputStream byteArrayOutputStream = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      name = name.replace(<span class="string">&quot;.&quot;</span>, File.separator);<span class="comment">//File.separator根据操作系统而变化</span></span><br><span class="line">      is = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(path + name + filePost));</span><br><span class="line">      byteArrayOutputStream = <span class="keyword">new</span> ByteArrayOutputStream();</span><br><span class="line">      <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">while</span> (-<span class="number">1</span> != (len = is.read())) &#123;</span><br><span class="line">        byteArrayOutputStream.write(len);</span><br><span class="line">      &#125;</span><br><span class="line">      data = byteArrayOutputStream.toByteArray();</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        is.close();</span><br><span class="line">        byteArrayOutputStream.close();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   执行结果： </span></span><br><span class="line"><span class="comment">   findClass,输出这句话说明我们自己的类加载器加载了指定的类</span></span><br><span class="line"><span class="comment">   com.poplar.classload.CustomClassLoader2@15db97422018699554</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    CustomClassLoader2 Loader2 = <span class="keyword">new</span> CustomClassLoader2(<span class="string">&quot;load2&quot;</span>);</span><br><span class="line">    test1(loader2) </span><br><span class="line">    CustomClassLoader2 Loader3 = <span class="keyword">new</span> CustomClassLoader2(<span class="string">&quot;load3&quot;</span>);</span><br><span class="line">    test1(loader3)    </span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">(CustomClassLoader2 loader2)</span> <span class="keyword">throws</span> ClassNotFoundException, InstantiationException, IllegalAccessException </span>&#123;</span><br><span class="line">          loader2.setPath(<span class="string">&quot;C:\\Users\\poplar\\Desktop\\&quot;</span>);</span><br><span class="line">          Class&lt;?&gt; clazz = loader2.loadClass(<span class="string">&quot;com.poplar.classload.ClassLoadTest&quot;</span>);</span><br><span class="line">          Object instance = clazz.newInstance();</span><br><span class="line">          System.out.println(instance.getClass().getClassLoader());</span><br><span class="line">          System.out.println(instance.hashCode());</span><br><span class="line">          System.out.println(<span class="string">&quot;-------------------------------------&quot;</span>);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><hr><p><strong>命名空间</strong></p><ul><li>每个类加载器都有自己的命名空间，<strong>命名空间由该加载器及所有父加载器所加载的类构成</strong>；</li><li>在同一个命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类；</li><li>在不同的命名空间中，有可能会出现类的完整名字（包括类的包名）相同的两个类；</li><li>同一命名空间内的类是互相可见的，<strong>非同一命名空间内的类是不可见的</strong>；</li><li>子加载器可以见到父加载器加载的类，<strong>父加载器也不能见到子加载器加载的类</strong>。</li></ul><hr><p><strong>注：</strong></p><ul><li>类加载器本身也是类加载器，类加载器又是谁加载的呢？？（先有鸡还是现有蛋）<br>类加载器是由启动类加载器去加载的，启动类加载器是C++写的，内嵌在JVM中。</li><li>内嵌于JVM中的启动类加载器会加载java.lang.ClassLoader以及其他的Java平台类。当JVM启动时，一块特殊的机器码会运行，它会加载扩展类加载器以及系统类加载器，这块特殊的机器码叫做启动类加载器。</li><li>启动类加载器并不是java类，其他的加载器都是java类。</li><li>启动类加载器是特定于平台的机器指令，它负责开启整个加载过程。</li></ul><hr><h2 id="1-类加载器与类的加载过程"><a href="#1-类加载器与类的加载过程" class="headerlink" title="1.类加载器与类的加载过程"></a>1.类加载器与类的加载过程</h2><ul><li><p>类加载器子系统作用</p><ul><li>类加载器子系统作用负责从文件系统或者网络中加载Class文件，class文件在文件开头会有特定的文件标识。</li><li>ClassLoader只负责class文件的加载，只与它是否可以运行，则由Execution Engine决定。</li><li>加载的类信息存放在一块称为<font color=red><strong>方法区</strong></font>的内存空间。除了类的信息外，方法区中还会存放运行时常量池信息，可能还包括字符串字面量和数字常量（这部分常量信息时Class文件中常量池部分的内存映射）</li></ul></li><li><p>类加载器ClassLoader的角色</p><img src="images/48.png" alt="img" style="zoom:60%;" /></li><li><p>类的加载过程</p><img src="images/49.png" alt="img" style="zoom:70%;" /><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloLoader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;谢谢ClassLoader加载我....&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;你的大恩大德，我下辈子再报！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="images/50.png" alt="img" style="zoom:70%;" /><ul><li><p>加载：</p><ol><li><p>通过一个类的全限名获取定义此类的二进制字节流</p></li><li><p>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构</p></li><li><p><font color=red><strong>在内存中生成一个代表这个类的java.lang.Class对象</strong></font>，作为方法区这个类的各种数据的访问入口</p></li></ol><ul><li>补充：加载.class文件放入方式<ul><li>从本地系统中直接加载</li><li>通过网络获取，典型场景：Web Applet</li><li>从zip压缩包中读取，成为日后jar、war格式的基础</li><li>运行时计算生成，使用最多的是：动态代理技术</li><li>由其他文件生成，典型场景：JSP应用</li><li>从专有数据库中提取.class文件，比较少见</li><li>从加密文件中获取，典型的防Class文件被反编译的保护措施</li></ul></li></ul></li><li><p>链接</p><p><img src="images/51.png" alt="img"></p></li><li><p>初始化</p><p><img src="images/52.png" alt="img"></p><hr><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassInitTest</span> </span>&#123;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> num = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">static</span>&#123;</span><br><span class="line">       num = <span class="number">2</span>;</span><br><span class="line">       number = <span class="number">20</span>;</span><br><span class="line">       System.out.println(num);</span><br><span class="line">       <span class="comment">//System.out.println(number);//报错：非法的前向引用。</span></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> number = <span class="number">10</span>;  <span class="comment">// linking之prepare: number = 0 --&gt; initial: 20 --&gt; 10</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(ClassInitTest.num);  <span class="comment">// 2</span></span><br><span class="line">        System.out.println(ClassInitTest.number);  <span class="comment">// 10</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p>​            2</p><p>​            10</p><p>通过jclasslib可以查看其内部执行过程</p><p><img src="images/53.png" alt="img"></p><hr><p>JVM会保证父类的&lt;clinit&gt;()首先执行</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClinitTest1</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Father</span></span>&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> A = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">static</span>&#123; A = <span class="number">2</span>; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Son</span> <span class="keyword">extends</span> <span class="title">Father</span></span>&#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> B = A;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//加载Father类，其次加载Son类。</span></span><br><span class="line">        System.out.println(Son.B);<span class="comment">//2</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>虚拟机必须保证一个类的&lt;clinit&gt;()方法在多线程下被同步加锁，并且只会被加载一次</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DeadThreadTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Runnable r = () -&gt; &#123;</span><br><span class="line">            System.out.println(Thread.currentThread().getName() + <span class="string">&quot;开始&quot;</span>);</span><br><span class="line">            DeadThread dead = <span class="keyword">new</span> DeadThread();</span><br><span class="line">            System.out.println(Thread.currentThread().getName() + <span class="string">&quot;结束&quot;</span>);</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        Thread t1 = <span class="keyword">new</span> Thread(r,<span class="string">&quot;线程1&quot;</span>);</span><br><span class="line">        Thread t2 = <span class="keyword">new</span> Thread(r,<span class="string">&quot;线程2&quot;</span>);</span><br><span class="line"></span><br><span class="line">        t1.start();</span><br><span class="line">        t2.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeadThread</span></span>&#123;</span><br><span class="line">    <span class="keyword">static</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            System.out.println(Thread.currentThread().getName() + <span class="string">&quot;初始化当前类&quot;</span>);</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p>​            线程1开始</p><p>​            线程2开始</p><p>​            线程1初始化当前类</p><p>​            线程2结束</p><p>​            线程1结束</p></li></ul></li></ul><h2 id="3-类加载器分类"><a href="#3-类加载器分类" class="headerlink" title="3 类加载器分类"></a>3 类加载器分类</h2><p>JVM 支持两种类型的类加载器，分别是<font color=red><strong>引导类加载器（Bootstrap ClassLoader）</strong></font>和<font color=red><strong>自定义类加载器（User-Defined ClassLoader）</strong></font></p><p>从概念上讲，自定义类加载器是指程序中由开发人员自定义的一类加载器，然而Java虚拟机规范却并没有这么定义，而是<font color=red><strong>将所有派生与抽象类 ClassLoader 的类加载器都划分为自定义类加载器</strong></font>。</p><p>无论类加载器的类型如何划分，在程序中我们最常见的类加载器始终只有三个，如下图：</p><img src="images/54.png" alt="img" style="zoom:55%;" /><p>Bootstrap ClassLoader是由C++语言实现的，其余的是由Java语言实现的</p><img src="images/55.png" alt="img" style="zoom:65%;" /><hr><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoaderTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取系统类加载器</span></span><br><span class="line">        ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader();</span><br><span class="line">        System.out.println(systemClassLoader);<span class="comment">//sun.misc.Launcher$AppClassLoader@18b4aac2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取其上层：扩展类加载器</span></span><br><span class="line">        ClassLoader extClassLoader = systemClassLoader.getParent();</span><br><span class="line">        System.out.println(extClassLoader);<span class="comment">//sun.misc.Launcher$ExtClassLoader@1540e19d</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取其上层：获取不到引导类加载器</span></span><br><span class="line">        ClassLoader bootstrapClassLoader = extClassLoader.getParent();</span><br><span class="line">        System.out.println(bootstrapClassLoader);<span class="comment">//null</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//对于用户自定义类来说：默认使用系统类加载器进行加载</span></span><br><span class="line">        ClassLoader classLoader = ClassLoaderTest.class.getClassLoader();</span><br><span class="line">        System.out.println(classLoader);<span class="comment">//sun.misc.Launcher$AppClassLoader@18b4aac2</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//String类使用引导类加载器进行加载的。---&gt; Java的核心类库都是使用引导类加载器进行加载的。</span></span><br><span class="line">        ClassLoader classLoader1 = String.class.getClassLoader();</span><br><span class="line">        System.out.println(classLoader1);<span class="comment">//null</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>虚拟机自带的加载器</p><ul><li>启动类加载器（引导类加载器，Bootstrap ClassLoader）<ul><li>这个类加载使用<font color=red><strong>C/C++语言实现的</strong></font>，嵌套在JVM内部</li><li>它用来加载Java核心类库(JAVA_HOME/jre/lib/rt.jar、resources.jar或sun.boot.class.path路径下的内容)，用于提供JVM自身需要的类</li><li>并不继承自java.lang.ClassLoader，没有父加载器</li><li>加载扩展类和应用程序加载器，并指定为他们的父类加载器</li><li>出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类</li></ul></li><li>扩展类加载器（Extension ClassLoader）<ul><li><font color=red><strong>Java语言编写</strong></font>，由sun.misc.Launcher$ExtClassLoader实现。</li><li><font color=red><strong>派生于ClassLoader类</strong></font></li><li>父类加载器为启动类加载器</li><li>从java.ext.dirs系统属性所指定的目录加载类库，或从JDK安装目录的jre/lib/ext子目录（扩展目录）下加载类库。<font color=red><strong>如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载</strong></font>。</li></ul></li><li>应用程序类加载器（系统类加载器，AppClassLoader）<ul><li>java语言编写，由sun.misc.Launcher$AppClassLoader实现。</li><li><font color=red><strong>派生于ClassLoader类</strong></font></li><li>父类加载器为启动类加载器</li><li>它负责加载环境变量classpath或系统属性java.class.path指定路径下的类库</li><li><font color=red><strong>该类加载是程序中默认的类加载器</strong></font>，一般来说，Java应用的类都是由它来完成加载</li><li>通过ClassLoader.getSystemClassLoader()方法可以获取到该类加载器</li></ul></li></ul></li><li><p>加载器加载内容</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoaderTest1</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;------------启动类加载器------------&quot;</span>);</span><br><span class="line">        <span class="comment">//获取BootstrapClassLoader能够加载的api的路径</span></span><br><span class="line">        URL[] urLs = sun.misc.Launcher.getBootstrapClassPath().getURLs();</span><br><span class="line">        <span class="keyword">for</span> (URL element : urLs) &#123;</span><br><span class="line">            System.out.println(element.toExternalForm());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//从上面的路径中随意选择一个类,来看看他的类加载器是什么:引导类加载器</span></span><br><span class="line">        ClassLoader classLoader = Provider.class.getClassLoader();</span><br><span class="line">        System.out.println(classLoader);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;------------扩展类加载器------------&quot;</span>);</span><br><span class="line">        String extDirs = System.getProperty(<span class="string">&quot;java.ext.dirs&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (String path : extDirs.split(<span class="string">&quot;;&quot;</span>)) &#123;</span><br><span class="line">            System.out.println(path);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//从上面的路径中随意选择一个类,来看看他的类加载器是什么:扩展类加载器</span></span><br><span class="line">        ClassLoader classLoader1 = CurveDB.class.getClassLoader();</span><br><span class="line">        System.out.println(classLoader1);<span class="comment">//sun.misc.Launcher$ExtClassLoader@1540e19d</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p>​            ————启动类加载器————</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/resources.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/rt.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/sunrsasign.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/jsse.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/jce.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/charsets.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/lib/jfr.jar</p><p>​            file:/D:/Java/jdk1.8.0_231/jre/classes</p><p>​            null</p><p>​            ————扩展类加载器————</p><p>​            D:\Java\jdk1.8.0_231\jre\lib\ext</p><p>​            C:\WINDOWS\Sun\Java\lib\ext</p><p>​            sun.misc.Launcher$ExtClassLoader@12a3a380</p></li><li><p>用户自定义类加载器</p><ul><li>在Java日常应用程序开发中，类的加载几乎是由上述3种加载器相互配合执行的，在必要时，我们还可以自定义类加载器，来定制类的加载方式。</li><li>为什么需要自定义类加载器？<ul><li>隔离加载类</li><li>修改类加载的方式</li><li>扩展加载源</li><li>防止源码泄露</li></ul></li><li>用户自定义类加载器实现步骤：<ul><li>开发人员可以通过集成抽象类java.lang.ClassLoader类的方式，实现自己的类加载器，以满足一些特殊的需求</li><li>在JDK1.2之前，在自定义类加载器时，总会去集成ClassLoader类并重写loadClass()方法，从而实现自定义的类加载器，但是在JDK1.2之后已不再建议用户去覆盖loadClass()方法，而是建议把自定义的类加载逻辑卸载findClass()方法中</li><li>在编写自定义的类加载器时，如果没有过于复杂的需求，可以直接继承URLClassLoader类，这样就可以避免自己去编写findClass()方法及获取字节码流的方式，使自定义类加载器编写更加简洁。</li></ul></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomClassLoader</span> <span class="keyword">extends</span> <span class="title">ClassLoader</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> Class&lt;?&gt; findClass(String name) <span class="keyword">throws</span> ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] result = getClassFromCustomPath(name);</span><br><span class="line">            <span class="keyword">if</span>(result == <span class="keyword">null</span>)&#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> FileNotFoundException();</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">return</span> defineClass(name,result,<span class="number">0</span>,result.length);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ClassNotFoundException(name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">byte</span>[] getClassFromCustomPath(String name)&#123;</span><br><span class="line">        <span class="comment">//从自定义路径中加载指定类:细节略</span></span><br><span class="line">        <span class="comment">//如果指定路径的字节码文件进行了加密，则需要在此方法中进行解密操作。</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        CustomClassLoader customClassLoader = <span class="keyword">new</span> CustomClassLoader();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Class&lt;?&gt; clazz = Class.forName(<span class="string">&quot;One&quot;</span>,<span class="keyword">true</span>,customClassLoader);</span><br><span class="line">            Object obj = clazz.newInstance();</span><br><span class="line">            System.out.println(obj.getClass().getClassLoader());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="4-ClassLoader的使用说明"><a href="#4-ClassLoader的使用说明" class="headerlink" title="4 ClassLoader的使用说明"></a>4 ClassLoader的使用说明</h2><ul><li><p>ClassLoader类，它是一个抽象类，其后所有的类加载器都继承自ClassLoader（不包括启动类加载器）</p><p><img src="images/56.png" alt="img"></p><img src="images/55.png" alt="img" style="zoom:65%;" /></li><li><p>获取ClassLoader的途径</p><ul><li>方式一：获取当前类的ClassLoader：class.getClassLoader()</li><li>方式二：获取当前线程上下文的ClassLoader：Thread.current().getContextLoader()</li><li>方式三：获取系统的ClassLoader：ClassLoader.getSystemClassLoader()</li><li>方式四：获取调用者的ClassLoader：DriverManager.getCallerClassLoader()</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoaderTest2</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1.</span></span><br><span class="line">            ClassLoader classLoader = Class.forName(<span class="string">&quot;java.lang.String&quot;</span>).getClassLoader();</span><br><span class="line">            System.out.println(classLoader);</span><br><span class="line">            <span class="comment">//2.</span></span><br><span class="line">            ClassLoader classLoader1 = Thread.currentThread().getContextClassLoader();</span><br><span class="line">            System.out.println(classLoader1);</span><br><span class="line">            <span class="comment">//3.</span></span><br><span class="line">            ClassLoader classLoader2 = ClassLoader.getSystemClassLoader().getParent();</span><br><span class="line">            System.out.println(classLoader2);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p>​            null</p><p>​            sun.misc.Launcher$AppClassLoader@18b4aac2</p><p>​            sun.misc.Launcher$ExtClassLoader@1b6d3586</p></li></ul><h2 id="5-双亲委派机制"><a href="#5-双亲委派机制" class="headerlink" title="5 双亲委派机制"></a>5 双亲委派机制</h2><ul><li><p>Java虚拟机对class文件采用的是<font color=red><strong>按需加载</strong></font>的方式，也就是说当需要使用该类时才会将他的class文件加载到内存生成Class对象。而且加载某个类的class文件是=时，Java虚拟机采用的是<font color=red><strong>双亲委派机制</strong></font>，即把请求交由父类处理，它是一种任务委派模式。</p></li><li><p>一个问题？在当前模块下，创建一个java.lang.String类，并使用，会使用我们创建的String吗？</p><img src="images/57.png" alt="img" style="zoom:85%;" /><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span> </span>&#123;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="keyword">static</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;我是自定义的String类的静态代码块&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//    //错误: 在类 java.lang.String 中找不到 main 方法</span></span><br><span class="line"><span class="comment">//    public static void main(String[] args) &#123;</span></span><br><span class="line"><span class="comment">//        System.out.println(&quot;hello,String&quot;);</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        java.lang.String str = <span class="keyword">new</span> java.lang.String();</span><br><span class="line">        System.out.println(<span class="string">&quot;hello,atguigu.com&quot;</span>);</span><br><span class="line"></span><br><span class="line">        StringTest test = <span class="keyword">new</span> StringTest();</span><br><span class="line">        System.out.println(test.getClass().getClassLoader());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p>​            hello,atguigu.com</p><p>​            sun.misc.Launcher$AppClassLoader@18b4aac2</p><p>从运行的结果看，是不会运行我们自定义的String的，原因就是因为双亲委派机制。</p></li><li><p>双亲委派机制</p><img src="images/58.png" alt="img" style="zoom:65%;" /><img src="images/59.png" alt="img" style="zoom:75%;" /><ul><li><p>优势</p><ul><li><p>避免类的重复加载</p></li><li><p>保护程序安全，防止核心API被随意篡改</p><ul><li><p>自定义类：java.lang.String</p></li><li><p>自定义类：java.lang.ShkStart</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> java.lang;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShkStart</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;hello!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>结果：</strong></p><p><img src="images/60.png" alt="img"></p></li></ul></li></ul></li><li><p>沙箱安全机制</p><ul><li>自定义String类，但是在加载自定义String类的时候回率先使用引导类加载器加载，而引导类加载器在加载的过程中会先加载jdk自带的文件（rt.jar包中java\lang\lang\String.class），报错信息说没有main方法，就是因为加载的是rt.jar包中的String类。这样可以保证对java核心源代码的保护，这就是<font color=red><strong>沙箱安全机制</strong></font>。</li></ul></li></ul></li></ul><h2 id="6-其他"><a href="#6-其他" class="headerlink" title="6 其他"></a>6 其他</h2><ul><li><p>在JVM中表示两个class对象是否为同一个类存在两个必要条件：</p><ul><li>类的完整名必须相同，包括包名。</li><li>加载这个类的ClassLoader（指ClassLoader实例对象）必须相同。</li></ul></li><li><p>换句话说，在JVM中，即使两个类对象（class对象）来源于同一个class文件，被同一个虚拟机所加载，但只要加载他们的ClassLoader实例对象不同，那么这两个类对象也是不同的。</p></li><li><p>对加载器的引用</p><ul><li>JVM必须知道一个类型是由启动类加载器加载还是用户类加载器加载的。如果一个类型是由用户类加载器加载的，那么JVM会<font color=red><strong>将这个类加载器的一个引用作为类型信息的一部分保存在方法区中</strong></font>。当解析一个类型到另一个类型的引用的时候，JVN需要保证这两个类型的类加载器时相同的。</li></ul></li><li><p>类的主动使用和被动使用</p><img src="images/61.png" alt="img" style="zoom:70%;" /></li></ul>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解JVM(2)_JVM和Java体系结构</title>
      <link href="2019/06/27/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(2)_JVM%E5%92%8CJava%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
      <url>2019/06/27/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(2)_JVM%E5%92%8CJava%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="JVM-和-Java-体系结构"><a href="#JVM-和-Java-体系结构" class="headerlink" title="JVM 和 Java 体系结构"></a>JVM 和 Java 体系结构</h1><h2 id="1-Java-及-JVM-简介"><a href="#1-Java-及-JVM-简介" class="headerlink" title="1.Java 及 JVM 简介"></a>1.Java 及 JVM 简介</h2><h2 id="1-1-Java-生态圈"><a href="#1-1-Java-生态圈" class="headerlink" title="1.1. Java 生态圈"></a>1.1. Java 生态圈</h2><ul><li><p><font color=red><strong>作为一个平台</strong></font></p><p>Java虚拟机扮演着举足轻重的作用。Groovy、Scala、JRuby、Kotlin等都是Java平台的一部分</p></li><li><p><font color=red><strong>作为一种文化</strong></font>：</p><ul><li>第三方开源软件和框架。如Tomcat、Struts、MyBatis、Spring等。</li><li>就连 JDK 和 JVM 自身也有不少开源的实现，如 OpenJDK、Harmony。</li></ul></li><li><p><font color=red><strong>作为一个社区</strong></font></p><p>Java拥有全世界最多的技术拥护者和开源社区支持，有数不清的论坛和资料。</p></li></ul><h2 id="1-2-Java-跨平台的语言"><a href="#1-2-Java-跨平台的语言" class="headerlink" title="1.2.Java 跨平台的语言"></a>1.2.Java 跨平台的语言</h2><img src="images/8.png" alt="img" style="zoom:50%;" /><h2 id="1-3-JVM-跨语言的平台"><a href="#1-3-JVM-跨语言的平台" class="headerlink" title="1.3. JVM 跨语言的平台"></a>1.3. JVM 跨语言的平台</h2><p><img src="images/10.png" alt="img"></p><ol><li>随着 Java7 的正式发布，Java 虚拟机的设计者们通过规范基本实现在 <font color=red><strong>Java虚拟机平台运行非Java语言编写的程序</strong></font></li><li>Java 虚拟机根本不关心运行在其内部的程序到底是使用何种语言编写的，<font color=red><strong>它值关心 “字节码” 文件</strong></font>。</li><li><font color=red><strong>Java 不是最强大的语言，但是JVM是最强大的虚拟机。</strong></font></li><li>Java 字节码，指的是用 java 语言编写成的字节码。准确的说任何能在 jvm 平台执行的字节码格式都是一样的。所以应该统称为:<font color=red><strong>jvm字节码</strong></font>。</li><li>不同的编译器，可以编译出相同的字节码文件，字节码文件也可以在不同的 JVM 上运行。</li><li>Java 虚拟机与 Java 语言并没有必然的联系，它只与特定的二进制文件格式 <code>Class</code> 文件格式所关联，<code>Class</code> 文件包含了 Java 虚拟机指令集（或者称为字节码、Bytecodes）和符号表，还有一些其他辅助信息。</li><li>多语言混合编程<ul><li>JVM 平台上的多语言混合编程称为主流，通过特定的语言去解决特定领域的问题是当前软件开发应对日趋复杂的项目需求的一个方向。</li><li>各种语言之间的交互不存在任何困难，就像使用自己语言的原生PAI一样方便，因为它们最终都运行在一个虚拟机上</li><li>对这些运行在 Java 虚拟机上、Java 之外的语言，来自系统的、底层的支持正在迅速增长，推动 Java 虚拟机从 “Java语言的虚拟机” 向 “多语言虚拟机” 的方向发展</li></ul></li></ol><h2 id="2-虚拟机与-Java-虚拟机"><a href="#2-虚拟机与-Java-虚拟机" class="headerlink" title="2. 虚拟机与 Java 虚拟机"></a>2. 虚拟机与 Java 虚拟机</h2><p>所谓虚拟机（Virtual Machine），就是一台虚拟的计算机。它是一款软件，用来执行一系列虚拟计算机指令。大体上，虚拟机可以分为<font color=blue><strong>系统虚拟机</strong></font>和<font color=blue><strong>程序虚拟机</strong></font>。</p><ol><li>大名鼎鼎的 Vitural Box，VMware 就属于系统虚拟机，他们<font color=blue><strong>完全是对物理计算机的仿真</strong></font>，提供了一个可运行完整操作系统的软件平台</li><li>程序虚拟机的典型代表就是 Java 虚拟机，它<font color=blue><strong>专门为执行单个计算机程序而设计</strong></font>，在 Java 虚拟机中执行的命令称为Java字节码指令。</li></ol><p>无论是系统虚拟机还是程序虚拟机，在上面运行的软件都被限制于虚拟机提供的资源中</p><h3 id="Java-虚拟机"><a href="#Java-虚拟机" class="headerlink" title="Java 虚拟机"></a>Java 虚拟机</h3><p>Java 虚拟机是一台执行 Java 字节码的虚拟计算机，它拥有独立的运行机制，其运行的 Java 字节码也未必是由 Java 语言编写而成的。</p><p>JVM 平台的各种语言可以共享 Java 虚拟机的跨平台、优秀的垃圾回收器，以及可靠的及时编译器。</p><p><font color=blue><strong>Java 技术的核心就是 Java 虚拟机</strong></font>（JVM，Java Virtual Machine），因为所有的Java程序都运行在Java虚拟机内部</p><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p><font color=blue><strong>Java 虚拟机就是二进制字节码的运行环境</strong></font>，负责装在字节码到其内部，解释/编译为对应平台的机器指令执行。每一条Java命令，Java虚拟机规范都有详细定义，如怎么去操作数，处理结果放在哪里。</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>一次编译，到处运行</li><li>自动内存管理</li><li>自动垃圾回收功能</li></ul><h3 id="JVM-的位置"><a href="#JVM-的位置" class="headerlink" title="JVM 的位置"></a>JVM 的位置</h3><img src="images/15.png" alt="img" style="zoom:50%;" /><h2 id="3-JVM-整体结构"><a href="#3-JVM-整体结构" class="headerlink" title="3 JVM 整体结构"></a>3 JVM 整体结构</h2><img src="images/19.png" alt="img" style="zoom:70%;" /><h2 id="4-Java-代码执行流程"><a href="#4-Java-代码执行流程" class="headerlink" title="4 Java 代码执行流程"></a>4 Java 代码执行流程</h2><img src="images/8.png" alt="img" style="zoom:50%;" /><img src="images/20.png" alt="img" style="zoom:75%;" /><h2 id="5-JVM-的架构模型"><a href="#5-JVM-的架构模型" class="headerlink" title="5 JVM 的架构模型"></a>5 JVM 的架构模型</h2><p>Java 编译器输入的指令流基本上是一种基于<font color=blue><strong>栈的指令集架构</strong></font>，另外一种指令集架构则是基于<font color=blue><strong>寄存器的指令集架构</strong></font>。</p><h3 id="基于栈式架构的特点"><a href="#基于栈式架构的特点" class="headerlink" title="基于栈式架构的特点"></a>基于栈式架构的特点</h3><ul><li>设计和实现简单，适用于资源受限的系统；</li><li>避开了寄存器的分配难题：使用零地址指令方式分配。</li><li>指令流中的大部分是零地址指令，其执行过程依赖于操作栈。指令集更小，编译器容易实现。</li><li>不需要硬件支持，可移植性更好，更好实现跨平台</li></ul><h3 id="基于寄存器架构的特点"><a href="#基于寄存器架构的特点" class="headerlink" title="基于寄存器架构的特点"></a>基于寄存器架构的特点</h3><ul><li>典型的应用是x86的二进制指令集：比如传统的PC以及Android的Davlik虚拟机。</li><li>指令集架构则完全依赖硬件，可移植性差</li><li>性能优秀和执行高效；</li><li>花费更少的指令去完成一项操作。</li><li>在大部分情况下，基于寄存器架构的指令集往往都是以一地址指令、二地址指令和三地址指令为主，而基于栈式架构的指令集却是以零地址指令为主。</li></ul><h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><p><font color=blue><strong>由于跨平台的设计，Java 的指令都是根据栈来设计的</strong></font>。不同平台的 CPU 架构不同，所以不能设计为基于寄存器的。</p><p>优点是跨平台，指令集小，编译器容易实现，缺点是性能下降，实现同样的功能需要更多的指令。</p><h2 id="6-JVM-的生命周期"><a href="#6-JVM-的生命周期" class="headerlink" title="6 JVM 的生命周期"></a>6 JVM 的生命周期</h2><h3 id="6-1-虚拟机的启动"><a href="#6-1-虚拟机的启动" class="headerlink" title="6.1. 虚拟机的启动"></a>6.1. <strong>虚拟机的启动</strong></h3><p>Java 虚拟机的启动是通过引导类加载器（bootstrap class loader）创建一个初始类（initial class）来完成的，这个类是由虚拟机的具体实现指定的。</p><h3 id="6-2-虚拟机的执行"><a href="#6-2-虚拟机的执行" class="headerlink" title="6.2. 虚拟机的执行"></a>6.2. <strong>虚拟机的执行</strong></h3><p>一个运行的 Java 虚拟机有着一个清晰的任务: 执行Java程序。</p><p>程序开始执行时他才运行，程序结束时他就停止。</p><p><font color=blue><strong>执行一个所谓的 Java 程序的时候，真真正正在执行的是一个叫做 Java 虚拟机的进程</strong></font>。</p><h3 id="6-3-虚拟机的退出"><a href="#6-3-虚拟机的退出" class="headerlink" title="6.3. 虚拟机的退出"></a>6.3. <strong>虚拟机的退出</strong></h3><ol><li><p>程序正常执行结束</p></li><li><p>程序在执行过程中遇到了异常或错误而异常终止</p></li><li><p>由于操作系统出现错误而导致 Java 虚拟机进程结束</p></li><li><p>某线程调用 Runtime 类或 System 类的 exit 方法，或 Runtime 类的 halt 方法，并且 Java 安全管理器也允许这次 exit 或 halt 操作。</p><ul><li><p>System</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">System</span> </span>&#123;   </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">exit</span><span class="params">(<span class="keyword">int</span> status)</span> </span>&#123;</span><br><span class="line">        Runtime.getRuntime().exit(status);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Runtime</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Runtime</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Runtime currentRuntime = <span class="keyword">new</span> Runtime();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Runtime <span class="title">getRuntime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> currentRuntime;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** Don&#x27;t let anyone else instantiate this class */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Runtime</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">exit</span><span class="params">(<span class="keyword">int</span> status)</span> </span>&#123;</span><br><span class="line">        SecurityManager security = System.getSecurityManager();</span><br><span class="line">        <span class="keyword">if</span> (security != <span class="keyword">null</span>) &#123;</span><br><span class="line">            security.checkExit(status);</span><br><span class="line">        &#125;</span><br><span class="line">        Shutdown.exit(status);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">halt</span><span class="params">(<span class="keyword">int</span> status)</span> </span>&#123;</span><br><span class="line">        SecurityManager sm = System.getSecurityManager();</span><br><span class="line">        <span class="keyword">if</span> (sm != <span class="keyword">null</span>) &#123;</span><br><span class="line">            sm.checkExit(status);</span><br><span class="line">        &#125;</span><br><span class="line">        Shutdown.halt(status);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ol><ol start="5"><li>除此之外，JNI（Java Native Interface）规范描述了用JNI Invocation API来加载或卸载Java虚拟机是，Java虚拟机的退出情况。</li></ol>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解JVM(1)_参考资料</title>
      <link href="2019/06/25/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(1)_%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/"/>
      <url>2019/06/25/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20JVM(1)_%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="第1章-JVM-和-Java-体系结构"><a href="#第1章-JVM-和-Java-体系结构" class="headerlink" title="第1章 JVM 和 Java 体系结构"></a>第1章 JVM 和 Java 体系结构</h1><h2 id="参考书目"><a href="#参考书目" class="headerlink" title="参考书目"></a>参考书目</h2><p>java8规范网址：<a href="https://docs.oracle.com/javase/specs/jls/se8/html/index.html">https://docs.oracle.com/javase/specs/jls/se8/html/index.html</a></p><p><img src="images/4.png" alt="img"></p><p><img src="images/5.png" alt="img"></p><p><img src="images/6.png" alt="img"></p><p><img src="images/7.png" alt="img"></p><h2 id="3-Java及JVM简介"><a href="#3-Java及JVM简介" class="headerlink" title="3 Java及JVM简介"></a>3 Java及JVM简介</h2><ul><li><p>语言热度排行榜：<a href="https://www.tiobe.com/tiobe-index/">https://www.tiobe.com/tiobe-index/</a></p></li><li><p>Java生态圈</p><ul><li><font color=red><strong>作为一个平台</strong></font>：Java虚拟机扮演着举足轻重的作用。Groovy、Scala、JRuby、Kotlin等都是Java平台的一部分</li><li><font color=red><strong>作为一种文化</strong></font>：<ul><li>第三方开源软件和框架。如Tomcat、Struts、MyBatis、Spring等。</li><li>就连JDK和JVM自身也有不少开源的实现，如OpenJDK、Harmony。</li></ul></li><li><font color=red><strong>作为一个社区</strong></font>：Java拥有全世界最多的技术拥护者和开源社区支持，有数不清的论坛和资料。</li></ul></li><li><p>Java：跨平台的语言</p><img src="images/8.png" alt="img" style="zoom:50%;" /></li><li><p>Java虚拟机规范</p><p><img src="images/9.png" alt="img"></p></li><li><p>JVM：跨语言的平台</p><p><img src="images/10.png" alt="img"></p><ul><li>随着Java7的正式发布，Java虚拟机的设计者们通过JSR-292规范基本实现在<font color=red><strong>Java虚拟机平台运行非Java语言编写的程序</strong></font></li><li>Java虚拟机根本不关心运行在其内部的程序到底是使用何种语言编写的，<font color=red><strong>它值关心“字节码”文件</strong></font>。</li></ul></li><li><p><font color=red><strong>Java不是最强大的语言，但是JVM是最强大的虚拟机。</strong></font></p></li><li><p>我们平时说的java字节码，指的是用java语言编写成的字节码。准确的说任何能在jvm平台执行的字节码格式都是一样的。所以应该统称为：<font color=red><strong>jvm字节码</strong></font>。</p></li><li><p>不同的编译器，可以编译出相同的字节码文件，字节码文件也可以在不同的JVM上运行。</p></li><li><p>Java虚拟机与Java语言并没有必然的联系，它只与特定的二进制文件格式——Class文件格式所关联，Class文件包含了Java虚拟机指令集（或者称为字节码、Bytecodes）和符号表，还有一些其他辅助信息。</p></li><li><p>多语言混合编程</p><ul><li><font color=red><strong>Java平台上的多语言混合编程称为主流，通过特定的语言去解决特定领域的问题是当前软件开发应对日趋复杂的项目需求的一个方向</strong></font>。</li><li>试想一下，在一个项目之中，并行处理用Clojure语言编写，展示层使用JRuby/Rails，中间层使用Java，每个应用层都将使用不同的编程语言来完成，而且，接口对每一层的开发者都是透明的，<font color=red><strong>各种语言之间的交互不存在任何困难，就像使用自己语言的原生PAI一样方便，因为它们最终都运行在一个虚拟机上</strong></font>。</li><li>对这些运行在Java虚拟机上、Java之外的语言，来自系统的、底层的支持正在迅速增长，以JSR-292为核心的一系列项目和功能改进（如DaCinci Machine项目、Nashorn引擎、InvokeDynamic指令、java.lang.invoke包等），<font color=red><strong>推动Java虚拟机从“Java语言的虚拟机”向“多语言虚拟机”的方向发展</strong></font>。</li></ul></li><li><p>如何真正搞懂JVM？</p><img src="images/11.png" alt="img" style="zoom:60%;" /></li></ul><h2 id="4-Java发展的重大事件"><a href="#4-Java发展的重大事件" class="headerlink" title="4 Java发展的重大事件"></a>4 Java发展的重大事件</h2><p><img src="images/12.png" alt="img"></p><p><img src="images/13.png" alt="img"></p><p><img src="images/14.png" alt="img"></p><h2 id="5-虚拟机与Java虚拟机"><a href="#5-虚拟机与Java虚拟机" class="headerlink" title="5 虚拟机与Java虚拟机"></a>5 虚拟机与Java虚拟机</h2><ul><li><p>虚拟机</p><ul><li>所谓虚拟机（Virtual Machine），就是一台虚拟的计算机。它是一款软件，用来执行一系列虚拟计算机指令。大体上，虚拟机可以分为<font color=red><strong>系统虚拟机</strong></font>和<font color=red><strong>程序虚拟机</strong></font>。<ul><li>大名鼎鼎的Vitural Box，VMware就属于系统虚拟机，他们<font color=red><strong>完全是对物理计算机的仿真</strong></font>，提供了一个可运行完整操作系统的软件平台</li><li>程序虚拟机的典型代表就是Java虚拟机，它<font color=red><strong>专门为执行单个计算机程序而设计</strong></font>，在Java虚拟机中执行的命令我们称为Java字节码指令。</li></ul></li><li>无论是系统虚拟机还是程序虚拟机，在上面运行的软件都被限制于虚拟机提供的资源中</li></ul></li><li><p>Java虚拟机</p><ul><li>Java虚拟机是一台执行Java字节码的虚拟计算机，它拥有独立的运行机制，其运行的Java字节码也未必是由Java语言编写而成的。</li><li>JVM平台的各种语言可以共享Java虚拟机的跨平台、优秀的垃圾回收器，以及可靠的及时编译器。</li><li><font color=red><strong>Java技术的核心就是Java虚拟机</strong></font>（JVM，Java Virtual Machine），因为所有的Java程序都运行在Java虚拟机内部</li><li>作用：<font color=red><strong>Java虚拟机就是二进制字节码的运行环境</strong></font>，负责装在字节码到其内部，解释/编译为对应平台的机器指令执行。每一条Java命令，Java虚拟机规范都有详细定义，如怎么去操作数，处理结果放在哪里。</li><li>特点<ul><li>一次编译，导出运行</li><li>自动内存管理</li><li>自动垃圾回收功能</li></ul></li></ul></li><li><p>JVM的位置</p><img src="images/15.png" alt="img" style="zoom:50%;" /><img src="images/16.png" alt="img" style="zoom:70%;" /></li><li><p>Google的Android系统结构</p><p><img src="images/17.png" alt="img"></p><p>Dalvik Virtal Machine解释执行.dex文件</p></li></ul><h2 id="6-JVM整体结构"><a href="#6-JVM整体结构" class="headerlink" title="6 JVM整体结构"></a>6 JVM整体结构</h2><img src="images/18.png" alt="img" style="zoom:70%;" /><img src="images/19.png" alt="img" style="zoom:70%;" /><h2 id="7-Java代码执行流程"><a href="#7-Java代码执行流程" class="headerlink" title="7 Java代码执行流程"></a>7 Java代码执行流程</h2><img src="images/8.png" alt="img" style="zoom:50%;" /><img src="images/20.png" alt="img" style="zoom:75%;" /><h2 id="8-JVM的架构模型"><a href="#8-JVM的架构模型" class="headerlink" title="8 JVM的架构模型"></a>8 JVM的架构模型</h2><ul><li><p>Java编译器输入的指令流基本上是一种基于<font color=red><strong>栈的指令集架构</strong></font>，另外一种指令集架构则是基于<font color=red><strong>寄存器的指令集架构</strong></font>。</p></li><li><p>具体来说：这两种架构之间的区别：</p><ul><li><font color=red><strong>基于栈式架构的特点</strong></font>：<ul><li>设计和实现简单，适用于资源受限的系统；</li><li>避开了寄存器的分配难题：使用零地址指令方式分配。</li><li>指令流中的大部分是零地址指令，其执行过程依赖于操作栈。指令集更小，编译器容易实现。</li><li>不需要硬件支持，可移植性更好，更好实现跨平台</li></ul></li><li><font color=red><strong>基于寄存器架构的特点</strong></font><ul><li>典型的应用是x86的二进制指令集：比如传统的PC以及Android的Davlik虚拟机。</li><li>指令集架构则完全依赖硬件，可移植性差</li><li>性能优秀和执行高效；</li><li>花费更少的指令去完成一项操作。</li><li>在大部分情况下，基于寄存器架构的指令集往往都是以一地址指令、二地址指令和三地址指令为主，而基于栈式架构的指令集却是以零地址指令为主。</li></ul></li></ul></li><li><p>举例：反编译javap</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StackStruTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//int i = 2 + 3;</span></span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">3</span>;</span><br><span class="line">        <span class="keyword">int</span> k = i + j;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="images/21.png" alt="img" style="zoom:75%;" /><img src="images/22.png" alt="img" style="zoom:60%;" /><img src="images/23.png" alt="img" style="zoom:60%;" /><img src="images/24.png" alt="img" style="zoom:60%;" /><img src="images/25.png" alt="img" style="zoom:70%;" /><img src="images/26.png" alt="img" style="zoom:70%;" /></li><li><p>总结：</p><ul><li><font color=red><strong>由于跨平台的设计，Java的指令都是根据栈来设计的</strong></font>。不同平台的CPU架构不同，所以不能设计为基于寄存器的。优点是跨平台，指令集小，编译器容易实现，缺点是性能下降，实现同样的功能需要更多的指令。</li><li>时至今日，尽管嵌入式平台已经不是Java程序的主流运行平台了（准确来说应该是HotSpotVM的宿主环境已经不局限于嵌入式平台了），那么为什么不将架构更换为基于寄存器的架构呢？这是因为这种方式实现简单；另外基于栈式的结果在各个平台可以用，没必要更换了。</li></ul></li></ul><h2 id="9-JVM的生命周期"><a href="#9-JVM的生命周期" class="headerlink" title="9 JVM的生命周期"></a>9 JVM的生命周期</h2><ul><li><p><strong>虚拟机的启动</strong></p><ul><li>Java虚拟机的启动是通过引导类加载器（bootstrap class loader）创建一个初始类（initial class）来完成的，这个类是由虚拟机的具体实现指定的。</li></ul></li><li><p><strong>虚拟机的执行</strong></p><ul><li>一个运行的Java虚拟机有着一个清晰的任务：执行Java程序。</li><li>程序开始执行时他才运行，程序结束时他就停止。</li><li><font color=red><strong>执行一个所谓的Java程序的时候，真真正正在执行的是一个叫做Java虚拟机的进程</strong></font>。</li></ul></li><li><p><strong>虚拟机的退出</strong></p><ul><li><p>有如下的几种情况：</p><ul><li>程序正常执行结束</li><li>程序在执行过程中遇到了异常或错误而异常终止</li><li>由于操作系统出现错误而导致Java虚拟机进程结束</li><li>某线程调用Runtime类或System类的exit方法，或Runtime类的halt方法，并且Java安全管理器也允许这次exit或halt操作。</li><li>除此之外，JNI（Java Native Interface）规范描述了用JNI Invocation API来加载或卸载Java虚拟机是，Java虚拟机的退出情况。</li></ul></li><li><p>System</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">System</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">exit</span><span class="params">(<span class="keyword">int</span> status)</span> </span>&#123;</span><br><span class="line">        Runtime.getRuntime().exit(status);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Runtime</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Runtime</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Runtime currentRuntime = <span class="keyword">new</span> Runtime();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Runtime <span class="title">getRuntime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> currentRuntime;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** Don&#x27;t let anyone else instantiate this class */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Runtime</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">exit</span><span class="params">(<span class="keyword">int</span> status)</span> </span>&#123;</span><br><span class="line">        SecurityManager security = System.getSecurityManager();</span><br><span class="line">        <span class="keyword">if</span> (security != <span class="keyword">null</span>) &#123;</span><br><span class="line">            security.checkExit(status);</span><br><span class="line">        &#125;</span><br><span class="line">        Shutdown.exit(status);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">halt</span><span class="params">(<span class="keyword">int</span> status)</span> </span>&#123;</span><br><span class="line">        SecurityManager sm = System.getSecurityManager();</span><br><span class="line">        <span class="keyword">if</span> (sm != <span class="keyword">null</span>) &#123;</span><br><span class="line">            sm.checkExit(status);</span><br><span class="line">        &#125;</span><br><span class="line">        Shutdown.halt(status);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个进程对应一个JVM，一个JVM就对应着一个Runtime</p></li></ul></li></ul><h2 id="10-JVM的发展历程"><a href="#10-JVM的发展历程" class="headerlink" title="10 JVM的发展历程"></a>10 JVM的发展历程</h2><img src="images/27.png" alt="img" style="zoom:50%;" /><img src="images/28.png" alt="img" style="zoom:50%;" /><img src="images/29.png" alt="img" style="zoom:50%;" /><img src="images/30.png" alt="img" style="zoom:50%;" /><img src="images/31.png" alt="img" style="zoom:50%;" /><img src="images/32.png" alt="img" style="zoom:50%;" /><img src="images/33.png" alt="img" style="zoom:50%;" /><img src="images/34.png" alt="img" style="zoom:50%;" /><img src="images/35.png" alt="img" style="zoom:50%;" /><img src="images/36.png" alt="img" style="zoom:50%;" /><img src="images/37.png" alt="img" style="zoom:50%;" /><img src="images/38.png" alt="img" style="zoom:50%;" /><p>将.apk文件改为.zip格式的，然后解压，里面显示的内容如下，我们可以看到.dex文件</p><img src="images/39.png" alt="img" style="zoom:60%;" /><img src="images/40.png" alt="img" style="zoom:60%;" /><img src="images/41.png" alt="img" style="zoom:50%;" /><ul><li>具体JVM的内存结构，其实取决于其实现，不同厂商的JVM，或者同一昌盛发布的不同版本，都有可能存在一定差异。本套课程主要以Oracle HotSpot VM为默认虚拟机。</li></ul><img src="images/42.png" alt="img" style="zoom:50%;" /><ul><li>如何知道学习什么技术？<ul><li>关注大公司用什么技术，比如阿里在大数据方面已经全面倒向Flink了，我们就应该学习Flink</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>JVM 类加载器</title>
      <link href="2019/06/25/JVM%20%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%E5%AD%A6%E4%B9%A0/"/>
      <url>2019/06/25/JVM%20%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>类的加载指的是将类的 .class 文件中的二进制数据读入到内存中，将其放在运行时数据区的**[方法区]<strong>内，然后在</strong>[堆区]**创建一个 <code>java.lang.Class</code> 对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的 Class 对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。 </p><a id="more"></a><h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h1><p>Sun 公司开发了 Java 语言，但任何人都可以在遵循 JVM 规范的前提下开发和提供 JVM 实现。所以目前业界有多种不同的JVM 实现，包括 Oracle Hostpot JVM、IBM JVM 和 Taobao JVM。<br>JRE 由 Java API 和 JVM 组成，JVM 通过类加载器(Class Loader)加类 Java 应用，并通过 Java API 进行执行。<br>最初 Java 语言被设计为基于虚拟机器在而非物理机器，重而实现 WORA(一次编写，到处运行)的目的，尽管这个目标几乎被世人所遗忘。所以，JVM 可以在所有的硬件环境上执行 Java 字节码而无须调整 Java 的执行模式。<img src="/Users/joker/Documents/Learnning/JVM/resources/images/3.png" alt="3" style="zoom:50%;" /></p><h1 id="2-基本特性"><a href="#2-基本特性" class="headerlink" title="2.基本特性"></a>2.基本特性</h1><ul><li><strong>基于栈 (Stack-based) 的虚拟机</strong></li><li><strong>符号引用 (Symbolic reference)</strong><br>  除基本类型外的所有 Java 类型 (类和接口) 都是通过符号引用取得关联的，而非显式的基于内存地址的引用。</li><li><strong>垃圾回收机制</strong><br>  类的实例通过用户代码进行显式创建，但却通过垃圾回收机制自动销毁。</li><li><strong>平台无关性</strong><br>  JVM 却通过明确的定义基本类型的字节长度来维持代码的平台兼容性，从而做到平台无关。</li><li><strong>网络字节序(Network byte order)</strong><br>  Java class文件的二进制表示使用的是基于网络的字节序(network byte order)。为了在使用小端(little endian)的Intel x86平台和在使用了大端(big endian)的RISC系列平台之间保持平台无关，必须要定义一个固定的字节序。JVM选择了网络传输协议中使用的网络字节序，即基于大端(big endian)的字节序。</li></ul><h1 id="3-Java-虚拟机与程序的生命周期"><a href="#3-Java-虚拟机与程序的生命周期" class="headerlink" title="3.Java 虚拟机与程序的生命周期"></a>3.Java 虚拟机与程序的生命周期</h1><p>在如下几种情况下。Java 虚拟机将结束生命周期</p><ol><li>执行了 System.exit()方法</li><li>程序正常执行结束</li><li>程序在执行过程中遇到了异常或错误而异常结束</li><li>由于操作系统出现错误而导致Java虚拟机进程终止<h1 id="4-类加载机制"><a href="#4-类加载机制" class="headerlink" title="4.类加载机制"></a>4.类加载机制</h1></li></ol><p>类的加载指的是将类的 <code>.class</code> 文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在内存区创建一个 <code>java.lang.Class</code> 对象，用来封装类在方法区内的数据结构<br><font color = 'red'> <strong>注意：</strong></font>规范并未说明 <em>Class</em> 对象位于哪里，<em>HotSpot</em> 虚拟机将其放在了方法区内。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2020-09-29 下午2.24.15.png" alt="截屏2020-09-29 下午2.24.15" style="zoom:50%;" /><h2 id="4-1-类加载时机"><a href="#4-1-类加载时机" class="headerlink" title="4.1. 类加载时机"></a>4.1. 类加载时机</h2><p>JVM 规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在<strong>程序首次主动</strong>使用该类才报告错误（LinkageError错误），如果这个类没有被程序主动使用，那么类加载器就不会报告错误。</p><h2 id="4-2-类加载过程"><a href="#4-2-类加载过程" class="headerlink" title="4.2. 类加载过程"></a>4.2. 类加载过程</h2><img src="/Users/joker/Documents/Learnning/JVM/resources/images/2.png" alt="2" style="zoom:50%;" /><h3 id="4-2-1-加载"><a href="#4-2-1-加载" class="headerlink" title="4.2.1. 加载"></a>4.2.1. 加载</h3><p>加载是类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情：</p><ul><li>通过一个类的全限定名来获取其定义的二进制字节流。</li><li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</li><li>在 Java 堆中生成一个代表这个类的 java.lang.Class 对象，作为对方法区中这些数据的访问入口。</li></ul><p>相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。</p><p>加载阶段完成后，虚拟机外部的 二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在 Java 堆中也创建一个java.lang.Class 类的对象，这样便可以通过该对象访问方法区中的这些数据。</p><h4 id="gt-加载-class-文件的方式"><a href="#gt-加载-class-文件的方式" class="headerlink" title="-&gt; 加载 .class 文件的方式"></a><strong>-&gt; 加载 .class 文件的方式</strong></h4><ul><li>从本地系统中直接加载</li><li>通过网络下载 .class 文件</li><li>从 zip, jar 等归档文件中加载 .class 文件</li><li>从专有数据库中提取 .class 文件，比较少见</li><li>运行时计算生成: 动态代理</li><li>将 Java 源文件动态编译为 .class 文件</li></ul><h3 id="4-2-2-连接"><a href="#4-2-2-连接" class="headerlink" title="4.2.2. 连接"></a>4.2.2. 连接</h3><p><strong>类被加载之后，进入连接阶段。连接阶段就是将已经读入到内存的类的二进制数据合并到虚拟机的运行时环境中去。</strong></p><h4 id="gt-验证"><a href="#gt-验证" class="headerlink" title="-&gt; 验证"></a><strong>-&gt; 验证</strong></h4><p>验证是连接阶段的第一步，这一阶段的目的是为了确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作：</p><ol><li><p><strong>文件格式验证</strong></p><p>验证字节流是否符合 Class 文件格式的规范；例如：是否以 <code>0xCAFEBABE</code> 开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。</p></li><li><p><strong>元数据验证</strong></p><p>对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了java.lang.Object之外。</p></li><li><p><strong>字节码验证</strong></p><p>通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。</p></li><li><p><strong>符号引用验证</strong></p><p>确保解析动作能正确执行。</p></li></ol><p>验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone 参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。</p><h4 id="gt-准备"><a href="#gt-准备" class="headerlink" title="-&gt; 准备"></a>-&gt; 准备</h4><p><strong>在准备阶段，Java 虚拟机为类的静态变量分配内存，并设置默认的初始值。</strong></p><blockquote><p>准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：</p></blockquote><ol><li><p>这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。</p></li><li><p>这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。</p><p>![截屏2020-09-29 下午4.25.03](/Users/joker/Library/Application Support/typora-user-images/截屏2020-09-29 下午4.25.03.png)</p></li></ol><p>假设一个类变量的定义为：public static int value = 3；</p><p>那么变量 value 在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何 Java 方法，而把 value 赋值为3的 putstatic 指令是在程序编译后，存放于类构造器 <clinit>() 方法之中的，所以把 value 赋值为 3 的动作将在初始化阶段才会执行。</p><p>例如对于以下 Sample 类，在准备阶段，将为 int 类型的静态变量 a 分配4个字节的内存空间，并且赋予默认值0，为long类型的静态变量b分配8个字节的内存空间，并且赋予默认值0</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Sample</span></span>&#123;</span><br><span class="line">       <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> a=<span class="number">1</span>;</span><br><span class="line">       <span class="keyword">public</span>  <span class="keyword">static</span> <span class="keyword">long</span> b;</span><br><span class="line">       <span class="keyword">public</span>  <span class="keyword">static</span> <span class="keyword">long</span> c;</span><br><span class="line">       <span class="keyword">static</span> &#123;</span><br><span class="line">           b=<span class="number">2</span>;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="gt-解析"><a href="#gt-解析" class="headerlink" title="-&gt; 解析"></a>-&gt; 解析</h4><p>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。<strong>符号引用</strong> 就是一组符号来描述目标，可以是任何字面量。</p><p><strong>直接引用</strong>就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。</p><h3 id="4-2-3-初始化"><a href="#4-2-3-初始化" class="headerlink" title="4.2.3. 初始化"></a>4.2.3. 初始化</h3><p><strong>在初始化阶段，Java 虚拟机执行类的初始化语句，为类的静态变量赋予初始值。</strong>JVM 负责对类进行初始化，主要对类变量进行初始化在程序中，静态变量的初始化有两种途径</p><p>初始化阶段就是执行类构造器方法<clinit>() 的过程</p><p>![截屏2020-09-29 下午4.30.01](/Users/joker/Library/Application Support/typora-user-images/截屏2020-09-29 下午4.30.01.png)</p><ol><li>在静态变量的声明处进行初始化</li><li>在静态代码块中进行初始化。</li></ol><p><strong><font color='blue'>准备阶段即使我们为静态变量赋值为任意的数值，但是该静态变量还是会被初始化为他的默认值，最后的初始化时才会把我们赋予的值设为该静态变量的值</font></strong></p><hr><h4 id="gt-初始化时机"><a href="#gt-初始化时机" class="headerlink" title="-&gt; 初始化时机"></a>-&gt; 初始化时机</h4><p><strong>Java 虚拟机实现必须在每个类或接口被 Java 程序 “首次主动使用” 时初始化他们</strong></p><ol><li>主动使用<ul><li>创建类的实例</li><li>访问某个类或接口的静态变量，或者对该静态变量赋值</li><li>调用该类的静态方法</li><li>反射</li><li>初始化一个类的子类</li><li>Java虚拟机启动时被标为启动类的类（Java Test）</li></ul></li><li>被动使用</li></ol><hr><h4 id="gt-类的初始化步骤"><a href="#gt-类的初始化步骤" class="headerlink" title="-&gt; 类的初始化步骤"></a>-&gt; <strong>类的初始化步骤</strong></h4><ol><li>假如这个类还没有被加载和连接，那就先进行加载和连接</li><li>假如类存在直接父类，并且这个父类还没有被初始化，那就先初始化直接父类</li><li>假如类中存在初始化语句，那就依次执行这些初始化语句</li></ol><p>当 Java 虚拟机初始化一个类时，要求它的所有父类都已经被初始化，<strong>但是这条规则不适用于接口</strong>。因此，一个父接口并不会因为它的子接口或者实现类的初始化而初始化。只有当程序首次使用特定的接口的静态变量时，才会导致该接口的初始化。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoadTest9</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;ClassLoadTest9&quot;</span>);</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(Child1.a);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parent1</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> a = <span class="number">9</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Parent1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child1</span> <span class="keyword">extends</span> <span class="title">Parent1</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Child1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 最后输出顺序</span></span><br><span class="line"><span class="comment">// ClassLoadTest9</span></span><br><span class="line"><span class="comment">// Parent1</span></span><br><span class="line"><span class="comment">// 9</span></span><br></pre></td></tr></table></figure><hr><p><strong>接口初始化</strong></p><ol><li>当一个接口在初始化时，并不要求其父接口都完成了初始化只有在真正使用到父接口的时候（如引用接口中定义的常量），才会初始化</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 当一个接口在初始化时，并不要求其父接口都完成了初始化</span></span><br><span class="line"><span class="comment"> * 只有在真正使用到父接口的时候（如引用接口中定义的常量），才会初始化</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoadTest5</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">       System.out.println(MyChild.b);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Student5</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">9</span>; <span class="comment">//前面省了public static final</span></span><br><span class="line">    Thread thread = <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">        &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;thread 初始化了&quot;</span>);<span class="comment">//如果父接口初始化了这句应该输出</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">MyChild</span> <span class="keyword">extends</span> <span class="title">Student5</span> </span>&#123;     <span class="comment">//接口属性默认是 public static final</span></span><br><span class="line">    String b = LocalDateTime.now().toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h2 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h2><p>类的加载由类加载器完成，JVM 提供的类加载器叫做系统类加载器，此外还可以通过继承 ClassLoader 基类来自定义类加载器。</p><h3 id="系统类加载器"><a href="#系统类加载器" class="headerlink" title="系统类加载器"></a>系统类加载器</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.poplar.classload;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoadTest18</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(System.getProperty(<span class="string">&quot;sun.boot.class.path&quot;</span>));<span class="comment">//根加载器路径</span></span><br><span class="line">        System.out.println(System.getProperty(<span class="string">&quot;java.ext.dirs&quot;</span>));<span class="comment">//扩展类加载器路径</span></span><br><span class="line">        System.out.println(System.getProperty(<span class="string">&quot;java.class.path&quot;</span>));<span class="comment">//应用类加载器路径</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p><strong>根类加载器</strong>（Bootstrap）</p><blockquote><p>该加载器没有父加载器，它负责加载虚拟机中的核心类库。根类加载器从系统属性 <code>sun.boot.class.path</code> 所指定的目录中加载类库。类加载器的实现依赖于底层操作系统，属于虚拟机的实现的一部分，它并没有集成<code>java.lang.ClassLoader</code> 类。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.poplar.classload;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoadTest7</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">     <span class="comment">//null 由于String是由根加载器加载，在rt.jar包下</span></span><br><span class="line">     System.out.println(String.class.getClassLoader());</span><br><span class="line">     <span class="comment">//sun.misc.Launcher$AppClassLoader@73d16e93 </span></span><br><span class="line">     System.out.println(C.class.getClassLoader());</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">C</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><ul><li><p><strong>扩展类加载器</strong>（Extension）</p><blockquote><p>它的父加载器为根类加载器。它从 <code>java.ext.dirs</code> 系统属性所指定的目录中加载类库，或者从JDK的安装目录的jre\lib\ext子目录（扩展目录）下加载类库，如果把用户创建的jar文件放在这个目录下，也会自动由扩展类加载器加载，扩展类加载器是纯java类，是java.lang.ClassLoader的子类。</p></blockquote></li><li><p><strong>系统应用类加载器</strong>（AppClassLoader/System）</p><blockquote><p>也称为应用类加载器，它的父加载器为扩展类加载器，它从环境变量classpath或者系统属性java.class.path所指定的目录中加载类，他是用户自定义的类加载器的默认父加载器。系统类加载器时纯java类，是java.lang.ClassLoader的子类。</p></blockquote></li></ul><h3 id="用户自定义的类加载器"><a href="#用户自定义的类加载器" class="headerlink" title="用户自定义的类加载器"></a><strong>用户自定义的类加载器</strong></h3><ul><li>java.lang.ClassLoader的子类</li><li>用户可以定制类的加载方式</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.poplar.classload;</span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**  </span></span><br><span class="line"><span class="comment"> * 自定义类加载器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomClassLoader</span> <span class="keyword">extends</span> <span class="title">ClassLoader</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> String classLoaderName;</span><br><span class="line">  <span class="keyword">private</span> String path;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPath</span><span class="params">(String path)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.path = path;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String filePost = <span class="string">&quot;.class&quot;</span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">CustomClassLoader</span><span class="params">(ClassLoader parent, String classLoaderName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(parent);<span class="comment">//显示指定该类的父类加载器</span></span><br><span class="line">    <span class="keyword">this</span>.classLoaderName = classLoaderName;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">CustomClassLoader</span><span class="params">(String classLoaderName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>();<span class="comment">//将系统类加载器当作该类的父类加载器</span></span><br><span class="line">    <span class="keyword">this</span>.classLoaderName = classLoaderName;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Class <span class="title">findClass</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;findClass,输出这句话说明我们自己的类加载器加载了指定的类&quot;</span>);</span><br><span class="line">    <span class="keyword">byte</span>[] b = loadClassData(name);</span><br><span class="line">    <span class="keyword">return</span> defineClass(name, b, <span class="number">0</span>, b.length);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">byte</span>[] loadClassData(String name) &#123;</span><br><span class="line">    InputStream is = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">byte</span>[] data = <span class="keyword">null</span>;</span><br><span class="line">    ByteArrayOutputStream byteArrayOutputStream = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      name = name.replace(<span class="string">&quot;.&quot;</span>, File.separator);<span class="comment">//File.separator根据操作系统而变化</span></span><br><span class="line">      is = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(path + name + filePost));</span><br><span class="line">      byteArrayOutputStream = <span class="keyword">new</span> ByteArrayOutputStream();</span><br><span class="line">      <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">while</span> (-<span class="number">1</span> != (len = is.read())) &#123;</span><br><span class="line">        byteArrayOutputStream.write(len);</span><br><span class="line">      &#125;</span><br><span class="line">      data = byteArrayOutputStream.toByteArray();</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        is.close();</span><br><span class="line">        byteArrayOutputStream.close();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   执行结果： </span></span><br><span class="line"><span class="comment">   findClass,输出这句话说明我们自己的类加载器加载了指定的类</span></span><br><span class="line"><span class="comment">   com.poplar.classload.CustomClassLoader2@15db97422018699554</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    CustomClassLoader2 Loader2 = <span class="keyword">new</span> CustomClassLoader2(<span class="string">&quot;load2&quot;</span>);</span><br><span class="line">    test1(loader2) </span><br><span class="line">    CustomClassLoader2 Loader3 = <span class="keyword">new</span> CustomClassLoader2(<span class="string">&quot;load3&quot;</span>);</span><br><span class="line">    test1(loader3)    </span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">(CustomClassLoader2 loader2)</span> <span class="keyword">throws</span> ClassNotFoundException, InstantiationException, IllegalAccessException </span>&#123;</span><br><span class="line">          loader2.setPath(<span class="string">&quot;C:\\Users\\poplar\\Desktop\\&quot;</span>);</span><br><span class="line">          Class&lt;?&gt; clazz = loader2.loadClass(<span class="string">&quot;com.poplar.classload.ClassLoadTest&quot;</span>);</span><br><span class="line">          Object instance = clazz.newInstance();</span><br><span class="line">          System.out.println(instance.getClass().getClassLoader());</span><br><span class="line">          System.out.println(instance.hashCode());</span><br><span class="line">          System.out.println(<span class="string">&quot;-------------------------------------&quot;</span>);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><hr><p><strong>命名空间</strong></p><ul><li>每个类加载器都有自己的命名空间，<strong>命名空间由该加载器及所有父加载器所加载的类构成</strong>；</li><li>在同一个命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类；</li><li>在不同的命名空间中，有可能会出现类的完整名字（包括类的包名）相同的两个类；</li><li>同一命名空间内的类是互相可见的，<strong>非同一命名空间内的类是不可见的</strong>；</li><li>子加载器可以见到父加载器加载的类，<strong>父加载器也不能见到子加载器加载的类</strong>。</li></ul><hr><p><strong>注：</strong></p><ul><li>类加载器本身也是类加载器，类加载器又是谁加载的呢？？（先有鸡还是现有蛋）<br>类加载器是由启动类加载器去加载的，启动类加载器是C++写的，内嵌在JVM中。</li><li>内嵌于JVM中的启动类加载器会加载java.lang.ClassLoader以及其他的Java平台类。当JVM启动时，一块特殊的机器码会运行，它会加载扩展类加载器以及系统类加载器，这块特殊的机器码叫做启动类加载器。</li><li>启动类加载器并不是java类，其他的加载器都是java类。</li><li>启动类加载器是特定于平台的机器指令，它负责开启整个加载过程。</li></ul><hr><h3 id="双亲委派机制"><a href="#双亲委派机制" class="headerlink" title="双亲委派机制"></a>双亲委派机制</h3><p>类加载器用来把类加载到 Java 虚拟机中。从 JDK1.2 版本开始，类的加载过程采用双亲委托机制，这种机制能更好地保证 Java 平台的安全。在此委托机制中，除了 Java 虚拟机自带的根类加载器以外，其余的类加载器都有且只有一个父加载器。当 Java 程序请求加载器 loader1 加载 Sample 类时，loader1 首先委托自己的父加载器去加载 Sample 类，若父加载器能加载，则有父加载器完成加载任务，否则才由加载器loader1 本身加载 Sample 类。</p><p>在双亲委托机制中，各个加载器按照父子关系形成了树形结构，除了根加载器之外，其余的类加载器都有一个父加载器若有一个类能够成功加载 Test 类，那么这个类加载器被称为<strong>定义类加载器</strong>，所有能成功返回Class对象引用的类加载器（包括定义类加载器）称为<strong>初始类加载器</strong>。</p><h4 id="gt-工作过程"><a href="#gt-工作过程" class="headerlink" title="-&gt; 工作过程"></a>-&gt; 工作过程</h4><p>如果一个类加载器收到了类加载的请求，他首先不会自己去尝试加载这个类，而是把这个请求委派父类加载器去完成。每一个层次的类加载器都是如此，因此所有的加载请求最终都传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个请求[加载器的搜索范围中没有找到所需的类]时，子加载器才会尝试自己去加载。</p><hr><h4 id="gt-优点"><a href="#gt-优点" class="headerlink" title="-&gt; 优点"></a>-&gt; 优点</h4><ol><li><p>可以确保 Java 和核心库的安全</p><blockquote><p>所有的 Java 应用都会引用 java.lang 中的类，也就是说在运行期java.lang中的类会被加载到虚拟机中，如果这个加载过程如果是由自己的类加载器所加载，那么很可能就会在JVM中存在多个版本的java.lang中的类，而且这些类是相互不可见的（命名空间的作用）。借助于双亲委托机制，Java核心类库中的类的加载工作都是由启动根加载器去加载，从而确保了Java应用所使用的的都是同一个版本的Java核心类库，他们之间是相互兼容的</p></blockquote></li><li><p>确保 Java 核心类库中的类不会被自定义的类所替代</p></li><li><p>不同的类加载器可以为相同名称的类（binary name）创建额外的命名空间。相同名称的类可以并存在Java虚拟机中，只需要用不同的类加载器去加载即可。相当于在 Java 虚拟机内部建立了一个又一个相互隔离的 Java 类空间。</p></li><li><p><strong>避免重复加载</strong>，父类已经加载过的类，子类无需重新加载。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.poplar.classload;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoadTest10</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;ClassLoadTest10&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/*执行结果：由于父类已经初始化过了所以Parent2只输出一次</span></span><br><span class="line"><span class="comment">   * ClassLoadTest10</span></span><br><span class="line"><span class="comment">   * Parent2</span></span><br><span class="line"><span class="comment">   * 2</span></span><br><span class="line"><span class="comment">   * Child2</span></span><br><span class="line"><span class="comment">   * 3</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    Parent2 parent2;</span><br><span class="line">    parent2 = <span class="keyword">new</span> Parent2();</span><br><span class="line">    System.out.println(Parent2.a);</span><br><span class="line">    System.out.println(Child2.b);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parent2</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> a = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Parent2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child2</span> <span class="keyword">extends</span> <span class="title">Parent2</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> b = <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Child2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><hr><h4 id="gt-双亲委派模型破坏"><a href="#gt-双亲委派模型破坏" class="headerlink" title="-&gt; 双亲委派模型破坏"></a>-&gt; <strong>双亲委派模型破坏</strong></h4><p>在实际的应用中双亲委派解决了java 基础类统一加载的问题，但是却着实存在着一定的缺席。jdk 中的基础类作为用户典型的api 被调用，但是也存在被 api 调用用户的代码的情况，典型的如 SPI 代码。</p><h5 id="SPI-机制简介"><a href="#SPI-机制简介" class="headerlink" title="SPI 机制简介"></a>SPI 机制简介</h5><hr><h3 id="类的卸载"><a href="#类的卸载" class="headerlink" title="类的卸载"></a>类的卸载</h3><ul><li>当一个类被加载、连接和初始化之后，它的生命周期就开始了。当此类的Class对象不再被引用，即不可触及时，Class对象就会结束生命周期，类在方法区内的数据也会被卸载。</li><li>一个类何时结束生命周期，取决于代表它的Class对象何时结束生命周期。</li><li>由Java虚拟机自带的类加载器所加载的类，在虚拟机的生命周期中，始终不会被卸载。Java虚拟机本身会始终引用这些加载器，而这些类加载器则会始终引用他们所加载的类的Class对象，因此这些Class对象是可触及的。</li><li>由用户自定义的类加载器所加载的类是可以被卸载的。（<strong>jvisualvm 查看当前java进程 -XX:+TraceClassUnloading这个用于追</strong>）</li></ul><img src="/Users/joker/Documents/Learnning/JVM/resources/images/截屏2020-09-29 下午2.23.49.png" alt="截屏2020-09-29 下午2.23.49" style="zoom:50%;" />]]></content>
      
      
      <categories>
          
          <category> 深入理解 JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 数据查询优化(1):理论基础</title>
      <link href="2019/06/05/MySQL-%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96-1-%EF%BC%9A%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"/>
      <url>2019/06/05/MySQL-%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96-1-%EF%BC%9A%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="SQL-执行时间长的原因"><a href="#SQL-执行时间长的原因" class="headerlink" title="SQL 执行时间长的原因"></a>SQL 执行时间长的原因</h2><ol><li>查询语句写的烂</li><li>索引失效</li><li>关联查询有太多 Join</li><li>服务器调优及各个参数设置，如缓冲、线程数等</li></ol><h2 id="一条-SQL-执行过长的时间，你如何优化，从哪些方面？"><a href="#一条-SQL-执行过长的时间，你如何优化，从哪些方面？" class="headerlink" title="一条 SQL 执行过长的时间，你如何优化，从哪些方面？"></a>一条 SQL 执行过长的时间，你如何优化，从哪些方面？</h2><ol><li>数据库主从分离，读写分离，降低读写针对同一表同时的压力，至于主从同步，MySQL 有自带的 binlog 实现主从同步</li><li>explain 分析 SQL 语句，查看执行计划，分析索引是否用上，分析扫描行数等等</li><li>查看 MySQL 执行日志，看看是否有其他方面的问题</li></ol><hr><h2 id="SQL-执行顺序"><a href="#SQL-执行顺序" class="headerlink" title="SQL 执行顺序"></a>SQL 执行顺序</h2><ol><li><p><strong>FROM</strong> <left_table></p><blockquote><p>sql 首先执行 from 将数据从硬盘加载到数据缓冲区中，以便对这些数据进行操作。如果有多个表则求所有表的笛卡尔积。<br>[ table1的记录条数 * table2的记录条数 * tableN的记录条数）这时第一个虚拟表产生VT1]</p></blockquote></li><li><p><strong>ON</strong> <join_condition> </p><blockquote><p>其次执行on，从 VT1 中取出匹配 on 条件的行, 产生 VT2。</p></blockquote></li><li><p><strong>JOIN</strong> </p><blockquote><p>left join，right join 外部连接就是在这个时候执行的，在 VT2 的基础上添加符合条件的外部的行，产生 VT3。</p></blockquote></li></ol><hr><ol start="4"><li><p><strong>WHERE</strong> <where_condition></p><blockquote><p>执行 where 过滤，产生 VT4<br>由于这个时候 select 没有执行，所以 select 中的别名不可以用于 where</p></blockquote></li><li><p><strong>GROUP BY</strong> <group_by_list></p><blockquote><p>在 VT4 的基础上执行 group by 分组数据，产生 VT5。</p></blockquote></li><li><p><strong>HAVING</strong>  <having_condition></p><blockquote><p>在 VT5 的基础上执行 having 过滤，产生 VT6。</p></blockquote></li></ol><hr><ol start="7"><li><p><strong>SELECT</strong> </p><blockquote><p>查出我们要的字段，产生 VT7</p></blockquote></li><li><p><strong>DISTINCT</strong> <select_list></p></li><li><p><strong>ORDER BY</strong> <order_by_condition></p><blockquote><p>排序 产生 VT8</p></blockquote></li><li><p><strong>LIMIT</strong> <limit_number></p><blockquote><p>限制返回行数</p></blockquote></li></ol><hr><h1 id="SQL-性能分析"><a href="#SQL-性能分析" class="headerlink" title="SQL 性能分析"></a>SQL 性能分析</h1><h1 id="Explain"><a href="#Explain" class="headerlink" title="Explain"></a>Explain</h1><p>Explain 命令，可以用显示 MySQL 如何使用索引来处理 select 语句以及连接表</p><h2 id="字段"><a href="#字段" class="headerlink" title="字段"></a>字段</h2><h3 id="id"><a href="#id" class="headerlink" title="id"></a><code>id</code></h3><ul><li><p>概述</p><blockquote><p>查询序号，表示查询中 select 语句执行顺序</p></blockquote></li><li><p>说明</p><ol><li>id 相同时，执行顺序由上至下</li><li>子查询 id 的序号会递增，id 值越大优先级越高，越先被执行</li><li>id 相同，可以视为一组，从上往下顺序执行</li></ol></li></ul><h3 id="select-type"><a href="#select-type" class="headerlink" title="select_type"></a><code>select_type</code></h3><ol><li><p>概述</p><p>查询类型，主要是用于区别普通查询、联合查询、子查询等复杂查询</p></li><li><p>说明</p><p><strong>[SIMPLE]</strong> 表示简单的 select，没有 union 和子查询</p><p><strong>[PRIMARY]</strong>  子查询的语句中，最外面的 select 查询就是 primary</p><p><strong>[UNION]</strong> union 语句的第二个或者说是后面那一个</p><p><strong>[DERIVED]</strong> 在 from 列表中的子查询被标记为 DERIVED[衍生]，MySQL会递归执行这些子查询，并把结果放在临时表中。</p></li></ol><h3 id="table"><a href="#table" class="headerlink" title="table"></a><code>table</code></h3><p>显示这一步所访问数据库中表名称[显示这一行的数据是关于哪张表的]，有时不是真实的表名字，可能是简称</p><h3 id="type"><a href="#type" class="headerlink" title="type"></a><code>type</code></h3><p>表示 MySQL 在表中找到所需行的方式，又称**”访问类型”**</p><p>常用的类型有:<strong>ALL, index, range, ref, eq_ref, const, system</strong>   <strong>[从左到右，性能从差到好]</strong></p><ol><li><p><strong>ALL</strong></p><blockquote><p>Full Table Scan， MySQL 将遍历全表以找到匹配的行</p></blockquote></li><li><p><strong>index</strong></p><blockquote><p>Full Index Scan，遍历所有的索引树，比 ALL 要快的多，因为索引文件要比数据文件小的多</p></blockquote></li><li><p><strong>range</strong></p><blockquote><p>查找某个索引的部分索引，一般在 where 子句中使用 &lt; 、&gt;、in、between 等关键词。只检索给定范围的行，属于范围查找</p></blockquote></li><li><p>ref</p><blockquote><p><strong><u>查找非唯一性索引</u>**，</strong>返回匹配某一条件的多条数据**。属于精确查找、数据返回可能是多条</p></blockquote></li><li><p>eq_ref</p><blockquote><p><u><strong>查找唯一性索引</strong></u>，<strong>返回的数据至多一条</strong>。属于精确查找</p></blockquote></li><li><p>const</p><blockquote><p><u><strong>查找主键索引</strong></u>，<strong>返回的数据至多一条（0或者1条）</strong>。属于精确查找（id为主键）</p></blockquote></li><li><p>system</p><blockquote><p>查找主键索引，<strong>返回的数据至多一条（0或者1条）</strong>。属于精确查找</p></blockquote></li></ol><h3 id="possible-keys"><a href="#possible-keys" class="headerlink" title="possible_keys"></a><code>possible_keys</code></h3><p>显示可能应用在这张表中的索引，一个或多个</p><p>查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用。</p><h3 id="key"><a href="#key" class="headerlink" title="key"></a><code>key</code></h3><p>显示 MySQL 实际决定使用的索引</p><p>如果没有选择索引，键是 NULL。</p><p>要想强制 MySQL 使用或忽视 possible_keys 列中的索引，在查询中使用 FORCE INDEX、USE INDEX 或者 IGNORE INDEX</p><h3 id="key-len"><a href="#key-len" class="headerlink" title="key_len"></a><code>key_len</code></h3><p>表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度[<code>key_len</code> 显示的值为索引字段的最大可能长度，并非实际使用长度，即 <code>key_len</code> 是根据表定义计算而得，不是通过表内检索出的]</p><ol><li><p>varchar(10) 变长字段并且允许 null </p><blockquote><p>key_len = 10 * (<strong>character set</strong>: utf8=3, gbk=2, latin=1)  + 1 [null] + 2 [变长字段]</p></blockquote></li><li><p>varchar(10) 变长字段不允许 null </p><blockquote><p>key_len = 10 * (<strong>character set</strong>: utf8=3, gbk=2, latin=1)  + 2 [变长字段]</p></blockquote></li><li><p>char(10) 固定字段并且允许 null </p><blockquote><p>key_len = 10 * (<strong>character set</strong>: utf8=3, gbk=2, latin=1)  + 1 [null]</p></blockquote></li><li><p>char(10) 固定字段不允许 null </p><blockquote><p>key_len = 10 * (<strong>character set</strong>: utf8=3, gbk=2, latin=1)</p></blockquote></li></ol><h3 id="ref"><a href="#ref" class="headerlink" title="ref"></a><code>ref</code></h3><h3 id="rows"><a href="#rows" class="headerlink" title="rows"></a><code>rows</code></h3><p>MySQL 估计为了找到所需的行而要读取的行，rows 值很重要，它决定采用哪个索引以及是否放弃索引改为全表。它是一个平均数，用来估算查找需要行而必须读取的平均值。</p><h3 id="extra"><a href="#extra" class="headerlink" title="extra"></a><code>extra</code></h3><p><strong><code>Using filesort</code></strong></p><p>得到所需结果集，需要对所有记录进行文件排序</p><p>这类 SQL 语句性能极差，需要进行优化。</p><p>在一个没有建立索引的列上进行 order by，就会触发 filesort，常见的优化方案是，在order by 的列上添加索引，避免每次查询都全量排序。</p><p><strong><code>Using temporary</code></strong></p><p>需要建立临时表(temporary table)来暂存中间结果。</p><p>这类 SQL 语句性能较低，往往也需要进行优化。</p><p>典型的，group by 和 order by 同时存在，且作用于不同的字段时，就会建立临时表，以便计算出最终的结果集。</p><p><strong><code>Using index</code></strong></p><p>SQL 所需要返回的所有列数据均在一棵索引树上，而无需访问实际的行记录。</p><p>出现这个说明 MySQL 使用了覆盖索引，避免访问了表的数据行，效率不错！通俗的说也就是查询的列不需要回表，在索引树上就能拿到结果</p><p><strong><code>Using index condition</code></strong></p><p>确实命中了索引，但不是所有的列数据都在索引树上，还需要访问实际的行记录。</p><p><strong><code>Using where</code></strong></p><p>说明服务器在存储引擎收到行后将进行过滤。有些where中的条件会有属于索引的列，当它读取使用索引的时候，就会被过滤，所以会出现有些where语句并没有在extra列中出现using where这么一个说明。</p><p>本例虽然 Extra 字段说明使用了 where 条件过滤，但 type 属性是 ALL，表示需要扫描全部数据，仍有优化空间。</p><p>常见的优化方法为，在where过滤属性上添加索引。</p><p><strong><code>Using join buffer</code></strong></p><p>需要进行嵌套循环计算。</p><p>这类 SQL 语句性能往往也较低，需要进行优化。</p><p>典型的，两个关联表join，关联字段均未建立索引，就会出现这种情况。常见的优化方案是，在关联字段上添加索引，避免每次嵌套循环计算。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 存储引擎</title>
      <link href="2019/06/03/MySQL-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"/>
      <url>2019/06/03/MySQL-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>数据库引擎简单来说就是一个”数据库发动机”。当你访问数据库时，不管是手工访问，还是程序访问，都不是直接读写数据库文件，而是通过数据库引擎去访问数据库文件。以关系型数据库为例，你发 SQL 语句给数据库引擎，数据库引擎解释 SQL 语句，提取出你需要的数据返回给你。因此，对访问者来说，数据库引擎就是SQL语句的解释器。</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>正式来说，数据库引擎是用于存储、处理和保护数据的核心服务。利用数据库引擎可以控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求，这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象(如索引、视图和存储过程)。存储数据的文件有不同的类型，每种文件类型对应各自不同的处理机制：比如处理文本用 txt 类型，处理表格用 excel，处理图片用 png 等数据库中的表也应该有不同的类型，表的类型不同，会对应 MySQL 不同的存取机制。</p><p>在 Oracle 和 SQL Server 等数据库中只有一种存储引擎，所有数据存储管理机制都是一样的。而 MySQL 数据库支持很多存储引擎，包括MyISAM、InnoDB 等，其中 InnoDB 和 BDB 支持事务安全。它还支持一些第三方的存储引擎。用户可以根据不同的需求为数据表选择不同的存储引擎，用户也可以根据自己的需要编写自己的存储引擎。用户可以根据应用的需求选择如何来存储数据、索引、是否使用事务等。选择合适的存储引擎往往能够有效的提高数据库的性能和数据的访问效率，另外一个数据库中的多个表可以使用不同引擎的组合以满足各种性能和实际需求。</p><p>利用 <strong>show engines</strong>; 可以查看当前版本数据库支持的存储引擎</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show engines;</span><br><span class="line">+----------+---------+----------------------------------+--------------+------+------------+</span><br><span class="line">| Engine             | Support | Comment                                                     | Transactions | XA   | Savepoints |</span><br><span class="line">+----------+---------+----------------------------------+--------------+------+------------+</span><br><span class="line">| InnoDB             | DEFAULT | Supports transactions, row-level locking, and foreign keys     | YES          | YES  | YES        |</span><br><span class="line">| MRG_MYISAM         | YES     | Collection of identical MyISAM tables                          | NO           | NO   | NO         |</span><br><span class="line">| MEMORY             | YES     | Hash based, stored <span class="keyword">in</span> memory, useful <span class="keyword">for</span> temporary tables      | NO           | NO   | NO         |</span><br><span class="line">| BLACKHOLE          | YES     | /dev/null storage engine (anything you write to it disappears) | NO           | NO   | NO         |</span><br><span class="line">| MyISAM             | YES     | MyISAM storage engine                                          | NO           | NO   | NO         |</span><br><span class="line">| CSV                | YES     | CSV storage engine                                             | NO           | NO   | NO         |</span><br><span class="line">| ARCHIVE            | YES     | Archive storage engine                                         | NO           | NO   | NO         |</span><br><span class="line">| PERFORMANCE_SCHEMA | YES     | Performance Schema                                             | NO           | NO   | NO         |</span><br><span class="line">| FEDERATED          | NO      | Federated MySQL storage engine                                 | NULL         | NULL | NULL       |</span><br><span class="line">+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+</span><br><span class="line">9 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure><h1 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h1><h3 id="MyISAM-数据存储"><a href="#MyISAM-数据存储" class="headerlink" title="MyISAM 数据存储"></a>MyISAM 数据存储</h3><h4 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h4><p>MyISAM 会将表数据存储在两个文件中：数据文件和索引文件，分别会以 .MYD 和 .MYI 为扩展名。MyISAM 表可以包含动态或者静态行。 MySQL 会根据表的定义来决定采用何种格式。 MyISAM 表可以存储的行记录数，一般受限于可用的磁盘空间，或者操作系统中单个文件的最大尺寸。<br>.frm是描述了数据表的结构</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@0440a971febb:/var/lib/mysql/test<span class="comment"># ls</span></span><br><span class="line">book.frm  book.ibddb.optperson.MYD  person.MYIperson.frm  reader.frmreader.ibd</span><br></pre></td></tr></table></figure><h3 id="MyISAM-特性"><a href="#MyISAM-特性" class="headerlink" title="MyISAM 特性"></a>MyISAM 特性</h3><h4 id="并发性和锁级别"><a href="#并发性和锁级别" class="headerlink" title="并发性和锁级别"></a>并发性和锁级别</h4><p>使用表级锁，当对表中数据做修改时，会对整个表的数据进行加锁，在读取数据时候，也需要对表中的数据加共享锁，所以对读写混合的操作并发性并不是太好。MyISAM 的读写锁调度是写优先，这也是 MyISAM 不适合做以数据写入为主的数据表引擎，因为在写锁后，其他线程不能做任何操作，大量的更新操作会使查询很难得到锁，从而造成永远阻塞。</p><h4 id="表的损坏和修复"><a href="#表的损坏和修复" class="headerlink" title="表的损坏和修复"></a>表的损坏和修复</h4><p>MyISAM 支持对任意意外关闭所损坏的表的检查和修复，这里的修复并不是通过事物务来修复的，有可能造成数据丢失</p><ul><li>如果mysqld已经宕掉，且无法启动，那么可以通过 mysiamchk 工具来进行修复。此工具在mysqld 服务没有启动时才可以使用。该工具可以检查并分析修复MyISAM表。</li><li>如果 mysqld 仍在运行，或者可以重新启动，那么可以通过 mysqlcheck 工具来进行修复。或者直接通过 mysql 的内置修复SQL 语句来修复：CHECK TABLE，REPAIR TABLE ，ANALYSE TABLE，OPTIMIZE TABLE。这两种方法可以同样达到对表的修复作用。 以上两种方式各有应用场景。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show create table person;</span><br><span class="line">+<span class="comment">--------+---------------------------------------------------------------------------+</span></span><br><span class="line">| Table  | <span class="keyword">Create</span> <span class="keyword">Table</span>                                                              |</span><br><span class="line">+<span class="comment">--------+---------------------------------------------------------------------------+</span></span><br><span class="line">| person | <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> person (</span><br><span class="line">  <span class="keyword">id</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">30</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  Age <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="keyword">id</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=MyISAM <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8 |</span><br><span class="line">+<span class="comment">--------+---------------------------------------------------------------------------+</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; check table person;</span><br><span class="line">+<span class="comment">-------------+-------+----------+----------+</span></span><br><span class="line">| Table       | Op    | Msg_type | Msg_text |</span><br><span class="line">+<span class="comment">-------------+-------+----------+----------+</span></span><br><span class="line">| test.person | <span class="keyword">check</span> | <span class="keyword">status</span>   | OK       |</span><br><span class="line">+<span class="comment">-------------+-------+----------+----------+</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">repair</span> <span class="keyword">table</span> person;</span><br><span class="line">+<span class="comment">-------------+--------+----------+----------+</span></span><br><span class="line">| Table       | Op     | Msg_type | Msg_text |</span><br><span class="line">+<span class="comment">-------------+--------+----------+----------+</span></span><br><span class="line">| test.person | <span class="keyword">repair</span> | <span class="keyword">status</span>   | OK       |</span><br><span class="line">+<span class="comment">-------------+--------+----------+----------+</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec) </span><br></pre></td></tr></table></figure><h3 id="MyISAM-适用场景"><a href="#MyISAM-适用场景" class="headerlink" title="MyISAM 适用场景"></a>MyISAM 适用场景</h3><ul><li>如果应用中需要执行大量的SELECT查询，可以考虑 MyISAM。</li></ul><h1 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h1><p>InnoDB 存储引擎: 主要面向 OLTP(Online Transaction Processing，在线事务处理) 方面的应用，是第一个完整支持 ACID 事务的存储引擎。</p><h3 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h3><h4 id="存储结构-1"><a href="#存储结构-1" class="headerlink" title="存储结构"></a>存储结构</h4><p>所有的数据表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件）MySQL 使用 InnoDB 存储表时，会将表的定义和数据索引等信息分开存储，其中前者存储在 .frm 文件中，后者存储在 .ibd 文件中</p><ol><li>.frm<br> 无论在 MySQL 中选择了哪个存储引擎，所有的 MySQL 表都会在硬盘上创建一个 .frm 文件用来描述表的格式或者说定义； .frm 文件的格式在不同的平台上都是相同的。</li><li>.ibd 文件<br> .ibd 文件就是每一个表独有的表空间，文件存储了当前表的数据和相关的索引数据。</li></ol><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>适用于更新密集型，支持事务，自动灾难恢复，行锁，外键</li><li>InnoDB 为 MySQL 表提供了ACID事务支持、系统崩溃修复能力和多版本并发控制（即MVCC Multi-Version Concurrency Control）的行锁</li><li>支持自增长列（auto_increment）,自增长列的值不能为空，如果在使用的时候为空则自动从现有值开始增值。</li><li>支持外键</li></ul><h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2><p><strong>MyISAM 是 MySQL 5.5 版本之前的默认数据库引擎。 虽然性能极佳，而且提供了大量的特性，包括全文索引、压缩、空间函数等，但 MyISAM 不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。不过，5.5版本之后，MySQL引入了InnoDB（事务性数据库引擎），MySQL 5.5版本后默认的存储引擎为InnoDB。</strong></p><ol><li><p>InnoDB 是第一个完整支持 ACID 事务的存储引擎, MyISAM 不支持</p></li><li><p>InnoDB 支持外键，MyISAM 不支持</p></li><li><p>MyISAM 只有表级锁，不会死锁，并发性能差；而 InnoDB 支持行级锁和表级锁,默认为行级锁，会死锁，并发性能好。</p></li><li><p>InnoDB 必须有主键，没有指定就为每一行数据生成不可见的 ROWID 列作为主键，MyISAM 可以没有主键</p></li><li><p>MyISAM 内置了一个计数器来存储表的行数。执行 select count(*) 时直接从计数器中读取，速度非常快。而 InnoDB 不保存这些信息。</p></li><li><p>InnoDB 是聚集索引，使用 B+Tree 作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按 B+Tree 组织的一个索引结构），必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。</p></li><li><p>MyISAM：可被压缩，存储空间小。支持三种不同的存储格式：静态表、动态表、压缩表。</p><p>Innodb：需要更多的内存和存储，它会在主内存中建立专用的缓冲池用于高速缓冲数据和索引。</p></li><li><p>MyISAM ：每个表在磁盘上存储成三个文件。</p><ul><li><p><code>.frm</code> 文件存储表定义</p></li><li><p><code>.MYD</code> 是数据文件的扩展名</p></li><li><p><code>.MYI</code> 是索引文件的扩展名。</p></li></ul><p>Innodb 有自己的表空间的概念，表中的数据是存储在表空间之中的，具体存储在什么样的表空间中呢？是由 innodb_file_per_table 这个参数决定的，</p><p>如果这个参数为ON:独立表空间，存储的表名为(表名.ibd),</p><p>如果参数为OFF:系统表空间(系统的共享表空间),存储的表名为(ibdataX(X为数字))) </p><pre><code>命令：show variables like &#39;innodb_file_per_table&#39;;       查看 mysql 数据库的存放位置: show global variables like &quot;%datadir%&quot;;接下来我们创建一个表来看一下create table myinnodb(id int,c1 varchar(100)) engine=&#39;innodb&#39;;            看一下文件系统是如何存储的，进入到数据库存放的位置，ls -lh myinnodb*            可以看到有 myinnodb.frm 和 myinnodb.ibd 两个文件，frm文件时记录表结构的，ibd 就是 innodb 表实际存储的位置       接着把 innodb_file_per_table 参数设置为 off,命令为 set global innodb_file_per_table=off;            show variables like &#39;innodb_file_per_table&#39;; 用这个命令检查是否关闭了            再创建一个表：create table myinnodb_g(id int,c1 varchar(100)) engine=&#39;innodb&#39;;            查看存储的位置，可以看到只有一个myinnodb_g.frm的文件，不存在ibd文件，也就是说它的数据存储在系统共享表的空间 存储在ibdata1中</code></pre></li></ol><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 下午7.05.39.png" alt="截屏2021-02-20 下午7.05.39" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 下午7.21.10.png" alt="截屏2021-02-20 下午7.21.10" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 下午7.21.42.png" alt="截屏2021-02-20 下午7.21.42" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 下午7.29.35.png" alt="截屏2021-02-20 下午7.29.35" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 下午7.31.03.png" alt="截屏2021-02-20 下午7.31.03" style="zoom:50%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-02-20 下午7.32.56.png" alt="截屏2021-02-20 下午7.32.56" style="zoom:50%;" />]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 存储引擎</title>
      <link href="2019/06/03/MySQL-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E5%89%AF%E6%9C%AC/"/>
      <url>2019/06/03/MySQL-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E5%89%AF%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>数据库引擎简单来说就是一个”数据库发动机”。当你访问数据库时，不管是手工访问，还是程序访问，都不是直接读写数据库文件，而是通过数据库引擎去访问数据库文件。以关系型数据库为例，你发 SQL 语句给数据库引擎，数据库引擎解释 SQL 语句，提取出你需要的数据返回给你。因此，对访问者来说，数据库引擎就是SQL语句的解释器。</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>正式来说，数据库引擎是用于存储、处理和保护数据的核心服务。利用数据库引擎可以控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求，这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象(如索引、视图和存储过程)。存储数据的文件有不同的类型，每种文件类型对应各自不同的处理机制：比如处理文本用 txt 类型，处理表格用 excel，处理图片用 png 等数据库中的表也应该有不同的类型，表的类型不同，会对应 MySQL 不同的存取机制。</p><p>在 Oracle 和 SQL Server 等数据库中只有一种存储引擎，所有数据存储管理机制都是一样的。而 MySQL 数据库支持很多存储引擎，包括MyISAM、InnoDB 等，其中 InnoDB 和 BDB 支持事务安全。它还支持一些第三方的存储引擎。用户可以根据不同的需求为数据表选择不同的存储引擎，用户也可以根据自己的需要编写自己的存储引擎。用户可以根据应用的需求选择如何来存储数据、索引、是否使用事务等。选择合适的存储引擎往往能够有效的提高数据库的性能和数据的访问效率，另外一个数据库中的多个表可以使用不同引擎的组合以满足各种性能和实际需求。</p><p>利用 <strong>show engines</strong>; 可以查看当前版本数据库支持的存储引擎</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show engines;</span><br><span class="line">+----------+---------+----------------------------------+--------------+------+------------+</span><br><span class="line">| Engine             | Support | Comment                                                     | Transactions | XA   | Savepoints |</span><br><span class="line">+----------+---------+----------------------------------+--------------+------+------------+</span><br><span class="line">| InnoDB             | DEFAULT | Supports transactions, row-level locking, and foreign keys     | YES          | YES  | YES        |</span><br><span class="line">| MRG_MYISAM         | YES     | Collection of identical MyISAM tables                          | NO           | NO   | NO         |</span><br><span class="line">| MEMORY             | YES     | Hash based, stored <span class="keyword">in</span> memory, useful <span class="keyword">for</span> temporary tables      | NO           | NO   | NO         |</span><br><span class="line">| BLACKHOLE          | YES     | /dev/null storage engine (anything you write to it disappears) | NO           | NO   | NO         |</span><br><span class="line">| MyISAM             | YES     | MyISAM storage engine                                          | NO           | NO   | NO         |</span><br><span class="line">| CSV                | YES     | CSV storage engine                                             | NO           | NO   | NO         |</span><br><span class="line">| ARCHIVE            | YES     | Archive storage engine                                         | NO           | NO   | NO         |</span><br><span class="line">| PERFORMANCE_SCHEMA | YES     | Performance Schema                                             | NO           | NO   | NO         |</span><br><span class="line">| FEDERATED          | NO      | Federated MySQL storage engine                                 | NULL         | NULL | NULL       |</span><br><span class="line">+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+</span><br><span class="line">9 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure><h1 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h1><h3 id="MyISAM-数据存储"><a href="#MyISAM-数据存储" class="headerlink" title="MyISAM 数据存储"></a>MyISAM 数据存储</h3><h4 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h4><p>MyISAM 会将表数据存储在两个文件中：数据文件和索引文件，分别会以 .MYD 和 .MYI 为扩展名。MyISAM 表可以包含动态或者静态行。 MySQL 会根据表的定义来决定采用何种格式。 MyISAM 表可以存储的行记录数，一般受限于可用的磁盘空间，或者操作系统中单个文件的最大尺寸。<br>.frm是描述了数据表的结构</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@0440a971febb:/var/lib/mysql/test<span class="comment"># ls</span></span><br><span class="line">book.frm  book.ibddb.optperson.MYD  person.MYIperson.frm  reader.frmreader.ibd</span><br></pre></td></tr></table></figure><h3 id="MyISAM-特性"><a href="#MyISAM-特性" class="headerlink" title="MyISAM 特性"></a>MyISAM 特性</h3><h4 id="并发性和锁级别"><a href="#并发性和锁级别" class="headerlink" title="并发性和锁级别"></a>并发性和锁级别</h4><p>使用表级锁，当对表中数据做修改时，会对整个表的数据进行加锁，在读取数据时候，也需要对表中的数据加共享锁，所以对读写混合的操作并发性并不是太好。MyISAM 的读写锁调度是写优先，这也是 MyISAM 不适合做以数据写入为主的数据表引擎，因为在写锁后，其他线程不能做任何操作，大量的更新操作会使查询很难得到锁，从而造成永远阻塞。</p><h4 id="表的损坏和修复"><a href="#表的损坏和修复" class="headerlink" title="表的损坏和修复"></a>表的损坏和修复</h4><p>MyISAM 支持对任意意外关闭所损坏的表的检查和修复，这里的修复并不是通过事物务来修复的，有可能造成数据丢失</p><ul><li>如果mysqld已经宕掉，且无法启动，那么可以通过 mysiamchk 工具来进行修复。此工具在mysqld 服务没有启动时才可以使用。该工具可以检查并分析修复MyISAM表。</li><li>如果 mysqld 仍在运行，或者可以重新启动，那么可以通过 mysqlcheck 工具来进行修复。或者直接通过 mysql 的内置修复SQL 语句来修复：CHECK TABLE，REPAIR TABLE ，ANALYSE TABLE，OPTIMIZE TABLE。这两种方法可以同样达到对表的修复作用。 以上两种方式各有应用场景。</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show create table person;</span><br><span class="line">+<span class="comment">--------+---------------------------------------------------------------------------+</span></span><br><span class="line">| Table  | <span class="keyword">Create</span> <span class="keyword">Table</span>                                                              |</span><br><span class="line">+<span class="comment">--------+---------------------------------------------------------------------------+</span></span><br><span class="line">| person | <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> person (</span><br><span class="line">  <span class="keyword">id</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">30</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  Age <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="keyword">id</span>)</span><br><span class="line">) <span class="keyword">ENGINE</span>=MyISAM <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8 |</span><br><span class="line">+<span class="comment">--------+---------------------------------------------------------------------------+</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; check table person;</span><br><span class="line">+<span class="comment">-------------+-------+----------+----------+</span></span><br><span class="line">| Table       | Op    | Msg_type | Msg_text |</span><br><span class="line">+<span class="comment">-------------+-------+----------+----------+</span></span><br><span class="line">| test.person | <span class="keyword">check</span> | <span class="keyword">status</span>   | OK       |</span><br><span class="line">+<span class="comment">-------------+-------+----------+----------+</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; <span class="keyword">repair</span> <span class="keyword">table</span> person;</span><br><span class="line">+<span class="comment">-------------+--------+----------+----------+</span></span><br><span class="line">| Table       | Op     | Msg_type | Msg_text |</span><br><span class="line">+<span class="comment">-------------+--------+----------+----------+</span></span><br><span class="line">| test.person | <span class="keyword">repair</span> | <span class="keyword">status</span>   | OK       |</span><br><span class="line">+<span class="comment">-------------+--------+----------+----------+</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec) </span><br></pre></td></tr></table></figure><h3 id="MyISAM-适用场景"><a href="#MyISAM-适用场景" class="headerlink" title="MyISAM 适用场景"></a>MyISAM 适用场景</h3><ul><li>如果应用中需要执行大量的SELECT查询，可以考虑 MyISAM。</li></ul><h1 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h1><p>InnoDB 存储引擎: 主要面向 OLTP(Online Transaction Processing，在线事务处理) 方面的应用，是第一个完整支持 ACID 事务的存储引擎。</p><h3 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h3><h4 id="存储结构-1"><a href="#存储结构-1" class="headerlink" title="存储结构"></a>存储结构</h4><p>所有的数据表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件）MySQL 使用 InnoDB 存储表时，会将表的定义和数据索引等信息分开存储，其中前者存储在 .frm 文件中，后者存储在 .ibd 文件中</p><ol><li>.frm<br> 无论在 MySQL 中选择了哪个存储引擎，所有的 MySQL 表都会在硬盘上创建一个 .frm 文件用来描述表的格式或者说定义； .frm 文件的格式在不同的平台上都是相同的。</li><li>.ibd 文件<br> .ibd 文件就是每一个表独有的表空间，文件存储了当前表的数据和相关的索引数据。</li></ol><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>适用于更新密集型，支持事务，自动灾难恢复，行锁，外键</li><li>InnoDB 为 MySQL 表提供了ACID事务支持、系统崩溃修复能力和多版本并发控制（即MVCC Multi-Version Concurrency Control）的行锁</li><li>支持自增长列（auto_increment）,自增长列的值不能为空，如果在使用的时候为空则自动从现有值开始增值。</li><li>支持外键</li></ul><h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2><p><strong>MyISAM 是 MySQL 5.5 版本之前的默认数据库引擎。 虽然性能极佳，而且提供了大量的特性，包括全文索引、压缩、空间函数等，但 MyISAM 不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。不过，5.5版本之后，MySQL引入了InnoDB（事务性数据库引擎），MySQL 5.5版本后默认的存储引擎为InnoDB。</strong></p><ol><li><p>InnoDB 是第一个完整支持 ACID 事务的存储引擎, MyISAM 不支持</p></li><li><p>InnoDB 支持外键，MyISAM 不支持</p></li><li><p>MyISAM 只有表级锁，不会死锁，并发性能差；而 InnoDB 支持行级锁和表级锁,默认为行级锁，会死锁，并发性能好。</p></li><li><p>InnoDB 必须有主键，没有指定就为每一行数据生成不可见的 ROWID 列作为主键，MyISAM 可以没有主键</p></li><li><p>MyISAM 内置了一个计数器来存储表的行数。执行 select count(*) 时直接从计数器中读取，速度非常快。而 InnoDB 不保存这些信息。</p><p><strong>InnoDB：</strong> 没有保存表的总行数，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了 wehre 条件后，MyISAM 和 innodb 处理的方式都一样。</p></li><li><p>InnoDB 是聚集索引，使用 B+Tree 作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按 B+Tree 组织的一个索引结构），必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。</p></li><li><p>如果执行大量的 SELECT，MyISAM 是更好的选择。如果你的数据执行大量的 INSERT 或 UPDATE，出于性能方面的考虑，应该使用 InnoDB 表</p></li><li><p>MyISAM：可被压缩，存储空间小。支持三种不同的存储格式：静态表、动态表、压缩表。</p><p>Innodb：需要更多的内存和存储，它会在主内存中建立专用的缓冲池用于高速缓冲数据和索引。</p></li><li><p>MyISAM ：每个表在磁盘上存储成三个文件。</p><ul><li><p><code>.frm</code> 文件存储表定义</p></li><li><p><code>.MYD</code> 是数据文件的扩展名</p></li><li><p><code>.MYI</code> 是索引文件的扩展名。</p></li></ul><p>Innodb 有自己的表空间的概念，表中的数据是存储在表空间之中的，具体存储在什么样的表空间中呢？是由 innodb_file_per_table 这个参数决定的，</p><p>如果这个参数为ON:独立表空间，存储的表名为(表名.ibd),</p><p>如果参数为OFF:系统表空间(系统的共享表空间),存储的表名为(ibdataX(X为数字))) </p><pre><code>命令：show variables like &#39;innodb_file_per_table&#39;;       查看 mysql 数据库的存放位置: show global variables like &quot;%datadir%&quot;;接下来我们创建一个表来看一下create table myinnodb(id int,c1 varchar(100)) engine=&#39;innodb&#39;;            看一下文件系统是如何存储的，进入到数据库存放的位置，ls -lh myinnodb*            可以看到有 myinnodb.frm 和 myinnodb.ibd 两个文件，frm文件时记录表结构的，ibd 就是 innodb 表实际存储的位置       接着把 innodb_file_per_table 参数设置为 off,命令为 set global innodb_file_per_table=off;            show variables like &#39;innodb_file_per_table&#39;; 用这个命令检查是否关闭了            再创建一个表：create table myinnodb_g(id int,c1 varchar(100)) engine=&#39;innodb&#39;;            查看存储的位置，可以看到只有一个myinnodb_g.frm的文件，不存在ibd文件，也就是说它的数据存储在系统共享表的空间 存储在ibdata1中</code></pre></li></ol><ol><li><p><strong>全文索引</strong></p><p><strong>MyISAM：</strong>支持 FULLTEXT类型的全文索引</p><p><strong>InnoDB：</strong>不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。</p></li><li><p><strong>事务支持</strong></p><p><strong>MyISAM：</strong>强调的是性能，每次查询具有原子性,其执行数度比 InnoDB 类型更快，但是不提供事务支持。</p><p><strong>InnoDB：</strong>提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。</p></li></ol><p><strong>可移植性、备份及恢复</strong></p><p><strong>MyISAM：</strong>数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。</p><p><strong>InnoDB：</strong>免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。</p><p><strong>数据和索引的组织方式不同。</strong></p><p>MyISAM 将索引和数据分开进行存储。索引存放在 <code>.MYI</code> 文件中，数据存放在 <code>.MYD</code> 文件中。索引中保存了相应数据的地址。以 <code>表名+.MYI</code> 文件分别保存。 InnoDB 的主键索引树的叶子节点保存主键和相应的数据。其它的索引树的叶子节点保存的是主键。也正是因为采取了这种存储方式，InnoDB 才强制要求每张表都要有主键。</p><p><strong>对 AUTO_INCREMENT 的处理方式不一样。</strong></p><p>如果将某个字段设置为 INCREMENT，InnoDB 中规定必须包含只有该字段的索引。但是在 MyISAM 中，也可以将该字段和其他字段一起建立联合索引。</p><p><strong>CURD 操作 MyISAM</strong></p><p>如果执行大量的SELECT，MyISAM 是更好的选择。 InnoDB：如果你的数据执行大量的 INSERT 或 UPDATE，出于性能方面的考虑，应该使用 InnoDB 表。DELETE 从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。</p><p><strong>锁的粒度不同。</strong></p><p>MyISAM 仅支持表锁。每次操作锁住整张表。这种处理方式一方面加锁的开销比较小，且不会出现死锁，但另一方面并发性能较差。InnoDB支持行锁。每次操作锁住一行数据，一方面行级锁在每次获取锁和释放锁的操作需要消耗比表锁更多的资源，速度较慢，且可能发生死锁，但是另一方面由于锁的粒度较小，发生锁冲突的概率也比较低，并发性较好。此外，即使是使用了InnoDB存储引擎，但如果MySQL执行一条sql语句时不能确定要扫描的范围，也会锁住整张表。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 索引</title>
      <link href="2019/06/03/MySQL-%E7%B4%A2%E5%BC%95/"/>
      <url>2019/06/03/MySQL-%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>除数据本身之外，数据库还维护着一个满足特定查找算法的数据结构，这些数据结构一某种方式指向数据，这样就可以在这些数据结构基础上实现高级查找算法，这种数据结构就是索引。</p><a id="more"></a><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>除数据本身之外，数据库还维护着一个满足特定查找算法的数据结构，这些数据结构一某种方式指向数据，这样就可以在这些数据结构基础上实现高级查找算法，这种数据结构就是索引。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>MySQL 官方定义为：<strong>索引是帮助 MySQL 高效获取数据的 <font color='red'>数据结构</font></strong></p><p><strong>本质：索引是一种数据结构</strong></p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ol><li><p>通过创建索引，可以提高数据检索的效率，降低数据库的 IO 成本</p></li><li><p>通过创建索引，降低数据排序的成本，降低了 CPU 的消耗</p></li></ol><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ol><li><p>索引本质也是一张表，保存了主键与索引字段，并指向实体表的记录，所以索引列也占用存储空间</p></li><li><p>虽然索引大大提高了查询速度，同时却会降低数据更新效率</p></li></ol><h2 id="索引分类"><a href="#索引分类" class="headerlink" title="索引分类"></a>索引分类</h2><h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><ol><li><p>非聚集索引</p><p><strong>非聚集索引的叶子节点为索引节点，但是有一个指针指向数据节点。</strong></p><p>MyISAM 是非聚集索引。</p></li><li><p>聚集索引</p><p><strong>聚集索引叶子节点就是数据节点。</strong></p><p><strong>关于聚集索引，innodb 会按照如下规则进行处理：</strong> </p><p>如果定义主键，则主键作为聚集索引 </p><p>如果没有主键被定义，则该表的第一个唯一非空索引被作为聚集索引 </p><p>如果没有主键也没有合适的唯一索引，那么 innodb 内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键是一个6个字节的列，改列的值会随着数据的插入自增。</p></li></ol><p><strong><font color='red'>注意事项</font></strong></p><blockquote><p>innodb 的普通索引，唯一索引，联合索引都是辅助索引，采用非聚集索引结构。InnoDB 的所有辅助索引都引用主键作为 data 域。</p></blockquote><p>聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 </p><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><ol><li>Hash索引</li></ol><p>Hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像 B+Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的 IO 访问，所以 Hash 索引的查询效率要远高于 B+Tree 索引。</p><p>虽然 Hash 索引效率高，但是 Hash 索引本身由于其特殊性也带来了 很多限制和弊端，主要有以下这些。</p><p><strong>Hash 索引仅仅能满足 “=”, “IN” 和 “&lt;=&gt;” 查询，不能使用范围查询。</strong></p><blockquote><p>由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和 Hash 运算前完全一样</p></blockquote><p><strong>Hash 索引无法被用来避免数据的排序操作</strong></p><blockquote><p>由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且 Hash 值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运</p></blockquote><p><strong>Hash 索引不能利用部分索引键查询</strong></p><p><strong>哈希索引也没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询</strong></p><p><strong>哈希索引也不支持多列联合索引的最左匹配规则</strong></p><blockquote><p>对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。</p></blockquote><p><strong>Hash 索引在任何时候都不能避免表扫描</strong></p><blockquote><p>Hash 索引是将索引键通过 Hash 运算之后，将 Hash 运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。</p></blockquote><p><strong>Hash 索引遇到大量 Hash 值相等的情况后性能并不一定就会比 B+Tree 索引高</strong></p><blockquote><p>对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下</p></blockquote><ol start="2"><li><p>B+Tree</p><blockquote><p>B+Tree 索引是 MySQL 数据库中使用最为频繁的索引类型，除了 Archive 存储引擎之外的其他所有的存储引擎都支持 B+Tree 索引。不仅仅在 MySQL 中是如此，实际上在其他的很多数据库管理系统中 B+Tree  索引也同样是作为最主要的索引类型，这主要是因为 B+Tree 索引的存储结构在数据库的数据检索中有非常优异的表现。</p></blockquote></li></ol><h2 id="其他分类"><a href="#其他分类" class="headerlink" title="其他分类"></a>其他分类</h2><ol><li><p><strong>普通索引</strong></p><p>最基本的索引，它没有任何限制，用于加速查询。</p></li><li><p><strong>唯一索引</strong></p><p>索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。</p></li><li><p><strong>主键索引</strong></p><p>是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引。</p></li><li><p><strong>组合索引</strong></p><p>指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合。</p></li><li><p><strong>全文索引</strong></p><p>主要用来查找文本中的关键字，而不是直接与索引中的值相比较。</p><p>fulltext 索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的 where 语句的参数匹配。</p></li><li><p><strong>覆盖索引</strong><br>覆盖索引（covering index）指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。<br>如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫做覆盖索引。</p></li></ol><h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><ol><li>频繁作为查询条件的字段应该创建索引</li><li>主键列</li><li>连接列</li><li>范围搜索列，因为索引进行了排序</li><li>经常与其他表进行连接的表，在连接字段上应该建立索引； </li><li>经常出现在 Where 子句中的字段，特别是大表的字段，应该建立索引； </li><li>索引应该建在选择性高的字段上，例如性别选择性很低，不适合建索引； </li><li>索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引； </li><li>复合索引的建立需要进行仔细分析；尽量考虑用单字段索引代替：</li><li>删除无用的索引，避免对执行计划造成负面影响；</li></ol><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><ol><li><p>查询很少的列不创建索引</p></li><li><p>全值匹配(查询条件的顺序和索引的顺序一致，这种方式最好，能够充分发挥索引的作用，使用and连接的查询提交也可以不与索引的顺序一致，MySQL 会自动优化</p></li><li><p>列值较少（性别）的列不创建索引，并不是所有索引对查询都有效</p><blockquote><p>SQL 是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL 查询可能不会去利用索引，如一表中有字段sex，male、female 几乎各一半，那么即使在 sex 上建了索引也对查询效率起不了作用。</p></blockquote></li><li><p>image，bit 数据类型的列不创建索引</p></li><li><p>修改性能远远大于索引性能的列</p><blockquote><p>索引会提高检索性能但会降低修改性能。索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。</p></blockquote></li><li><p>只要列中包含有 NULL 值都将不会被包含在索引中，所以我们在数据库设计时不要让字段的默认值为 NULL。</p></li><li><p>对字符串列进行索引，如果可能应该指定一个前缀长度。</p><blockquote><p>例如，如果有一个CHAR(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。</p></blockquote></li><li><p>like “%aaa%” 不会使用索引而 like”aaa%” 可以使用索引, 以 % 开头不会利用到索引，结尾可以。</p></li><li><p>不要在索引列上进行运算</p><blockquote><p> 不要在索引列上做任何操作（计算、函数、(自动or手动)类型转换），会导致索引失效而转向全表扫描，在查询语句中不要使用表达式，会严重影响性能</p><p> 索引列上不要使用表达式，如 where substr(a, 1, 3) = ‘hhh’、where a = a + 1，表达式是一大忌讳，再简单 mysql 也不认。有时数据量不是大到严重影响速度时，一般可以先查出来，比如先查所有订单记录的数据，再在程序中去筛选。</p><p> 我们可以吧 id - 2 = 1改成 id = 1 + 2 的形式</p></blockquote></li><li><p>不使用 NOT IN 和 &lt;&gt; 操作</p></li><li><p>MySQL 在使用不等于(!= 或者&lt;&gt;)的时候无法使用索引，会导致全表扫描。is null 、is not null 也无法使用索引</p></li><li><p><strong>数据类型出现隐式转换的时候不会命中索引，特别是当列类型是字符串，字符串不加单引号索引失效</strong></p></li><li><p>用 or 分割开的条件，如果 or 前的条件中列有索引，而后面的列中没有索引，那么涉及到的索引都不会被用到。</p><p>因为 or 后面的条件列中没有索引，那么后面的查询肯定要走全表扫描，在存在全表扫描的情况下，就没有必要多一次索引扫描增加 IO 访问。</p></li><li><p>符合最左前缀原则</p><blockquote><p>最佳左前缀法则：如果索引了多列，要遵守最左前缀法则，指的是查询从索引的最左前列开始并且不跳过索引中的列，尤其是索引的头。如果查询条件中没有索引的头，会导致索引失效，也就是说使用索引的时候是从头开始，且索引键之间不能断</p></blockquote></li></ol><p>利用覆盖索引进行查询，避免回表。</p><p>被查询的列，数据能从索引中取得，而不用通过行定位符row-locator再到row上获取，即“被查询列要被所建的索引覆盖”，这能够加速查询速度。</p><h1 id="结构-1"><a href="#结构-1" class="headerlink" title="结构"></a>结构</h1><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><p>一般来说， MySQL 中的 B-Tree 索引的物理文件大多都是以 Balance Tree 的结构来存储的，也就是所有实际需要的数据都存放于 Tree 的 Leaf Node ，而且到任何一个 Leaf Node 的最短路径的长度都是完全相同的，所以我们大家都称之为 B-Tree 索引。</p><p>当然，可能各种数据库（或 MySQL 的各种存储引擎）在存放自己的 B-Tree 索引的时候会对存储结构稍作改造。如 Innodb 存储引擎的 B-Tree 索引实际使用的存储结构实际上是 B+Tree ，也就是在 B-Tree 数据结构的基础上做了很小的改造，在每一个 Leaf Node 上面出了存放索引键的相关信息之外，还存储了指向与该 Leaf Node 相邻的后一个 LeafNode 的指针信息，这主要是为了加快检索多个相邻 Leaf Node 的效率考虑。</p><h2 id="Innodb"><a href="#Innodb" class="headerlink" title="Innodb"></a>Innodb</h2><p>在 Innodb 存储引擎中，存在两种不同形式的索引，一种是聚集形式的主键索引（Primary Key ），另外一种则是和其他存储引擎存放形式基本相同的普通 B-Tree 索引，这种索引在 Innodb 存储引擎中被称为 Secondary Index 。</p><p>在主键索引中， 叶子结点存放的是表的实际数据，不仅仅包括主键字段的数据，还包括其他字段的数据据以主键值有序的排列。而 Secondary Index 则和其他普通的 B-Tree 索引没有太大的差异，Leaf Nodes 除了存放索引键 的相关信息外，还存放了 Innodb 的主键值。</p><p>所以，在 Innodb 中如果通过主键来访问数据效率是非常高的，而如果是通过 Secondary Index 来访问数据的话， Innodb 首先通过 Secondary Index 的相关信息，通过相应的索引键检索到 Leaf Node之后，需要再通过 Leaf Node 中存放的主键值再通过主键索引来获取相应的数据行。</p><h2 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h2><p>MyISAM 存储引擎的主键索引和非主键索引差别很小，只不过是主键索引的索引键是一个唯一且非空的键而已。而且 MyISAM 存储引擎的索引和 Innodb 的 Secondary Index 的存储结构也基本相同，主要的区别只是 MyISAM 存储引擎在 Leaf Nodes 上面除了存放索引键信息之外，再存放能直接定位到 MyISAM 数据文件中相应的数据行的信息（如 Row Number ），但并不会存放主键的键值信息。</p><h2 id="B"><a href="#B" class="headerlink" title="B+"></a>B+</h2><p>一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：</p><p>B+ 树是应文件系统所需而产生的一种 B 树的变形树, 类似文件的目录一级一级索引，只有最底层的叶子节点[文件]保存数据，非叶子节点只保存索引，不保存实际的数据，数据都保存在叶子节点中,所有的非叶子节点都可以看成索引的一部分。</p><ol><li><p><strong>B+ 树的磁盘读写代价更低</strong></p><blockquote><p>B+ 树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对 B 树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。</p></blockquote></li><li><p><strong>B+树的查询效率更加稳定</strong></p><blockquote><p>由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。</p></blockquote></li><li><p><strong>方便</strong></p><blockquote><p>由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+ 树更加适合在区间查询的情况，所以通常 B+ 树用于数据库索引。</p></blockquote></li></ol><p>而红黑树这种结构，h 明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 事务</title>
      <link href="2019/06/02/MySQL-%E4%BA%8B%E5%8A%A1/"/>
      <url>2019/06/02/MySQL-%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>一个最小的不可再分的工作单元。通常一个事务对应一个完整的业务 (例如：银行账户转账业务，该业务就是一个最小的工作单元)。一个完整的业务需要批量的 DML (insert、update、delete) 语句共同联合完成。事务只和 DML 语句有关，或者说 DML 语句才有事务。这个和业务逻辑有关，业务逻辑不同，DML 语句的个数不同。</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>一个最小的不可再分的工作单元。通常一个事务对应一个完整的业务</strong></p><p>一个完整的业务需要批量的 DML (insert、update、delete) 语句共同联合完成。事务只和 DML 语句有关，或者说 DML 语句才有事务。这个和业务逻辑有关，业务逻辑不同，DML 语句的个数不同。</p><h2 id="事务并发问题"><a href="#事务并发问题" class="headerlink" title="事务并发问题"></a>事务并发问题</h2><ol><li><h5 id="更新丢失"><a href="#更新丢失" class="headerlink" title="更新丢失"></a>更新丢失</h5><p>当两个事务选择同一行，然后更新数据，由于每个事务都不知道其他事务的存在，就会发生丢失更新的问题。（你我同时读取同一行数据，进行修改，你 commit 之后我也 commit，那么我的结果将会覆盖掉你的结果）</p></li><li><h5 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h5><p>一个事务读取到了其他事务还没有提交的数据，就叫做脏读。[一个事务正在对一条记录做修改，在这个事务提交之前，别的事务读取到了这个事务修改之后的数据]</p></li><li><h5 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h5><p>一个事务读某条数据读两遍，读到的是不一样的数据，也就是说，一个事务在进行中读取到了其他事务对旧数据的修改结果。（比如说 我开一个事务 修改某条数据 先查后改执行修改动作的时候发现这条数据已经被别的事务删掉了）</p></li><li><h5 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h5><p>一个事务中，读取到了其他事务新增的数据，仿佛出现了幻象。幻读与不可重复读类似，不可重复读是读到了其他事务 <code>update/delete</code> 的结果，幻读是读到了其他事务 <code>insert</code> 的结果</p><blockquote><p>MySQL 中默认采用的是自动提交 autocommit 模式，在自动提交模式下，如果没有start transaction 显式地开始一个事务，那么每个 SQL 语句都会被当做一个事务执行提交操作。<br>通过如下方式，可以关闭 autocommit；需要注意的是，autocommit 参数是针对连接的，在一个连接中修改了参数，不会对其他连接产生影响。</p></blockquote></li></ol><hr><hr><h1 id="特征-ACID"><a href="#特征-ACID" class="headerlink" title="特征 [ACID]"></a>特征 [ACID]</h1><p>按照严格的标准，只有同时满足 ACID 特性才是事务；但是在各大数据库厂商的实现中，真正满足 ACID 的事务少之又少。例如 MySQL 的 NDB Cluster 事务不满足持久性和隔离性；InnoDB 默认事务隔离级别是可重复读，不满足隔离性；Oracle默认的事务隔离级别为 READ COMMITTED，不满足隔离性，因此与其说 ACID 是事务必须满足的条件，不如说它们是衡量事务的四个维度。</p><h3 id="原子性-A"><a href="#原子性-A" class="headerlink" title="原子性 [A]"></a>原子性 [A]</h3><p><strong>简介</strong></p><p><strong>整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。</strong><br><strong>事务在执行过程中发生错误，会被回滚 (Rollback) 到事务开始前的状态，就像这个事务从来没有执行过一样。</strong></p><hr><p><strong>实现原理</strong></p><p>实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的 SQL 语句。</p><p>undo log 回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的 SQL 语句</p><p>undo log 是逻辑日志。<strong>可以认为当 delete 一条记录时，undo log 中会记录一条对应的 insert 记录，反之亦然，当 update 一条记录时，它记录一条对应相反的 update 记录。</strong></p><p>例如</p><ul><li>当你 delete 一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert 这条旧数据</li><li>当你 update 一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行 update 操作</li><li>当年 insert 一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行 delete 操作</li></ul><p>undo log 记录了这些回滚需要的信息，当事务执行失败或调用了 rollback，导致事务需要回滚，便可以利用undo log 中的信息将数据回滚到修改之前的样子</p><p>当事务提交的时候，innodb 不会立即删除 undo log，因为后续还可能会用到 undo log，如隔离级别为repeatable read 时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除，即 undo log 不能删除。</p><p>但是在事务提交的时候，会将该事务对应的 undo log 放入到删除列表中，未来通过 purge 删除。并且提交事务时，还会判断 undo log 分配的页是否可以重用，如果可以重用，则会分配给后面来的事务，避免为每个独立的事务分配独立的 undo log 页而浪费存储空间和性能。</p><p>通过 undo log 记录 delete 和 update 操作的结果发现：(insert操作无需分析，就是插入行而已)</p><ul><li>delete操作实际上不会直接删除，而是将 delete 对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的。</li><li>update分为两种情况：update的列是否是主键列。<ul><li>如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。</li><li>如果是主键列，update分两部执行：先删除该行，再插入一行目标行。</li></ul></li></ul><hr><h3 id="隔离性-I"><a href="#隔离性-I" class="headerlink" title="隔离性 [I]"></a>隔离性 [I]</h3><p><strong>简介</strong></p><p>隔离状态执行事务，使它们好像是系统在给定时间内执行的唯一操作。如果有两个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一事务在系统中认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化或序列化请求，使得在同一时间仅有一个请求用于同一数据。</p><hr><p><strong>隔离级别</strong></p><p>为了解决多个事务并发会引发的问题，进行并发控制。SQL 标准中定义了四种隔离级别，并规定了每种隔离级别下上述几个问题是否存在。一般来说，隔离级别越低，系统开销越低，可支持的并发越高，但隔离性也越差</p><p><strong>读未提交： read uncommitted</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set session transaction isolation level READ UNCOMMITTED;</span><br></pre></td></tr></table></figure><p>在一个事务中，可以读取到其他事务未提交的数据变化，叫做脏读现象，在生产环境中切勿使用。这种隔离级别最低，这种级别一般是在理论上存在，数据库隔离级别一般都高于该级别。</p><p><strong>读已提交：read committed</strong></p><ul><li><p>概述</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set session transaction isolation level READ COMMITTED;</span><br></pre></td></tr></table></figure><p>在一个事务中，可以读取到其他事务已经提交的数据变化，这种读取也就叫做<strong>不可重复读</strong>，因为两次同样的查询可能会得到不一样的结果。</p></li><li><p>实现</p><ul><li><p>版本链 </p><p>对于使用 InnoDB 存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列（row_id 并不是必要的，我们创建的表中有主键或者非 NULL 唯一键时都不会包含 row_id 列）：</p><ul><li>trx_id：每次对某条记录进行改动时，都会把对应的事务 id 赋值给 trx_id 隐藏列。</li><li>roll_pointer：每次对某条记录进行改动时，这个隐藏列会存一个指针，可以通过这个指针找到该记录修改前的信息 </li></ul></li><li><p>ReadView</p><p>版本链中的哪个版本是当前事务可见的。ReadView 中主要包含4个比较重要的内容：</p></li><li><p>m_ids：表示在生成 ReadView 时当前系统中活跃的读写事务的事务 id 列表。</p><ul><li>min_trx_id：表示在生成 ReadView 时当前系统中活跃的读写事务中最小的事务id，也就是 m_ids 中的最小值。</li></ul></li><li><p>max_trx_id：表示生成 ReadView 时系统中应该分配给下一个事务的 id 值。</p><ul><li>creator_trx_id：表示生成该 ReadView 的事务的事务 id。</li></ul></li></ul></li></ul><p><strong>可重复读：repeatable read</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set session transaction isolation level REPEATABLE READ;</span><br></pre></td></tr></table></figure><p>MySQL 默认隔离级别，在一个事务中，直到事务结束前，都可以反复读取到事务刚开始时看到的数据，并一直不会发生变化，避免了脏读、不可重复读现象，但是它还是无法解决幻读问题。</p><p><strong>串行化：serializable</strong></p><p>这是最高的隔离级别，它强制事务串行执行，避免了前面说的幻读现象，简单来说，它会在读取的每一行数据上都加锁，所以可能会导致大量的超时和锁争用问题。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>(1) 隔离级别</strong></p><ol><li>READ UNCOMMITTED 隔离级别下，可能发生**”脏读”、”不可重复读”、”幻读”** 等问题。</li><li>READ COMMITTED 隔离级别下，可能发生 <strong>“不可重复读”</strong> 和 <strong>“幻读问题”**，但是不会发生 **”脏读”</strong> 问题。</li><li>REPEATABLE READ 隔离级别下, 可能发生 <strong>“幻读”</strong> 问题,不会发生 <strong>“脏读”</strong> 和 <strong>“不可重复读”</strong> 问题。</li><li>SERIALIZABLE 隔离级别下，各种问题都不会发生。</li></ol><p><font color='red'><strong>[注意]</strong>   这四种隔离级别是 SQL 的标准定义，不同的数据库会有不同的表现，特别需要注意的是 MySQL 在 REPEATABLE READ 隔离级别下，是可以禁止幻读问题的发生的。</font></p><p><strong>(2) MVCC</strong></p><p><strong>MVCC</strong>，全称 Multi-Version Concurrency Control，即多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。</p><hr><h3 id="持久性-D"><a href="#持久性-D" class="headerlink" title="持久性 [D]"></a>持久性 [D]</h3><p><strong>简介</strong></p><p>在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。</p><hr><p><strong>实现原理</strong></p><p>MySQL 是先把磁盘上的数据加载到内存中，在内存中对数据进行修改，再刷回磁盘上。如果此时突然宕机，内存中的数据就会丢失</p><p>在执行上面这条 sql 语句时，MySQL 会判断内存中有没有 user_id = 345981 的数据，没有，则去磁盘找到这条数据所在的「页」，把整页数据都加载到内存，然后找到 user_id = 345981 的 row 数据，把内存中这行数据的 age 设置为 18。</p><p>这时，内存的数据是新的、正确的，而磁盘数据是旧的、过时的，所以我们称这时的磁盘对应的页数据，为「脏页」。</p><p>这里补充一个知识点：<strong>MySQL 是按页为单位来读取数据的</strong>，一个页里面有很多行记录，从内存刷数据到磁盘，也是以页为单位来刷。</p><p>决定采用redo log解决上面的问题。当做数据修改的时候，不仅在内存中操作，还会在redo log中记录这次操作。当事务提交的时候，会将 redo log 日志进行刷盘(redo log一部分在内存中，一部分在磁盘上)。当数据库宕机重启的时候，会将 redo log 中的内容恢复到数据库中，再根据 undo log 和 binlog 内容决定回滚数据还是提交数据。</p><p>事务的持久性是由 redo log 和 undo log 一起实现，undo log 保存旧数据，redo log保存新数据，在事务提交时只需将redo log 落盘，持久化到磁盘上就可以。</p><blockquote><p>redo log 和 undo log 都属于 InnoDB 的事务日志。<br><code>InnoDB</code> 作为 MySQL 的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘IO，效率会很低。为此，<code>InnoDB</code> 提供了缓存(Buffer Pool)，Buffer Pool 中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从 Buffer Pool 中读取，如果 Buffer Pool 中没有，则从磁盘读取后放入 Buffer Pool；当向数据库写入数据时，会首先写入 Buffer Pool，Buffer Pool 中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）。</p></blockquote><p>Buffer Pool 的使用大大提高了读写数据的效率，但是也带了新的问题：如果 MySQL 宕机，而此时 Buffer Pool 中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。</p><p>redo log 被引入来解决这个问题：当数据修改时，除了修改 Buffer Pool 中的数据，还会在redo log 记录这次操作；当事务提交时，会对 redo log 进行刷盘。如果 MySQL 宕机，重启时可以读取 redo log 中的数据，对数据库进行恢复。redo log 采用的是 WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到 Buffer Pool，保证了数据不会因 MySQL 宕机而丢失，从而满足了持久性要求。</p><p>既然 <code>redo log</code> 也需要在事务提交时将日志写入磁盘，为什么它比直接将 <code>Buffer Pool</code> 中修改的数据写入磁盘(即刷脏)要快呢？主要有以下两方面的原因：</p><ol><li><p>刷脏是随机IO，因为每次修改的数据位置随机，但写 redo log 是追加操作，属于顺序IO。</p></li><li><p>刷脏是以数据页（Page）为单位的，MySQL 默认页大小是16KB，一个 Page 上一个小修改都要整页写入；而 redo log 中只包含真正需要写入的部分，无效IO大大减少。</p></li></ol><hr><h3 id="一致性-C"><a href="#一致性-C" class="headerlink" title="一致性 [C]"></a>一致性 [C]</h3><p><strong>简介</strong></p><p><strong>一致性是指事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。数据库的完整性约束包括但不限于：实体完整性（如行的主键存在且唯一）、列完整性（如字段的类型、大小、长度要符合要求）、外键约束、用户自定义完整性（如转账前后，两个账户余额的和应该不变）</strong><br><em>———————————————————————————————————————————————————————-</em></p><p>从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说 ACID 四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现 AID 三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。</p><h6 id="补充"><a href="#补充" class="headerlink" title=" [ 补充 ]"></a><font color = 'blue'> [ 补充 ]</font></h6><p>完整性约束：规定了什么样的数据能够存储到数据库系统当中。当写入的数据不满足当前的约束的时候，就不允许写入。防止错误数据的输入和输出造成错误结果和无效操作。<br>为了维护数据的完整性，数据库必须提供定义完整性约束条件的机制</p><ol><li>实体完整性约束 （行的完整性）：<br> 将一个实体区分，其中必须要有一个主键，能够唯一地标识对应的记录，其值不能为空。除了primary key约束之外，还可以通过索引、unique 约束或者 identity 属性等实现数据的实体完整性</li><li>域完整性约束（列完整性约束）<br> 指的是数据输入的有效性。通过数据类型来限制，格式是通过 check 约束和规则来限制可能的取值范围（通过check约束、default定义，not null）等。</li><li>参照完整性约束<br> 约束可以保证一个实体找到另外一个相关联的实体。通过定义外键（外码）与主键（主码）之间或外键与唯一键之间的对应关系实现</li><li>用户自定义完整性约束<br> 如转账前后，两个账户余额的和应该不变</li></ol><h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p>一致性是事务追求的最终目标，原子性、持久性和隔离性，都是为了保证数据库状态的一致性。此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。</p><p>实现一致性的措施包括：</p><ol><li>保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证</li><li>数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等</li><li>应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致</li></ol><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>在 RR 的隔离级别下，<code>Innodb</code> 使用 <code>MVVC</code> 和 <code>next-key locks</code> 解决幻读，<code>MVVC</code> 解决的是普通读（快照读）的幻读，<code>next-key locks</code> 解决的是当前读情况下的幻读。</p><p>所谓当前读，指的是加锁的 select, update, delete等语句。在 RR 的事务隔离级别下，数据库会使用next-key locks 来锁住本条记录以及索引区间。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> <span class="keyword">id</span> &gt;<span class="number">3</span> </span><br></pre></td></tr></table></figure><p>锁住的就是 id=3 这条记录以及 id&gt;3 这个区间范围，锁住索引记录之间的范围，避免范围间插入记录，以避免产生幻影行记录。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lambda 架构</title>
      <link href="2019/05/10/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%9E%B6%E6%9E%84-Lambda/"/>
      <url>2019/05/10/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%9E%B6%E6%9E%84-Lambda/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Lambda 架构是由 Storm 的作者 Nathan Marz 提出的一个实时大数据处理框架。Lambda 架构是其根据多年进行分布式大数据系统的经验总结提炼而成。Lambda 架构的目标是设计出一个能满足实时大数据系统关键特性的架构，包括有：高容错、低延时和可扩展等。Lambda 架构整合离线计算和实时计算，融合不可变性（Immunability），读写分离和复杂性隔离等一系列架构原则，可集成 Hadoop，Kafka，Storm，Spark，Hbase 等各类大数据组件。</p><a id="more"></a><h1 id="1-Lambda-架构"><a href="#1-Lambda-架构" class="headerlink" title="1. Lambda 架构"></a>1. Lambda 架构</h1><h2 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1. 简介"></a>1.1. 简介</h2><p>Lambda 架构是由 Storm 的作者 Nathan Marz 提出的一个实时大数据处理框架。Lambda 架构是其根据多年进行分布式大数据系统的经验总结提炼而成。Lambda 架构的目标是设计出一个能满足实时大数据系统关键特性的架构，包括有：高容错、低延时和可扩展等。Lambda 架构整合离线计算和实时计算，融合不可变性（Immunability），读写分离和复杂性隔离等一系列架构原则，可集成 Hadoop，Kafka，Storm，Spark，Hbase 等各类大数据组件。</p><p>数据从底层的数据源开始，经过各种各样的格式进入大数据平台，在大数据平台中经过Kafka、Flume等数据组件进行收集，然后分成两条线进行计算。一条线是进入流式计算平台（例如 Storm、Flink或者Spark Streaming），去计算实时的一些指标；另一条线进入批量数据处理离线计算平台（例如Mapreduce、Hive，Spark SQL），去计算T+1的相关业务指标，这些指标需要隔日才能看见。</p><h2 id="1-2-三层架构"><a href="#1-2-三层架构" class="headerlink" title="1.2. 三层架构"></a>1.2. 三层架构</h2><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2020-09-15 上午9.36.06.png" alt="截屏2020-09-15 上午9.36.06" style="zoom:40%;" /><h3 id="1-2-1-Batch-Layer-批处理层"><a href="#1-2-1-Batch-Layer-批处理层" class="headerlink" title="1.2.1. Batch Layer(批处理层)"></a>1.2.1. Batch Layer(批处理层)</h3><p>在全体数据集上在线运行查询函数得到结果的代价太大，同时处理查询时间过长，导致用户体验不好。如果预先在数据集上计算并保存预计算的结果，查询的时候直接返回预计算的结果，而无需重新进行复制耗时的计算。</p><p>batchview 是一个批处理过程，如采用 Hadoop 或 spark 支持的 map－reduce 方式。采用这种方式计算得到的每个view 都支持再次计算，且每次计算的结果都相同。</p><p>批处理层使用可处理大量数据的分布式处理系统预先计算结果。它通过处理所有的已有历史数据来实现数据的准确性。这意味着它是基于完整的数据集来重新计算的，能够修复任何错误，然后更新现有的数据视图。输出通常存储在只读数据库中，更新则完全取代现有的预先计算好的视图。</p><p>Batch Layer 的功能主要有两点：</p><ol><li>存储数据集</li><li>在数据集上预先计算查询函数，构建查询所对应的 View</li></ol><h3 id="1-2-2-Speed-Layer-速度处理层"><a href="#1-2-2-Speed-Layer-速度处理层" class="headerlink" title="1.2.2. Speed Layer(速度处理层)"></a>1.2.2. Speed Layer(速度处理层)</h3><p>Batch Layer可以很好的处理离线数据，但有很多场景数据不断实时生成，且需要实时查询处理。Speed Layer是用来处理增量的实时数据。</p><p>SpeedLayer 和 BatchLayer 比较类似，对数据进行计算并生成 RealtimeView，其主要的区别在于</p><ol><li>SpeedLayer 处理的数据是最近的增量数据流，BatchLayer 处理的是全体数据集</li><li>Speed<strong>Layer **为了效率，接收到新数据及时更新 Realtime</strong>View<strong>，而 Batch</strong>Layer** 根据全体离线数据直接得到Batch<strong>View</strong>。Speed**Layer **是一种增量计算，而非重新计算（recomputation）。</li><li>Speed<strong>Layer</strong>因为采用增量计算，所以延迟小，而 Batch<strong>Layer</strong> 是全数据集的计算，耗时比较长。</li></ol><p>速度层通过提供最新数据的实时视图来最小化延迟。速度层所生成的数据视图可能不如批处理层最终生成的视图那样准确或完整，但它们几乎在收到数据后立即可用。而当同样的数据在批处理层处理完成后，在速度层的数据就可以被替代掉了。</p><h3 id="1-2-3-Serving-Layer"><a href="#1-2-3-Serving-Layer" class="headerlink" title="1.2.3. Serving Layer"></a>1.2.3. Serving Layer</h3><p>Batch<strong>Layer</strong> 通过对 Master<strong>Dataset **执行查询获得 Batch</strong>View<strong>，</strong>Speed Layer <strong>通过增量计算提供 Realtime</strong>View<strong>。Lambda 架构的 Serving</strong>Layer <strong>用于响应用户的查询请求，合并 BatchView 和 Realtime View 中的结果数据集到最终的数据集。因此，Serving</strong>Layer **的职责包含：</p><ol><li>对 batch<strong>View **和 RealTime</strong>View **的随机访问</li><li>更新 Batch<strong>Veiw **和 RealTime</strong>View**，并负责结合两者的数据，对用户提供统一的接口</li></ol><h2 id="1-3-流程"><a href="#1-3-流程" class="headerlink" title="1.3. 流程"></a>1.3. 流程</h2><p>数据流进入系统后，同时发往 Batch Layer 和 Speed Layer 处理。Batch Layer 以不可变模型离线存储所有数据集，通过在全体数据集上不断重新计算构建查询所对应的 Batch Views。Speed Layer 处理增量的实时数据流，不断更新查询所对应的 Realtime Views。Serving Layer 响应用户的查询请求，合并 Batch View 和 Realtime View 中的结果数据集到最终的数据集。</p><h2 id="1-4-资料"><a href="#1-4-资料" class="headerlink" title="1.4. 资料"></a>1.4. 资料</h2><p>例如广告投放预测这种推荐系统一般都会用到 Lambda 架构。一般能做精准广告投放的公司都会拥有海量用户特征、用户历史浏览记录和网页类型分类这些历史数据的。业界比较流行的做法有在批处理层用 Alternating Least Squares (ALS) 算法，也就是 Collaborative Filtering 协同过滤算法，可以得出与用户特性一致其他用户感兴趣的广告类型，也可以得出和用户感兴趣类型的广告相似的广告，而用 k-means 也可以对客户感兴趣的广告类型进行分类。这里的结果是批处理层的结果。</p><p>在速度层中根据用户的实时浏览网页类型在之前分好类的广告中寻找一些top K的广告出来。最终服务层可以结合速度层的top K广告和批处理层中分类好的点击率高的相似广告，做出选择投放给用户。</p><h2 id="1-5-组件选型"><a href="#1-5-组件选型" class="headerlink" title="1.5. 组件选型"></a>1.5. 组件选型</h2><p>Lambda 架构中各组件在大数据生态系统中和阿里集团的常用组件。</p><p>数据流存储选用不可变日志的分布式系统 Kafka；BatchLayer 数据集的存储选用 Hadoop 的 HDFS；BatchView 的加工采用 MapReduce，Spark；BatchView 数据的存储采用 MySQL（查询少量的最近结果数据）、Hbase（查询大量的历史结果数据）。SpeedLayer 采用增量数据处理 Flink；RealtimeView 增量结果数据集采用内存数据库 Redis。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2020-09-14 下午4.40.45.png" alt="截屏2020-09-14 下午4.40.45" style="zoom:30%;" /><h1 id="2-实时处理系统架构"><a href="#2-实时处理系统架构" class="headerlink" title="2.实时处理系统架构"></a>2.实时处理系统架构</h1><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2020-09-14 下午4.35.49.png" alt="截屏2020-09-14 下午4.35.49" style="zoom:50%;" /><p>即从上面的架构中我们可以看出，其由下面的几部分构成：</p><ol><li>Flume 集群</li><li>Kafka 集群</li><li>Flink 集群</li></ol><h3 id="2-1-1-Flume-集群"><a href="#2-1-1-Flume-集群" class="headerlink" title="2.1.1. Flume 集群"></a>2.1.1. Flume 集群</h3><p>Flume 的基本架构是 Agent。它是一个完整的数据收集工具，含有三个核心组件，分别是 Source、Channel、Sink。数据以Event为基本单位经过Source、Channel、Sink，从外部数据源来，向外部的目的地去。</p><h3 id="2-1-2-Kafka-集群"><a href="#2-1-2-Kafka-集群" class="headerlink" title="2.1.2. Kafka 集群"></a>2.1.2. Kafka 集群</h3><p>Kafka 是一个分布式的、可分区的、可复制的消息系统，维护消息队列。</p><p>Kafka 的整体架构非常简单，是显式分布式架构，Producer、Broker 和 Consumer 都可以有多个。Producer，consumer 实现 Kafka 注册的接口，数据从 Producer 发送到 Broker，Broker 承担一个中间缓存和分发的作用。Broker 分发注册到系统中的 Consumer。Broker 的作用类似于缓存，即活跃的数据和离线处理系统之间的缓存。客户端和服务器端的通信，是基于简单、高性能、且与编程语言无关的TCP协议。</p><h3 id="2-1-3-Flink-集群"><a href="#2-1-3-Flink-集群" class="headerlink" title="2.1.3. Flink 集群"></a>2.1.3. Flink 集群</h3><p>Flink 核心是一个流式的数据流执行引擎，其针对数据流的分布式计算提供了数据分布、数据通信以及容错机制等功能。基于流执行引擎，Flink 提供了诸多更高抽象层的 API 以便用户编写分布式任</p><h2 id="3-2-离线处理系统架构"><a href="#3-2-离线处理系统架构" class="headerlink" title="3.2. 离线处理系统架构"></a>3.2. 离线处理系统架构</h2><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2020-09-15 下午3.35.45.png" alt="截屏2020-09-15 下午3.35.45" style="zoom:50%;" /><h1 id="4-Lambda-架构不足"><a href="#4-Lambda-架构不足" class="headerlink" title="4.Lambda 架构不足"></a>4.Lambda 架构不足</h1><p>虽然 Lambda 架构使用起来灵活，并且可以适用于很多的应用场景，但在实际应用的时候，Lambda 架构也存在着一些不足，主要表现在它的维护很复杂。</p><p>维护 Lambda 架构的复杂性在于我们要同时维护两套系统架构：批处理层和速度层，在架构中加入批处理层是因为从批处理层得到的结果具有高准确性，而加入速度层是因为它在处理大规模数据时具有低延时性。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Kappa 架构</title>
      <link href="2019/05/10/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%9E%B6%E6%9E%84-Kappa/"/>
      <url>2019/05/10/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%9E%B6%E6%9E%84-Kappa/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>虽然 Lambda 架构使用起来十分灵活，并且可以适用于很多的应用场景，但在实际应用的时候，Lambda 架构也存在着一些不足，主要表现在它的维护很复杂。使用 Lambda 架构时，架构师需要维护两个复杂的分布式系统，并且保证他们逻辑上产生相同的结果输出到服务层中。</p><a id="more"></a><h1 id="1-Kappa-架构"><a href="#1-Kappa-架构" class="headerlink" title="1. Kappa 架构"></a>1. Kappa 架构</h1><p>Kappa 架构是由 LinkedIn 的前首席工程师杰伊·克雷普斯（Jay Kreps）提出的一种架构思想。</p><p>像 Apache Kafka 这样的流处理平台是具有永久保存数据日志的功能的，通过平台的这一特性，我们可以重新处理部署于速度层架构中的历史数据。</p><p>与 Lambda 架构不同的是，Kappa 架构去掉了批处理层这一体系结构，而只保留了速度层。你只需要在业务逻辑改变又或者是代码更改的时候进行数据的重新处理。</p><p>Kappa 架构的核心思想包括以下三点：</p><ol><li>用 Kafka 或者类似的分布式队列系统保存数据，你需要几天的数据量就保存几天。</li><li>当需要全量重新计算时，重新起一个流计算实例，从头开始读取数据进行处理，并输出到一个新的结果存储中。</li><li>当新的实例做完后，停止老的流计算实例，并把老的一些结果删除。</li></ol><p>和 Lambda 架构相比，在 Kappa 架构下，只有在有必要的时候才会对历史数据进行重复计算，并且实时计算和批处理过程使用的是同一份代码。或许有些人会质疑流式处理对于历史数据的高吞吐量会力不从心，但是这可以通过控制新实例的并发数进行改善。</p><p>上面架构图中，新老实例使用了各自的结果存储，这便于随时进行回滚，更进一步，假如我们产出的是一些算法模型之类的数据，用户还可以同时对新老两份数据进行效果验证，做一些A/B test或者使用bandit算法来最大限度的使用这些数据。</p><h1 id="2-Kappa-选型"><a href="#2-Kappa-选型" class="headerlink" title="2. Kappa 选型"></a>2. Kappa 选型</h1><h1 id="3-Kappa-实现"><a href="#3-Kappa-实现" class="headerlink" title="3. Kappa 实现"></a>3. Kappa 实现</h1><p>Apache Kafka 这样的流处理平台是具有永久保存数据日志的功能的。通过平台这一特性，我们可以重新处理部署速度层架构的历史数据了。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2020-09-15 上午9.31.26.png" alt="截屏2020-09-15 上午9.31.26" style="zoom:50%;" /><ol><li><p>第一步。部署 Apache Kafka，并设置数据日志的保留期。这里的保留期指的是希望能够重新处理的历史数据的时间区间。</p><p>例如，你希望重新处理最多一年的历史数据，那就可以把 Apache Kafka 中的保留期设置为 365 天。如果你希望能够处理所有的历史数据，那就可以把 Apache Kafka 中的保留期设置成“永久”。</p></li><li><p>第二步。如果我们需要改进现有的逻辑算法，那就表示需要对历史数据进行重新处理。</p><p>重新启动一个 Apache Kafka 作业实例。这个作业实例将重头开始，重新计算保留好的历史数据，并将结果输出到一个新的数据视图中，Apache Kafka 的底层是使用 Log Offset 来判断现在已经处理到哪个数据块了，所以只需要把 Log Offset 参数设置成0，新的作业实例就会重头开始处理历史数据。</p></li><li><p>第三步。当这个新的数据视图处理过的数据进度赶上了旧的数据视图时，我们的应用便可以切换到新的数据视图中读取。</p></li><li><p>第四步。停止旧版本的作业实例，并删除旧的数据视图。</p></li></ol><h1 id="4-Kappa-总结"><a href="#4-Kappa-总结" class="headerlink" title="4. Kappa 总结"></a>4. Kappa 总结</h1><p>因为 Kappa 架构只保留了速度层而缺少批处理层，在速度层上处理大规模数据可能会有数据更新出错的情况发生，这就需要花费更多的时间在处理这些错误异常上面。</p><p>还有一点，Kappa 架构的批处理和流处理都放在了速度层上，这导致了这种架构是使用同一套代码来处理算法逻辑的。所以 Kappa 架构并不适用于批处理和流处理代码逻辑不一致的场景。</p><p>1、消息中间件缓存的数据量和回溯数据有性能瓶颈。通常算法需要过去180天的数据，如果都存在消息中间件，无疑有非常大的压力。同时，一次性回溯订正 180 天级别的数据，对实时计算的资源消耗也非常大。</p><p>2、在实时数据处理时，遇到大量不同的实时流进行关联时，非常依赖实时计算系统的能力，很可能因为数据流先后顺序问题，导致数据丢失。</p><p>如果你所面对的业务逻辑是设计一种稳健的机器学习模型来预测即将发生的事情，那么你应该优先考虑使用 Lambda 架构，因为它拥有批处理层和速度层来确保更少的错误。</p><p>如果你所面对的业务逻辑是希望实时性比较高，而且客户端又是根据运行时发生的实时事件来做出回应的，那么你就应该优先考虑使用 Kappa 架构。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Kafka 消息有序</title>
      <link href="2019/04/15/Flink-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/Kafka%20%E6%B6%88%E6%81%AF%E6%9C%89%E5%BA%8F/"/>
      <url>2019/04/15/Flink-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/Kafka%20%E6%B6%88%E6%81%AF%E6%9C%89%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Kafka 消息不丢失</title>
      <link href="2019/04/12/Flink-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/Kafka%20%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/"/>
      <url>2019/04/12/Flink-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/Kafka%20%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>生产者，Broker，消费者都是有可能丢数据的</strong></p><a id="more"></a><h3 id="生产端"><a href="#生产端" class="headerlink" title="生产端"></a><strong>生产端</strong></h3><p>生产者丢数据，即发送的数据根本没有保存到 Broker 端。出现这个情况的原因可能是，网络抖动，导致消息压根就没有发送到 Broker 端；也可能是消息本身不合格导致 Broker 拒绝接收（比如消息太大了，超过了 Broker 的承受能力）等等。</p><p>上面所说比如网络原因导致消息没有成功发送到 broker 端，常见，也并不可怕。可怕的不是没发送成功，而是发送失败了你不做任何处理。</p><p>很简单的一个<strong>重试配置</strong>，基本就可以解决这种网络瞬时抖动问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(<span class="string">&quot;retries&quot;</span>, <span class="number">10</span>);</span><br></pre></td></tr></table></figure><p>当然还有很多其他原因导致的，不能只依靠 kafka 的配置来做处理，我们看一下 kafka 发送端的源码，其实人家是提供了两个方法的，通常会出问题的方法是那个简单的 send，没有 callback（回调）。简单的 send发送后不会去管它的结果是否成功，而 callback 能准确地告诉你消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。</p><p><font color='red'><strong>因此，一定要使用带有回调通知的 send 方法。</strong></font></p><p>我们知道，broker 一般不会有一个，我们就是要通过多 Broker 达到高可用的效果，所以对于生产者程序来说，也不能简单的认为发送到一台就算成功，如果只满足于一台，那台机器如果损坏了，那消息必然会丢失。设置 <strong>acks = all</strong>，表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”，这样可以达到高可用的效果。</p><h3 id="Broker-端"><a href="#Broker-端" class="headerlink" title="Broker 端"></a><strong>Broker 端</strong></h3><p>数据已经保存在 broker 端，但是数据却丢失了。出现这个的原因可能是，Broker 机器 down 了，当然broker 是高可用的，假如你的消息保存在 N 个 Kafka Broker 上，那么至少有 1 个存活就不会丢。</p><h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><ol><li><h5 id="消息冗余"><a href="#消息冗余" class="headerlink" title="消息冗余"></a><font color='blue'>消息冗余</font></h5><p>前面我们说到，kafka 是有限度的保证消息不丢失，这里的限度，指至少要有一台 broker 可以正常提供服务。至少一台，这种说法可并不准确，应该说至少一台存储了你消息的的 broker。我们知道分区可以设置副本数，假如你只设置副本为1，只要挂的刚好是你副本的那台，即使你有1000台broker，也无济于事。</p><p>因此，副本的设置尤为重要，一般设置 <strong><code>replication.factor &gt;= 3</code>**，毕竟目前</strong>防止消息丢失的主要机制就是冗余**。</p><p>但仅仅设置副本数就有用吗？并不能保证 broker 端一定存储了三个副本呀。假如共有三个broker，发送一条消息的时候，某个 broker 刚好宕机了，即使你配置了<code>replication.factor = 3</code>，也最多只会有2台副本。因此，我们还要确认，至少要被写入到多少个副本才算是“已提交”。</p><p><strong><code>min.insync.replicas &gt; 1</code></strong> <strong>,</strong> 控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。</p><p>说到这，可能会有疑问，上面生产端不是已经配置 <code>acks=all</code>了，和这个参数不是冲突了吗？？注意 <code>acks = all</code> 是针对所有副本 Broker 都要接收到消息，假如 ISR中只有1个副本了，<code>acks=all</code> 也就相当于 <code>acks=1</code> 了，引入 <code>min.insync.replicas</code> 的目的就是为了做一个下限的限制，不能只满足于 <code>ISR</code> 全部写入，还要保证ISR 中的写入个数不少于 <code>min.insync.replicas</code>。</p><p>对了，请确保 <strong>replication.factor &gt; min.insync.replicas</strong>。一般设置为<strong>replication.factor = min.insync.replicas + 1</strong>。如果两者相等，有一个副本挂机，整个分区就无法正常工作了。我们不仅要考虑消息的可靠性，防止消息丢失，更应该考虑可用性问题。</p></li><li><h5 id="leader-选举"><a href="#leader-选举" class="headerlink" title="leader 选举"></a><strong><font color='blue'>leader 选举</font></strong></h5><p>我们知道kafka中有领导者副本（Leader Replica）和追随者副本（Follower Replica），而follower replica存在的唯一目的就是防止消息丢失，并不参与具体的业务逻辑的交互。只有leader 才参与服务，follower的作用就是充当leader的候补，平时的操作也只有信息同步。ISR也就是这组与leader保持同步的replica集合，我们要保证不丢消息，首先要保证ISR的存活（至少有一个备份存活），那存活的概念是什么呢，不仅需要机器正常，还需要跟上leader的消息进度，当达到一定程度的时候就会认为“非存活”状态。</p><p>假设这么一种场景，有Leader,Follow1,Follow2；其中Follow2落后于Leader太多，因此不在leader副本和follower1副本所在的ISR集合之中。此时Leader,Follow1都宕机了，只剩下Follow2了，Follow2还在，就会进行新的选举，不过在选举之前首先要判断<strong>unclean.leader.election.enable</strong>参数的值。如果<strong>unclean.leader.election.enable参数的值为false，那么就意味着非ISR中的副本不能够参与选举</strong>，此时无法进行新的选举，此时整个分区处于不可用状态。如果unclean.leader.election.enable参数的值为true，那么可以从非ISR集合中选举follower副本称为新的leader。如果让非ISR中的Follow2成为Leader会有什么后果呢？</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/W801CaTfHvWaFrR74ZUdpjXa1bibaWGJVvpGEwX6kTcN6iciaB3UxYQKpMIpjBN3zyt68JGdxvapgicBSUevcbkvQg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="img"></p><p>我们说Follow2已经落后之前的Leader很多，他成为新的Leader后从客户端继续收取消息，此时，原来的leader副本恢复，成为了新的follower副本，准备向新的leader副本同步消息，但是它发现自身的LEO（LEO是Log End Offset的缩写，它表示了当前日志文件中下一条待写入消息的offset）比leader副本的LEO还要大。Kafka中有一个准则，follower副本的LEO是不能够大于leader副本的，所以新的follower副本就需要截断日志至leader副本的LEO处，截断日志，不就丢失了之前的消息吗？即图中所示，丢失了3和4两条数据，并且新的Follow和新Leader之间的消息也不一致。</p></li></ol><p>   因此，如果要保证消息不丢失，需设置：</p><p>   <strong>unclean.leader.election.enable=false</strong>，但是Kafka的可用性就会降低，具体怎么选择需要读者根据实际的业务逻辑进行权衡，可靠性优先还是可用性优先。从Kafka 0.11.0.0版本开始将此参数从true设置为false，可以看出Kafka的设计者偏向于可靠性。</p><h3 id="消费端丢数据"><a href="#消费端丢数据" class="headerlink" title="消费端丢数据"></a><strong>消费端丢数据</strong></h3><p>Consumer 程序有个“位移”的概念，表示的是这个 Consumer 当前消费到的 Topic 分区的位置。Kafka默认是自动提交位移的，这样可能会有个问题，假如你在pull(拉取)30条数据，处理到第20条时自动提交了offset，但是在处理21条的时候出现了异常，当你再次pull数据时，由于之前是自动提交的offset，所以是从30条之后开始拉取数据，这也就意味着21-30条的数据发生了丢失。</p><p>消费端保证不丢数据，最重要就是保证offset的准确性。我们能做的，就是确保消息消费完成再提交。Consumer 端有个参数 ，设置 <strong>enable.auto.commit=</strong> <strong>false</strong>， 并且采用手动提交位移的方式。如果在处理数据时发生了异常，那就把当前处理失败的offset进行提交(放在finally代码块中)注意一定要确保offset的正确性，当下次再次消费的时候就可以从提交的offset处进行再次消费。consumer在处理数据的时候失败了，其实可以把这条数据给缓存起来，可以是redis、DB、file等，也可以把这条消息存入专门用于存储失败消息的topic中，让其它的consumer专门处理失败的消息。</p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 事务</title>
      <link href="2019/03/25/MySQL%E4%BA%8B%E5%8A%A1/"/>
      <url>2019/03/25/MySQL%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>一个最小的不可再分的工作单元。通常一个事务对应一个完整的业务 (例如：银行账户转账业务，该业务就是一个最小的工作单元)。一个完整的业务需要批量的 DML (insert、update、delete) 语句共同联合完成。事务只和 DML 语句有关，或者说 DML 语句才有事务。这个和业务逻辑有关，业务逻辑不同，DML 语句的个数不同。</p><a id="more"></a><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现</p><hr><hr><h2 id="2-事务并发问题"><a href="#2-事务并发问题" class="headerlink" title="2. 事务并发问题"></a>2. 事务并发问题</h2><p>MySQL 中默认采用的是自动提交(autocommit)模式，在自动提交模式下，如果没有 start transaction 显式地开始一个事务，那么每个 sql 语句都会被当做一个事务执行提交操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;%autocommit%&#39;;</span><br><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| autocommit    | OFF   |</span><br><span class="line">+---------------+-------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>可以关闭 autocommit; 需要注意的是, autocommit 参数是针对连接的，在一个连接中修改了参数，不会对其他连接产生影响。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global autocommit&#x3D;1;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><ol><li>更新丢失<br> 当两个事务选择同一行，然后更新数据，由于每个事务都不知道其他事务的存在，就会发生丢失更新的问题。（你我同时读取同一行数据，进行修改，你 commit 之后我也 commit，那么我的结果将会覆盖掉你的结果）</li><li>脏读<br> 一个事务读取到了其他事务还没有提交的数据，就叫做脏读。[一个事务正在对一条记录做修改，在这个事务提交之前，别的事务读取到了这个事务修改之后的数据]</li><li>不可重复读<br> 一个事务读某条数据读两遍，读到的是不一样的数据，也就是说，一个事务在进行中读取到了其他事务对旧数据的修改结果。（比如说 我开一个事务 修改某条数据 先查后改执行修改动作的时候发现这条数据已经被别的事务删掉了）</li><li>幻读<br> 一个事务中，读取到了其他事务新增的数据，仿佛出现了幻象。(幻读与不可重复读类似，不可重复读是读到了其他事务update/delete 的结果，幻读是读到了其他事务 insert 的结果)</li></ol><blockquote><h5 id="注意：-幻读和不可重复读的区别？"><a href="#注意：-幻读和不可重复读的区别？" class="headerlink" title="注意： 幻读和不可重复读的区别？"></a><font color='red'>注意： 幻读和不可重复读的区别？</font></h5><p>不可重复读的重点是修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）。</p><p>幻读的重点在于新增或者删除：在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除）。</p></blockquote><hr><hr><h2 id="3-特征-ACID"><a href="#3-特征-ACID" class="headerlink" title="3. 特征 (ACID)"></a>3. 特征 (ACID)</h2><p>按照严格的标准，只有同时满足 ACID 特性才是事务；但是在各大数据库厂商的实现中，真正满足 ACID 的事务少之又少。例如 MySQL 的 NDB Cluster 事务不满足持久性和隔离性；InnoDB 默认事务隔离级别是可重复读，不满足隔离性；Oracle默认的事务隔离级别为READ COMMITTED，不满足隔离性，因此与其说 ACID 是事务必须满足的条件，不如说它们是衡量事务的四个维度。</p><h3 id="3-1-原子性-A"><a href="#3-1-原子性-A" class="headerlink" title="3.1. 原子性 [A]"></a>3.1. 原子性 [A]</h3><h4 id="3-1-1-简介"><a href="#3-1-1-简介" class="headerlink" title="3.1.1. 简介"></a>3.1.1. 简介</h4><p>整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。<br>事务在执行过程中发生错误，会被回滚 (Rollback) 到事务开始前的状态，就像这个事务从来没有执行过一样。</p><h4 id="3-1-2-实现原理"><a href="#3-1-2-实现原理" class="headerlink" title="3.1.2. 实现原理"></a>3.1.2. 实现原理</h4><p>实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的sql语句。InnoDB 实现回滚，靠的是 <code>undo log</code>：当事务对数据库进行修改时，InnoDB 会生成对应的 undo log; 如果事务执行失败或调用了 rollback ，导致事务需要回滚，便可以利用 undo log 中的信息将数据回滚到修改之前的样子。</p><p><font color='red'>**[注意 ]**undo log 属于逻辑日志，它记录的是 sql 执行相关的信息。当发生回滚时，InnoDB 会根据 undo log 的内容做与之前相反的工作: 对于每个 insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。</font></p><h4 id="3-1-3-学习示例"><a href="#3-1-3-学习示例" class="headerlink" title="3.1.3. 学习示例"></a>3.1.3. 学习示例</h4><p>以update操作为例：当事务执行update时，其生成的undo log中会包含被修改行的主键(以便知道修改了哪些行)、修改了哪些列、这些列在修改前后的值等信息，回滚时便可以使用这些信息将数据还原到 update 之前的状态。</p><hr><h3 id="3-2-隔离性-I"><a href="#3-2-隔离性-I" class="headerlink" title="3.2. 隔离性 [I]"></a>3.2. 隔离性 [I]</h3><h4 id="3-2-1-简介"><a href="#3-2-1-简介" class="headerlink" title="3.2.1. 简介"></a>3.2.1. 简介</h4><blockquote><p>隔离状态执行事务，使它们好像是系统在给定时间内执行的唯一操作。如果有两个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一事务在系统中认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化或序列化请求，使得在同一时间仅有一个请求用于同一数据。</p></blockquote><h4 id="3-2-2-隔离级别"><a href="#3-2-2-隔离级别" class="headerlink" title="3.2.2. 隔离级别"></a>3.2.2. 隔离级别</h4><p>为了解决多个事务并发会引发的问题，进行并发控制。SQL 标准中定义了四种隔离级别，并规定了每种隔离级别下上述几个问题是否存在。一般来说，隔离级别越低，系统开销越低，可支持的并发越高，但隔离性也越差</p><h5 id="1-读未提交：-read"><a href="#1-读未提交：-read" class="headerlink" title="(1) 读未提交： read"></a>(1) 读未提交： read</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set session transaction isolation level READ UNCOMMITTED;</span><br></pre></td></tr></table></figure><p>在一个事务中，可以读取到其他事务未提交的数据变化，这种读取其他会话还没提交的事务，叫做脏读现象，在生产环境中切勿使用。这种隔离级别最低，这种级别一般是在理论上存在，数据库隔离级别一般都高于该级别。</p><h5 id="2-读已提交：read-committed"><a href="#2-读已提交：read-committed" class="headerlink" title="(2) 读已提交：read committed"></a>(2) 读已提交：read committed</h5><ul><li><p>概述</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set session transaction isolation level READ COMMITTED;</span><br></pre></td></tr></table></figure><p>在一个事务中，可以读取到其他事务已经提交的数据变化，这种读取也就叫做<strong>不可重复读</strong>，因为两次同样的查询可能会得到不一样的结果。</p></li><li><p>实现</p><ul><li><p>版本链 </p><p>对于使用 InnoDB 存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列（row_id 并不是必要的，我们创建的表中有主键或者非 NULL 唯一键时都不会包含 row_id 列）：</p><ul><li>trx_id：每次对某条记录进行改动时，都会把对应的事务 id 赋值给 trx_id 隐藏列。</li><li>roll_pointer：每次对某条记录进行改动时，这个隐藏列会存一个指针，可以通过这个指针找到该记录修改前的信息 </li></ul></li><li><p>ReadView</p><p>版本链中的哪个版本是当前事务可见的。ReadView 中主要包含4个比较重要的内容：</p></li><li><p>m_ids：表示在生成 ReadView 时当前系统中活跃的读写事务的事务 id 列表。</p><ul><li>min_trx_id：表示在生成 ReadView 时当前系统中活跃的读写事务中最小的事务id，也就是 m_ids 中的最小值。</li></ul></li><li><p>max_trx_id：表示生成 ReadView 时系统中应该分配给下一个事务的 id 值。</p><ul><li>creator_trx_id：表示生成该 ReadView 的事务的事务 id。</li></ul></li></ul></li></ul><h5 id="3-可重复读：repeatable-read"><a href="#3-可重复读：repeatable-read" class="headerlink" title="(3) 可重复读：repeatable read"></a>(3) 可重复读：repeatable read</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set session transaction isolation level REPEATABLE READ;</span><br></pre></td></tr></table></figure><p>MySQL 默认隔离级别，在一个事务中，直到事务结束前，都可以反复读取到事务刚开始时看到的数据，并一直不会发生变化，避免了脏读、不可重复读现象，但是它还是无法解决幻读问题。</p><h5 id="4-串行化：serializable"><a href="#4-串行化：serializable" class="headerlink" title="(4) 串行化：serializable"></a>(4) 串行化：serializable</h5><p>这是最高的隔离级别，它强制事务串行执行，避免了前面说的幻读现象，简单来说，它会在读取的每一行数据上都加锁，所以可能会导致大量的超时和锁争用问题。</p><h3 id="3-2-3-总结"><a href="#3-2-3-总结" class="headerlink" title="3.2.3. 总结"></a>3.2.3. 总结</h3><p><strong>(1) 隔离级别</strong></p><ul><li>READ UNCOMMITTED 隔离级别下，可能发生**”脏读”、”不可重复读”、”幻读”** 等问题。</li><li>READ COMMITTED 隔离级别下，可能发生 <strong>“不可重复读”</strong> 和 <strong>“幻读问题”**，但是不会发生 **”脏读”</strong> 问题。</li><li>REPEATABLE READ 隔离级别下, 可能发生 <strong>“幻读”</strong> 问题,不会发生 <strong>“脏读”</strong> 和 <strong>“不可重复读”</strong> 问题。</li><li>SERIALIZABLE 隔离级别下，各种问题都不会发生。</li></ul><p><font color='red'><strong>[注意]</strong>   这四种隔离级别是 SQL 的标准定义，不同的数据库会有不同的表现，特别需要注意的是 MySQL 在 REPEATABLE READ 隔离级别下，是可以禁止幻读问题的发生的。</font></p><p><strong>(2) MVCC</strong></p><p><strong>MVCC</strong>，全称 Multi-Version Concurrency Control，即多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。</p><hr><h3 id="3-3-持久性-D"><a href="#3-3-持久性-D" class="headerlink" title="3.3. 持久性 [D]"></a>3.3. 持久性 [D]</h3><h4 id="3-3-1-简介"><a href="#3-3-1-简介" class="headerlink" title="3.3.1. 简介"></a>3.3.1. 简介</h4><p>在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。</p><h4 id="3-3-2-实现原理"><a href="#3-3-2-实现原理" class="headerlink" title="3.3.2. 实现原理"></a>3.3.2. 实现原理</h4><p><del>redo log和undo log都属于InnoDB的事务日志。下面先聊一下redo log存在的背景。</del><br><code>InnoDB</code> 作为 MySQL 的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘 IO，效率会很低。为此，<code>InnoDB</code> 提供了缓存(Buffer Pool)，<code>Buffer Pool</code> 中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从 <code>Buffer Pool</code> 中读取，如果 <code>Buffer Pool</code> 中没有，则从磁盘读取后放入 <code>Buffer Pool</code>；当向数据库写入数据时，会首先写入 <code>Buffer Pool</code>，<code>Buffer Pool</code> 中修改的数据会定期刷新到磁盘中(这一过程称为刷脏)。</p><p><code>Buffer Pool</code> 的使用大大提高了读写数据的效率，但是也带了新的问题：如果 MySQL 宕机，而此时 <code>Buffer Pool</code> 中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。</p><p>redo log 被引入来解决这个问题：当数据修改时，除了修改 Buffer Pool 中的数据，还会在 redo log 记录这次操作；当事务提交时，会调用 fsync 接口对 redo log 进行刷盘。如果 MySQL 宕机，重启时可以读取 redo log 中的数据，对数据库进行恢复。redo log 采用的是 WAL(Write-ahead logging，预写式日志)，所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因 MySQL 宕机而丢失，从而满足了持久性要求。</p><blockquote><p><strong><font color='blue'>既然 redo log 也需要在事务提交时将日志写入磁盘，为什么比直接将 Buffer Pool 中修改的数据写入磁盘(即刷脏)要快呢？</font></strong></p></blockquote><blockquote><ul><li>刷脏是随机IO，因为每次修改的数据位置随机，但写 redo log 是追加操作，属于顺序IO。</li></ul></blockquote><blockquote><ul><li>刷脏是以数据页(Page)为单位的，MySQL 默认页大小是16KB，一个 Page 上一个小修改都要整页写入；而redo log 中只包含真正需要写入的部分，无效 IO 大大减少。</li></ul></blockquote><hr><h3 id="3-4-一致性-C"><a href="#3-4-一致性-C" class="headerlink" title="3.4. 一致性 [C]"></a>3.4. 一致性 [C]</h3><h4 id="3-4-1-简介"><a href="#3-4-1-简介" class="headerlink" title="3.4.1. 简介"></a>3.4.1. 简介</h4><p>一致性是指事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。数据库的完整性约束包括但不限于：实体完整性（如行的主键存在且唯一）、列完整性（如字段的类型、大小、长度要符合要求）、外键约束、用户自定义完整性（如转账前后，两个账户余额的和应该不变）。<br>*———————————————————————————————————————————————————————-*</p><h6 id="补充"><a href="#补充" class="headerlink" title=" [ 补充 ]"></a><font color = 'blue'> [ 补充 ]</font></h6><p>完整性约束：规定了什么样的数据能够存储到数据库系统当中。当写入的数据不满足当前的约束的时候，就不允许写入。防止错误数据的输入和输出造成错误结果和无效操作。<br>为了维护数据的完整性，数据库必须提供定义完整性约束条件的机制</p><ul><li>实体完整性约束 (行的完整性)<br>将一个实体区分，其中必须要有一个主键，能够唯一地标识对应的记录，其值不能为空。除了 primary key 约束之外，还可以通过索引、unique 约束或者 identity 属性等实现数据的实体完整性</li><li>域完整性约束(列完整性约束)<br>指的是数据输入的有效性。<br>通过数据类型来限制，格式是通过check约束和规则来限制可能的取值范围(通过check约束、default定义，not null)等。</li><li>参照完整性约束<br>约束可以保证一个实体找到另外一个相关联的实体。通过定义外键与主键之间或外键与唯一键之间的对应关系实现</li><li>用户自定义完整性约束<br>如转账前后，两个账户余额的和应该不变<h4 id="3-4-2-实现原理"><a href="#3-4-2-实现原理" class="headerlink" title="3.4.2. 实现原理"></a>3.4.2. 实现原理</h4>一致性是事务追求的最终目标，原子性、持久性和隔离性，都是为了保证数据库状态的一致性。此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。</li></ul><p>实现一致性的措施包括：</p><ul><li>保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证</li><li>数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等</li><li>应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致</li></ul>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>频繁项集挖掘（二）FP-Growth算法</title>
      <link href="2019/03/17/14_FP-Growth%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
      <url>2019/03/17/14_FP-Growth%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="频繁项集挖掘（二）FP-Growth算法"><a href="#频繁项集挖掘（二）FP-Growth算法" class="headerlink" title="频繁项集挖掘（二）FP-Growth算法"></a>频繁项集挖掘（二）FP-Growth算法</h2><p>FP-Growth（Frequent Patterns）相比于Apriori是一种更加有效的频繁项集挖掘算法，FP-Growth算法只需要对数据库进行两次扫描，而Apriori算法对于每次产生的候选项集都会扫描一次数据集来判断是否频繁，因此当数据量特别巨大，且扫描数据库的成本比较高时，FP-Growth的速度要比Apriori快。</p><p>但是FP-Growth只能用于发现频繁项集，不能用于发现关联规则。</p><h4 id="FP-Growth原理分析"><a href="#FP-Growth原理分析" class="headerlink" title="FP-Growth原理分析"></a>FP-Growth原理分析</h4><p>FP-Growth算法实现步骤</p><ul><li>构建FP树</li><li>从FP树中挖掘频繁项集</li></ul><p>FP-Growth算法将数据存储在一种被称为FP树的紧凑数据结构中。</p><p><img src="/img/fp-growth2.png"></p><p>下图就是利用上面的数据构建的一棵FP树（最小支持度为3）：</p><p><img src="/img/fp-growth1.png"></p><ul><li>FP树中最小支持度指项集总共出现的次数</li><li>一个元素项可以在一棵FP树中出现多次</li><li>FP树存储项集的出现频率，且每个项集会以路径的方式存储在树中</li><li>存在相似元素的集合会共享树的一部分</li><li>只有当集合之间完全不同时，树才会分叉</li><li>树节点上给出集合中的单个元素及其在序列中的出现次数，路径会给出该序列的出现次数</li></ul><p>FP-Growth算法工作流程：</p><ul><li>扫描数据集两遍</li><li>第一遍对所有元素项的出现次数进行计数</li><li>根据前面的结论，如果某元素是不频繁的，那么包含该元素的超集也是不频繁的</li><li>第二遍扫描，只考虑那些频繁元素，并且第二遍扫描开始构建FP树</li></ul><h4 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">treeNode</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, nameValue, numOccur, parentNode</span>):</span></span><br><span class="line">        <span class="comment"># 节点名称</span></span><br><span class="line">        self.name = nameValue</span><br><span class="line">        <span class="comment"># 节点计数</span></span><br><span class="line">        self.count = numOccur</span><br><span class="line">        <span class="comment"># 记录相似的元素项</span></span><br><span class="line">        self.nodeLink = <span class="literal">None</span></span><br><span class="line">        <span class="comment"># 父节点对象</span></span><br><span class="line">        self.parent = parentNode</span><br><span class="line">        <span class="comment"># 子节点</span></span><br><span class="line">        self.children = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inc</span>(<span class="params">self, numOccur</span>):</span></span><br><span class="line">        self.count += numOccur</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">disp</span>(<span class="params">self, ind=<span class="number">1</span></span>):</span></span><br><span class="line">        print(<span class="string">&#x27;--&#x27;</span>*ind, self.name, <span class="string">&#x27; &#x27;</span>, self.count)</span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> self.children.values():</span><br><span class="line">            child.disp(ind+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span>(<span class="params">dataSet, minSup=<span class="number">1</span></span>):</span>  <span class="comment"># create FP-tree from dataset but don&#x27;t mine</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;遍历数据集两遍&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 第一遍对元素计数</span></span><br><span class="line">    originHeaderTable = &#123;&#125;    <span class="comment"># headerTable用于记录树的结构情况</span></span><br><span class="line">    <span class="keyword">for</span> trans <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> trans:</span><br><span class="line">            originHeaderTable[item] = originHeaderTable.get(item, <span class="number">0</span>) + dataSet[trans]</span><br><span class="line"></span><br><span class="line">    popKeys = []</span><br><span class="line">    <span class="comment"># 过滤掉非频繁项集</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> originHeaderTable.keys():</span><br><span class="line">        <span class="comment"># 记录非频繁项</span></span><br><span class="line">        <span class="keyword">if</span> originHeaderTable[k] &lt; minSup:</span><br><span class="line">            popKeys.append(k)</span><br><span class="line"></span><br><span class="line">    freqItemSet = set(originHeaderTable.keys()) - set(popKeys)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># headerTable用于记录树的结构情况</span></span><br><span class="line">    headerTable = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> len(freqItemSet) == <span class="number">0</span>:   <span class="comment"># 如果初选没有频繁项集，那么直接退出</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 重新构建headerTable</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> freqItemSet:</span><br><span class="line">        headerTable[k] = [originHeaderTable[k], <span class="literal">None</span>]  <span class="comment"># reformat headerTable to use Node link</span></span><br><span class="line">    <span class="keyword">del</span> originHeaderTable</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建空树，根节点为空集</span></span><br><span class="line">    root_node = treeNode(<span class="string">&#x27;Null Set&#x27;</span>, <span class="number">1</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># 第二遍扫描，开始构建FP树</span></span><br><span class="line">    <span class="keyword">for</span> tranSet, count <span class="keyword">in</span> dataSet.items():  <span class="comment"># go through dataset 2nd time</span></span><br><span class="line">        localD = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> tranSet:  <span class="comment"># put transaction items in order</span></span><br><span class="line">            <span class="keyword">if</span> item <span class="keyword">in</span> freqItemSet:</span><br><span class="line">                localD[item] = headerTable[item][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> len(localD) &gt; <span class="number">0</span>:</span><br><span class="line">            orderedItems = [v[<span class="number">0</span>] <span class="keyword">for</span> v <span class="keyword">in</span> sorted(localD.items(), key=<span class="keyword">lambda</span> p: p[<span class="number">1</span>], reverse=<span class="literal">True</span>)]</span><br><span class="line">            updateTree(orderedItems, root_node, headerTable, count)  <span class="comment"># populate tree with ordered freq itemset</span></span><br><span class="line">    <span class="keyword">return</span> root_node, headerTable  <span class="comment"># return tree and header table</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateTree</span>(<span class="params">items, parentNode, headerTable, count</span>):</span></span><br><span class="line">    <span class="comment"># 判断第一个项集是已经是当前节点的子节点</span></span><br><span class="line">    <span class="keyword">if</span> items[<span class="number">0</span>] <span class="keyword">in</span> parentNode.children:  <span class="comment"># check if orderedItems[0] in retTree.children</span></span><br><span class="line">        <span class="comment"># 如果是，那么直接count + 1</span></span><br><span class="line">        parentNode.children[items[<span class="number">0</span>]].inc(count)  <span class="comment"># incrament count</span></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># add items[0] to inTree.children</span></span><br><span class="line">        <span class="comment"># 如果不是，那么新建节点，并存储为当前节点的子节点</span></span><br><span class="line">        parentNode.children[items[<span class="number">0</span>]] = treeNode(items[<span class="number">0</span>], count, parentNode)</span><br><span class="line">        <span class="comment"># 更新headerTable</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 判断当前item是否是第一次记录</span></span><br><span class="line">        <span class="keyword">if</span> headerTable[items[<span class="number">0</span>]][<span class="number">1</span>] == <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 如果是第一次，那么把新建的节点直接记录到头表中</span></span><br><span class="line">            headerTable[items[<span class="number">0</span>]][<span class="number">1</span>] = parentNode.children[items[<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 如果不是第一次，那么说明新节点是当前item的节点的子节点，因此将它记录到当前分支的末位去，即设置为当前分支的叶子节点</span></span><br><span class="line">            updateHeader(headerTable[items[<span class="number">0</span>]][<span class="number">1</span>], parentNode.children[items[<span class="number">0</span>]])</span><br><span class="line">    <span class="comment"># 如果还有第二个元素，那么递归执行以上操作</span></span><br><span class="line">    <span class="keyword">if</span> len(items) &gt; <span class="number">1</span>:</span><br><span class="line">        updateTree(items[<span class="number">1</span>::], parentNode.children[items[<span class="number">0</span>]], headerTable, count)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateHeader</span>(<span class="params">lastNode, newLeafNode</span>):</span></span><br><span class="line">    <span class="comment"># 判断上一节点是否有连接节点，如果没有，那么说明上一节点就是叶子节点，那么直接将新节点设为叶子节点</span></span><br><span class="line">    <span class="keyword">while</span> (lastNode.nodeLink != <span class="literal">None</span>):</span><br><span class="line">        <span class="comment"># 如果上一节点已经有连接节点，那么循环知道遍历到叶子节点，再设置新叶子节点</span></span><br><span class="line">        lastNode = lastNode.nodeLink</span><br><span class="line">    <span class="comment"># 将新的叶子节点设置为旧叶子节点的连接节点</span></span><br><span class="line">    lastNode.nodeLink = newLeafNode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadTestDataset</span>():</span></span><br><span class="line">    dataset = [[<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;j&#x27;</span>, <span class="string">&#x27;p&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, <span class="string">&#x27;v&#x27;</span>, <span class="string">&#x27;u&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;s&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;z&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;s&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;p&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;q&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;t&#x27;</span>, <span class="string">&#x27;m&#x27;</span>]]</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createInitDataset</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    dictDataset = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> trans <span class="keyword">in</span> dataSet:</span><br><span class="line">        dictDataset[frozenset(trans)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> dictDataset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildCombinedItems</span>(<span class="params">leafNode, combinedItems</span>):</span></span><br><span class="line">    <span class="keyword">if</span> leafNode.parent != <span class="literal">None</span>:</span><br><span class="line">        combinedItems.append(leafNode.name)</span><br><span class="line">        buildCombinedItems(leafNode.parent, combinedItems)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildCombinedDataset</span>(<span class="params">nodeObject</span>):</span></span><br><span class="line">    <span class="comment"># 根据节点名称，组合出新的项集节点</span></span><br><span class="line">    combinedDataset = &#123;&#125;</span><br><span class="line">    <span class="keyword">while</span> nodeObject != <span class="literal">None</span>:</span><br><span class="line">        combinedItems = []</span><br><span class="line">        buildCombinedItems(nodeObject, combinedItems)</span><br><span class="line">        <span class="keyword">if</span> len(combinedItems) &gt; <span class="number">1</span>:</span><br><span class="line">            combinedDataset[frozenset(combinedItems[<span class="number">1</span>:])] = nodeObject.count</span><br><span class="line">        nodeObject = nodeObject.nodeLink</span><br><span class="line">    <span class="keyword">return</span> combinedDataset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanFPTree</span>(<span class="params">headerTable, minSup, parentNodeNames, freqItemList</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历排序后的headerTable，(节点名称，节点信息）</span></span><br><span class="line">    <span class="keyword">for</span> baseNode, nodeInfo <span class="keyword">in</span> headerTable.items():</span><br><span class="line">        <span class="comment"># 根据prefix</span></span><br><span class="line">        newFreqSet = parentNodeNames.copy()</span><br><span class="line">        newFreqSet.add(baseNode)</span><br><span class="line">        <span class="comment"># 节点计数值</span></span><br><span class="line">        nodeCount = nodeInfo[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 节点对象</span></span><br><span class="line">        nodeObject = nodeInfo[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 记录下频繁项集以及计数</span></span><br><span class="line">        freqItemList.append((newFreqSet, nodeCount))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据当前节点的子节点，构建出新的项集组合</span></span><br><span class="line">        combinedDataset = buildCombinedDataset(nodeObject)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据新的项集组合，重合构建子FP树</span></span><br><span class="line">        subFPTree, subFPTreeHeaderTable = createTree(combinedDataset, minSup)</span><br><span class="line">        <span class="comment"># 如果头表不为空，那么递归新树的头表</span></span><br><span class="line">        <span class="keyword">if</span> subFPTreeHeaderTable != <span class="literal">None</span>:</span><br><span class="line">            print(<span class="string">&#x27;conditional tree for: &#x27;</span>, newFreqSet)</span><br><span class="line">            subFPTree.disp(<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 根据新的头表 扫描FP-Tree</span></span><br><span class="line">            scanFPTree(subFPTreeHeaderTable, minSup, newFreqSet, freqItemList)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    simpDat = loadTestDataset()</span><br><span class="line">    initSet = createInitDataset(simpDat)</span><br><span class="line">    <span class="comment"># 构建初始的FP-Tree</span></span><br><span class="line">    initFPtree, initFPtreeHeaderTable = createTree(initSet, <span class="number">3</span>)</span><br><span class="line">    initFPtree.disp(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    freqItems = []    <span class="comment"># 存储频繁项集</span></span><br><span class="line">    <span class="comment"># 扫描FP树，找出所有符合条件的频繁项集</span></span><br><span class="line"></span><br><span class="line">    root_node_names = set([])    <span class="comment"># 从根路径空集开始扫描</span></span><br><span class="line">    scanFPTree(initFPtreeHeaderTable, <span class="number">3</span>, root_node_names, freqItems)</span><br><span class="line">    pprint(freqItems)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 推荐算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关键规则挖掘算法（一）Apriori算法</title>
      <link href="2019/03/17/13_Apriori%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
      <url>2019/03/17/13_Apriori%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="关键规则挖掘算法（一）Apriori算法"><a href="#关键规则挖掘算法（一）Apriori算法" class="headerlink" title="关键规则挖掘算法（一）Apriori算法"></a>关键规则挖掘算法（一）Apriori算法</h2><h4 id="Apriori算法原理"><a href="#Apriori算法原理" class="headerlink" title="Apriori算法原理"></a>Apriori算法原理</h4><p>Apriori算法是著名的关联规则挖掘算法。</p><p>假如我们在经营一家商品种类并不多的杂货店，我们对哪些经常在一起被购买的商品非常感兴趣。我们只有四种商品：商品0、商品1、商品2、商品3。那么所有可能被一起购买的商品组合都有哪些？这些商品组合可能著有一种商品，比如商品0，也可能包括两种、三种或所有四种商品。但我们不关心某人买了两件商品0以及四件商品2的情况，只关心他购买了一种或多种商品。</p><p>下图显示了物品之间所有可能的组合：</p><ul><li>图中使用物品的编号0来表示物品0本身。</li><li>图中从上往下的第一个集合是$\phi$，表示空集或不包含任何物品的集合。</li><li>物品集合之间的连线表明两个或者更多集合可以组合形成一个更大的集合。</li></ul><p><img src="/img/apriori1.png"></p><p><strong>目标：</strong>我们的目标是找到经常在一起购买的物品集合。我们使用集合的支持度来度量其出现的频率。</p><blockquote><p>一个集合的支持度是指有多少比例的交易记录包含该集合。</p></blockquote><p><strong>问题：</strong> 如何对一个给定的集合，比如<code>&#123;0，3&#125;</code>，来计算其支持度？</p><ul><li>我们可以遍历毎条记录并检查该记录包含0和3，如果记录确实同时包含这两项，那么就增加总计数值。在扫描完所有数据之后，使用统计得到的总数除以总的交易记录数，就可以得到支持度。</li></ul><p><strong>注意：</strong>上述过程和结果只是针对单个集合{0,3}。要获得每种可能集合的支持度就需要多次重复上述过程。我们可以数一下图中的集合数目，会发现即使对于仅有4种物品的集合，也需要遍历数据15次。而随着物品数目的增加遍历次数会急剧增长。对于包含N种物品的数据集共有$2^{N-1}$种项集组合。而且实际上出售10 000或更多种物品的商店并不少见。即使只出售100种商品的商店也会有$1.26 * 10^{30}$种可能的项集组合。这样的运算量，其实即使是对于现在的很多计算机而言，也需要很长的时间才能完成运算。</p><p><strong>Apriori算法的原理可以帮我们减少可能感兴趣的项集，降低所需的计算时间。</strong></p><p>Apriori算法原理：</p><ul><li><p>如果某个项集是频繁的，那么它的所有子集都是频繁的，例如，假设<code>&#123;1,2&#125;</code>是频繁的，那么<code>&#123;1&#125;</code>和<code>&#123;2&#125;</code>也一定是频繁的。</p></li><li><p>将这个原理取反会发现：如果一个项集是非频繁的，那么它的所有超集也是非频繁的</p><p>如下图中，已知项集<code>&#123;2,3&#125;</code>是非频繁的，那么可立即判断出项集<code>&#123;0,2,3&#125;</code>、<code>&#123;1,2,3&#125;</code>、<code>&#123;0,1,2,3&#125;</code>都是非频繁的，因此这些项集的支持度也就不需要再计算</p><p><img src="/img/apriori2.png"></p></li></ul><p><strong>Apriori算法的一般过程：</strong></p><ol><li>收集数据：使用任意方法。</li><li>准备数据：任何数据类型都可以，因为我们只保存集合。</li><li>分析数据：使用任意方法。</li><li>训练算法：使用Apriori算法来找到频繁项集。</li><li>测试算法：不需要测试过程。</li><li>使用算法：用于发现频繁项集以及物品之间的关联规则。</li></ol><h4 id="Apriori算法实现"><a href="#Apriori算法实现" class="headerlink" title="Apriori算法实现"></a>Apriori算法实现</h4><p><img src="/img/%E6%8C%96%E6%8E%98%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86.png"></p><p>实现数据集扫描方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    加载数据集</span></span><br><span class="line"><span class="string">    :return: dataset</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> [[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createC1</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    创建C1候选项集，C1是所有大小为1的候选项集的列表</span></span><br><span class="line"><span class="string">    :param dataSet:</span></span><br><span class="line"><span class="string">    :return: C1</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># C1是所有大小为1的候选项集的列表</span></span><br><span class="line">    C1 = []</span><br><span class="line">    <span class="comment"># 遍历数据集，逐个添加到C1中</span></span><br><span class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> record:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> [item] <span class="keyword">in</span> C1:</span><br><span class="line">                C1.append([item])</span><br><span class="line">    C1.sort()</span><br><span class="line">    <span class="comment"># 使用不变集合存储C1内部的每个候选项集，那么就可以将其作为字典的Key，如果是list类型不能直接作为字典的Key</span></span><br><span class="line">    <span class="keyword">return</span> list(map(frozenset, C1))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanDataset</span>(<span class="params">dataset, ck, minSupport</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    扫描数据集，判断频繁项集</span></span><br><span class="line"><span class="string">    :param dataset:</span></span><br><span class="line"><span class="string">    :param ck: ck是所有大小为k的候选项集的列表</span></span><br><span class="line"><span class="string">    :param minSupport: 设置的最小支持度阈值</span></span><br><span class="line"><span class="string">    :return: 符合条件的项集、每个项集的支持度</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 存储项集的出现次数</span></span><br><span class="line">    selectedSetCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> dataset:    <span class="comment"># 遍历每一条记录</span></span><br><span class="line">        <span class="keyword">for</span> candidateSet <span class="keyword">in</span> ck:</span><br><span class="line">            <span class="comment"># 判断当前候选项集是不是当前记录的子集</span></span><br><span class="line">            <span class="keyword">if</span> candidateSet.issubset(record):    </span><br><span class="line">                <span class="keyword">if</span> candidateSet <span class="keyword">not</span> <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">                    selectedSetCount[candidateSet] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    selectedSetCount[candidateSet] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算总条目数</span></span><br><span class="line">    numItems = float(len(dataset))</span><br><span class="line">    <span class="comment"># 存储符合条件的项集</span></span><br><span class="line">    retList = []</span><br><span class="line">    <span class="comment"># 存储项集的支持度</span></span><br><span class="line">    supportData = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">        <span class="comment"># 计算支持度</span></span><br><span class="line">        support = selectedSetCount[key] / numItems</span><br><span class="line">        <span class="keyword">if</span> support &gt;= minSupport:</span><br><span class="line">            retList.insert(<span class="number">0</span>, key)</span><br><span class="line">        supportData[key] = support</span><br><span class="line">    <span class="keyword">return</span> retList, supportData</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    c1 = createC1(dataset)</span><br><span class="line">    pprint(scanDataset(dataset, c1, <span class="number">0.5</span>))</span><br></pre></td></tr></table></figure><p>实现频繁项集挖掘：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createCk</span>(<span class="params">lastFrequentItems, k</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    根据k-1项的频繁项集列表生成k项的候选项集</span></span><br><span class="line"><span class="string">    :param lastFrequentItems: k-1项的频繁项集</span></span><br><span class="line"><span class="string">    :param k: 第k个项集</span></span><br><span class="line"><span class="string">    :return: ck项集</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    retList = []</span><br><span class="line">    lenLk = len(lastFrequentItems)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(lenLk):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, lenLk):</span><br><span class="line">            <span class="comment"># 因为新构建的ck项集，特征是任意一个k项集其中k-1项都必须存在于lastCk中</span></span><br><span class="line">            <span class="comment"># 通过以下判断，能筛选出那些符合要求的k-1项</span></span><br><span class="line">            L1 = list(lastFrequentItems[i])[:k<span class="number">-2</span>]; L2 = list(lastFrequentItems[j])[:k<span class="number">-2</span>]</span><br><span class="line">            L1.sort(); L2.sort()</span><br><span class="line">            <span class="keyword">if</span> L1==L2:</span><br><span class="line">                retList.append(lastFrequentItems[i] | lastFrequentItems[j])</span><br><span class="line">    <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apriori</span>(<span class="params">dataSet, minSupport=<span class="number">0.5</span></span>):</span></span><br><span class="line">    C1 = createC1(dataSet)</span><br><span class="line">    k1FrequentItems, supportData = scanDataset(dataSet, C1, minSupport)</span><br><span class="line">    frequentItemsList = [k1FrequentItems]</span><br><span class="line">    <span class="comment"># 应为k=1的频繁项集已经找到，因此从k=2继续</span></span><br><span class="line">    k = <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 根据k-1的频繁项集，创建k候选集，</span></span><br><span class="line">        <span class="comment"># k-1-1是因为列表下表从0开始</span></span><br><span class="line">        ck = createCk(frequentItemsList[k<span class="number">-1</span><span class="number">-1</span>], k)</span><br><span class="line">        <span class="comment"># 再次扫描数据集，找出新的k项频繁项集</span></span><br><span class="line">        newFrequentItems, supK = scanDataset(dataSet, ck, minSupport)</span><br><span class="line">        <span class="comment"># 更新项集的支持度</span></span><br><span class="line">        supportData.update(supK)</span><br><span class="line">        <span class="comment"># 如果无法生成新的频繁项集，那么推出循环</span></span><br><span class="line">        <span class="keyword">if</span> len(newFrequentItems) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 存储所有的频繁项集</span></span><br><span class="line">        frequentItemsList.append(newFrequentItems)</span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> frequentItemsList, supportData</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    c1 = createC1(dataset)</span><br><span class="line"></span><br><span class="line">    pprint(apriori(dataset, <span class="number">0.3</span>))</span><br></pre></td></tr></table></figure><p>实现关联规则挖掘：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateRules</span>(<span class="params">frequentItemsList, supportData, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    <span class="comment"># 存储关联规则</span></span><br><span class="line">    ruleList = []</span><br><span class="line">    <span class="comment"># 从含有2项item的频繁项集开始遍历，计算两两的置信度</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(frequentItemsList)):</span><br><span class="line">        <span class="comment"># 遍历每一阶段的频繁项集</span></span><br><span class="line">        <span class="keyword">for</span> frequentItem <span class="keyword">in</span> frequentItemsList[i]:</span><br><span class="line">            print(frequentItem)</span><br><span class="line">            subItems = [frozenset([item]) <span class="keyword">for</span> item <span class="keyword">in</span> frequentItem]</span><br><span class="line">            print(subItems)</span><br><span class="line">            <span class="keyword">if</span> (i == <span class="number">1</span>):</span><br><span class="line">                <span class="comment"># 先计算2项item的频繁项集的置信度，并将关联规则存储到ruleList</span></span><br><span class="line">                calculateConfidence(frequentItem, subItems, supportData, ruleList, minConf)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 然后使用递归依次计算3到k项item频繁项集之间两两的置信度，并提取关联规则</span></span><br><span class="line">                rulesFromRecursive(frequentItem, subItems, supportData, ruleList, minConf)</span><br><span class="line">    <span class="keyword">return</span> ruleList</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculateConfidence</span>(<span class="params">frequentItem, subItems, supportData, ruleList, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    <span class="comment"># 存储符合最小置信度阈值的item</span></span><br><span class="line">    retList = []</span><br><span class="line">    <span class="keyword">for</span> subItem <span class="keyword">in</span> subItems:</span><br><span class="line">        <span class="comment">#支持度(&#123;豆奶, 莴苣&#125;)/支持度(&#123;豆奶&#125;)</span></span><br><span class="line">        <span class="comment"># 计算置信度[frozenset(&#123;2, 3&#125;), frozenset(&#123;3, 5&#125;), frozenset(&#123;2, 5&#125;), frozenset(&#123;1, 3&#125;)],</span></span><br><span class="line">        conf = supportData[frequentItem]/supportData[frequentItem-subItem]</span><br><span class="line">        <span class="keyword">if</span> conf &gt;= minConf:</span><br><span class="line">            print(<span class="string">&quot;Rule：&quot;</span>, frequentItem-subItem, <span class="string">&#x27;--&gt;&#x27;</span>, subItem, <span class="string">&#x27;confidence:&#x27;</span>, conf)</span><br><span class="line">            ruleList.append((frequentItem-subItem, subItem, conf))</span><br><span class="line">            retList.append(subItem)</span><br><span class="line">    <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rulesFromRecursive</span>(<span class="params">frequentItem, subItems, supportData, ruleList, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    m = len(subItems[<span class="number">0</span>])    <span class="comment"># 判断当前子项集的长度</span></span><br><span class="line">    <span class="keyword">if</span> (len(frequentItem) &gt; (m + <span class="number">1</span>)): <span class="comment">#frozenset(&#123;2, 3, 5&#125;)</span></span><br><span class="line">        <span class="comment"># 根据子项集得出CK候选集</span></span><br><span class="line">        ck = createCk(subItems, m+<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 根据候选集再筛选出符合最小置信度的item集合</span></span><br><span class="line">        newItems = calculateConfidence(frequentItem, ck, supportData, ruleList, minConf)</span><br><span class="line">        <span class="comment"># 如果符合要求的item至少有2个，那么继续递归</span></span><br><span class="line">        <span class="keyword">if</span> (len(newItems) &gt; <span class="number">1</span>):</span><br><span class="line">            rulesFromRecursive(frequentItem, newItems, supportData, ruleList, minConf)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    c1 = createC1(dataset)</span><br><span class="line">    <span class="comment"># pprint(scanDataset(dataset, c1, 0.5))</span></span><br><span class="line"></span><br><span class="line">    pprint(generateRules(*apriori(dataset, <span class="number">0.3</span>)))</span><br></pre></td></tr></table></figure><p>面向对象封装</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    加载数据集</span></span><br><span class="line"><span class="string">    :return: dataset</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> [[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>]]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AssociationRule</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, minSupport=<span class="number">0.5</span>, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">        self.minSupport = minSupport</span><br><span class="line">        self.minConf = minConf</span><br><span class="line">        self.dataset = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        self.frequentItemsList, self.supportData = self.apriori(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_createC1</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        创建C1候选项集，C1是所有大小为1的候选项集的列表</span></span><br><span class="line"><span class="string">        :return: C1</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># C1是所有大小为1的候选项集的列表</span></span><br><span class="line">        C1 = []</span><br><span class="line">        <span class="comment"># 遍历数据集，逐个添加到C1中</span></span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> dataset:</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> record:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> [item] <span class="keyword">in</span> C1:</span><br><span class="line">                    C1.append([item])</span><br><span class="line">        C1.sort()</span><br><span class="line">        <span class="comment"># 使用不变集合存储C1内部的每个候选项集，那么就可以将其作为字典的Key，如果是list类型不能直接作为字典的Key</span></span><br><span class="line">        <span class="keyword">return</span> list(map(frozenset, C1))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_scanDataset</span>(<span class="params">self, ck</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        扫描数据集，判断频繁项集</span></span><br><span class="line"><span class="string">        :param ck: ck是所有大小为k的候选项集的列表</span></span><br><span class="line"><span class="string">        :return: 符合条件的项集、每个项集的支持度</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 存储项集的出现次数</span></span><br><span class="line">        selectedSetCount = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> self.dataset:  <span class="comment"># 遍历每一条记录</span></span><br><span class="line">            <span class="keyword">for</span> candidateSet <span class="keyword">in</span> ck:</span><br><span class="line">                <span class="comment"># 判断当前候选项集是不是当前记录的子集</span></span><br><span class="line">                <span class="keyword">if</span> candidateSet.issubset(record):</span><br><span class="line">                    <span class="keyword">if</span> candidateSet <span class="keyword">not</span> <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">                        selectedSetCount[candidateSet] = <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        selectedSetCount[candidateSet] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 计算总条目数</span></span><br><span class="line">        numItems = float(len(self.dataset))</span><br><span class="line">        <span class="comment"># 存储符合条件的项集</span></span><br><span class="line">        retList = []</span><br><span class="line">        <span class="comment"># 存储项集的支持度</span></span><br><span class="line">        supportData = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> selectedSetCount:</span><br><span class="line">            <span class="comment"># 计算支持度</span></span><br><span class="line">            support = selectedSetCount[key] / numItems</span><br><span class="line">            <span class="keyword">if</span> support &gt;= self.minSupport:</span><br><span class="line">                retList.insert(<span class="number">0</span>, key)</span><br><span class="line">            supportData[key] = support</span><br><span class="line">        <span class="keyword">return</span> retList, supportData</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_createCk</span>(<span class="params">self, lastFrequentItems, k</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        根据k-1项的频繁项集列表生成k项的候选项集</span></span><br><span class="line"><span class="string">        :param lastFrequentItems: k-1项的频繁项集</span></span><br><span class="line"><span class="string">        :param k: 第k个项集</span></span><br><span class="line"><span class="string">        :return: ck项集</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        retList = []</span><br><span class="line">        lenLk = len(lastFrequentItems)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(lenLk):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, lenLk):</span><br><span class="line">                <span class="comment"># 因为新构建的ck项集，特征是任意一个k项集其中k-1项都必须存在于lastCk中</span></span><br><span class="line">                <span class="comment"># 通过以下判断，能筛选出那些符合要求的k-1项</span></span><br><span class="line">                L1 = list(lastFrequentItems[i])[:k - <span class="number">2</span>]</span><br><span class="line">                L2 = list(lastFrequentItems[j])[:k - <span class="number">2</span>]</span><br><span class="line">                L1.sort()</span><br><span class="line">                L2.sort()</span><br><span class="line">                <span class="keyword">if</span> L1 == L2:</span><br><span class="line">                    retList.append(lastFrequentItems[i] | lastFrequentItems[j])</span><br><span class="line">        <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">apriori</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        C1 = self._createC1(dataset)</span><br><span class="line">        k1FrequentItems, supportData = self._scanDataset(C1)</span><br><span class="line">        frequentItemsList = [k1FrequentItems]</span><br><span class="line">        <span class="comment"># 应为k=1的频繁项集已经找到，因此从k=2继续</span></span><br><span class="line">        k = <span class="number">2</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="comment"># 根据k-1的频繁项集，创建k候选集，</span></span><br><span class="line">            <span class="comment"># k-1-1是因为列表下表从0开始</span></span><br><span class="line">            ck = self._createCk(frequentItemsList[k - <span class="number">1</span> - <span class="number">1</span>], k)</span><br><span class="line">            <span class="comment"># 再次扫描数据集，找出新的k项频繁项集</span></span><br><span class="line">            newFrequentItems, supK = self._scanDataset(ck)</span><br><span class="line">            <span class="comment"># 更新项集的支持度</span></span><br><span class="line">            supportData.update(supK)</span><br><span class="line">            <span class="comment"># 如果无法生成新的频繁项集，那么推出循环</span></span><br><span class="line">            <span class="keyword">if</span> len(newFrequentItems) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment"># 存储所有的频繁项集</span></span><br><span class="line">            frequentItemsList.append(newFrequentItems)</span><br><span class="line">            k += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> frequentItemsList, supportData</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateRules</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 存储关联规则</span></span><br><span class="line">        ruleList = []</span><br><span class="line">        <span class="comment"># 从含有2项item的频繁项集开始遍历，计算两两的置信度</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(self.frequentItemsList)):</span><br><span class="line">            <span class="comment"># 遍历每一阶段的频繁项集</span></span><br><span class="line">            <span class="keyword">for</span> frequentItem <span class="keyword">in</span> self.frequentItemsList[i]:</span><br><span class="line">                subItems = [frozenset([item]) <span class="keyword">for</span> item <span class="keyword">in</span> frequentItem]</span><br><span class="line">                <span class="keyword">if</span> (i == <span class="number">1</span>):</span><br><span class="line">                    <span class="comment"># 先计算2项item的频繁项集的置信度，并将关联规则存储到ruleList</span></span><br><span class="line">                    self._calculateConfidence(frequentItem, subItems, self.supportData, ruleList)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 然后使用递归依次计算3到k项item频繁项集之间两两的置信度，并提取关联规则</span></span><br><span class="line">                    self._rulesFromRecursive(frequentItem, subItems, self.supportData, ruleList)</span><br><span class="line">        <span class="keyword">return</span> ruleList</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_calculateConfidence</span>(<span class="params">self, frequentItem, subItems, supportData, ruleList</span>):</span></span><br><span class="line">        <span class="comment"># 存储符合最小置信度阈值的item</span></span><br><span class="line">        retList = []</span><br><span class="line">        <span class="keyword">for</span> subItem <span class="keyword">in</span> subItems:</span><br><span class="line">            <span class="comment"># 计算置信度</span></span><br><span class="line">            conf = supportData[frequentItem] / supportData[frequentItem - subItem]</span><br><span class="line">            <span class="keyword">if</span> conf &gt;= self.minConf:</span><br><span class="line">                print(<span class="string">&quot;Rule：&quot;</span>, frequentItem - subItem, <span class="string">&#x27;--&gt;&#x27;</span>, subItem, <span class="string">&#x27;confidence:&#x27;</span>, conf)</span><br><span class="line">                ruleList.append((frequentItem - subItem, subItem, conf))</span><br><span class="line">                retList.append(subItem)</span><br><span class="line">        <span class="keyword">return</span> retList</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_rulesFromRecursive</span>(<span class="params">self, frequentItem, subItems, supportData, ruleList</span>):</span></span><br><span class="line">        m = len(subItems[<span class="number">0</span>])  <span class="comment"># 判断当前子项集的长度</span></span><br><span class="line">        <span class="keyword">if</span> (len(frequentItem) &gt; (m + <span class="number">1</span>)):</span><br><span class="line">            <span class="comment"># 根据子项集得出CK候选集</span></span><br><span class="line">            ck = self._createCk(subItems, m + <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 根据候选集再筛选出符合最小置信度的item集合</span></span><br><span class="line">            newItems = self._calculateConfidence(frequentItem, ck, supportData, ruleList)</span><br><span class="line">            <span class="comment"># 如果符合要求的item至少有2个，那么继续递归</span></span><br><span class="line">            <span class="keyword">if</span> (len(newItems) &gt; <span class="number">1</span>):</span><br><span class="line">                self._rulesFromRecursive(frequentItem, newItems, supportData, ruleList)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line">    dataset = loadDataSet()</span><br><span class="line">    ar = AssociationRule()</span><br><span class="line">    <span class="comment"># pprint(scanDataset(dataset, c1, 0.5))</span></span><br><span class="line">    ar.fit(dataset)</span><br><span class="line">    pprint(ar.generateRules())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pprint(ar.generateRules(*ar.apriori(dataset, 0.3)))</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(12)  基于关联规则的推荐</title>
      <link href="2019/03/16/12_%E5%9F%BA%E4%BA%8E%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E7%9A%84%E6%8E%A8%E8%8D%90/"/>
      <url>2019/03/16/12_%E5%9F%BA%E4%BA%8E%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E7%9A%84%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于关联规则的推荐"><a href="#基于关联规则的推荐" class="headerlink" title="基于关联规则的推荐"></a>基于关联规则的推荐</h2><p>基于关联规则的推荐思想类似基于物品的协同过滤推荐</p><p><strong>“啤酒与尿布”</strong></p><p>关联分析中最有名的例子就是“啤酒与尿布”。</p><p>据报道，在美国沃尔玛超市会发现一个很有趣的现象：货架上啤酒与尿布竟然放在一起售卖，这看似两者毫不相关的东西，为什么会放在一起售卖呢？</p><p>原来，在美国，妇女们经常会嘱咐她们的丈夫下班以后给孩子买一点尿布回来，而丈夫在买完尿布后，大都会顺手买回一瓶自己爱喝的啤酒（由此看出美国人爱喝酒）。商家通过对一年多的原始交易记录进行详细的分析，发现了这对神奇的组合。于是就毫不犹豫地将尿布与啤酒摆放在一起售卖，通过它们的关联性，互相促进销售。“啤酒与尿布”的故事一度是营销界的神话。</p><p>那么问题来了，<strong>商家是如何发现啤酒与尿布两者之间的关联性呢？</strong></p><p>这里我们可以使用数据挖掘中的关联规则挖掘技术，目的就是为了找出两个对象（如X,Y）之间的关联性。一旦找出二者关联性，那么就可以根据它来进行推荐。</p><p><strong>基于关联规则的推荐</strong></p><p>一般我们可以找出用户购买的所有物品数据里频繁出现的项集活序列，来做频繁集挖掘，找到满足支持度阈值的关联物品的频繁N项集或者序列。如果用户购买了频繁N项集或者序列里的部分物品，那么我们可以将频繁项集或序列里的其他物品按一定的评分准则推荐给用户，这个评分准则可以包括支持度，置信度和提升度等。</p><p>常用的关联推荐算法有Apriori，FP-Growth</p><h4 id="关联分析"><a href="#关联分析" class="headerlink" title="关联分析"></a>关联分析</h4><p>关联分析是一种在大规模数据集中寻找有趣关系的任务。 这些关系可以有两种形式:</p><ul><li>频繁项集（frequent item sets）是指经常出现在一块的物品的集合。</li><li>关联规则（associational rules）是暗示两种物品之间可能存在很强的关系。</li></ul><p>从大规模数据集中寻找物品间的隐含关系被称作关联分析(association analysis)或者关联规则学习（association rule learning）</p><h4 id="关联性衡量指标"><a href="#关联性衡量指标" class="headerlink" title="关联性衡量指标"></a>关联性衡量指标</h4><p>假设我们下图所示的一份数据集</p><p><img src="/img/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%95%B0%E6%8D%AE%E7%A4%BA%E4%BE%8B.png"></p><p>确定X， Y的关联性，需要用两个指标来衡量：</p><ul><li><p><strong>支持度（support）</strong></p><p>支持度是针对项集而言的</p><p>项集的支持度被定义为数据集中包含该项集的记录所占的比例</p><p>那么项集<code>&#123;豆奶&#125;</code>的支持度就是4/5，那么项集<code>&#123;豆奶, 莴苣&#125;</code>的支持度就是3/5</p></li><li><p><strong>置信度（confidence）</strong></p><p>置信度也成为可信度，是针对一个关联规则而言的，如<code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>，表示<code>&#123;豆奶&#125;</code>之于<code>&#123;莴苣&#125;</code>的关联程度（注意：<code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>不等价于<code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>）</p><p><code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>的置信度 = 支持度(<code>&#123;豆奶, 莴苣&#125;</code>)/支持度(<code>&#123;豆奶&#125;</code>)，即3/4</p><p><code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>的置信度 = 支持度(<code>&#123;豆奶, 莴苣&#125;</code>)/支持度(<code>&#123;莴苣&#125;</code>)，即3/4</p><p>注意：这里他们俩的置信度相等纯属巧合</p></li></ul><p>如果不考虑关联规则的支持度和置信度，那么在数据库中会存在着无穷多的关联规则。因此我们为了提取出真正的频繁项集和关联规则，必须指定一个最小支持度阈值和最小置信度阈值，因为对于支持度和置信度太低的关联规则基本没有什么使用价值。</p><ul><li><p><strong>最小支持度</strong>：</p><p>它表示了一组物品集在统计意义上需要满足的最低程度</p></li><li><p><strong>最小可信度</strong></p><p>它反映了关联规则的最低可靠程度</p></li></ul><p><strong>同时满足最小可信度阈值和最小支持度阈值的关联规则被称为强关联规则。</strong>比如啤酒与尿布。</p><p>比如这里，如果我们假设最小支持度阈值为50%，最小可信度阈值为70%，那么这里<code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>和<code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>都属于符合条件的两条关联规则，分别表示：</p><ul><li>同时购买豆奶和莴苣的顾客占全部顾客的60%</li><li><code>&#123;豆奶&#125;</code> &gt;&gt;&gt;<code>&#123;莴苣&#125;</code>：在购买豆奶的用户中，有75%的顾客会购买莴苣</li><li><code>&#123;莴苣&#125;</code> &gt;&gt;&gt;<code>&#123;豆奶&#125;</code>：在购买莴苣的用户中，有75%的顾客会购买豆奶</li></ul>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(11)  基于内容的电影推荐：物品冷启动处理</title>
      <link href="2019/03/15/11_%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90(ContentBased)_%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A8%E5%A4%84%E7%90%86/"/>
      <url>2019/03/15/11_%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90(ContentBased)_%E7%89%A9%E5%93%81%E5%86%B7%E5%90%AF%E5%8A%A8%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于内容的电影推荐：物品冷启动处理"><a href="#基于内容的电影推荐：物品冷启动处理" class="headerlink" title="基于内容的电影推荐：物品冷启动处理"></a>基于内容的电影推荐：物品冷启动处理</h2><p>利用Word2Vec可以计算电影所有标签词之间的关系程度，可用于计算电影之间的相似度</p><h4 id="word2vec原理简介"><a href="#word2vec原理简介" class="headerlink" title="word2vec原理简介"></a>word2vec原理简介</h4><ul><li><p>word2vec是google在2013年开源的一个NLP(Natural Language Processing自然语言处理) 工具，它的特点是将所有的词向量化，这样词与词之间就可以定量的去度量他们之间的关系，挖掘词之间的联系。</p></li><li><p>one-hot vector VS. word vector</p><ul><li>用向量来表示词并不是word2vec的首创</li><li>最早的词向量是很冗长的，它使用是词向量维度大小为整个词汇表的大小，对于每个具体的词汇表中的词，将对应的位置置为1。</li><li>比如下面5个词组成词汇表，词”Queen”的序号为2， 那么它的词向量就是(0,1,0,0,0)同样的道理，词”Woman”的词向量就是(0,0,0,1,0)。</li></ul><p><img src="/img/word2vec1.png"></p></li><li><p>one hot vector的问题</p><ul><li>如果词汇表非常大，如达到万级别，这样每个词都用万维的向量来表示浪费内存。这样的向量除了一个位置是1，其余位置全部为0，表达效率低(稀疏)，需要降低词向量的维度</li><li>难以发现词之间的关系，以及难以捕捉句法（结构）和语义（意思）之间的关系</li><li>Dristributed representation可以解决One hot representation的问题，它的思路是通过训练，将每个词都映射到一个较短的词向量上来。所有的这些词向量就构成了向量空间，进而可以用普通的统计学的方法来研究词与词之间的关系。这个较短的词向量维度一般需要我们在训练时指定。</li><li>比如下图我们将词汇表里的词用”Royalty(王位)”,”Masculinity(男性气质)”, “Femininity(女性气质)”和”Age”4个维度来表示，King这个词对应的词向量可能是(0.99,0.99,0.05,0.7)。当然在实际情况中，我们并不一定能对词向量的每个维度做一个很好的解释。</li></ul><p><img src="/img/word2vec2.png"></p></li><li><p>有了用Dristributed representation表示的较短的词向量，就可以较容易的分析词之间的关系，比如将词的维度降维到2维，用下图的词向量表示我们的词时，发现：$\vec{King} - \vec{Man} + \vec{Woman} = \vec{Queen}​$ </p><p><img src="/img/word2vec3.png"></p></li><li><p>什么是word vector（词向量）</p><ul><li>每个单词被表征为多维的浮点数，每一维的浮点数的数值大小表示了它与另一个单词之间的“距离”，表征的结果就是语义相近的词被映射到相近的集合空间上，好处是这样单词之间就是可以计算的：</li></ul><table>    <th>    <td> animal </td>    <td> pet </td>    </th><tr> <td> dog </td> <td> -0.4 </td> <td> 0.02 </td></tr><tr> <td> lion </td> <td> 0.2 </td> <td> 0.35 </td></tr></table><p>animal那一列表示的就是左边的词与animal这个概念的”距离“</p></li><li><h4 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h4><h5 id="两个重要模型：CBOW和Skip-Gram"><a href="#两个重要模型：CBOW和Skip-Gram" class="headerlink" title="两个重要模型：CBOW和Skip-Gram"></a>两个重要模型：CBOW和Skip-Gram</h5><ul><li><p>介绍：CBOW把一个词从词窗剔除。在CBOW下给定<em>n</em>词围绕着词<em>w</em>，word2vec预测一个句子中其中一个缺漏的词<em>c</em>，即以概率$p(c|w)$来表示。相反地，Skip-gram给定词窗中的文本，预测当前的词$p(w|c)​$。</p></li><li><p>原理：拥有差不多上下文的两个单词的意思往往是相近的</p></li><li><p><strong>Continuous Bag-of-Words(CBOW)</strong> 连续词袋向量</p><ul><li><p><img src="/img/CBOW.png"></p></li><li><p>功能：通过上下文预测当前词出现的概率</p></li><li><p>原理分析</p><p>假设文本如下：“the florid <u>prose of</u> <strong>the</strong> <u>nineteenth century.</u>”</p><p>想象有个滑动窗口，中间的词是关键词，两边为相等长度的文本来帮助分析。文本的长度为7，就得到了7个one-hot向量，作为神经网络的输入向量，训练目标是：最大化在给定前后文本情况下输出正确关键词的概率，比如给定(“prose”,”of”,”nineteenth”,”century”)的情况下，要最大化输出”the”的概率，用公式表示就是</p><p>P(“the”|(“prose”,”of”,”nineteenth”,”century”))</p></li><li><p>特性</p><ul><li>hidden layer只是将权重求和，传递到下一层，是线性的</li></ul></li></ul></li><li><p><strong>Continuous Skip-gram</strong></p><ul><li><img src="/img/skip-gram.png"></li><li>功能：根据当前词预测上下文</li><li>原理分析<ul><li>和CBOW相反，则我们要求的概率就变为P(Context(w)|w)</li></ul></li></ul></li></ul></li><li><p><strong>总结：</strong>word2vec算法可以计算出每个词语的一个词向量，我们可以用它来表示该词的语义层面的含义</p></li></ul><h4 id="Word2Vec使用"><a href="#Word2Vec使用" class="headerlink" title="Word2Vec使用"></a>Word2Vec使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_dataset</span>():</span></span><br><span class="line">    <span class="comment"># 加载基于所有电影的标签</span></span><br><span class="line">    <span class="comment"># all-tags.csv来自ml-latest数据集中</span></span><br><span class="line">    <span class="comment"># 由于ml-latest-small中标签数据太多，因此借助其来扩充</span></span><br><span class="line">    _tags = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/all-tags.csv&quot;</span>, usecols=range(<span class="number">1</span>, <span class="number">3</span>)).dropna()</span><br><span class="line">    tags = _tags.groupby(<span class="string">&quot;movieId&quot;</span>).agg(list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载电影列表数据集</span></span><br><span class="line">    movies = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/movies.csv&quot;</span>, index_col=<span class="string">&quot;movieId&quot;</span>)</span><br><span class="line">    <span class="comment"># 将类别词分开</span></span><br><span class="line">    movies[<span class="string">&quot;genres&quot;</span>] = movies[<span class="string">&quot;genres&quot;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment"># 为每部电影匹配对应的标签数据，如果没有将会是NAN</span></span><br><span class="line">    movies_index = set(movies.index) &amp; set(tags.index)</span><br><span class="line">    new_tags = tags.loc[list(movies_index)]</span><br><span class="line">    ret = movies.join(new_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建电影数据集，包含电影Id、电影名称、类别、标签四个字段</span></span><br><span class="line">    <span class="comment"># 如果电影没有标签数据，那么就替换为空列表</span></span><br><span class="line">    movie_dataset = pd.DataFrame(</span><br><span class="line">        map(</span><br><span class="line">            <span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], x[<span class="number">2</span>]+x[<span class="number">3</span>]) <span class="keyword">if</span> x[<span class="number">3</span>] <span class="keyword">is</span> <span class="keyword">not</span> np.nan <span class="keyword">else</span> (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], []), ret.itertuples())</span><br><span class="line">        , columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tags&quot;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    movie_dataset.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line"></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    _movie_profile = []</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(movie_dataset.itertuples()):</span><br><span class="line">        mid = data[<span class="number">0</span>]</span><br><span class="line">        title = data[<span class="number">1</span>]</span><br><span class="line">        genres = data[<span class="number">2</span>]</span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        movie_tags = sorted(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        topN_tags_weights = dict(map(<span class="keyword">lambda</span> x: (dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line">        <span class="comment"># 将类别词的添加进去，并设置权重值为1.0</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">            topN_tags_weights[g] = <span class="number">1.0</span></span><br><span class="line">        topN_tags = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> topN_tags_weights.items()]</span><br><span class="line">        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))</span><br><span class="line"></span><br><span class="line">    movie_profile = pd.DataFrame(_movie_profile, columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;profile&quot;</span>, <span class="string">&quot;weights&quot;</span>])</span><br><span class="line">    movie_profile.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">movie_profile = create_movie_profile(movie_dataset)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gensim, logging</span><br><span class="line"></span><br><span class="line">logging.basicConfig(format=<span class="string">&#x27;%(asctime)s : %(levelname)s : %(message)s&#x27;</span>, level=logging.INFO)</span><br><span class="line"></span><br><span class="line">sentences = list(movie_profile[<span class="string">&quot;profile&quot;</span>].values)</span><br><span class="line"></span><br><span class="line">model = gensim.models.Word2Vec(sentences, window=<span class="number">3</span>, min_count=<span class="number">1</span>, iter=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    words = input(<span class="string">&quot;words: &quot;</span>)  <span class="comment"># action</span></span><br><span class="line">    ret = model.wv.most_similar(positive=[words], topn=<span class="number">10</span>)</span><br><span class="line">    print(ret)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><p>Doc2Vec是建立在Word2Vec上的，用于直接计算以文档为单位的文档向量，这里我们将一部电影的所有标签词，作为整个文档，这样可以计算出每部电影的向量，通过计算向量之间的距离，来判断用于计算电影之间的相似程度。</p><p>这样可以解决物品冷启动问题</p><h4 id="Doc2Vec使用"><a href="#Doc2Vec使用" class="headerlink" title="Doc2Vec使用"></a>Doc2Vec使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_dataset</span>():</span></span><br><span class="line">    <span class="comment"># 加载基于所有电影的标签</span></span><br><span class="line">    <span class="comment"># all-tags.csv来自ml-latest数据集中</span></span><br><span class="line">    <span class="comment"># 由于ml-latest-small中标签数据太多，因此借助其来扩充</span></span><br><span class="line">    _tags = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/all-tags.csv&quot;</span>, usecols=range(<span class="number">1</span>, <span class="number">3</span>)).dropna()</span><br><span class="line">    tags = _tags.groupby(<span class="string">&quot;movieId&quot;</span>).agg(list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载电影列表数据集</span></span><br><span class="line">    movies = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/movies.csv&quot;</span>, index_col=<span class="string">&quot;movieId&quot;</span>)</span><br><span class="line">    <span class="comment"># 将类别词分开</span></span><br><span class="line">    movies[<span class="string">&quot;genres&quot;</span>] = movies[<span class="string">&quot;genres&quot;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment"># 为每部电影匹配对应的标签数据，如果没有将会是NAN</span></span><br><span class="line">    movies_index = set(movies.index) &amp; set(tags.index)</span><br><span class="line">    new_tags = tags.loc[list(movies_index)]</span><br><span class="line">    ret = movies.join(new_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建电影数据集，包含电影Id、电影名称、类别、标签四个字段</span></span><br><span class="line">    <span class="comment"># 如果电影没有标签数据，那么就替换为空列表</span></span><br><span class="line">    movie_dataset = pd.DataFrame(</span><br><span class="line">        map(</span><br><span class="line">            <span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], x[<span class="number">2</span>]+x[<span class="number">3</span>]) <span class="keyword">if</span> x[<span class="number">3</span>] <span class="keyword">is</span> <span class="keyword">not</span> np.nan <span class="keyword">else</span> (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], []), ret.itertuples())</span><br><span class="line">        , columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tags&quot;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    movie_dataset.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line"></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    _movie_profile = []</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(movie_dataset.itertuples()):</span><br><span class="line">        mid = data[<span class="number">0</span>]</span><br><span class="line">        title = data[<span class="number">1</span>]</span><br><span class="line">        genres = data[<span class="number">2</span>]</span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        movie_tags = sorted(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        topN_tags_weights = dict(map(<span class="keyword">lambda</span> x: (dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line">        <span class="comment"># 将类别词的添加进去，并设置权重值为1.0</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">            topN_tags_weights[g] = <span class="number">1.0</span></span><br><span class="line">        topN_tags = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> topN_tags_weights.items()]</span><br><span class="line">        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))</span><br><span class="line"></span><br><span class="line">    movie_profile = pd.DataFrame(_movie_profile, columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;profile&quot;</span>, <span class="string">&quot;weights&quot;</span>])</span><br><span class="line">    movie_profile.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">movie_profile = create_movie_profile(movie_dataset)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gensim, logging</span><br><span class="line"><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> Doc2Vec, TaggedDocument</span><br><span class="line"></span><br><span class="line">logging.basicConfig(format=<span class="string">&#x27;%(asctime)s : %(levelname)s : %(message)s&#x27;</span>, level=logging.INFO)</span><br><span class="line"></span><br><span class="line">documents = [TaggedDocument(words, [movie_id]) <span class="keyword">for</span> movie_id, words <span class="keyword">in</span> movie_profile[<span class="string">&quot;profile&quot;</span>].iteritems()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型并保存</span></span><br><span class="line">model = Doc2Vec(documents, vector_size=<span class="number">100</span>, window=<span class="number">3</span>, min_count=<span class="number">1</span>, workers=<span class="number">4</span>, epochs=<span class="number">20</span>)</span><br><span class="line"><span class="keyword">from</span> gensim.test.utils <span class="keyword">import</span> get_tmpfile</span><br><span class="line">fname = get_tmpfile(<span class="string">&quot;my_doc2vec_model&quot;</span>)</span><br><span class="line">model.save(fname)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">words = movie_profile[<span class="string">&quot;profile&quot;</span>].loc[<span class="number">6</span>]</span><br><span class="line">print(words)</span><br><span class="line">inferred_vector = model.infer_vector(words)</span><br><span class="line">sims = model.docvecs.most_similar([inferred_vector], topn=<span class="number">10</span>)</span><br><span class="line">print(sims)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(9)  基于内容的电影推荐：用户画像</title>
      <link href="2019/03/15/09_%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90(ContentBased)_%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/"/>
      <url>2019/03/15/09_%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90(ContentBased)_%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于内容的电影推荐：用户画像"><a href="#基于内容的电影推荐：用户画像" class="headerlink" title="基于内容的电影推荐：用户画像"></a>基于内容的电影推荐：用户画像</h2><p>用户画像构建步骤：</p><ul><li>根据用户的评分历史，结合物品画像，将有观影记录的电影的画像标签作为初始标签反打到用户身上</li><li>通过对用户观影标签的次数进行统计，计算用户的每个初始标签的权重值，排序后选取TOP-N作为用户最终的画像标签</li></ul><h4 id="用户画像建立"><a href="#用户画像建立" class="headerlink" title="用户画像建立"></a>用户画像建立</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">user profile画像建立：</span></span><br><span class="line"><span class="string">1. 提取用户观看列表</span></span><br><span class="line"><span class="string">2. 根据观看列表和物品画像为用户匹配关键词，并统计词频</span></span><br><span class="line"><span class="string">3. 根据词频排序，最多保留TOP-k个词，这里K设为100，作为用户的标签</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_user_profile</span>():</span></span><br><span class="line">    watch_record = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=range(<span class="number">2</span>), dtype=&#123;<span class="string">&quot;userId&quot;</span>:np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32&#125;)</span><br><span class="line"></span><br><span class="line">    watch_record = watch_record.groupby(<span class="string">&quot;userId&quot;</span>).agg(list)</span><br><span class="line">    <span class="comment"># print(watch_record)</span></span><br><span class="line"></span><br><span class="line">    movie_dataset = get_movie_dataset()</span><br><span class="line">    movie_profile = create_movie_profile(movie_dataset)</span><br><span class="line"></span><br><span class="line">    user_profile = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> uid, mids <span class="keyword">in</span> watch_record.itertuples():</span><br><span class="line">        record_movie_prifole = movie_profile.loc[list(mids)]</span><br><span class="line">        counter = collections.Counter(reduce(<span class="keyword">lambda</span> x, y: list(x)+list(y), record_movie_prifole[<span class="string">&quot;profile&quot;</span>].values))</span><br><span class="line">        <span class="comment"># 兴趣词</span></span><br><span class="line">        interest_words = counter.most_common(<span class="number">50</span>)</span><br><span class="line">        maxcount = interest_words[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">        interest_words = [(w,round(c/maxcount, <span class="number">4</span>)) <span class="keyword">for</span> w,c <span class="keyword">in</span> interest_words]</span><br><span class="line">        user_profile[uid] = interest_words</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> user_profile</span><br><span class="line"></span><br><span class="line">user_profile = create_user_profile()</span><br><span class="line">pprint(user_profile)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(10) 基于内容的电影推荐：为用户产生TOP-N推荐结果</title>
      <link href="2019/03/15/10_%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90(ContentBased)_TOP-N%E7%94%A8%E6%88%B7%E6%8E%A8%E8%8D%90/"/>
      <url>2019/03/15/10_%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90(ContentBased)_TOP-N%E7%94%A8%E6%88%B7%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于内容的电影推荐：为用户产生TOP-N推荐结果"><a href="#基于内容的电影推荐：为用户产生TOP-N推荐结果" class="headerlink" title="基于内容的电影推荐：为用户产生TOP-N推荐结果"></a>基于内容的电影推荐：为用户产生TOP-N推荐结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">user_profile = create_user_profile()</span><br><span class="line"></span><br><span class="line">watch_record = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=range(<span class="number">2</span>),dtype=&#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32&#125;)</span><br><span class="line"></span><br><span class="line">watch_record = watch_record.groupby(<span class="string">&quot;userId&quot;</span>).agg(list)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> uid, interest_words <span class="keyword">in</span> user_profile.items():</span><br><span class="line">    result_table = &#123;&#125; <span class="comment"># 电影id:[0.2,0.5,0.7]</span></span><br><span class="line">    <span class="keyword">for</span> interest_word, interest_weight <span class="keyword">in</span> interest_words:</span><br><span class="line">        related_movies = inverted_table[interest_word]</span><br><span class="line">        <span class="keyword">for</span> mid, related_weight <span class="keyword">in</span> related_movies:</span><br><span class="line">            _ = result_table.get(mid, [])</span><br><span class="line">            _.append(interest_weight)    <span class="comment"># 只考虑用户的兴趣程度</span></span><br><span class="line">            <span class="comment"># _.append(related_weight)    # 只考虑兴趣词与电影的关联程度</span></span><br><span class="line">            <span class="comment"># _.append(interest_weight*related_weight)    # 二者都考虑</span></span><br><span class="line">            result_table.setdefault(mid, _)</span><br><span class="line"></span><br><span class="line">    rs_result = map(<span class="keyword">lambda</span> x: (x[<span class="number">0</span>], sum(x[<span class="number">1</span>])), result_table.items())</span><br><span class="line">    rs_result = sorted(rs_result, key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">100</span>]</span><br><span class="line">    print(uid)</span><br><span class="line">    pprint(rs_result)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 历史数据  ==&gt;  历史兴趣程度 ==&gt;  历史推荐结果       离线推荐    离线计算</span></span><br><span class="line">    <span class="comment"># 在线推荐 ===&gt;    娱乐(王思聪)   ===&gt;   我 ==&gt;  王思聪 100%  </span></span><br><span class="line">    <span class="comment"># 近线：最近1天、3天、7天           实时计算</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(1)_ 基于模型的协同过滤推荐</title>
      <link href="2019/03/10/01_%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/"/>
      <url>2019/03/10/01_%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h4 id="Model-Based-协同过滤算法"><a href="#Model-Based-协同过滤算法" class="headerlink" title="Model-Based 协同过滤算法"></a>Model-Based 协同过滤算法</h4><p>随着机器学习技术的逐渐发展与完善，推荐系统也逐渐运用机器学习的思想来进行推荐。将机器学习应用到推荐系统中的方案真是不胜枚举。以下对Model-Based CF算法做一个大致的分类：</p><ul><li>基于分类算法、回归算法、聚类算法</li><li>基于矩阵分解的推荐</li><li>基于神经网络算法</li><li>基于图模型算法</li></ul><p>接下来我们重点学习以下几种应用较多的方案：</p><ul><li><strong>基于K最近邻的协同过滤推荐</strong></li><li><strong>基于回归模型的协同过滤推荐</strong></li><li><strong>基于矩阵分解的协同过滤推荐</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 推荐算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Memstore Flush 机制</title>
      <link href="2019/02/28/HBase%20-Memstore%20Flush/"/>
      <url>2019/02/28/HBase%20-Memstore%20Flush/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Region 是 HBase 集群负载均衡和数据分发的基本单元。当 HBase 中表的容量非常庞大时，用户就需要将表中的内容分布到多台机器上。需要根据行键的值对表中的行进行划分，每个行区间构成一个 Region，一个 Region 包含了位于某个阈值区间的所有数据。</p><a id="more"></a> <p>当 MemStore 中的数据量达到阈值，就将数据 Flush 到 HDFS 中，以 Storefile 形式存储</p><h2 id="Flush-时机"><a href="#Flush-时机" class="headerlink" title="Flush 时机"></a>Flush 时机</h2><ol><li><p><strong>Region 中所有 MemStore 占用的内存超过相关阈值</strong></p><p>当一个 Region 中所有 MemStore 占用的内存（包括 OnHeap + OffHeap）大小超过刷写阈值的时候会触发一次刷写，这个阈值由 <code>hbase.hregion.memstore.flush.size</code> 参数控制，默认为128MB。我们每次调用 put、delete 等操作都会检查的这个条件的。</p></li><li><p><strong>整个 RegionServer 的 MemStore 占用内存总和大于相关阈值</strong></p><p>HBase 为 RegionServer 的 MemStore 分配了一定的写缓存，大小等于 （RegionServer 占用的堆内存大小）* <code>hbase.regionserver.global.memstore.size</code>。</p><p><code>hbase.regionserver.global.memstore.size</code> 的默认值是 0.4，也就是说写缓存大概占用 RegionServer 整个 JVM 内存使用量的 40%。</p><p>如果整个 RegionServer 的 MemStore 占用内存总和大于 <code>hbase.regionserver.global.memstore.size.lower.limit</code> * <code>hbase.regionserver.global.memstore.size</code> * hbase_heapsize 的时候，将会触发 MemStore 的刷写。其中 <code>hbase.regionserver.global.memstore.size.lower.limit</code> 的默认值为 0.95。</p><p><font color='grey'>举个例子，如果我们 HBase 堆内存总共是 32G，按照默认的比例，那么触发 RegionServer 级别的 Flush 是 RS 中所有的 MemStore 占用内存为：32 * 0.4 * 0.95 = 12.16G。</font></p><p>RegionServer 级别的 Flush 策略是每次找到 RegionServer 中占用内存最大的 Region 对他进行刷写，这个操作是循环进行的，直到总体内存的占用低于全局 MemStore 刷写下<br>限（hbase.regionserver.global.memstore.size.lower.limit * hbase.regionserver.global.memstore.size * hbase_heapsize）才会停止。</p><p><strong>需要注意的是，如果达到了 RegionServer 级别的 Flush，那么当前 RegionServer 的所有写操作将会被阻塞。</strong></p></li><li><p><strong>WAL 数量大于相关阈值</strong></p><p>WAL（Write-ahead log，预写日志）用来解决宕机之后的操作恢复问题的。数据到达 Region 的时候是先写入 WAL，然后再被写到 Memstore 的。如果 WAL 的数量越来越大，这就意味着 MemStore 中未持久化到磁盘的数据越来越多。当 RegionServer 挂掉的时候，恢复时间将会变长，所以有必要在 WAL 到达一定的数量时进行一次刷写操作。</p></li></ol><h2 id="触发-MemStore-刷写操作"><a href="#触发-MemStore-刷写操作" class="headerlink" title="触发 MemStore 刷写操作"></a>触发 MemStore 刷写操作</h2><p>put、delete、append、increment、调用 flush 命令、Region 分裂、Region Merge、bulkLoad HFiles 以及给表做快照操作都会对上面的相关条件做检查，以便判断要不要做刷写操作。</p><h2 id="MemStore-刷写策略"><a href="#MemStore-刷写策略" class="headerlink" title="MemStore 刷写策略"></a>MemStore 刷写策略</h2><p>在 HBase 1.1 之前，MemStore 刷写是 Region 级别的。就是说，如果要刷写某个 MemStore ，MemStore 所在的 Region 中其他 MemStore 也是会被一起刷写的！这会造成一定的问题，比如小文件问题针对这个问题，Hbase 引入列族级别的刷写。我们可以通过 <code>hbase.regionserver.flush.policy</code> 参数选择不同的刷写策略。</p><p><strong>FlushAllStoresPolicy</strong></p><p>这种刷写策略实现最简单，直接返回当前 Region 对应的所有 MemStore。也就是每次刷写都是对 Region 里面所有的 MemStore 进行 Flush ，这个行为和 HBase 1.1 之前是一样的。</p><p><strong>FlushAllLargeStoresPolicy</strong></p><p>在 HBase 2.0 之前版本是 <code>FlushLargeStoresPolicy</code>，后面被拆分成分 <code>FlushAllLargeStoresPolicy</code>和<code>FlushNonSloppyStoresFirstPolicy</code>，参见 <a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0xNDkyMA==&article=true">HBASE-14920</a>。</p><p>这种策略会先判断 Region 中每个 MemStore 的使用内存（ＯnHeap +　OffHeap）是否大于某个阀值，大于这个阀值的 MemStore 将会被刷写。阀值的计算是由 <code>hbase.hregion.percolumnfamilyflush.size.lower.bound</code>、<code>hbase.hregion.percolumnfamilyflush.size.lower.bound.min</code> 以及 <code>hbase.hregion.memstore.flush.size</code> 参数决定的。</p><p><strong>FlushNonSloppyStoresFirstPolicy</strong></p><p>HBase 2.0 引入了 in-memory compaction，参见 <a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0xMzQwOA==&article=true">HBASE-13408</a>。如果我们对相关列族 <code>hbase.hregion.compacting.memstore.type</code> 参数的值不是 <code>NONE</code>，那么这个 MemStore 的 <code>isSloppyMemStore</code> 值就是 true，否则就是 false。</p><p><code>FlushNonSloppyStoresFirstPolicy</code> 策略将 Region 中的 MemStore 按照 <code>isSloppyMemStore</code> 分到两个 HashSet 里面（<code>sloppyStores</code> 和 <code>regularStores</code>）。然后</p><ul><li>判断 <code>regularStores</code> 里面是否有 MemStore 内存占用大于相关阀值的 MemStore ，有的话就会对这些 MemStore 进行刷写，其他的不做处理，这个阀值计算和 <code>FlushAllLargeStoresPolicy</code> 的阀值计算逻辑一致。</li><li>如果 <code>regularStores</code> 里面没有 MemStore 内存占用大于相关阀值的 MemStore，这时候就开始在 <code>sloppyStores</code> 里面寻找是否有 MemStore 内存占用大于相关阀值的 MemStore，有的话就会对这些 MemStore 进行刷写，其他的不做处理。</li><li>如果上面 <code>sloppyStores</code> 和 <code>regularStores</code> 都没有满足条件的 MemStore 需要刷写，这时候就 <code>FlushNonSloppyStoresFirstPolicy</code> 策略久退化成 <code>FlushAllStoresPolicy</code> 策略了。</li></ul><h2 id="刷写过程"><a href="#刷写过程" class="headerlink" title="刷写过程"></a>刷写过程</h2><p>从上面的实现可以看出，Flush 操作主要分以下几步做的</p><ul><li><strong><em>prepareFlush 阶段\</em></strong>：刷写的第一步是对 MemStore 做 snapshot，为了防止刷写过程中更新的数据同时在 snapshot 和 MemStore 中而造成后续处理的困难，所以在刷写期间需要持有 updateLock 。持有了 updateLock 之后，这将阻塞客户端的写操作。所以只在创建 snapshot 期间持有 updateLock，而且 snapshot 的创建非常快，所以此锁期间对客户的影响一般非常小。对 MemStore 做 snapshot 是 <code>internalPrepareFlushCache</code> 里面进行的。</li><li><strong><em>flushCache 阶段\</em></strong>：如果创建快照没问题，那么返回的 <code>result.result</code> 将为 null。这时候我们就可以进行下一步 <code>internalFlushCacheAndCommit</code>。其实 <code>internalFlushCacheAndCommit</code> 里面包含两个步骤：<code>flushCache</code> 和 <code>commit</code> 阶段。flushCache 阶段其实就是将 <code>prepareFlush</code> 阶段创建好的快照写到临时文件里面，临时文件是存放在对应 Region 文件夹下面的 <code>.tmp</code> 目录里面。</li><li><strong><em>commit 阶段\</em></strong>：将 <code>flushCache</code> 阶段生产的临时文件移到（<code>rename</code>）对应的列族目录下面，并做一些清理工作，比如删除第一步生成的 snapshot。</li></ul>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Memstore Flush机制</title>
      <link href="2019/02/28/HBase%20-Memstore%20Flush(1)/"/>
      <url>2019/02/28/HBase%20-Memstore%20Flush(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Region 是 HBase 集群负载均衡和数据分发的基本单元。当 HBase 中表的容量非常庞大时，用户就需要将表中的内容分布到多台机器上。需要根据行键的值对表中的行进行划分，每个行区间构成一个 Region，一个 Region 包含了位于某个阈值区间的所有数据。</p><a id="more"></a> <p>当 MemStore 中的数据量达到阈值，就将数据 Flush 到 HDFS 中，以 Storefile 形式存储</p><h2 id="Flush-时机"><a href="#Flush-时机" class="headerlink" title="Flush 时机"></a>Flush 时机</h2><ol><li><p><strong>Region 中所有 MemStore 占用的内存超过相关阈值</strong></p><p>当一个 Region 中所有 MemStore 占用的内存（包括 OnHeap + OffHeap）大小超过刷写阈值的时候会触发一次刷写，这个阈值由 <code>hbase.hregion.memstore.flush.size</code> 参数控制，默认为128MB。我们每次调用 put、delete 等操作都会检查的这个条件的。</p></li><li><p><strong>整个 RegionServer 的 MemStore 占用内存总和大于相关阈值</strong></p><p>HBase 为 RegionServer 的 MemStore 分配了一定的写缓存，大小等于 （RegionServer 占用的堆内存大小）* <code>hbase.regionserver.global.memstore.size</code>。</p><p><code>hbase.regionserver.global.memstore.size</code> 的默认值是 0.4，也就是说写缓存大概占用 RegionServer 整个 JVM 内存使用量的 40%。</p><p>如果整个 RegionServer 的 MemStore 占用内存总和大于 <code>hbase.regionserver.global.memstore.size.lower.limit</code> * <code>hbase.regionserver.global.memstore.size</code> * hbase_heapsize 的时候，将会触发 MemStore 的刷写。其中 <code>hbase.regionserver.global.memstore.size.lower.limit</code> 的默认值为 0.95。</p><p><font color='grey'>举个例子，如果我们 HBase 堆内存总共是 32G，按照默认的比例，那么触发 RegionServer 级别的 Flush 是 RS 中所有的 MemStore 占用内存为：32 * 0.4 * 0.95 = 12.16G。</font></p><p>RegionServer 级别的 Flush 策略是每次找到 RegionServer 中占用内存最大的 Region 对他进行刷写，这个操作是循环进行的，直到总体内存的占用低于全局 MemStore 刷写下<br>限（hbase.regionserver.global.memstore.size.lower.limit * hbase.regionserver.global.memstore.size * hbase_heapsize）才会停止。</p><p><strong>需要注意的是，如果达到了 RegionServer 级别的 Flush，那么当前 RegionServer 的所有写操作将会被阻塞。</strong></p></li><li><p><strong>WAL 数量大于相关阈值</strong></p><p>WAL（Write-ahead log，预写日志）用来解决宕机之后的操作恢复问题的。数据到达 Region 的时候是先写入 WAL，然后再被写到 Memstore 的。如果 WAL 的数量越来越大，这就意味着 MemStore 中未持久化到磁盘的数据越来越多。当 RegionServer 挂掉的时候，恢复时间将会变长，所以有必要在 WAL 到达一定的数量时进行一次刷写操作。</p></li></ol><h2 id="触发-MemStore-刷写操作"><a href="#触发-MemStore-刷写操作" class="headerlink" title="触发 MemStore 刷写操作"></a>触发 MemStore 刷写操作</h2><p>put、delete、append、increment、调用 flush 命令、Region 分裂、Region Merge、bulkLoad HFiles 以及给表做快照操作都会对上面的相关条件做检查，以便判断要不要做刷写操作。</p><h2 id="MemStore-刷写策略"><a href="#MemStore-刷写策略" class="headerlink" title="MemStore 刷写策略"></a>MemStore 刷写策略</h2><p>在 HBase 1.1 之前，MemStore 刷写是 Region 级别的。就是说，如果要刷写某个 MemStore ，MemStore 所在的 Region 中其他 MemStore 也是会被一起刷写的！这会造成一定的问题，比如小文件问题针对这个问题，Hbase 引入列族级别的刷写。我们可以通过 <code>hbase.regionserver.flush.policy</code> 参数选择不同的刷写策略。</p><p><strong>FlushAllStoresPolicy</strong></p><p>这种刷写策略实现最简单，直接返回当前 Region 对应的所有 MemStore。也就是每次刷写都是对 Region 里面所有的 MemStore 进行 Flush ，这个行为和 HBase 1.1 之前是一样的。</p><p><strong>FlushAllLargeStoresPolicy</strong></p><p>在 HBase 2.0 之前版本是 <code>FlushLargeStoresPolicy</code>，后面被拆分成分 <code>FlushAllLargeStoresPolicy</code>和<code>FlushNonSloppyStoresFirstPolicy</code>，参见 <a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0xNDkyMA==&article=true">HBASE-14920</a>。</p><p>这种策略会先判断 Region 中每个 MemStore 的使用内存（ＯnHeap +　OffHeap）是否大于某个阀值，大于这个阀值的 MemStore 将会被刷写。阀值的计算是由 <code>hbase.hregion.percolumnfamilyflush.size.lower.bound</code>、<code>hbase.hregion.percolumnfamilyflush.size.lower.bound.min</code> 以及 <code>hbase.hregion.memstore.flush.size</code> 参数决定的。</p><p><strong>FlushNonSloppyStoresFirstPolicy</strong></p><p>HBase 2.0 引入了 in-memory compaction，参见 <a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0xMzQwOA==&article=true">HBASE-13408</a>。如果我们对相关列族 <code>hbase.hregion.compacting.memstore.type</code> 参数的值不是 <code>NONE</code>，那么这个 MemStore 的 <code>isSloppyMemStore</code> 值就是 true，否则就是 false。</p><p><code>FlushNonSloppyStoresFirstPolicy</code> 策略将 Region 中的 MemStore 按照 <code>isSloppyMemStore</code> 分到两个 HashSet 里面（<code>sloppyStores</code> 和 <code>regularStores</code>）。然后</p><ul><li>判断 <code>regularStores</code> 里面是否有 MemStore 内存占用大于相关阀值的 MemStore ，有的话就会对这些 MemStore 进行刷写，其他的不做处理，这个阀值计算和 <code>FlushAllLargeStoresPolicy</code> 的阀值计算逻辑一致。</li><li>如果 <code>regularStores</code> 里面没有 MemStore 内存占用大于相关阀值的 MemStore，这时候就开始在 <code>sloppyStores</code> 里面寻找是否有 MemStore 内存占用大于相关阀值的 MemStore，有的话就会对这些 MemStore 进行刷写，其他的不做处理。</li><li>如果上面 <code>sloppyStores</code> 和 <code>regularStores</code> 都没有满足条件的 MemStore 需要刷写，这时候就 <code>FlushNonSloppyStoresFirstPolicy</code> 策略久退化成 <code>FlushAllStoresPolicy</code> 策略了。</li></ul><h2 id="刷写过程"><a href="#刷写过程" class="headerlink" title="刷写过程"></a>刷写过程</h2><p>从上面的实现可以看出，Flush 操作主要分以下几步做的</p><ul><li><strong><em>prepareFlush 阶段\</em></strong>：刷写的第一步是对 MemStore 做 snapshot，为了防止刷写过程中更新的数据同时在 snapshot 和 MemStore 中而造成后续处理的困难，所以在刷写期间需要持有 updateLock 。持有了 updateLock 之后，这将阻塞客户端的写操作。所以只在创建 snapshot 期间持有 updateLock，而且 snapshot 的创建非常快，所以此锁期间对客户的影响一般非常小。对 MemStore 做 snapshot 是 <code>internalPrepareFlushCache</code> 里面进行的。</li><li><strong><em>flushCache 阶段\</em></strong>：如果创建快照没问题，那么返回的 <code>result.result</code> 将为 null。这时候我们就可以进行下一步 <code>internalFlushCacheAndCommit</code>。其实 <code>internalFlushCacheAndCommit</code> 里面包含两个步骤：<code>flushCache</code> 和 <code>commit</code> 阶段。flushCache 阶段其实就是将 <code>prepareFlush</code> 阶段创建好的快照写到临时文件里面，临时文件是存放在对应 Region 文件夹下面的 <code>.tmp</code> 目录里面。</li><li><strong><em>commit 阶段\</em></strong>：将 <code>flushCache</code> 阶段生产的临时文件移到（<code>rename</code>）对应的列族目录下面，并做一些清理工作，比如删除第一步生成的 snapshot。</li></ul>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>列族设计</title>
      <link href="2019/02/28/HBase%20-%E5%88%97%E6%97%8F%E8%AE%BE%E8%AE%A1(1)/"/>
      <url>2019/02/28/HBase%20-%E5%88%97%E6%97%8F%E8%AE%BE%E8%AE%A1(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>不要在一张表中定义太多的列族。目前HBase并不能很好的处理2<del>3以上的列族，HBase 中每张表的列族个数建议设在1</del>3之间。</p><a id="more"></a><h2 id="列族数对-Flush-的影响"><a href="#列族数对-Flush-的影响" class="headerlink" title="列族数对 Flush 的影响"></a>列族数对 Flush 的影响</h2><p>在 HBase 中，调用 API 往对应的表插入数据是会写到 MemStore 的，而 MemStore 是一种内存结构，每个列族对应一个 MemStore（和零个或多个 HFile）。如果我们的表有两个列族，那么相应的 Region 中存在两个 MemStore。</p><p>越多的列族，将会导致内存中存在越多的 MemStore；而储存在 MemStore 中的数据在满足一定条件的时候将会进行 Flush 操作；每次 Flush 的时候，每个 MemStore 将在磁盘生产一个 HFile 文件</p><p>这样会导致越多的列族最终持久化到磁盘的 HFile 越多。当前 Flush 操作是 Region 级别的（从HBase 1.1，HBase 2.0 开始 Flush 已经可以设置成列族级别的了），也就是说， Region 中某个 MemStore 被 Flush，同一个 Region 的其他 MemStore 也会进行 Flush 操作。当表有很多列族，而且列族之间数据不均匀，比如一个列族有100W行，一个列族只有10行，这样会导致持久化到磁盘的文件数很多，同时有很多小文件，而且每次 Flush 操作也涉及到一定的 IO 操作。</p><p>为了解决每次 Flush 都对整个 Region 中 MemStore 进行的，<a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0xMDIwMQ==&article=true">HBASE-10201</a>/<a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0zMTQ5&article=true">HBASE-3149</a>引入了对 Flush 策略进行选择的功能（<code>hbase.regionserver.flush.policy</code>），可以仅对超过阈值（<code>hbase.hregion.percolumnfamilyflush.size.lower.bound.min</code>）的 MemStore 进行 Flush 操作。但是如果没有 MemStore 大于这个阈值，还是会对所有的 MemStore 进行 Flush 操作。</p><p>如果我们的列族数过多，这可能会导致触发 RegionServer 级别的 Flush 操作；这将会导致落在该 RegionServer 上的更新操作被阻塞，而且阻塞时间可能会达到分钟级别。</p><h2 id="列族数对-Split-的影响"><a href="#列族数对-Split-的影响" class="headerlink" title="列族数对 Split 的影响"></a>列族数对 Split 的影响</h2><p>当 HBase 表中某个 Region 过大（比如大于 <code>hbase.hregion.max.filesize</code> 配置的大小。<strong>当然，Region 分裂并不是说整个 Region 大小加起来大于 <code>hbase.hregion.max.filesize</code> 就拆分，而是说 Region 中某个最大的 Store/HFile/storeFile 大于 <code>hbase.hregion.max.filesize</code> 才会触发 Region 拆分的</strong>），会被拆分成两个。如果我们有很多个列族，而这些列族之间的数据量相差悬殊，比如有些列族有 100W 行，而有些列族只有10行，这样在 Region Split 的时候会导致原本数据量很小的 HFile 文件进一步被拆分，从而产生更多的小文件。</p><p><strong>注意，Region Split 是针对所有的列族进行的，这样做的目的是同一行的数据即使在 Split 后也是存在同一个 Region 的。</strong></p><h2 id="列族数对-Compaction-的影响"><a href="#列族数对-Compaction-的影响" class="headerlink" title="列族数对 Compaction 的影响"></a>列族数对 Compaction 的影响</h2><p>与 Flush 操作一样，目前 HBase 的 Compaction 操作也是 Region 级别的，过多的列族也会产生不必要的 IO。</p><h2 id="列族数对-HDFS-的影响"><a href="#列族数对-HDFS-的影响" class="headerlink" title="列族数对 HDFS 的影响"></a>列族数对 HDFS 的影响</h2><p>HDFS 其实对一个目录下的文件数有限制的（<code>dfs.namenode.fs-limits.max-directory-items</code>）。</p><p>如果我们有 N 个列族，M 个 Region，那么我们持久化到 HDFS 至少会产生 <code>N*M</code> 个文件；而每个列族对应底层的 HFile 文件往往不止一个，我们假设为 K 个，那么最终表在 HDFS 目录下的文件数将是 <code>N*M*</code>K，这可能会操作 HDFS 的限制。</p><h2 id="列族数对-RegionServer-内存的影响"><a href="#列族数对-RegionServer-内存的影响" class="headerlink" title="列族数对 RegionServer 内存的影响"></a>列族数对 RegionServer 内存的影响</h2><p>一个列族在 RegionServer 中对应于一个 MemStore。而 HBase 从 0.90.1 版本开始引入了 MSLAB（Memstore-Local Allocation Buffers，参考<a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0zNDU1&article=true">HBASE-3455</a>），这个功能默认是开启的（通过<code>hbase.hregion.memstore.mslab.enabled</code>），这使得每个 MemStore 在内存占用了 2MB （通过<code>hbase.hregion.memstore.mslab.chunksize</code> 配置）的 buffer。如果我们有很多的列族，而且一般一个 RegionServer 上会存在很多个 Region，这么算起来 MemStore 的缓存就会占用很多的内存。<strong>要注意的是，如果没有往 MemStore 里面写数据，那么 MemStore 的 MSLAB 是不占用空间的。</strong></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在设置列族之前，我们最好想想，有没有必要将不同的列放到不同的列族里面。如果没有必要最好放一个列族。如果真要设置多个列族，但是其中一些列族相对于其他列族数据量相差非常悬殊，比如1000W相比100行，是不是考虑用另外一张表来存储相对小的列族。</p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>列族设计</title>
      <link href="2019/02/28/HBase%20-%E5%88%97%E6%97%8F%E8%AE%BE%E8%AE%A1/"/>
      <url>2019/02/28/HBase%20-%E5%88%97%E6%97%8F%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>不要在一张表中定义太多的列族。目前HBase并不能很好的处理2<del>3以上的列族，HBase 中每张表的列族个数建议设在1</del>3之间。</p><a id="more"></a><h2 id="列族数对-Flush-的影响"><a href="#列族数对-Flush-的影响" class="headerlink" title="列族数对 Flush 的影响"></a>列族数对 Flush 的影响</h2><p>在 HBase 中，调用 API 往对应的表插入数据是会写到 MemStore 的，而 MemStore 是一种内存结构，每个列族对应一个 MemStore（和零个或多个 HFile）。如果我们的表有两个列族，那么相应的 Region 中存在两个 MemStore。</p><p>越多的列族，将会导致内存中存在越多的 MemStore；而储存在 MemStore 中的数据在满足一定条件的时候将会进行 Flush 操作；每次 Flush 的时候，每个 MemStore 将在磁盘生产一个 HFile 文件</p><p>这样会导致越多的列族最终持久化到磁盘的 HFile 越多。当前 Flush 操作是 Region 级别的（从HBase 1.1，HBase 2.0 开始 Flush 已经可以设置成列族级别的了），也就是说， Region 中某个 MemStore 被 Flush，同一个 Region 的其他 MemStore 也会进行 Flush 操作。当表有很多列族，而且列族之间数据不均匀，比如一个列族有100W行，一个列族只有10行，这样会导致持久化到磁盘的文件数很多，同时有很多小文件，而且每次 Flush 操作也涉及到一定的 IO 操作。</p><p>为了解决每次 Flush 都对整个 Region 中 MemStore 进行的，<a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0xMDIwMQ==&article=true">HBASE-10201</a>/<a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0zMTQ5&article=true">HBASE-3149</a>引入了对 Flush 策略进行选择的功能（<code>hbase.regionserver.flush.policy</code>），可以仅对超过阈值（<code>hbase.hregion.percolumnfamilyflush.size.lower.bound.min</code>）的 MemStore 进行 Flush 操作。但是如果没有 MemStore 大于这个阈值，还是会对所有的 MemStore 进行 Flush 操作。</p><p>如果我们的列族数过多，这可能会导致触发 RegionServer 级别的 Flush 操作；这将会导致落在该 RegionServer 上的更新操作被阻塞，而且阻塞时间可能会达到分钟级别。</p><h2 id="列族数对-Split-的影响"><a href="#列族数对-Split-的影响" class="headerlink" title="列族数对 Split 的影响"></a>列族数对 Split 的影响</h2><p>当 HBase 表中某个 Region 过大（比如大于 <code>hbase.hregion.max.filesize</code> 配置的大小。<strong>当然，Region 分裂并不是说整个 Region 大小加起来大于 <code>hbase.hregion.max.filesize</code> 就拆分，而是说 Region 中某个最大的 Store/HFile/storeFile 大于 <code>hbase.hregion.max.filesize</code> 才会触发 Region 拆分的</strong>），会被拆分成两个。如果我们有很多个列族，而这些列族之间的数据量相差悬殊，比如有些列族有 100W 行，而有些列族只有10行，这样在 Region Split 的时候会导致原本数据量很小的 HFile 文件进一步被拆分，从而产生更多的小文件。</p><p><strong>注意，Region Split 是针对所有的列族进行的，这样做的目的是同一行的数据即使在 Split 后也是存在同一个 Region 的。</strong></p><h2 id="列族数对-Compaction-的影响"><a href="#列族数对-Compaction-的影响" class="headerlink" title="列族数对 Compaction 的影响"></a>列族数对 Compaction 的影响</h2><p>与 Flush 操作一样，目前 HBase 的 Compaction 操作也是 Region 级别的，过多的列族也会产生不必要的 IO。</p><h2 id="列族数对-HDFS-的影响"><a href="#列族数对-HDFS-的影响" class="headerlink" title="列族数对 HDFS 的影响"></a>列族数对 HDFS 的影响</h2><p>HDFS 其实对一个目录下的文件数有限制的（<code>dfs.namenode.fs-limits.max-directory-items</code>）。</p><p>如果我们有 N 个列族，M 个 Region，那么我们持久化到 HDFS 至少会产生 <code>N*M</code> 个文件；而每个列族对应底层的 HFile 文件往往不止一个，我们假设为 K 个，那么最终表在 HDFS 目录下的文件数将是 <code>N*M*</code>K，这可能会操作 HDFS 的限制。</p><h2 id="列族数对-RegionServer-内存的影响"><a href="#列族数对-RegionServer-内存的影响" class="headerlink" title="列族数对 RegionServer 内存的影响"></a>列族数对 RegionServer 内存的影响</h2><p>一个列族在 RegionServer 中对应于一个 MemStore。而 HBase 从 0.90.1 版本开始引入了 MSLAB（Memstore-Local Allocation Buffers，参考<a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9IQkFTRS0zNDU1&article=true">HBASE-3455</a>），这个功能默认是开启的（通过<code>hbase.hregion.memstore.mslab.enabled</code>），这使得每个 MemStore 在内存占用了 2MB （通过<code>hbase.hregion.memstore.mslab.chunksize</code> 配置）的 buffer。如果我们有很多的列族，而且一般一个 RegionServer 上会存在很多个 Region，这么算起来 MemStore 的缓存就会占用很多的内存。<strong>要注意的是，如果没有往 MemStore 里面写数据，那么 MemStore 的 MSLAB 是不占用空间的。</strong></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在设置列族之前，我们最好想想，有没有必要将不同的列放到不同的列族里面。如果没有必要最好放一个列族。如果真要设置多个列族，但是其中一些列族相对于其他列族数据量相差非常悬殊，比如1000W相比100行，是不是考虑用另外一张表来存储相对小的列族。</p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Region 分区及定位</title>
      <link href="2019/02/26/HBase%20Region%E5%AE%9A%E4%BD%8D(1)/"/>
      <url>2019/02/26/HBase%20Region%E5%AE%9A%E4%BD%8D(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Region 是 HBase 集群负载均衡和数据分发的基本单元。当 HBase 中表的容量非常庞大时，用户就需要将表中的内容分布到多台机器上。需要根据行键的值对表中的行进行划分，每个行区间构成一个 Region，一个 Region 包含了位于某个阈值区间的所有数据。</p><a id="more"></a><h1 id="Region-定位"><a href="#Region-定位" class="headerlink" title="Region 定位"></a><strong>Region 定位</strong></h1><p>在 HBase 中，表的所有行都是按照 RowKey 的字典序排列的，表在行的方向上分割为多个分区（Region）</p><p>每张表一开始只有一个 Region，但是随着数据的插入，HBase 会根据一定的规则将表进行水平拆分，形成两个 Region。当表中的行越来越多时，就会产生越来越多的 Region，而这些 Region 无法存储到一台机器上时，则可将其分布存储到多台机器上。</p><p>Master 主服务器把不同的 Region 分配到不同的 RegionServer 上，同一个行键的 Region 不会被拆分到多个 RegionServer 上。通常在每个 RegionServer 上会放置 10 ~ 1000 个 Region。</p><p>客户端在插入、删除、查询数据时需要知道哪个 Region 服务器上存储所需的数据，这个查找 Region 的过程称为 Region 定位。</p><p>HBase 中的每个 Region 由三个要素组成，包括 Region 所属的表、第一行和最后一行。其中，第一个 Region 没有首行，最后一个 Region 没有末行。每个 Region 都有一个 RegionlD 来标识它的唯一性</p><p><strong>Region 标识符就可以表示成 “表名+开始行键+RegionID”。</strong></p><img src="/images/hbase3.png" alt="" align="middle" style="zoom:60%;"/><h2 id="Meta-表"><a href="#Meta-表" class="headerlink" title="Meta 表"></a>Meta 表</h2><p><strong>有了 Region 标识符，就可以唯一标识每个 Region。为定位 Region 所在位置，可以构建一张映射表。</strong></p><p>映射表的每个条目包含两项内容，一项是 Region 标识符，另一项是 Region 服务器标识。这个条目就表示 Region 和 Region 服务器之间的对应关系，从而就可以使用户知道某个 Region 存储在哪个 Region 服务器中。这个映射表包含了关于 Region 的元数据，因此也被称为 “元数据表”，又名 “Meta表”。</p><p>Meta 表中的每一行记录了一个 Region 的信息。RowKey 包含表名、起始行键和时间戳信息，中间用逗号隔开，第一个 Region 的起始行键为空。时间戳之后用 <code>.</code> 隔开的为分区名称的编码字符串，该信息是由前面的表名、起始行键和时间戳进行字符串编码后形成的。</p><p>Meta 表里有一个列族 info。info 包含了三个列，分别为 RegioninfoServer, Serverstartcode以及 Server 。Regionlnfo中记录了 Region 的详细信息，包括行键范围 StartKey 和 EndKey、列族列表和属性。</p><p>Server 记录了管理该 Region 的 Region 服务器的地址，如 localhost:16201。Serverstartcode 记录了 Region 服务器开始托管该 Region 的时间。</p><p>当用户表特别大时，用户表的 Region 也会非常多。Meta 表存储了这些 Region 信息，也变得非常大。Meta 表也需要划分成多个 Region，每个 Meta 分区记录一部分用户表和分区管理的情况。</p><h2 id="Region-定位-1"><a href="#Region-定位-1" class="headerlink" title="Region 定位"></a>Region 定位</h2><h3 id="三层定位"><a href="#三层定位" class="headerlink" title="三层定位"></a>三层定位</h3><p>在 HBase 的早期设计中，Region 的查找是通过三层架构来进行查询的，即在集群中有一个总入口 ROOT 表，记录了 Meta 表分区信息及各个入口的地址。这个 ROOT 表存储在某个 RegionServer 上，但是它的地址保存在 ZooKeeper 中。</p><p>这种早期的三层架构通过先找到 ROOT 表，从中获取分区 Meta 表位置；然后再获取分区 Meta 表信息，找出 Region 所在的 Region 服务器。</p><h3 id="二层定位"><a href="#二层定位" class="headerlink" title="二层定位"></a>二层定位</h3><p>从 0.96 版本以后，三层架构被改为二层架构，去掉了 ROOT 表，同时 ZooKeeper 中的 /hbase/root-region-server 也被去掉。Meta 表所在的 Region 服务器信息直接存储在 ZooKeeper 中的 /hbase/meta-region-server 中。</p><p>客户端通过 ZooKeeper 获取 Meta 表分区存储的地址，首先在对应的 RegionServer 获取 Meta 表的信息，得到所需的表和行键所在的 Region 信息，然后从 Region 服务器上找到所需的数据。</p><p><strong><font color='red'>一般客户端获取 Region 信息后会进行缓存，用户下次再查询不必从 ZooKeeper 开始寻址。</font></strong></p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Region 分区及定位</title>
      <link href="2019/02/26/HBase%20Region%E5%AE%9A%E4%BD%8D/"/>
      <url>2019/02/26/HBase%20Region%E5%AE%9A%E4%BD%8D/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Region 是 HBase 集群负载均衡和数据分发的基本单元。当 HBase 中表的容量非常庞大时，用户就需要将表中的内容分布到多台机器上。需要根据行键的值对表中的行进行划分，每个行区间构成一个 Region，一个 Region 包含了位于某个阈值区间的所有数据。</p><a id="more"></a><h1 id="Region-定位"><a href="#Region-定位" class="headerlink" title="Region 定位"></a><strong>Region 定位</strong></h1><p>在 HBase 中，表的所有行都是按照 RowKey 的字典序排列的，表在行的方向上分割为多个分区（Region）</p><p>每张表一开始只有一个 Region，但是随着数据的插入，HBase 会根据一定的规则将表进行水平拆分，形成两个 Region。当表中的行越来越多时，就会产生越来越多的 Region，而这些 Region 无法存储到一台机器上时，则可将其分布存储到多台机器上。</p><p>Master 主服务器把不同的 Region 分配到不同的 RegionServer 上，同一个行键的 Region 不会被拆分到多个 RegionServer 上。通常在每个 RegionServer 上会放置 10 ~ 1000 个 Region。</p><p>客户端在插入、删除、查询数据时需要知道哪个 Region 服务器上存储所需的数据，这个查找 Region 的过程称为 Region 定位。</p><p>HBase 中的每个 Region 由三个要素组成，包括 Region 所属的表、第一行和最后一行。其中，第一个 Region 没有首行，最后一个 Region 没有末行。每个 Region 都有一个 RegionlD 来标识它的唯一性</p><p><strong>Region 标识符就可以表示成 “表名+开始行键+RegionID”。</strong></p><img src="/images/hbase3.png" alt="" align="middle" style="zoom:60%;"/><h2 id="Meta-表"><a href="#Meta-表" class="headerlink" title="Meta 表"></a>Meta 表</h2><p><strong>有了 Region 标识符，就可以唯一标识每个 Region。为定位 Region 所在位置，可以构建一张映射表。</strong></p><p>映射表的每个条目包含两项内容，一项是 Region 标识符，另一项是 Region 服务器标识。这个条目就表示 Region 和 Region 服务器之间的对应关系，从而就可以使用户知道某个 Region 存储在哪个 Region 服务器中。这个映射表包含了关于 Region 的元数据，因此也被称为 “元数据表”，又名 “Meta表”。</p><p>Meta 表中的每一行记录了一个 Region 的信息。RowKey 包含表名、起始行键和时间戳信息，中间用逗号隔开，第一个 Region 的起始行键为空。时间戳之后用 <code>.</code> 隔开的为分区名称的编码字符串，该信息是由前面的表名、起始行键和时间戳进行字符串编码后形成的。</p><p>Meta 表里有一个列族 info。info 包含了三个列，分别为 RegioninfoServer, Serverstartcode以及 Server 。Regionlnfo中记录了 Region 的详细信息，包括行键范围 StartKey 和 EndKey、列族列表和属性。</p><p>Server 记录了管理该 Region 的 Region 服务器的地址，如 localhost:16201。Serverstartcode 记录了 Region 服务器开始托管该 Region 的时间。</p><p>当用户表特别大时，用户表的 Region 也会非常多。Meta 表存储了这些 Region 信息，也变得非常大。Meta 表也需要划分成多个 Region，每个 Meta 分区记录一部分用户表和分区管理的情况。</p><h2 id="Region-定位-1"><a href="#Region-定位-1" class="headerlink" title="Region 定位"></a>Region 定位</h2><h3 id="三层定位"><a href="#三层定位" class="headerlink" title="三层定位"></a>三层定位</h3><p>在 HBase 的早期设计中，Region 的查找是通过三层架构来进行查询的，即在集群中有一个总入口 ROOT 表，记录了 Meta 表分区信息及各个入口的地址。这个 ROOT 表存储在某个 RegionServer 上，但是它的地址保存在 ZooKeeper 中。</p><p>这种早期的三层架构通过先找到 ROOT 表，从中获取分区 Meta 表位置；然后再获取分区 Meta 表信息，找出 Region 所在的 Region 服务器。</p><h3 id="二层定位"><a href="#二层定位" class="headerlink" title="二层定位"></a>二层定位</h3><p>从 0.96 版本以后，三层架构被改为二层架构，去掉了 ROOT 表，同时 ZooKeeper 中的 /hbase/root-region-server 也被去掉。Meta 表所在的 Region 服务器信息直接存储在 ZooKeeper 中的 /hbase/meta-region-server 中。</p><p>客户端通过 ZooKeeper 获取 Meta 表分区存储的地址，首先在对应的 RegionServer 获取 Meta 表的信息，得到所需的表和行键所在的 Region 信息，然后从 Region 服务器上找到所需的数据。</p><p><strong><font color='red'>一般客户端获取 Region 信息后会进行缓存，用户下次再查询不必从 ZooKeeper 开始寻址。</font></strong></p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>行键设计</title>
      <link href="2019/02/25/HBase%20-%E8%A1%8C%E9%94%AE%E8%AE%BE%E8%AE%A1(1)/"/>
      <url>2019/02/25/HBase%20-%E8%A1%8C%E9%94%AE%E8%AE%BE%E8%AE%A1(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HBase 作为一个数据库，在使用中无外乎 <strong>增删改查</strong> 操作，这些操作在 HBase 中都是和 RowKey 紧密相关的，所以优秀的 RowKey 设计方案是非常重要的。</p><a id="more"></a><h2 id="RowKey-的作用"><a href="#RowKey-的作用" class="headerlink" title="RowKey 的作用"></a>RowKey 的作用</h2><p>HBase 中 RowKey 可以唯一标识一行记录，在 HBase 中检索数据有以下三种方式：</p><ol><li>通过 <strong>get</strong> 方式，指定 <strong>RowKey</strong> 获取唯一一条记录</li><li>通过 <strong>scan</strong> 方式，设置 <strong>startRow</strong> 和 <strong>stopRow</strong> 参数进行范围匹配</li><li><strong>全表扫描</strong>，即直接扫描整张表中所有行记录</li></ol><h2 id="RowKey-的设计"><a href="#RowKey-的设计" class="headerlink" title="RowKey 的设计"></a>RowKey 的设计</h2><ol><li><p><strong>长度原则</strong></p><p>RowKey 是一个二进制码流，可以是任意字符串，最大长度为64kb，实际应用中一般为10-100byte，以byte[]形式保存，一般设计成定长。建议越短越好，不要超过16个字节，原因如下：</p><ol><li>数据的持久化文件HFile中时按照Key-Value存储的，如果RowKey过长，例如超过100byte，那么1000w行的记录，仅RowKey就需占用近1GB的空间。这样会极大影响HFile的存储效率。</li><li>MemStore会缓存部分数据到内存中，若RowKey字段过长，内存的有效利用率就会降低，就不能缓存更多的数据，从而降低检索效率。</li><li>目前操作系统都是64位系统，内存8字节对齐，控制在16字节，8字节的整数倍利用了操作系统的最佳特性。</li></ol></li><li><p><strong>唯一原则</strong></p><p>必须在设计上保证 RowKey 的唯一性。由于在 HBase 中数据存储是 Key-Value 形式，若向 HBase 中同一张表插入相同 RowKey 的数据，则原先存在的数据会被新的数据覆盖。</p></li><li><p><strong>散列原则</strong></p><p>设计的 RowKey 应均匀的分布在各个HBase节点上。</p></li><li><p><strong>排序原则</strong></p><p>HBase 的 RowKey 是按照 ASCII 有序排序的，在设计 RowKey 的时候要充分利用这点。</p></li></ol><h3 id="避免数据热点"><a href="#避免数据热点" class="headerlink" title="避免数据热点"></a>避免数据热点</h3><p>当大量请求访问 HBase 集群的一个或少数几个节点，造成少数 RegionServer 的读写请求过多、负载过大，而其他 RegionServer 负载却很小，这样就造成<strong>热点现象</strong>。大量访问会使热点 Region 所在的主机负载过大，引起性能下降，甚至导致 Region 不可用。所以我们在向 HBase 中插入数据的时候，应尽量均衡地把记录分散到不同的 Region 里去，平衡每个 Region 的压力。</p><p><strong>Reversing</strong></p><p>如果经初步设计出的RowKey在数据分布上不均匀，但RowKey尾部的数据却呈现出了良好的随机性，此时，可以考虑将RowKey的信息翻转，或者直接将尾部的bytes提前到RowKey的开头。Reversing可以有效的使RowKey随机分布，但是牺牲了RowKey的有序性。</p><p>缺点：</p><p>利于Get操作，但不利于Scan操作，因为数据在原RowKey上的自然顺序已经被打乱。</p><p><strong>Salting</strong></p><p>Salting（加盐）的原理是在原 RowKey 的前面添加固定长度的随机数，也就是给 RowKey 分配一个随机前缀使它和之间的 RowKey 的开头不同。随机数能保障数据在所有 Regions 间的负载均衡。</p><p>缺点：</p><p>因为添加的是随机数，基于原 RowKey 查询时无法知道随机数是什么，那样在查询的时候就需要去各个可能的Regions中查找，Salting 对于读取是利空的。并且加盐这种方式增加了读写时的吞吐量。</p><p><strong>Hashing</strong></p><p>基于 RowKey 的完整或部分数据进行 Hash，而后将 Hashing 后的值完整替换或部分替换原 RowKey 的前缀部分。这里说的 hash 包含 MD5、sha1、sha256 或 sha512 等算法。</p><p>缺点：</p><p>与 Reversing 类似，Hashing 也不利于 Scan，因为打乱了原RowKey的自然顺序。</p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>行键设计</title>
      <link href="2019/02/25/HBase%20-%E8%A1%8C%E9%94%AE%E8%AE%BE%E8%AE%A1/"/>
      <url>2019/02/25/HBase%20-%E8%A1%8C%E9%94%AE%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HBase 作为一个数据库，在使用中无外乎 <strong>增删改查</strong> 操作，这些操作在 HBase 中都是和 RowKey 紧密相关的，所以优秀的 RowKey 设计方案是非常重要的。</p><a id="more"></a><h2 id="RowKey-的作用"><a href="#RowKey-的作用" class="headerlink" title="RowKey 的作用"></a>RowKey 的作用</h2><p>HBase 中 RowKey 可以唯一标识一行记录，在 HBase 中检索数据有以下三种方式：</p><ol><li>通过 <strong>get</strong> 方式，指定 <strong>RowKey</strong> 获取唯一一条记录</li><li>通过 <strong>scan</strong> 方式，设置 <strong>startRow</strong> 和 <strong>stopRow</strong> 参数进行范围匹配</li><li><strong>全表扫描</strong>，即直接扫描整张表中所有行记录</li></ol><h2 id="RowKey-的设计"><a href="#RowKey-的设计" class="headerlink" title="RowKey 的设计"></a>RowKey 的设计</h2><ol><li><p><strong>长度原则</strong></p><p>RowKey是一个二进制码流，可以是任意字符串，最大长度为64kb，实际应用中一般为10-100byte，以byte[]形式保存，一般设计成定长。建议越短越好，不要超过16个字节，原因如下：</p><ol><li>数据的持久化文件HFile中时按照Key-Value存储的，如果RowKey过长，例如超过100byte，那么1000w行的记录，仅RowKey就需占用近1GB的空间。这样会极大影响HFile的存储效率。</li><li>MemStore会缓存部分数据到内存中，若RowKey字段过长，内存的有效利用率就会降低，就不能缓存更多的数据，从而降低检索效率。</li><li>目前操作系统都是64位系统，内存8字节对齐，控制在16字节，8字节的整数倍利用了操作系统的最佳特性。</li></ol></li><li><p><strong>唯一原则</strong></p><p>必须在设计上保证 RowKey 的唯一性。由于在 HBase 中数据存储是 Key-Value 形式，若向 HBase 中同一张表插入相同 RowKey 的数据，则原先存在的数据会被新的数据覆盖。</p></li><li><p><strong>散列原则</strong></p><p>设计的 RowKey 应均匀的分布在各个HBase节点上。</p></li><li><p><strong>排序原则</strong></p><p>HBase 的 RowKey 是按照 ASCII 有序排序的，在设计 RowKey 的时候要充分利用这点。</p></li></ol><h3 id="避免数据热点"><a href="#避免数据热点" class="headerlink" title="避免数据热点"></a>避免数据热点</h3><p>当大量请求访问 HBase 集群的一个或少数几个节点，造成少数 RegionServer 的读写请求过多、负载过大，而其他 RegionServer 负载却很小，这样就造成<strong>热点现象</strong>。大量访问会使热点 Region 所在的主机负载过大，引起性能下降，甚至导致 Region 不可用。所以我们在向 HBase 中插入数据的时候，应尽量均衡地把记录分散到不同的 Region 里去，平衡每个 Region 的压力。</p><p><strong>Reversing</strong></p><p>如果经初步设计出的RowKey在数据分布上不均匀，但RowKey尾部的数据却呈现出了良好的随机性，此时，可以考虑将RowKey的信息翻转，或者直接将尾部的bytes提前到RowKey的开头。Reversing可以有效的使RowKey随机分布，但是牺牲了RowKey的有序性。</p><p>缺点：</p><p>利于Get操作，但不利于Scan操作，因为数据在原RowKey上的自然顺序已经被打乱。</p><p><strong>Salting</strong></p><p>Salting（加盐）的原理是在原 RowKey 的前面添加固定长度的随机数，也就是给 RowKey 分配一个随机前缀使它和之间的 RowKey 的开头不同。随机数能保障数据在所有 Regions 间的负载均衡。</p><p>缺点：</p><p>因为添加的是随机数，基于原 RowKey 查询时无法知道随机数是什么，那样在查询的时候就需要去各个可能的Regions中查找，Salting 对于读取是利空的。并且加盐这种方式增加了读写时的吞吐量。</p><p><strong>Hashing</strong></p><p>基于 RowKey 的完整或部分数据进行 Hash，而后将 Hashing 后的值完整替换或部分替换原 RowKey 的前缀部分。这里说的 hash 包含 MD5、sha1、sha256 或 sha512 等算法。</p><p>缺点：</p><p>与 Reversing 类似，Hashing 也不利于 Scan，因为打乱了原RowKey的自然顺序。</p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 哨兵模式</title>
      <link href="2019/02/23/Redis-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"/>
      <url>2019/02/23/Redis-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。<strong>这不是一种推荐的方式，更多时候，我们优先考虑</strong>哨兵模式。</p><a id="more"></a><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>哨兵模式是一种特殊的模式，首先 Redis 提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是<strong>哨兵通过发送命令，等待 Redis 服务器响应，从而监控运行的多个 Redis 实例。</strong></p><p>这里的哨兵有两个作用</p><ul><li>通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。</li><li>当哨兵监测到master宕机，会自动将slave切换成master，然后通过<strong>发布订阅模式</strong>通知其他的从服务器，修改配置文件，让它们切换主机。</li></ul><p>然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。</p><p>用文字描述一下<strong>故障切换（failover）</strong>的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为<strong>主观下线</strong>。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为<strong>客观下线</strong>。这样对于客户端而言，一切都是透明的。</p><h1 id="2-Redis-配置哨兵模式"><a href="#2-Redis-配置哨兵模式" class="headerlink" title="2. Redis 配置哨兵模式"></a>2. Redis 配置哨兵模式</h1><h1 id="3-原理"><a href="#3-原理" class="headerlink" title="3. 原理"></a>3. 原理</h1><ol><li>每个 Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。</li><li>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值，则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）。</li><li>如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有<br>Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态。</li><li>当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）。</li><li>在一般情况下， 每个Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。</li><li>当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。</li><li>若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 哨兵模式</title>
      <link href="2019/02/23/Redis-%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"/>
      <url>2019/02/23/Redis-%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，全部发送到后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。</p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，全部发送到后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。</p><h2 id="2-起因"><a href="#2-起因" class="headerlink" title="2. 起因"></a>2. 起因</h2><p>缓存击穿的情况，经常发生在热点数据过期失效</p><h2 id="3-解决方案"><a href="#3-解决方案" class="headerlink" title="3. 解决方案"></a>3. 解决方案</h2><p>对于访问特别频繁的热点数据，不设置过期时间，对热点数据的访问请求，都可以在缓存中进行处理，而 Redis 数万级别的高吞吐量可以很好地应对大量的并发请求访问。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 哨兵模式</title>
      <link href="2019/02/23/Redis-%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4/"/>
      <url>2019/02/23/Redis-%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>一致性包含了两种情况: 缓存中有数据缓存的数据值需要和数据库中的值相同,缓存中本身没有数据，那么，数据库中的值必须是最新值。</p><a id="more"></a><h2 id="1-读写缓存"><a href="#1-读写缓存" class="headerlink" title="1. 读写缓存"></a>1. 读写缓存</h2><p>根据是否接收写请求，可以把缓存分成读写缓存和只读缓存。对于读写缓存来说，如果要对数据进行增删改，就需要在缓存中进行，同时还要根据采取的写回策略，决定是否同步写回到数据库中。同步直写策略：写缓存时，也同步写数据库，缓存和数据库中的数据一致；异步写回策略：写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障，那么，此时，数据库就没有最新的数据了。</p><p>对于读写缓存来说，要想保证缓存和数据库中的数据一致，就要采用同步直写策略。采用这种策略，就需要同时更新缓存和数据库, 使用事务机制，来保证缓存和数据库的更新具有原子性。</p><h2 id="2-只读缓存"><a href="#2-只读缓存" class="headerlink" title="2. 只读缓存"></a>2. 只读缓存</h2><p>对于只读缓存来说，如果有数据新增，会直接写入数据库；而有数据删改时，就需要把只读缓存中的数据标记为无效。这样一来，应用后续再访问这些增删改的数据时，因为缓存中没有相应的数据，应用再从数据库中把数据读入缓存，后续再访问数据时，就能够直接从缓存中读取。</p><h3 id="2-1-新增数据"><a href="#2-1-新增数据" class="headerlink" title="2.1. 新增数据"></a>2.1. 新增数据</h3><p>如果是新增数据，数据会直接写到数据库中，不用对缓存做任何操作，此时，缓存中本身就没有新增数据，而数据库中是最新值，这种情况符合我们刚刚所说的一致性的第 2 种情况，所以，此时，缓存和数据库的数据是一致的。</p><h3 id="2-2-删改数据"><a href="#2-2-删改数据" class="headerlink" title="2.2. 删改数据"></a>2.2. 删改数据</h3><p>如果发生删改操作，应用既要更新数据库，也要在缓存中删除数据。两个操作如果无法保证原子性会出现数据不一致问题</p><h4 id="2-2-1-先删除缓存，再更新数据库"><a href="#2-2-1-先删除缓存，再更新数据库" class="headerlink" title="2.2.1. 先删除缓存，再更新数据库"></a>2.2.1. 先删除缓存，再更新数据库</h4><p>如果缓存删除成功，但是数据库更新失败，那么，应用再访问数据时，缓存中没有数据，就会发生缓存缺失。然后，应用再访问数据库，但是数据库中的值为旧值，应用就访问到旧值了</p><h4 id="2-2-2-先更新数据库，再删除缓存"><a href="#2-2-2-先更新数据库，再删除缓存" class="headerlink" title="2.2.2. 先更新数据库，再删除缓存"></a>2.2.2. 先更新数据库，再删除缓存</h4><p>如果应用先完成了数据库的更新，但是，在删除缓存时失败了，那么，数据库中的值是新值，而缓存中的是旧值，这肯定是不一致的。这个时候，如果有其他的并发请求来访问数据，按照正常的缓存访问流程，就会先在缓存中查询，但此时，就会读到旧值了。</p><h2 id="3-如何解决数据不一致问题？"><a href="#3-如何解决数据不一致问题？" class="headerlink" title="3. 如何解决数据不一致问题？"></a>3. 如何解决数据不一致问题？</h2><p>可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中(例如使用 Kafka 消息队列)。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。如果能够成功地删除或更新，就要把这些值从消息队列中去除，以免重复操作，此时，也可以保证数据库和缓存的数据一致了。否则的话，还需要再次进行重试。如果重试超过的一定次数，还是没有成功，需要向业务层发送报错信息了。</p><h2 id="4-高并发下的数据不一致"><a href="#4-高并发下的数据不一致" class="headerlink" title="4. 高并发下的数据不一致"></a>4. 高并发下的数据不一致</h2><p>实际上，即使这两个操作第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据。</p><h3 id="4-1-先删除缓存，再更新数据库"><a href="#4-1-先删除缓存，再更新数据库" class="headerlink" title="4.1. 先删除缓存，再更新数据库"></a>4.1. 先删除缓存，再更新数据库</h3><p>假设线程 A 删除缓存值后，还没有来得及更新数据库(网络延迟)，线程 B 就开始读取数据了，线程 B 发现缓存缺失，就只能去数据库读取。这会带来两个问题：</p><ol><li>线程 B 读取到了旧值</li><li>线程 B 是在缓存缺失的情况下读取的数据库，它还会把旧值写入缓存，这可能会导致其他线程从缓存中读到旧值。</li></ol><p>等到线程 B 从数据库读取完数据、更新了缓存后，线程 A 才开始更新数据库，此时，缓存中的数据是旧值，而数据库中的是最新值，两者就不一致了。</p><h4 id="4-1-2-解决方案"><a href="#4-1-2-解决方案" class="headerlink" title="4.1.2. 解决方案"></a>4.1.2. 解决方案</h4><p>在线程 A 更新完数据库值以后，我们可以让它先 sleep 一小段时间，再进行一次缓存删除操作。</p><p>sleep 是为了让线程 B 能够先从数据库读取数据，再把缺失的数据写入缓存，然后，线程 A 再进行删除。所以，线程 A sleep 的时间，就需要大于线程 B 读取数据再写入缓存的时间。</p><h3 id="4-2-先更新数据库值，再删除缓存值。"><a href="#4-2-先更新数据库值，再删除缓存值。" class="headerlink" title="4.2. 先更新数据库值，再删除缓存值。"></a>4.2. 先更新数据库值，再删除缓存值。</h3><p>如果线程 A 删除了数据库中的值，但还没来得及删除缓存值，线程 B 就开始读取数据了，那么此时，线程 B 查询缓存时，发现缓存命中，就会直接从缓存中读取旧值。不过，在这种情况下，如果其他线程并发读缓存的请求不多，那么，就不会有很多请求读取到旧值。而且，线程 A 一般也会很快删除缓存值，这样一来，其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小。</p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>缓存和数据库的数据不一致一般是由两个原因导致的</p><ol><li>删除缓存值或更新数据库失败而导致数据不一致，可以使用重试机制确保删除或更新操作成功。</li><li>在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是延迟双删。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 缓存污染</title>
      <link href="2019/02/23/Redis-%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93/"/>
      <url>2019/02/23/Redis-%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。</p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>当缓存污染不严重时，只有少量数据占据缓存空间，此时，对缓存系统的影响不大。但是，缓存污染一旦变得严重后，就会有大量不再访问的数据滞留在缓存中。如果这时数据占满了缓存空间，我们再往缓存中写入新数据时，就需要先把这些数据逐步淘汰出缓存，这就会引入额外的操作时间开销，进而会影响应用的性能。</p><h2 id="2-如何解决缓存污染问题？"><a href="#2-如何解决缓存污染问题？" class="headerlink" title="2. 如何解决缓存污染问题？"></a>2. 如何解决缓存污染问题？</h2><p>要解决缓存污染，是得把不会再被访问的数据筛选出来并淘汰掉。不用等到缓存被写满以后，再逐一淘汰旧数据之后，才能写入新数据了。而哪些数据能留存在缓存中，是由缓存的淘汰策略决定的。</p><h3 id="2-1-业务层误操作"><a href="#2-1-业务层误操作" class="headerlink" title="2.1. 业务层误操作"></a>2.1. 业务层误操作</h3><p>缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据</p><h4 id="2-1-2-解决方案"><a href="#2-1-2-解决方案" class="headerlink" title="2.1.2. 解决方案"></a>2.1.2. 解决方案</h4><ol><li><p>缓存空值或缺省值</p><p>一旦发生缓存穿透，可以针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值(例如，库存的缺省值可以设为 0)。紧接着，应用发送的后续请求再进行查询时，就可以直接从 Redis 中读取空值或缺省值，返回给业务应用了，避免了把大量请求发送给数据库处理，保持了数据库的正常运行。</p></li><li><p>布隆过滤器</p><p>布隆过滤器由一个初值都为 0 的 bit 数组和 N 个哈希函数组成，可以用来快速判断某个数据是否存在。当标记某个数据存在时(例如，数据已被写入数据库)，布隆过滤器会通过三个操作完成标记</p><ul><li><p>使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值</p></li><li><p>把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置</p></li><li><p>最后，把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作</p></li></ul><p>如果数据不存在(例如，数据库里没有写入数据)，也就没有用布隆过滤器标记过数据，bit 数组对应 bit 位的值仍然为 0。当需要查询某个数据时，先得到这个数据在 bit 数组中对应的 N 个位置。紧接着，查看 bit 数组中这 N 个位置上的 bit 值。只要这 N 个 bit 值有一个不为 1，这就表明布隆过滤器没有对该数据做过标记，所以，查询的数据一定没有在数据库中保存</p></li></ol><p>   正是基于布隆过滤器的快速检测特性，我们可以在把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。这样一来，即使发生缓存穿透了，大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。布隆过滤器可以使用 Redis 实现，本身就能承担较大的并发访问压力。</p><ol start="3"><li><p>请求入口的前端进行请求检测</p><p>缓存穿透的一个原因是有大量的恶意请求访问不存在的数据，所以，一个有效的应对方案是在请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库。这样一来，也就不会出现缓存穿透问题了。</p></li></ol><h3 id="2-2-恶意攻击"><a href="#2-2-恶意攻击" class="headerlink" title="2.2. 恶意攻击"></a>2.2. 恶意攻击</h3><h2 id="3-解决方案"><a href="#3-解决方案" class="headerlink" title="3. 解决方案"></a>3. 解决方案</h2><p>对于访问特别频繁的热点数据，不设置过期时间，对热点数据的访问请求，都可以在缓存中进行处理，而 Redis 数万级别的高吞吐量可以很好地应对大量的并发请求访问。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 哨兵模式</title>
      <link href="2019/02/23/Redis-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/"/>
      <url>2019/02/23/Redis-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。此时，应用也无法从数据库中读取数据再写入缓存，来服务后续请求，这样一来，缓存也就成了摆设，如果应用持续有大量请求访问数据，就会同时给缓存和数据库带来巨大压力。</p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。此时，应用也无法从数据库中读取数据再写入缓存，来服务后续请求，这样一来，缓存也就成了摆设，如果应用持续有大量请求访问数据，就会同时给缓存和数据库带来巨大压力。</p><h2 id="2-起因"><a href="#2-起因" class="headerlink" title="2. 起因"></a>2. 起因</h2><h3 id="2-1-业务层误操作"><a href="#2-1-业务层误操作" class="headerlink" title="2.1. 业务层误操作"></a>2.1. 业务层误操作</h3><p>缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据</p><h4 id="2-1-2-解决方案"><a href="#2-1-2-解决方案" class="headerlink" title="2.1.2. 解决方案"></a>2.1.2. 解决方案</h4><ol><li><p>缓存空值或缺省值</p><p>一旦发生缓存穿透，可以针对查询的数据，在 Redis 中缓存一个空值或是和业务层协商确定的缺省值(例如，库存的缺省值可以设为 0)。紧接着，应用发送的后续请求再进行查询时，就可以直接从 Redis 中读取空值或缺省值，返回给业务应用了，避免了把大量请求发送给数据库处理，保持了数据库的正常运行。</p></li><li><p>布隆过滤器</p><p>布隆过滤器由一个初值都为 0 的 bit 数组和 N 个哈希函数组成，可以用来快速判断某个数据是否存在。当标记某个数据存在时(例如，数据已被写入数据库)，布隆过滤器会通过三个操作完成标记</p><ul><li><p>使用 N 个哈希函数，分别计算这个数据的哈希值，得到 N 个哈希值</p></li><li><p>把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置</p></li><li><p>最后，把对应位置的 bit 位设置为 1，这就完成了在布隆过滤器中标记数据的操作</p></li></ul><p>如果数据不存在(例如，数据库里没有写入数据)，也就没有用布隆过滤器标记过数据，bit 数组对应 bit 位的值仍然为 0。当需要查询某个数据时，先得到这个数据在 bit 数组中对应的 N 个位置。紧接着，查看 bit 数组中这 N 个位置上的 bit 值。只要这 N 个 bit 值有一个不为 1，这就表明布隆过滤器没有对该数据做过标记，所以，查询的数据一定没有在数据库中保存</p></li></ol><p>   正是基于布隆过滤器的快速检测特性，我们可以在把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。这样一来，即使发生缓存穿透了，大量请求只会查询 Redis 和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。布隆过滤器可以使用 Redis 实现，本身就能承担较大的并发访问压力。</p><ol start="3"><li><p>请求入口的前端进行请求检测</p><p>缓存穿透的一个原因是有大量的恶意请求访问不存在的数据，所以，一个有效的应对方案是在请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库。这样一来，也就不会出现缓存穿透问题了。</p></li></ol><h3 id="2-2-恶意攻击"><a href="#2-2-恶意攻击" class="headerlink" title="2.2. 恶意攻击"></a>2.2. 恶意攻击</h3><h2 id="3-解决方案"><a href="#3-解决方案" class="headerlink" title="3. 解决方案"></a>3. 解决方案</h2><p>对于访问特别频繁的热点数据，不设置过期时间，对热点数据的访问请求，都可以在缓存中进行处理，而 Redis 数万级别的高吞吐量可以很好地应对大量的并发请求访问。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 哨兵模式</title>
      <link href="2019/02/23/Redis-%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/"/>
      <url>2019/02/23/Redis-%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。</p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。</p><h2 id="2-起因"><a href="#2-起因" class="headerlink" title="2. 起因"></a>2. 起因</h2><h3 id="2-1-缓存中有大量数据同时过期，导致大量请求无法得到处理。"><a href="#2-1-缓存中有大量数据同时过期，导致大量请求无法得到处理。" class="headerlink" title="2.1. 缓存中有大量数据同时过期，导致大量请求无法得到处理。"></a>2.1. 缓存中有大量数据同时过期，导致大量请求无法得到处理。</h3><h4 id="2-1-1-概述"><a href="#2-1-1-概述" class="headerlink" title="2.1.1. 概述"></a>2.1.1. 概述</h4><p>当数据保存在缓存中，并且设置了过期时间时，如果在某一个时刻，大量数据同时过期，此时，应用再访问这些数据的话，就会发生缓存缺失。紧接着，应用就会把请求发送给数据库，从数据库中读取数据。如果应用的并发请求量很大，那么数据库的压力也就很大</p><h4 id="2-1-2-解决方案"><a href="#2-1-2-解决方案" class="headerlink" title="2.1.2. 解决方案"></a>2.1.2. 解决方案</h4><ol><li><p>微调过期时间</p><p>避免给大量的数据设置相同的过期时间。如果业务层的确要求有些数据同时失效，可以在用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数（例如，随机增加 1~3 分钟），这样一来，不同数据的过期时间有所差别，但差别又不会太大，既避免了大量数据同时过期，同时也保证了这些数据基本在相近的时间失效，仍然能满足业务需求</p></li><li><p>服务降级</p><p>所谓的服务降级，是指发生缓存雪崩时，针对不同的数据采取不同的处理方式。</p><ul><li><p>当业务应用访问的是非核心数据(例如电商商品属性)时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息</p></li><li><p>当业务应用访问的是核心数据(例如电商商品库存)时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。</p></li></ul></li></ol><h2 id="2-2-Redis-缓存实例发生故障宕机"><a href="#2-2-Redis-缓存实例发生故障宕机" class="headerlink" title="2.2. Redis 缓存实例发生故障宕机"></a>2.2. Redis 缓存实例发生故障宕机</h2><h4 id="2-2-1-概述"><a href="#2-2-1-概述" class="headerlink" title="2.2.1. 概述"></a>2.2.1. 概述</h4><p>除了大量数据同时失效会导致缓存雪崩，还有一种情况也会发生缓存雪崩，那就是，Redis 缓存实例发生故障宕机了，无法处理请求，这就会导致大量请求一下子积压到数据库层，从而发生缓存雪崩。</p><p>一般来说，一个 Redis 实例可以支持数万级别的请求处理吞吐量，而单个数据库可能只能支持数千级别的请求处理吞吐量，它们两个的处理能力可能相差了近十倍。由于缓存雪崩，Redis 缓存失效，所以，数据库就可能要承受近十倍的请求压力，从而因为压力过大而崩溃。</p><h4 id="2-1-2-解决方案-1"><a href="#2-1-2-解决方案-1" class="headerlink" title="2.1.2. 解决方案"></a>2.1.2. 解决方案</h4><ol><li><p>业务系统中实现服务熔断</p><p>发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，暂停业务应用对缓存系统的接口访问。再具体点说，就是业务应用调用缓存接口时，缓存客户端并不把请求发给 Redis 缓存实例，而是直接返回，等到 Redis 缓存实例重新恢复服务后，再允许应用请求发送到缓存系统,避免了大量请求因缓存缺失，而积压到数据库系统，保证了数据库系统的正常运行。</p></li><li><p>请求限流</p><p>服务熔断虽然可以保证数据库的正常运行，但是暂停了整个缓存系统的访问，对业务应用的影响范围大。为了尽可能减少这种影响，我们也可以进行请求限流。这里说的请求限流，就是指，我们在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。</p></li><li><p>构建 Redis 缓存高可靠集群</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 锁</title>
      <link href="2019/02/22/MySQL-%E9%94%81/"/>
      <url>2019/02/22/MySQL-%E9%94%81/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。加锁是实现数据库并发控制的一个非常重要的技术。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>相对其他数据库而言，MySQL 的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。</p><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>MySQL 大致可归纳为以下 3 种锁：</p><ol><li><p>表级锁：</p><ul><li>偏向 <code>MyISAM</code> 存储引擎，开销小，加锁快 </li><li>不会出现死锁</li><li>锁定粒度大，发生锁冲突的概率最高，并发度最低。</li></ul></li><li><p>行级锁</p><ul><li><p>开销大，加锁慢</p></li><li><p>会出现死锁 </p></li><li><p>锁定粒度最小，发生锁冲突的概率最低，并发度也最高</p></li></ul></li><li><p>页面锁</p><ul><li><p>开销和加锁时间界于表锁和行锁之间 </p></li><li><p>会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般</p></li></ul></li></ol><h2 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h2><p>MySQL 的表级锁有两种模式</p><ol><li>表共享读锁 Table Read Lock</li><li>写独占写锁 Table Write Lock</li></ol><h2 id="相关-SQL-语句"><a href="#相关-SQL-语句" class="headerlink" title="相关 SQL 语句"></a>相关 SQL 语句</h2><ol><li><p>手动增加表锁 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lock table 表名字 read(write)，表名字 read(write)，...;</span><br></pre></td></tr></table></figure></li><li><p>查看表上加过的锁</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show open tables;</span><br></pre></td></tr></table></figure></li><li><p>释放表锁</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unlock tables;</span><br></pre></td></tr></table></figure></li></ol><h2 id="实验数据"><a href="#实验数据" class="headerlink" title="实验数据"></a>实验数据</h2><p>创建 Person 数据表，其存储引擎为 MyISAM</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE person (</span><br><span class="line">  id int primary key, </span><br><span class="line">  name varchar(30), </span><br><span class="line">  Age int</span><br><span class="line">)ENGINE&#x3D;MyISAM DEFAULT CHARSET&#x3D;utf8;</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from person;</span><br><span class="line">+----+-------+------+</span><br><span class="line">| id | name  | Age  |</span><br><span class="line">+----+-------+------+</span><br><span class="line">|  6 | go    |   11 |</span><br><span class="line">|  5 | hello |   11 |</span><br><span class="line">|  4 | jack  |   11 |</span><br><span class="line">|  3 | chen  |   12 |</span><br><span class="line">|  2 | tom   |   10 |</span><br><span class="line">|  1 | jerry |   16 |</span><br><span class="line">+----+-------+------+</span><br><span class="line">6 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><h3 id="读锁"><a href="#读锁" class="headerlink" title="读锁"></a>读锁</h3><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p>对 MyISAM 表加读锁，不会阻塞其他进程对同一表的读请求，但会阻塞对同一表的写请求，只有当读锁释放后，才会执行其他进程的写操作。</p><h4 id="学习示例"><a href="#学习示例" class="headerlink" title="学习示例"></a>学习示例</h4><p>在客户端 [1]中，为 person 表添加读锁</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; lock table person read;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">mysql&gt; show open tables;</span><br><span class="line">+--------------------+---------------------------------------------+--------+-------------+</span><br><span class="line">| Database           | Table                                       | In_use | Name_locked |</span><br><span class="line">+--------------------+---------------------------------------------+--------+-------------+</span><br><span class="line">| performance_schema | events_statements_current                   |      0 |           0 |</span><br><span class="line">| performance_schema | events_stages_current                       |      0 |           0 |</span><br><span class="line">| performance_schema | events_waits_summary_by_instance            |      0 |           0 |</span><br><span class="line">| test               | person                                      |      1 |           0 |</span><br></pre></td></tr></table></figure><p>对 MyISAM 表加读锁，不会阻塞其他进程对同一表的读请求</p><p>在客户端 [2] 中，可以正常读取数据表 person</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from person;</span><br><span class="line">+<span class="comment">----+-------+------+</span></span><br><span class="line">| id | name  | Age  |</span><br><span class="line">+<span class="comment">----+-------+------+</span></span><br><span class="line">|  6 | go    |   11 |</span><br><span class="line">|  5 | hello |   11 |</span><br><span class="line">|  4 | jack  |   11 |</span><br><span class="line">|  3 | chen  |   12 |</span><br><span class="line">|  2 | tom   |   10 |</span><br><span class="line">|  1 | jerry |   16 |</span><br><span class="line">+<span class="comment">----+-------+------+</span></span><br><span class="line">6 rows in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>对 MyISAM 表加读锁，会阻塞其他进程对同一表的写请求</p><p>在客户端 [2] 中，无法正常修改数据表 person,会一直处于阻塞状态。直至客户端 [1] 释放表锁。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into person (id, name, Age) values (7, &#x27;zxc&#x27;, 11);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><font color='red'><strong>注意:</strong></font> 在客户端 [1] 中，无法正常查看其他数据表数据。直至客户端 [1] 释放表锁。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from book;</span><br><span class="line">ERROR 1100 (HY000): Table &#x27;book&#x27; was not locked <span class="keyword">with</span> <span class="keyword">LOCK</span> <span class="keyword">TABLES</span></span><br></pre></td></tr></table></figure><h3 id="写锁"><a href="#写锁" class="headerlink" title="写锁"></a>写锁</h3><h4 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h4><p>对 MyISAM 表加写锁，会阻塞其他进程对同一表的读和写操作，只有当写锁释放后，才会执行其他进程的写操作。</p><h4 id="学习示例-1"><a href="#学习示例-1" class="headerlink" title="学习示例"></a>学习示例</h4><blockquote><p>在客户端 [1]中，为 person 表添加读锁</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; lock table person write;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">mysql&gt; show open tables;</span><br><span class="line">+--------------------+--------------------------------------------+--------+-------------+</span><br><span class="line">| Database           | Table                                      | In_use | Name_locked |</span><br><span class="line">+--------------------+--------------------------------------------+--------+-------------+</span><br><span class="line">| performance_schema | events_statements_current                  |      0 |           0 |</span><br><span class="line">| performance_schema | events_stages_current                      |      0 |           0 |</span><br><span class="line">| performance_schema | events_waits_summary_by_instance           |      0 |           0 |</span><br><span class="line">| test               | person                                     |      1 |           0 |</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>对 MyISAM 表加写锁，会阻塞其他进程对同一表的读请求，直至客户端 [1]释放锁</p><p>在客户端 [2] 中，读取数据表 person 出现阻塞</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from person;</span><br><span class="line">mysql&gt;</span><br><span class="line">mysql&gt;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>对 MyISAM 表加读锁，会阻塞其他进程对同一表的写请求</p><p>在客户端 [2] 中，无法正常修改数据表 person,会一直处于阻塞状态。直至客户端 [1] 释放表锁。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into person (id, name, Age) values (9, &#x27;chener&#x27;, 11);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="分析表锁定"><a href="#分析表锁定" class="headerlink" title="分析表锁定"></a>分析表锁定</h3><blockquote><p> 可以通过 show status like ‘table%’ 检查 table_locks_waited 和 table_locks_immediate 状态变量来分析系统上的表锁定</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show status like &#39;table%&#39;;</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">| Variable_name              | Value |</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">| Table_locks_immediate      | 142   |</span><br><span class="line">| Table_locks_waited         | 0     |</span><br><span class="line">| Table_open_cache_hits      | 4     | </span><br><span class="line">| Table_open_cache_misses    | 4     |</span><br><span class="line">| Table_open_cache_overflows | 0     |</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">5 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li><p>Table_locks_immediate</p><blockquote><p>产生表级锁定的次数，表示可以立即获取锁的查询次数，每次立即获取锁加1</p></blockquote></li><li><p>Table_locks_waited</p><blockquote><p>出现表级锁定争用发生等待的次数(不能立即获取锁的次数，每等待一次锁值加1)，此值高则 说明存在着较严重的表级锁争用情况。</p></blockquote></li></ol><p>此外，MyISAM 的读写锁调度是写优先，这也是 MyISAM 不适合做以数据写如为主的表引擎，因为在写锁后，其他线程不能做任何操作，大量的更新操作会使查询很难得到锁，从而造成永远阻塞。</p><h2 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h2><h4 id="加锁的方式"><a href="#加锁的方式" class="headerlink" title="加锁的方式"></a>加锁的方式</h4><p>自动加锁。对于 UPDATE、DELETE 和 INSERT 语句，InnoDB 会自动给涉及数据集加排他锁；</p><p>对于普通 SELECT 语句，InnoDB 不会加任何锁</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">共享锁：<span class="keyword">select</span> * <span class="keyword">from</span> tableName <span class="keyword">where</span> ... + <span class="keyword">lock</span> <span class="keyword">in</span> <span class="keyword">share</span> more</span><br><span class="line">排他锁：<span class="keyword">select</span> * <span class="keyword">from</span> tableName <span class="keyword">where</span> ... + <span class="keyword">for</span> <span class="keyword">update</span> </span><br></pre></td></tr></table></figure><p>In share mode 获得共享锁，主要用于确认某行数据是否存在，并确保没有人对这个记录进行更新或者删除操作，但是如果当前事务也需要对该记录进行更新操作，就有可能造成死锁；因此对于锁定行记录之后还需要进行更新操作，应该是用 for update 获得排它锁</p><p>行锁开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。最大程度的支持并发，同时也带来了最大的锁开销。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set autocommit &#x3D; 0;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update staffs set age&#x3D;&#39;16&#39; where id&#x3D;&#39;2&#39;;</span><br><span class="line">Query OK, 1 row affected (0.12 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from staffs;</span><br><span class="line">+----+------+-----+---------+---------------------+</span><br><span class="line">| id | name | age | pos     | add_time            |</span><br><span class="line">+----+------+-----+---------+---------------------+</span><br><span class="line">|  1 | Z3   |  22 | manager | 2019-11-24 05:36:40 |</span><br><span class="line">|  2 | July |  16 | dev     | 2019-11-24 05:36:40 |</span><br><span class="line">|  3 | 2000 |  22 | dev     | 2019-11-24 05:36:40 |</span><br><span class="line">+----+------+-----+---------+---------------------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="行锁演示案例"><a href="#行锁演示案例" class="headerlink" title="行锁演示案例"></a>行锁演示案例</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update staffs <span class="built_in">set</span> age=<span class="string">&#x27;3&#x27;</span> <span class="built_in">where</span> id=<span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">Query OK, 1 row affected (0.01 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 阻塞</span></span><br><span class="line">mysql&gt; update staffs <span class="built_in">set</span> age=<span class="string">&#x27;10&#x27;</span> <span class="built_in">where</span> id=<span class="string">&#x27;1&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; commit;</span><br><span class="line">Query OK, 0 rows affected (0.13 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update staffs <span class="built_in">set</span> age=<span class="string">&#x27;10&#x27;</span> <span class="built_in">where</span> id=<span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">Query OK, 1 row affected (43.86 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; commit ;</span><br><span class="line">Query OK, 0 rows affected (0.05 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>不同行不阻塞</p></blockquote><p>1 InnoDB 支持表锁和行锁，使用索引作为检索条件修改数据时采用行锁，否则采用表锁。</p><p>2 InnoDB 自动给修改操作加锁，给查询操作不自动加锁</p><p>3 行锁可能因为未使用索引而升级为表锁，所以除了检查索引是否创建的同时，也需要通过 explain 执行计划查询索引是否被实际使用。</p><p>4 行锁相对于表锁来说，优势在于高并发场景下表现更突出，毕竟锁的粒度小。</p><p>5 当表的大部分数据需要被修改，或者是多表复杂关联查询时，建议使用表锁优于行锁。</p><p>6 为了保证数据的一致完整性，任何一个数据库都存在锁定机制。锁定机制的优劣直接影响到一个数据库的并发处理能力和性能。</p><h3 id="2-3-行锁升级为表锁"><a href="#2-3-行锁升级为表锁" class="headerlink" title="2.3. 行锁升级为表锁"></a>2.3. 行锁升级为表锁</h3><p>varchar必须用 ‘’</p><h3 id="2-5-锁定一行"><a href="#2-5-锁定一行" class="headerlink" title="2.5. 锁定一行"></a>2.5. 锁定一行</h3><p><img src="https://img-blog.csdnimg.cn/20200111103106459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200111103446655.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200111131714835.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2020011113173370.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200111131817318.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="间隙锁"><a href="#间隙锁" class="headerlink" title="间隙锁"></a>间隙锁</h2><h3 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h3><p>编程的思想源于生活，生活中的例子能帮助我们更好的理解一些编程中的思想。<br>生活中排队的场景，小明，小红，小花三个人依次站成一排，此时，如何让新来的小刚不能站在小红旁边，这时候只要将小红和她前面的小明之间的空隙封锁，将小红和她后面的小花之间的空隙封锁，那么小刚就不能站到小红的旁边。这里的小红，小明，小花，小刚就是数据库的一条条记录。<br>他们之间的空隙也就是间隙，而封锁他们之间距离的锁，叫做间隙锁。</p><p><strong>间隙锁（Gap Lock）是 Innodb 在可重复读提交下为了解决幻读问题时引入的锁机制，幻读的问题存在是因为新增操作，这时如果进行范围查询的时候（加锁查询），会出现不一致的问题，这时使用不同的行锁已经没有办法满足要求，需要对一定范围内的数据进行加锁，间隙锁就是解决这类问题的。</strong></p><p><strong>在可重复读隔离级别下，数据库是通过行锁和间隙锁共同组成的[next-key lock]，来实现的</strong></p><p><strong>当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB 会给符合条件的已有数据记录的索引项加锁，对于键值在条件范围内但并不存在的记录，叫做  间隙 GAP</strong></p><p>InnoDB 也会对这个 <strong>间隙 GAP</strong> 加锁，这种锁机制就是所谓的  <strong>间隙锁 Next-Key 锁</strong></p><h2 id="加锁规则"><a href="#加锁规则" class="headerlink" title="加锁规则"></a>加锁规则</h2><ol><li>加锁的基本单位是（next-key lock）,他是前开后闭原则</li><li>插叙过程中访问的对象会增加锁</li><li>索引上的等值查询–给唯一索引加锁的时候，next-key lock升级为行锁</li><li>索引上的等值查询–向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁</li><li>唯一索引上的范围查询会访问到不满足条件的第一个值为止</li></ol><h2 id="间隙锁的目的是为了防止幻读，主要通过两个方面实现"><a href="#间隙锁的目的是为了防止幻读，主要通过两个方面实现" class="headerlink" title="间隙锁的目的是为了防止幻读，主要通过两个方面实现"></a><strong>间隙锁的目的是为了防止幻读，主要通过两个方面实现</strong></h2><ol><li>防止间隙内有新数据被插入</li><li>防止已存在的数据，更新成间隙内的数据（例如防止numer=3的记录通过update变成number=5）</li></ol><h2 id="innodb-使用间隙锁的条件"><a href="#innodb-使用间隙锁的条件" class="headerlink" title="innodb 使用间隙锁的条件"></a>innodb 使用间隙锁的条件</h2><ol><li>必须在 REPEATABLE READ 级别下</li><li>检索条件必须有索引，如果没有索引，MySQL 会全表扫描，那样会锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加。</li></ol><h3 id="危害"><a href="#危害" class="headerlink" title="危害"></a>危害</h3><p>执行查询过程中通过范围查找会锁定整个范围内的所有索引键值，即使这个键值并不存在，造成锁定的时候无法插入键值范围内的任何数据，在某些场景下可能对性能造成很大的危害。</p><h2 id="5-2PL"><a href="#5-2PL" class="headerlink" title="5. 2PL"></a>5. <code>2PL</code></h2><p>2PL,两阶段加锁协议:主要用于单机事务中的一致性与隔离性。</p><p>2PC,两阶段提交协议:主要用于分布式事务。</p><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>并行操作对并行事务的操作的调度是随机的，不同的调度可能产生不同的结果。在这些不同的调度中，肯定有些调度的结果是正确的，究竟哪些调度是正确的呢？<br>若每个事务的基本操作都串连在一起，没有其它事务的操作与之交叉执行，这样的调度称为串行调度，多个事务的的串行调度，其执行结果一定是正确的。但串行调度限制了系统并行性的发挥，而很多并行调度又不具有串行调度的结果，所以我们必须研究具有串行调度效果的并行调度方法。</p><p><strong>当且仅当某组并发事务的交叉调度产生的结果和这些事务的某一串行调度的结果相同，则称这个交叉调度是可串行化。</strong><br>可串行化是并行事务正确性的准则，一个交叉调度，当且仅当它是可串行化的，它才是正确的。两段锁协议是保证并行事务可串行化的方法。</p><hr><p><strong>定理：</strong>若所有事务均遵守两段锁协议，则这些事务的所有交叉调度都是可串行化的。</p><hr><p>两阶段锁协议是指所有事务必须分两个阶段对数据加锁和解锁，在对任何数据进行读、写操作之前，事务首先要获得对该数据的封锁；在释放一个封锁之后，事务不再申请和获得任何其他封锁。</p><p>两段锁协议规定所有的事务应遵守的规则：</p><ol><li>在对任何数据进行读、写操作之前，首先要申请并获得对该数据的封锁。</li><li>在释放一个封锁之后，事务不再申请和获得其它任何封锁。</li></ol><p>即事务的执行分为两个阶段：</p><ol><li>第一阶段是获得封锁的阶段，称为扩展阶段。</li><li>第二阶段是释放封锁的阶段，称为收缩阶段。</li></ol><h3 id="加锁阶段"><a href="#加锁阶段" class="headerlink" title="加锁阶段"></a>加锁阶段</h3><p>在对记录更新操作或者(select for update、lock in share model)时，会对记录加锁(有共享锁、排它锁、意向锁、gap锁、nextkey锁等等)</p><p>当对记录进行更新操作或者 <code>select for update (X锁)、</code> <code>lock in share mode(S锁) </code>时，会对记录进行加锁。</p><p>加锁阶段：在该阶段可以进行加锁操作。在对任何数据进行读操作之前要申请并获得 <code>S</code> 锁[共享锁，其它事务可以继续加共享锁，但不能加排它锁]，在进行写操作之前要申请并获得 X 锁[排它锁，其它事务不能再获得任何锁]。加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。</p><h3 id="解锁"><a href="#解锁" class="headerlink" title="解锁"></a>解锁</h3><p>在一个事务中，只有在 <code>commit</code> 或者 <code>rollback</code> 时，才是解锁阶段。</p><h2 id="6-2PC"><a href="#6-2PC" class="headerlink" title="6. 2PC"></a>6. <code>2PC</code></h2><p>为了性能考虑，每次提交事务的时候，只需要将 redo 和 undo 落盘就代表事务已经持久化了，而不需要等待数据落盘。这样就已经能保证事务的 crash 时的前滚或者回滚。</p><p>由于 undo 的信息也会写入 redo，所以其实我们只需要根据 redo 是否落盘而决定crash recovrey的时候是重做还是回滚。而上面提到，开启binlog后，还需要考虑binlog是否落盘（binlog牵扯到主从数据一致性，全备恢复的位点）。根据事务是否成功写binlog决定事务的重做还是回滚。</p><p>2PC 即innodb对于事务的两阶段提交机制。当mysql开启binlog的时候，会存在一个内部XA的问题：事务在存储引擎层（redo）commit的顺序和在binlog中提交的顺序不一致的问题。</p><h4 id="2PC-原理"><a href="#2PC-原理" class="headerlink" title="2PC 原理"></a>2PC 原理</h4><p>将事务的 commit 分为 prepare 和 commit 两个阶段</p><ol><li><p>prepare 阶段</p><p>redo 持久化到磁盘（redo group commit），并将回滚段置为 prepared 状态，此时 binlog 不做操作。</p></li><li><p>commit 阶段</p><p>innodb 释放锁，释放回滚段，设置提交状态，binlog 持久化到磁盘，然后存储引擎层提交</p></li></ol><h3 id="Group-Commit"><a href="#Group-Commit" class="headerlink" title="Group Commit"></a>Group Commit</h3><p>日志的写入基本上是顺序IO。WAL 用顺序的日志写入代替数据的随机 IO 实现事务持久化。但是尽管如此，每次事务提交都需要日志刷盘，仍然受限于磁盘IO。group commit 的出现就是为了将日志（redo/binlog）刷盘的动作合并，从而提升 IO 性能</p><h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><p>两阶段锁协议是指所有事务必须分两个阶段对数据加锁和解锁，在对任何数据进行读、写操作之前，事务首先要获得对该数据的封锁；在释放一个封锁之后，事务不再申请和获得任何其他封锁。</p><p>对应到 MySQL 上分为两个阶段：</p><ol><li>扩展阶段（事务开始后，commit 之前）：获取锁</li><li>收缩阶段（commit 之后）：释放锁</li></ol><p>就是说呢，只有遵循两段锁协议，才能实现 可串行化调度。</p><p>但是两阶段锁协议不要求事务必须一次将所有需要使用的数据加锁，并且在加锁阶段没有顺序要求，所以这种并发控制方式会形成死锁。</p><h3 id="MySQL-如何处理死锁"><a href="#MySQL-如何处理死锁" class="headerlink" title="MySQL 如何处理死锁 ?"></a><strong>MySQL 如何处理死锁</strong> ?</h3><p>MySQL 有两种死锁处理方式：</p><ol><li><p>等待，直到超时</p><p><strong><code>innodb_lock_wait_timeout=50s</code></strong></p><blockquote><p>直观方法是在两个事务相互等待时，当一个等待时间超过设置的某一阀值时，对其中一个事务进行回滚，另一个事务就能继续执行。这种方法简单有效，在 innodb 中，参数 innodb_lock_wait_timeout 用来设置超时时间。</p></blockquote></li><li><p>发起死锁检测，主动回滚一条事务，让其他事务继续执行</p><p><strong><code>innodb_deadlock_detect=on</code></strong></p><blockquote><p>innodb 还提供了 wait-for graph 算法来主动进行死锁检测，每当加锁请求无法立即满足需要并进入等待时，wait-for graph 算法都会被触发</p></blockquote><blockquote><p>innodb 将各个事务看为一个个节点，资源就是各个事务占用的锁，当事务1需要等待事务2的锁时，就生成一条有向边从1指向2，最后行成一个有向图。</p></blockquote></li></ol><p>由于性能原因，一般都是使用死锁检测来进行处理死锁。</p><h3 id="死锁成因"><a href="#死锁成因" class="headerlink" title="死锁成因"></a>死锁成因</h3><h5 id="不同表相同记录行锁冲突"><a href="#不同表相同记录行锁冲突" class="headerlink" title="不同表相同记录行锁冲突"></a><strong>不同表相同记录行锁冲突</strong></h5><p>这种情况很好理解，事务A和事务B操作两张表，但出现循环等待锁情况。</p><h5 id="同表记录行锁冲突"><a href="#同表记录行锁冲突" class="headerlink" title="同表记录行锁冲突"></a>同表记录行锁冲突</h5><h3 id="如何避免发生死锁"><a href="#如何避免发生死锁" class="headerlink" title="如何避免发生死锁 ?"></a><strong>如何避免发生死锁 ?</strong></h3><p><strong>收集死锁信息：</strong></p><ol><li>利用命令 <strong><code>SHOW ENGINE INNODB STATUS</code></strong> 查看死锁原因。</li><li>调试阶段开启 **<code>innodb_print_all_deadlocks</code>**，收集所有死锁日志。</li></ol><p><strong>减少死锁：</strong></p><ol><li>使用事务，不使用 lock tables 。</li><li>保证没有长事务。</li><li>操作完之后立即提交事务，特别是在交互式命令行中。</li><li>如果在用 (SELECT … FOR UPDATE or SELECT … LOCK IN SHARE MODE)，尝试降低隔离级别。</li><li>修改多个表或者多个行的时候，将修改的顺序保持一致。</li><li>创建索引，可以使创建的锁更少。</li><li>最好不要用 (SELECT … FOR UPDATE or SELECT … LOCK IN SHARE MODE)。</li><li>如果上述都无法解决问题，那么尝试使用 lock tables t1, t2, t3 锁多张表</li></ol><h1 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h1><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><p>innodb 的意向锁主要用户多粒度的锁并存的情况。比如事务 A 要在一个表上加 S 锁，如果表中的一行已被事务B 加了 X 锁，那么该锁的申请也应被阻塞。如果表中的数据很多，逐行检查锁标志的开销将很大，系统的性能将会受到影响。为了解决这个问题，可以在表级上引入新的锁类型来表示其所属行的加锁情况，这就引出了 <strong>“意向锁”</strong> 的概念。</p><p>如果表中记录1亿，事务 A 把其中有几条记录上了行锁了，这时事务 B 需要给这个表加表级锁，如果没有意向锁的话，那就要去表中查找这一亿条记录是否上锁了。如果存在意向锁，那么假如事务Ａ在更新一条记录之前，先加意向锁，再加Ｘ锁，事务 B 先检查该表上是否存在意向锁，存在的意向锁是否与自己准备加的锁冲突，如果有冲突，则等待直到事务Ａ释放，而无须逐条记录去检测。事务Ｂ更新表时，其实无须知道到底哪一行被锁了，它只要知道反正有一行被锁了就行了。</p><h2 id="6-2-作用"><a href="#6-2-作用" class="headerlink" title="6.2. 作用"></a>6.2. 作用</h2><p>意向锁的主要作用是处理行锁和表锁之间的矛盾，能够显示“某个事务正在某一行上持有了锁，或者准备去持有锁”</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase WAL机制</title>
      <link href="2019/02/22/HBase-WAL%E6%9C%BA%E5%88%B6(1)/"/>
      <url>2019/02/22/HBase-WAL%E6%9C%BA%E5%88%B6(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在分布式环境下，用户必须要考虑系统出错的情形，例如，Region服务器发生故障时， MemStore 缓存中还没有被写入文件的数据会全部丢失。因此，HBase 采用 HLog 来保证系统发生故障时能够恢复到正常的状态。HBase 的 Write Ahead Log (WAL) 提供了一种高并发、持久化的日志保存与回放机制。每一个业务数据的写入操作（PUT / DELETE）执行前，都会记账在 WAL 中。</p><a id="more"></a><p>每个 Region 服务器都有一个 HLog 文件，同一个 Region 服务器的 Region 对象共用一个 HLog，HLog 是一种预写日志（Write Ahead Log）文件。</p><p>也就是说，用户更新数据必须先被记入日志后才能写入 MemStore 缓存，当缓存内容对应的日志已经被写入磁盘后，即日志写成功后，缓存的内容才会被写入磁盘。</p><p>ZooKeeper 会实时监测每个 Region 服务器的状态，当某个 Region 服务器发生故障时，ZooKeeper 会通知 Master，Master 首先会处理该故障 Region 服务器上遗留的 HLog 文件。</p><p>由于一个 Region 服务器上可能会维护着多个 Region 对象，这些 Region 对象共用一个 HLog 文件，因此这个遗留的 HLog 文件中包含了来自多个 Region 对象的日志记录。</p><p>系统会根据每条日志记录所属的 Region 对象对 HLog 数据进行拆分，并分别存放到相应 Region 对象的目录下。再将失效的 Region 重新分配到可用的 Region 服务器中，并在可用的 Region 服务器中重新进行日志记录中的各种操作， 把日志记录中的数据写入 MemStore 然后刷新到磁盘的 StoreFile 文件中，完成数据恢复。</p><p>在 HBase 系统中每个 Region 服务器只需要一个 HLog 文件，所有 Region 对象共用一个 HLog，而不是每个 Region 使用一个 HLog。在这种 Region 对象共用一个 HLog 的方式中，多个 Region 对象在进行更新操作需要修改日志时，只需要不断地把日志记录追加到单个日志文件中，而不需要同时打开、写入多个日志文件中，因此可以减少磁盘寻址次数，提高对表的写操作性能。</p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase WAL机制</title>
      <link href="2019/02/22/HBase-WAL%E6%9C%BA%E5%88%B6/"/>
      <url>2019/02/22/HBase-WAL%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在分布式环境下，用户必须要考虑系统出错的情形，例如，Region服务器发生故障时， MemStore 缓存中还没有被写入文件的数据会全部丢失。因此，HBase 采用 HLog 来保证系统发生故障时能够恢复到正常的状态。HBase 的 Write Ahead Log (WAL) 提供了一种高并发、持久化的日志保存与回放机制。每一个业务数据的写入操作（PUT / DELETE）执行前，都会记账在 WAL 中。</p><a id="more"></a><p>每个 Region 服务器都有一个 HLog 文件，同一个 Region 服务器的 Region 对象共用一个 HLog，HLog 是一种预写日志（Write Ahead Log）文件。</p><p>也就是说，用户更新数据必须先被记入日志后才能写入 MemStore 缓存，当缓存内容对应的日志已经被写入磁盘后，即日志写成功后，缓存的内容才会被写入磁盘。</p><p>ZooKeeper 会实时监测每个 Region 服务器的状态，当某个 Region 服务器发生故障时，ZooKeeper 会通知 Master，Master 首先会处理该故障 Region 服务器上遗留的 HLog 文件。</p><p>由于一个 Region 服务器上可能会维护着多个 Region 对象，这些 Region 对象共用一个 HLog 文件，因此这个遗留的 HLog 文件中包含了来自多个 Region 对象的日志记录。</p><p>系统会根据每条日志记录所属的 Region 对象对 HLog 数据进行拆分，并分别存放到相应 Region 对象的目录下。再将失效的 Region 重新分配到可用的 Region 服务器中，并在可用的 Region 服务器中重新进行日志记录中的各种操作， 把日志记录中的数据写入 MemStore 然后刷新到磁盘的 StoreFile 文件中，完成数据恢复。</p><p>在 HBase 系统中每个 Region 服务器只需要一个 HLog 文件，所有 Region 对象共用一个 HLog，而不是每个 Region 使用一个 HLog。在这种 Region 对象共用一个 HLog 的方式中，多个 Region 对象在进行更新操作需要修改日志时，只需要不断地把日志记录追加到单个日志文件中，而不需要同时打开、写入多个日志文件中，因此可以减少磁盘寻址次数，提高对表的写操作性能。</p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase 读写流程</title>
      <link href="2019/02/22/HBase%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B(1)/"/>
      <url>2019/02/22/HBase%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HBase 的核心模块是 RegionServer。RegionServer 由多个 Region 块构成，Region 块中存储一系列连续的数据集。RegionServer 主要构成部分是 HLog 和 Region 块。HLog 记录该 Region 的操作日志。</p><p>Region 对象由多个 Store 组成，每个 Store 对应当前分区中的一个列族，每个 Store 管理一块内存，即 MemStoreo 当 MemStore 中的数据达到一定条件时会写入 StoreFile 文件中，因此每个 Store 包含若干个 StoreFile 文件。StoreFile 文件对应 HDFS 中的 HFile 文件。</p><a id="more"></a><h1 id="1-读流程"><a href="#1-读流程" class="headerlink" title="1.读流程"></a>1.读流程</h1><p>客户端读取数据有两种方式， <strong>Get</strong> 与 <strong>Scan</strong>。 Get 是一种随机点查的方式，根据 rowkey 返回一行数据，也可以在构造 Get 对象的时候传入一个 rowkey 列表，这样一次 RPC 请求可以返回多条数据。Get 对象可以设置列与 filter，只获取特定 rowkey 下的指定列的数据。Scan 是范围查询，通过指定 Scan 对象的 startRow 与 endRow 来确定一次扫描的数据范围，获取该区间的所有数据。</p><p>单条 rowkey 的 Get 请求为例，当用户初始化到 zookeeper 的连接之后，并发送一个 Get 请求时，需要先定位这条 rowkey 的 HRegion 地址。如果该地址不在缓存之中，就需要请求 zookeeper ，询问 meta 表的地址。在获取到 meta 表地址之后去读取 meta 表的数据来根据 rowkey 定位到该 rowkey 属于的 HRegion 信息和 RegionServer 的地址，缓存该地址并发 Get 请求点对点发送到对应的 RegionServer，至此，客户端定位发送请求的流程走通。</p><h2 id="1-1-步骤"><a href="#1-1-步骤" class="headerlink" title="1.1.步骤"></a>1.1.步骤</h2><ol><li><p>Client 访问 ZooKeeper（/hbase/meta-region-server)，获取 <strong>hbase:meta</strong> 表所在 Region 的位置信息，并将该位置信息写入 Client Cache。</p><p><strong><font color='red'>注：为了加快数据访问速度，我们将元数据、Region 位置等信息缓存在 Client Cache</font></strong></p></li><li><p>Client 根据位置信息访问 RegionServer 读取 <strong>hbase:meta</strong> 表，根据读请求的 Namespace、表名和 RowKey 等相关信息，获取目标数据的 Region 的位置信息。client 将保存着 RegionServer 位置信息的元数据表 <strong>hbase:meta</strong> 进行缓存</p></li><li><p>Client 向 HRegionServer 发出读请求</p></li><li><p>分别在 Block Cache（读缓冲），MemStore 和 StoreFile（HFile）中查询目标数据，并将查到的所有数据进行合并。</p><p><strong><font color='red'>注：此处所有数据是指同一条数据的不同版本或者不同类型</font></strong></p></li><li><p>将文件中查询得到的数据块（Block，HFile数据存储单元，默认为64KB）缓冲到 Block Cache。</p><p>注：BlockCache 采用的算法为 LRU（最近最少使用算法），因此当 BlockCache 达到上限后，会启动淘汰机制，淘汰掉最老的一批数据。</p></li><li><p>将合并后的结果返回给客户端</p></li></ol><h2 id="1-2-注意事项"><a href="#1-2-注意事项" class="headerlink" title="1.2.注意事项"></a>1.2.注意事项</h2><ol><li>在通用层面，在客户端与服务端建连需要与 zookeeper 通信，再通过 meta 表定位到 region 信息，为了加快数据访问速度，我们将元数据、Region位置等信息缓存在Client Cache中，所以在初次读取 HBase 的时候 rt 都会比较高，避免这个情况就需要客户端针对表来做预热，简单的预热可以通过获取 table 所有的 region 信息，再对每一个 region 发送一个 Scan 或者 Get 请求，这样就会缓存 region 的地址。</li><li>读写流程与 HMaster 无关，干掉 HMaster 依旧可以读写 HBase，但是无法切分和合并。</li></ol><h1 id="2-写流程"><a href="#2-写流程" class="headerlink" title="2.写流程"></a>2.写流程</h1><h2 id="2-1-步骤"><a href="#2-1-步骤" class="headerlink" title="2.1.步骤"></a>2.1.步骤</h2><ol><li><p>Client访问 zookeeper，获取 hbase:meta 表所在 Region 的位置信息，并将该位置信息写入客户端缓存 Client Cache。</p><p><strong><font color='red'>注：为了加快数据访问速度，我们将元数据、Region 位置等信息缓存在 Client Cache </font></strong></p></li><li><p>Client 根据位置信息访问 RegionServer 读取 hbase:meta 表，再根据读请求信息 Namespace、表名和 RowKey 等相关信息，获取目标数据的 Region 的位置信息，最后 client 端会将 meta 表写入Client Cache。</p></li><li><p>Client 向 HRegionServer 发出写请求。</p></li><li><p>HRegionServer 先将操作和数据写入 HLog（预写日志，Write Ahead Log，WAL），再将数据写入 MemStore，并保持有序。 </p></li><li><p>随着数据量的不断增加，当 MemStore 的数据量超过阈值时，将数据溢写磁盘，生成一个 StoreFile 文件。<br>当 Store 中 StoreFile 的数量超过阈值时，将若干小 StoreFile 合并（Compact）为一个大StoreFile。<br>当 Region 中最大 Store 的大小超过阈值时，Region分裂（Split），等分成两个子 Region。</p></li></ol><h2 id="2-2-优化"><a href="#2-2-优化" class="headerlink" title="2.2.优化"></a>2.2.优化</h2>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase 读写流程</title>
      <link href="2019/02/22/HBase%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B(2)/"/>
      <url>2019/02/22/HBase%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B(2)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HBase 的核心模块是 RegionServer。RegionServer 由多个 Region 块构成，Region 块中存储一系列连续的数据集。RegionServer 主要构成部分是 HLog 和 Region 块。HLog 记录该 Region 的操作日志。</p><p>Region 对象由多个 Store 组成，每个 Store 对应当前分区中的一个列族，每个 Store 管理一块内存，即 MemStoreo 当 MemStore 中的数据达到一定条件时会写入 StoreFile 文件中，因此每个 Store 包含若干个 StoreFile 文件。StoreFile 文件对应 HDFS 中的 HFile 文件。</p><a id="more"></a><h1 id="1-读流程"><a href="#1-读流程" class="headerlink" title="1.读流程"></a>1.读流程</h1><p>客户端读取数据有两种方式， <strong>Get</strong> 与 <strong>Scan</strong>。 Get 是一种随机点查的方式，根据 rowkey 返回一行数据，也可以在构造 Get 对象的时候传入一个 rowkey 列表，这样一次 RPC 请求可以返回多条数据。Get 对象可以设置列与 filter，只获取特定 rowkey 下的指定列的数据。Scan 是范围查询，通过指定 Scan 对象的 startRow 与 endRow 来确定一次扫描的数据范围，获取该区间的所有数据。</p><p>单条 rowkey 的 Get 请求为例，当用户初始化到 zookeeper 的连接之后，并发送一个 Get 请求时，需要先定位这条 rowkey 的 HRegion 地址。如果该地址不在缓存之中，就需要请求 zookeeper ，询问 meta 表的地址。在获取到 meta 表地址之后去读取 meta 表的数据来根据 rowkey 定位到该 rowkey 属于的 HRegion 信息和 RegionServer 的地址，缓存该地址并发 Get 请求点对点发送到对应的 RegionServer，至此，客户端定位发送请求的流程走通。</p><h2 id="1-1-步骤"><a href="#1-1-步骤" class="headerlink" title="1.1.步骤"></a>1.1.步骤</h2><ol><li><p>Client 访问 ZooKeeper（/hbase/meta-region-server)，获取 <strong>hbase:meta</strong> 表所在 Region 的位置信息，并将该位置信息写入 Client Cache。</p><p><strong><font color='red'>注：为了加快数据访问速度，我们将元数据、Region 位置等信息缓存在 Client Cache</font></strong></p></li><li><p>Client 根据位置信息访问 RegionServer 读取 <strong>hbase:meta</strong> 表，根据读请求的 Namespace、表名和 RowKey 等相关信息，获取目标数据的 Region 的位置信息。client 将保存着 RegionServer 位置信息的元数据表 <strong>hbase:meta</strong> 进行缓存</p></li><li><p>Client 向 HRegionServer 发出读请求</p></li><li><p>分别在 Block Cache（读缓冲），MemStore 和 StoreFile（HFile）中查询目标数据，并将查到的所有数据进行合并。</p><p><strong><font color='red'>注：此处所有数据是指同一条数据的不同版本或者不同类型</font></strong></p></li><li><p>将文件中查询得到的数据块（Block，HFile数据存储单元，默认为64KB）缓冲到 Block Cache。</p><p>注：BlockCache 采用的算法为 LRU（最近最少使用算法），因此当 BlockCache 达到上限后，会启动淘汰机制，淘汰掉最老的一批数据。</p></li><li><p>将合并后的结果返回给客户端</p></li></ol><h2 id="1-2-注意事项"><a href="#1-2-注意事项" class="headerlink" title="1.2.注意事项"></a>1.2.注意事项</h2><ol><li>在通用层面，在客户端与服务端建连需要与 zookeeper 通信，再通过 meta 表定位到 region 信息，为了加快数据访问速度，我们将元数据、Region位置等信息缓存在Client Cache中，所以在初次读取 HBase 的时候 rt 都会比较高，避免这个情况就需要客户端针对表来做预热，简单的预热可以通过获取 table 所有的 region 信息，再对每一个 region 发送一个 Scan 或者 Get 请求，这样就会缓存 region 的地址。</li><li>读写流程与 HMaster 无关，干掉 HMaster 依旧可以读写 HBase，但是无法切分和合并。</li></ol><h1 id="2-写流程"><a href="#2-写流程" class="headerlink" title="2.写流程"></a>2.写流程</h1><h2 id="2-1-步骤"><a href="#2-1-步骤" class="headerlink" title="2.1.步骤"></a>2.1.步骤</h2><ol><li><p>Client访问 zookeeper，获取 hbase:meta 表所在 Region 的位置信息，并将该位置信息写入客户端缓存 Client Cache。</p><p><strong><font color='red'>注：为了加快数据访问速度，我们将元数据、Region 位置等信息缓存在 Client Cache </font></strong></p></li><li><p>Client 根据位置信息访问 RegionServer 读取 hbase:meta 表，再根据读请求信息 Namespace、表名和 RowKey 等相关信息，获取目标数据的 Region 的位置信息，最后 client 端会将 meta 表写入Client Cache。</p></li><li><p>Client 向 HRegionServer 发出写请求。</p></li><li><p>HRegionServer 先将操作和数据写入 HLog（预写日志，Write Ahead Log，WAL），再将数据写入 MemStore，并保持有序。 </p></li><li><p>随着数据量的不断增加，当 MemStore 的数据量超过阈值时，将数据溢写磁盘，生成一个 StoreFile 文件。<br>当 Store 中 StoreFile 的数量超过阈值时，将若干小 StoreFile 合并（Compact）为一个大StoreFile。<br>当 Region 中最大 Store 的大小超过阈值时，Region分裂（Split），等分成两个子 Region。</p></li></ol><h2 id="2-2-优化"><a href="#2-2-优化" class="headerlink" title="2.2.优化"></a>2.2.优化</h2>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase 读写流程</title>
      <link href="2019/02/22/HBase%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/"/>
      <url>2019/02/22/HBase%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HBase 的核心模块是 RegionServer。RegionServer 由多个 Region 块构成，Region 块中存储一系列连续的数据集。RegionServer 主要构成部分是 HLog 和 Region 块。HLog 记录该 Region 的操作日志。</p><p>Region 对象由多个 Store 组成，每个 Store 对应当前分区中的一个列族，每个 Store 管理一块内存，即 MemStoreo 当 MemStore 中的数据达到一定条件时会写入 StoreFile 文件中，因此每个 Store 包含若干个 StoreFile 文件。StoreFile 文件对应 HDFS 中的 HFile 文件。</p><a id="more"></a><h1 id="1-读流程"><a href="#1-读流程" class="headerlink" title="1.读流程"></a>1.读流程</h1><p>客户端读取数据有两种方式， <strong>Get</strong> 与 <strong>Scan</strong>。 Get 是一种随机点查的方式，根据 rowkey 返回一行数据，也可以在构造 Get 对象的时候传入一个 rowkey 列表，这样一次 RPC 请求可以返回多条数据。Get 对象可以设置列与 filter，只获取特定 rowkey 下的指定列的数据。Scan 是范围查询，通过指定 Scan 对象的 startRow 与 endRow 来确定一次扫描的数据范围，获取该区间的所有数据。</p><p>单条 rowkey 的 Get 请求为例，当用户初始化到 zookeeper 的连接之后，并发送一个 Get 请求时，需要先定位这条 rowkey 的 HRegion 地址。如果该地址不在缓存之中，就需要请求 zookeeper ，询问 meta 表的地址。在获取到 meta 表地址之后去读取 meta 表的数据来根据 rowkey 定位到该 rowkey 属于的 HRegion 信息和 RegionServer 的地址，缓存该地址并发 Get 请求点对点发送到对应的 RegionServer，至此，客户端定位发送请求的流程走通。</p><h2 id="1-1-步骤"><a href="#1-1-步骤" class="headerlink" title="1.1.步骤"></a>1.1.步骤</h2><ol><li><p>Client 访问 ZooKeeper（/hbase/meta-region-server)，获取 <strong>hbase:meta</strong> 表所在 Region 的位置信息，并将该位置信息写入 Client Cache。</p><p><strong><font color='red'>注：为了加快数据访问速度，元数据、Region 位置等信息缓存在 Client Cache</font></strong></p></li><li><p>Client 根据位置信息访问 RegionServer 读取 <strong>hbase:meta</strong> 表，根据读请求的 Namespace、表名和 RowKey 等相关信息，获取目标数据的 Region 的位置信息。client 将保存着 RegionServer 位置信息的元数据表 <strong>hbase:meta</strong> 进行缓存</p></li><li><p>Client 向 HRegionServer 发出读请求</p></li><li><p>分别在 Block Cache（读缓冲），MemStore 和 StoreFile（HFile）中查询目标数据，并将查到的所有数据进行合并。</p><p><strong><font color='red'>注：此处所有数据是指同一条数据的不同版本或者不同类型</font></strong></p></li><li><p>将文件中查询得到的数据块（Block，HFile数据存储单元，默认为64KB）缓冲到 Block Cache。</p><p>注：BlockCache 采用的算法为 LRU（最近最少使用算法），因此当 BlockCache 达到上限后，会启动淘汰机制，淘汰掉最老的一批数据。</p></li><li><p>将合并后的结果返回给客户端</p></li></ol><h2 id="1-2-注意事项"><a href="#1-2-注意事项" class="headerlink" title="1.2.注意事项"></a>1.2.注意事项</h2><ol><li>在通用层面，在客户端与服务端建连需要与 zookeeper 通信，再通过 meta 表定位到 region 信息，为了加快数据访问速度，我们将元数据、Region位置等信息缓存在Client Cache中，所以在初次读取 HBase 的时候 rt 都会比较高，避免这个情况就需要客户端针对表来做预热，简单的预热可以通过获取 table 所有的 region 信息，再对每一个 region 发送一个 Scan 或者 Get 请求，这样就会缓存 region 的地址。</li><li>读写流程与 HMaster 无关，干掉 HMaster 依旧可以读写 HBase，但是无法切分和合并。</li></ol><h1 id="2-写流程"><a href="#2-写流程" class="headerlink" title="2.写流程"></a>2.写流程</h1><h2 id="2-1-步骤"><a href="#2-1-步骤" class="headerlink" title="2.1.步骤"></a>2.1.步骤</h2><ol><li><p>Client访问 zookeeper，获取 hbase:meta 表所在 Region 的位置信息，并将该位置信息写入客户端缓存 Client Cache。</p><p><strong><font color='red'>注：为了加快数据访问速度，将元数据、Region 位置等信息缓存在 Client Cache </font></strong></p></li><li><p>Client 根据位置信息访问 RegionServer 读取 hbase:meta 表，再根据读请求信息 Namespace、表名和 RowKey 等相关信息，获取目标数据的 Region 的位置信息，最后 client 端会将 meta 表写入Client Cache。</p></li><li><p>Client 向 HRegionServer 发出写请求。</p></li><li><p>HRegionServer 先将操作和数据写入 HLog（预写日志，Write Ahead Log，WAL），再将数据写入 MemStore，并保持有序。 </p></li><li><p>随着数据量的不断增加，当 MemStore 的数据量超过阈值时，将数据溢写磁盘，生成一个 StoreFile 文件。<br>当 Store 中 StoreFile 的数量超过阈值时，将若干小 StoreFile 合并（Compact）为一个大StoreFile。<br>当 Region 中最大 Store 的大小超过阈值时，Region分裂（Split），等分成两个子 Region。</p></li></ol><h2 id="2-2-优化"><a href="#2-2-优化" class="headerlink" title="2.2.优化"></a>2.2.优化</h2>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello HBase</title>
      <link href="2019/02/22/HBase%E6%A6%82%E8%BF%B0(1)/"/>
      <url>2019/02/22/HBase%E6%A6%82%E8%BF%B0(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HBase 是一种构建在 HDFS 之上的分布式、面向列的存储系统。在需要实时读写、随机访问超大规模数据集时，可以使用 HBase。</p><a id="more"></a><h2 id="HBase-特点"><a href="#HBase-特点" class="headerlink" title="HBase 特点"></a>HBase 特点</h2><ol><li><p><strong>海量存储</strong></p><p><font color='grey'> HBase 适合存储 PB 级别的海量数据</font></p><p>上百亿行 x 上百万列</p><p>并没有列的限制</p></li><li><p><strong>面向列</strong></p><p>面向列的存储和权限控制，并支持独立检索，可以动态增加列，即，<strong>可单独对列进行各方面的操作</strong></p><p>列式存储，其数据在表中是按照某列存储的，这样在查询只需要少数几个字段的时候，能大大减少读取的数量</p></li><li><p><strong>多版本</strong></p><p>Hbase 的每一个列的数据存储有多个 Version，比如住址列，可能有多个变更，所以该列可以有多个version</p></li><li><p><strong>稀疏</strong></p><p>为空的列并不占用存储空间，表可以设计的非常稀疏。不必像关系型数据库那样需要预先知道所有列名然后再进行 null 填充</p></li><li><p><strong>高并发、低延迟</strong></p><p>底层的 <strong>LSM数据结构</strong> 和 RowKey 字典有序排列等架构上的独特设计，使得 Hbase <strong>写入性能</strong>非常高。</p><p>Region切分、主键索引、缓存机制使得 Hbase 在海量数据下具备一定的随机读取性能，该性能针对Rowkey 的查询能够到达毫秒级别</p><p><strong><font color='grey'>LSM树，树形结构，最末端的子节点是以内存的方式进行存储的，内存中的小树会flush到磁盘中（当子节点达到一定阈值以后，会放到磁盘中，且存入的过程会进行实时merge成一个主节点，然后磁盘中的树定期会做merge操作，合并成一棵大树，以优化读性能。</font></strong></p></li><li><p><strong>易扩展</strong></p><p><strong><font color='grey'>底层依赖HDFS，当磁盘空间不足的时候，只需要动态增加 Datanode 节点服务</font></strong></p></li></ol><h2 id="HBase-VS-MySQL"><a href="#HBase-VS-MySQL" class="headerlink" title="HBase VS MySQL"></a>HBase <code>VS</code> MySQL</h2><ol><li><p><strong>存储方式</strong></p><p>MySQL 是关系数据库，其只能存储结构化的数据；HBase一个分布式的基于列式存储的非关系数据库，核心概念是列族，适合存储半结构化或非结构化数据</p><p>MySQL 中要提前定义表结构，数据表共有多少列需要提前定义好，并且同时需要定义每个列所占用的存储空间。数据以行为单位组织在一起的，某一行的某一列没有数据，也需要占用存储空间。HBase 则是以列为单位存储数据，每一列就是一个 key-value，HBase 的列不用提前定义，而且列可以动态扩展</p></li><li><p><strong>容量</strong></p><p>MySQL 并不是天生支持分布式的，所以其存储空间容易受到机器限制，而 HBase 则不同，依靠于 HDFS 分布式文件系统，其存储容量可以达到无限大</p></li><li><p><strong>元数据管理</strong></p><p>HBase 必须依托于 zookeeper 来管理元数据，而 MySQL 不需要</p></li></ol><h2 id="列存储-VS-行存储"><a href="#列存储-VS-行存储" class="headerlink" title="列存储 VS 行存储"></a>列存储 <code>VS</code> 行存储</h2><p>列数据库在数据仓库、商务智能领域应用中有着先天的优势: 独特的存储方式, 能够迅速地执行复杂查询; 列数据库的压缩技术, 更是能为数据仓库、商务智能应用中巨大的数据量节约存储成本; 列数据库先进的索引技术也大大提高了数据库的管理。两者的本质区别在于其物理存储是基于列存储还是基于行存储。</p><ol><li><p><strong>数据写入</strong></p><p>行存储的写入是一次完成。如果这种写入建立在操作系统的文件系统上，可以保证写入过程的成功或者失败，数据的完整性因此可以确定。</p><p>列存储由于需要把一行记录拆分成单列保存，那么要进行一行一行的数据写入的时候，可能就需要 “跳跃式” 的将每一行每一列的值写入到不同的区块，写入次数明显比行存储多，再加上磁头需要在盘片上移动和定位花费的时间，实际时间消耗会更大。所以，行存储在写入上占有很大的优势。</p></li><li><p><strong>数据修改</strong></p><p>还有数据修改,这实际也是一次写入过程。不同的是，数据修改是对磁盘上的记录做删除标记。行存储是在指定位置写入一次，列存储是将磁盘定位到多个列上分别写入，这个过程仍是行存储的列数倍。所以，数据修改也是以行存储占优。 </p></li><li><p><strong>数据读取</strong></p><p>数据读取时，行存储通常将一行数据完全读出，如果只需要其中几列数据的情况，就会存在冗余列，出于缩短处理时间的考量，消除冗余列的过程通常是在内存中进行的。</p><p>列存储每次读取的数据是集合的一段或者全部，如果读取多列时，就需要移动磁头，再次定位到下一列的位置继续读取。</p></li><li><p><strong>数据删除</strong></p><p>无论是在行数据库还是列数据库中，在删除一条记录时, 都会出现一个物理存储空间上不连续的空洞。</p><p>在行数据库中, 随着一段时间的增删操作, 这些空洞会越来越多, 越来越大。这一方面会导致物理存储空间的闲置和浪费, 另一方面会使得访问数据库的效率下降。因此, 行数据库管理员为了填补这些空洞、消除空洞带来的负面影响, 经常在维护时要做的事情是把数据全部导出来, 再重新导回去。列数据库因为在每一列上都采用了轻量的稀疏索引, 在插入删除数据时, 利用这些索引可以把空洞尽量减小, 免除了数据库管理员的大量导入、导出工作。</p></li><li><p><strong>压缩优势</strong></p><p><font color='grey'>列数据库按列存储的结构, 便于在列上对数据进行轻量级的压缩, 列上多个相同的值只需要存储一份。压缩能够大量地降低存储成本。</font></p></li></ol><h2 id="HBase-架构"><a href="#HBase-架构" class="headerlink" title="HBase 架构"></a>HBase 架构</h2><p>HBase 架构包括 HMaster、HRegionSever等。HBase底层依赖 HDFS，通过 DFS Cilent 进行 HDFS 操作。HMaster 负责把 HRegion 分配给HRegionServer，每一个 HRegionServer 可以包含多个 HRegion，多个 HRegion 共享HLog，HLog 用来做灾难恢复。每一个 HRegion 由一个或多个 Store 组成，一个 Store 对应表的一个列族，每个 Store中包含与其对应的 MemStore 以及一个或多个 StoreFile（是实际数据存储文件HFile的轻量级封装），MemStore是在内存中的，保存了修改的数据，MemStore中的数据写到文件中就是StoreFile。</p><img src="/images/hbase1.png" alt="" style="zoom:60%;" /><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p><strong>客户端包含访问 HBase 的接口，是整个 HBase 系统的入口，使用者直接通过客户端操作 HBase。客户端使用 HBase 的 RPC 机制与 HMaster 和 RegionServer 进行通信。</strong></p><p>在一般情况下，客户端与 HMaster 进行管理类操作的通信，在获取 RegionServer 的信息后，直接与 RegionServer 进行数据读写类操作。而且客户端获取 Region 的位置信息后会缓存下来，用来加速后续数据的访问过程。</p><p>客户端可以用 Java 语言来实现，也可以使用 Thrift、Rest 等客户端模式，甚至 MapReduce 也可以算作一种客户端。</p><h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><p><strong>HMaster 是 HBase 集群中的主服务器，负责监控集群中所有 RegionServer，并且是所有元数据更改的接口</strong></p><p>在分布式集群中，HMaster 服务器通常运行在 HDFS 的 NameNode 上，HMaster 通过 ZooKeeper来避免单点故障，在集群中可以启动多个 HMaster，但 ZooKeeper 的选举机制能够保证同时只有一个 HMaster 处于 Active 状态，其他的 HMaster 处于热备份状态。</p><p><strong>HMaster 主要负责表和 Region 的管理工作。</strong></p><ol><li>管理用户对表的增、删、改、查操作。</li><li>管理 RegionServer 的负载均衡，调整 Region 的分配。</li><li>Region 的分配和移除</li><li>处理 RegionServer 的故障转移。</li></ol><h3 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h3><p>ZooKeeper 是一个高性能、集中化、分布式应用程序协调服务，主要是用来解决分布式应用中用户经常遇到的一些数据管理问题，例如，数据发布/订阅、命名服务、分布式协调通知、集群管理、Master 选举、分布式锁和分布式队列等功能。其中，Master 选举是 ZooKeeper 最典型的应用场景。</p><p>在 Hadoop 中，ZooKeeper 主要用于实现高可靠性（High Availability, HA），包括 HDFS 的 NameNode 和 YARN 的 ResourceManager 的 HA。 以 HDFS 为例，NameNode 作为 HDFS 的主节点，负责管理文件系统的命名空间以及客户端对文件的访问，同时需要监控整个 HDFS 中每个 DataNode 的状态，实现负载均衡和容错。</p><p>为了实现 HA，必须有多个 NameNode 并存，并且只有一个 NameNode 处于活跃状态，其他的则处于备用状态。当活跃的 NameNode 无法正常工作时， 处于备用状态的 NameNode 会通过竞争选举产生新的活跃节点来保证 HDFS 集群的高可靠性。</p><p><strong>ZooKeeper 在 HBase 中的负责协调的任务如下：</strong></p><ul><li><p><strong>Master 选举</strong></p><blockquote><p>同 HDFS 的 HA 机制一样，HBase 集群中有多个 HMaster 并存，通过竞争选举机制保证同一时刻只有一个 HMaster 处于活跃状态，一旦这个 HMaster 无法使用，则从备用节点中选出一个顶上，保证集群的高可靠性。</p></blockquote></li><li><p><strong>系统容错</strong></p><blockquote><p>在 HBase 启动时，每个 RegionServer 在加入集群时都需要到 ZooKeeper 中进行注册，创建一个状态节点，ZooKeeper 会实时监控每个 RegionServer 的状态，同时 HMaster 会监听注册的 RegionServer。</p></blockquote><blockquote><p>当某个 RegionServer 挂断的时候，ZooKeeper 会因为一段时间内接收不到它的心跳信息而删除该 RegionServer 对应的状态节点，并且给 HMaster 发送节点删除的通知。这时，HMaster 获知集群中某节点断开，会立即调度其他节点开启容错机制。</p></blockquote></li><li><p><strong>Region 元数据管理</strong></p><blockquote><p> 在 HBase 集群中，Region 元数据被存储在 Meta 表中。每次客户端发起新的请求时，需要查询 Meta 表来获取 Region 的位置，而 Meta 表是存在 ZooKeeper 中的。</p></blockquote><blockquote><p>当 Region 发生变化时，例如，Region 的手工移动、进行负载均衡的移动或 Region 所在的 RegionServer 出现故障等，就能够通过 ZooKeeper 来感知到这一变化，保证客户端能够获得正确的 Region 元数据信息。</p></blockquote></li><li><p><strong>Region 状态管理</strong></p><blockquote><p>HBase 集群中 Region 会经常发生变更，其原因可能是系统故障，配置修改，或者是 Region 的分裂和合并。只要 Region 发生变化，就需要让集群的所有节点知晓，否则就会出现某些事务性的异常。</p></blockquote><blockquote><p>而对于 HBase 集群，Region 的数量会达到 10 万，甚至更多。如此规模的 Region 状态管理如果直接由 HMaster 来实现，则 HMaster 的负担会很重，因此只有依靠 ZooKeeper 系统来完成。</p></blockquote></li><li><p><strong>提供 Meta 表存储位置</strong></p><blockquote><p>在 HBase 集群中，数据库表信息、列族信息及列族存储位置信息都属于元数据。这些元数据存储在 Meta 表中，而 Meta 表的位置入口由 ZooKeeper 来提供。</p></blockquote></li></ul><h3 id="RegionServer"><a href="#RegionServer" class="headerlink" title="RegionServer"></a>RegionServer</h3><p>在 HDFS 中，DataNode 负责存储实际数据。RegionServer 主要负责响应用户的请求，向 HDFS 读写数据。一般在分布式集群中，RegionServer 运行在 DataNode 服务器上，实现数据的本地性。</p><p>RegionServer 是 HBase 中最核心的模块，其内部管理了一系列 Region 对象，每个 Region 由多个 HStore 组成，每个 HStore 对应表中一个列族的存储。</p><p>HBase 是按列进行存储的，将列族作为一个集中的存储单元，并且 HBase 将具备相同 I/O 特性的列存储到一个列族中，这样可以保证读写的高效性。</p><p>每个 RegionServer 包含多个 Region，它负责的功能如下：</p><ul><li><strong>处理分批给它的 Region。</strong></li><li><strong>处理客户端读写请求。</strong></li><li><strong>刷新缓存到 HDFS 中。</strong></li><li><strong>处理 Region 分片。</strong></li><li><strong>执行压缩。</strong></li></ul><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p>HBase 是一种列存储模式与键值对存储模式结合的 NoSQL 数据库，它具有灵活的数据模型，不仅可以基于键进行快速查询，还可以实现基于值、列名等的全文遍历和检索。</p><p>HBase 可以实现自动的数据分片，用户不需要知道数据存储在哪个节点上，只要说明检索的要求，系统会自动进行数据的查询和反馈</p><p>HBase 不支持关系模型，它可以根据用户的需求提供更灵活和可扩展的表设计。与传统的关系型数据库类似，HBase 也是以表的方式组织数据，应用程序将数据存于 HBase 的表中，HBase 的表也由行和列组成。</p><img src="/images/hbase2.png" alt="" style="zoom:60%;" /><h3 id="行键"><a href="#行键" class="headerlink" title="行键"></a><strong>行键</strong></h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>在 HBase 表里，每一行代表一个数据对象，每一行都以行键（Row Key）来进行唯一标识。</p><p>在 HBase 内部，行键是不可分割的字节数组，并且按照字典排序由低到高存储在表中的。</p><p>在 HBase 中可以针对行键建立索引，提高检索数据的速度。</p><h4 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h4><ul><li><p><strong>rowkey 长度原则</strong></p><p>rowkey 是一个二进制数组，可以是任意字符串，最大长度 64kb。实际应用中一般为 10-100 bytes，以byte[] 形式保存，一般设计成定长。建议越短越好，不要超过16个字节，原因如下：</p><ul><li><p>目前操作系统都是64位系统，内存 8 字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。</p></li><li><p>hbase 将部分数据加载到内存当中，如果 rowkey 过长，内存的有效利用率就会下降</p></li></ul></li><li><p><strong>rowkey 散列原则</strong></p><p>建议将 rowkey 的高位字节采用散列字段处理，由程序随即生成。低位放时间字段，这样将提高数据均衡分布，各个 regionServer 负载均衡的几率。</p><p>如果 rowkey 按照时间戳的方式递增，不进行散列处理，首字段直接使用时间信息，所有该时段的数据都将集中到一个 regionServer 当中，这样当检索数据时，负载会集中到个别 regionServer 上，造成热点问题，会降低查询效率。</p></li><li><p><strong>rowkey 唯一原则</strong></p><p> 必须在设计上保证其唯一性</p></li></ul><h3 id="列族-amp-列"><a href="#列族-amp-列" class="headerlink" title="列族 &amp; 列"></a><strong>列族</strong> &amp; 列</h3><p>HBase 中的列族是一些列的集合，列族支持动态扩展，用户可以很轻松地添加一个列族或列，无须预定义列的数量以及类型。</p><p>所有列均以字符串形式存储，用户在使用时需要自行进行数据类型转换。</p><h2 id="单元格"><a href="#单元格" class="headerlink" title="单元格"></a>单元格</h2><p>每一个行键、列族、列标识共同确定一个单元格。</p><p>单元格的内容没有特定的数据类型，以二进制字节来存储。</p><p>每个单元格保存着同一份数据的多个版本，不同时间版本的数据按照时间先后顺序排序，最新的数据排在最前面。</p><p>单元格可以用 &lt;RowKey,Column Family: Column Qualifier,Timestamp&gt; 元组来进行访问。</p><h2 id="时间戳"><a href="#时间戳" class="headerlink" title="时间戳"></a>时间戳</h2><p>在默认情况下，每一个单元格插入数据时都会用时间戳来进行版本标识，如果没有设置时间戳，默认使用当前时间.读取单元格数据时，如果时间戳没有被指定，则默认返回最新的数据；</p><p>每一个列族的单元格版本数量都被 HBase 单独维护，默认情况下 HBase 保留 3 个版本数据。</p><h1 id="HBase-故障处理"><a href="#HBase-故障处理" class="headerlink" title="HBase 故障处理"></a>HBase 故障处理</h1><p>宕机分为 HMaster 宕机和 HRegionServer 宕机。</p><h3 id="HRegionServer-宕机"><a href="#HRegionServer-宕机" class="headerlink" title="HRegionServer 宕机"></a>HRegionServer 宕机</h3><p>如果是 HRegionServer 宕机，HMaster 会将其所管理的 region 重新分布到其他活动的 RegionServer 上，由于数据和日志都持久在 HDFS 中，该操作不会导致数据丢失，所以数据的一致性和安全性是有保障的。</p><ol><li><p>ZooKeeper 会监控 HRegionServer 的上下线情况，当 ZooKeeper 发现某个 HRegionServer 宕机之后会通知 HMaster 进行失效备援</p></li><li><p>HRegionServer 会停止对外提供服务，就是它所负责的 region 暂时停止对外提供服务</p></li><li><p>HMaster 会将该 HRegionServer 所负责的 region 转移到其他 HRegionServer 上，并且会对HRegionServer 上存在 Memstore 中还未持久化到磁盘中的数据进行恢复；这个恢复的工作是由 WAL 重播来完成。</p><p>这个过程如下：对应 RegionServer 宕机发生时，读取该 RegionServer 所对应的路径 /hbase/WAL/ 下的 WAL 文件，然后根据不同的 region 切分成不同的临时文件 [recover.edits] 当 region 被分配到新的 RegionServer 中，RegionServer 读取 region 时会进行是否存在 recover.edits，如果有则进行恢复</p></li></ol><h3 id="HMaster-宕机"><a href="#HMaster-宕机" class="headerlink" title="HMaster 宕机"></a>HMaster 宕机</h3><p>HMaster 没有单点问题， HBase 中可以启动多个 HMaster，通过 Zookeeper 的 Master Election 机制保证总有一个 Master 运行。即 ZooKeeper 会保证总会有一个 HMaster 在对外提供服务。</p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello HBase</title>
      <link href="2019/02/22/HBase%E6%A6%82%E8%BF%B0/"/>
      <url>2019/02/22/HBase%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>HBase 是一种构建在 HDFS 之上的分布式、面向列的存储系统。在需要实时读写、随机访问超大规模数据集时，可以使用 HBase。</p><a id="more"></a><h2 id="HBase-特点"><a href="#HBase-特点" class="headerlink" title="HBase 特点"></a>HBase 特点</h2><ol><li><p><strong>海量存储</strong></p><p><font color='grey'> HBase 适合存储 PB 级别的海量数据</font></p><p>上百亿行 x 上百万列</p><p>并没有列的限制</p></li><li><p><strong>面向列</strong></p><p>面向列的存储和权限控制，并支持独立检索，可以动态增加列，即，<strong>可单独对列进行各方面的操作</strong></p><p>列式存储，其数据在表中是按照某列存储的，这样在查询只需要少数几个字段的时候，能大大减少读取的数量</p></li><li><p><strong>多版本</strong></p><p>Hbase 的每一个列的数据存储有多个 Version，比如住址列，可能有多个变更，所以该列可以有多个version</p></li><li><p><strong>稀疏</strong></p><p>为空的列并不占用存储空间，表可以设计的非常稀疏。不必像关系型数据库那样需要预先知道所有列名然后再进行 null 填充</p></li><li><p><strong>高并发、低延迟</strong></p><p>底层的 <strong>LSM数据结构</strong> 和 RowKey 字典有序排列等架构上的独特设计，使得 Hbase <strong>写入性能</strong>非常高。</p><p>Region切分、主键索引、缓存机制使得 Hbase 在海量数据下具备一定的随机读取性能，该性能针对Rowkey 的查询能够到达毫秒级别</p><p><strong><font color='grey'>LSM树，树形结构，最末端的子节点是以内存的方式进行存储的，内存中的小树会flush到磁盘中（当子节点达到一定阈值以后，会放到磁盘中，且存入的过程会进行实时merge成一个主节点，然后磁盘中的树定期会做merge操作，合并成一棵大树，以优化读性能。</font></strong></p></li><li><p><strong>易扩展</strong></p><p><strong><font color='grey'>底层依赖HDFS，当磁盘空间不足的时候，只需要动态增加 Datanode 节点服务</font></strong></p></li></ol><h2 id="HBase-VS-MySQL"><a href="#HBase-VS-MySQL" class="headerlink" title="HBase VS MySQL"></a>HBase <code>VS</code> MySQL</h2><ol><li><p><strong>存储方式</strong></p><p>MySQL 是关系数据库，其只能存储结构化的数据；HBase一个分布式的基于列式存储的非关系数据库，核心概念是列族，适合存储半结构化或非结构化数据</p><p>MySQL 中要提前定义表结构，数据表共有多少列需要提前定义好，并且同时需要定义每个列所占用的存储空间。数据以行为单位组织在一起的，某一行的某一列没有数据，也需要占用存储空间。HBase 则是以列为单位存储数据，每一列就是一个 key-value，HBase 的列不用提前定义，而且列可以动态扩展</p></li><li><p><strong>容量</strong></p><p>MySQL 并不是天生支持分布式的，所以其存储空间容易受到机器限制，而 HBase 则不同，依靠于 HDFS 分布式文件系统，其存储容量可以达到无限大</p></li><li><p><strong>元数据管理</strong></p><p>HBase 必须依托于 zookeeper 来管理元数据，而 MySQL 不需要</p></li></ol><h2 id="列存储-VS-行存储"><a href="#列存储-VS-行存储" class="headerlink" title="列存储 VS 行存储"></a>列存储 <code>VS</code> 行存储</h2><p>列数据库在数据仓库、商务智能领域应用中有着先天的优势: 独特的存储方式, 能够迅速地执行复杂查询; 列数据库的压缩技术, 更是能为数据仓库、商务智能应用中巨大的数据量节约存储成本; 列数据库先进的索引技术也大大提高了数据库的管理。两者的本质区别在于其物理存储是基于列存储还是基于行存储。</p><ol><li><p><strong>数据写入</strong></p><p>行存储的写入是一次完成。如果这种写入建立在操作系统的文件系统上，可以保证写入过程的成功或者失败，数据的完整性因此可以确定。</p><p>列存储由于需要把一行记录拆分成单列保存，那么要进行一行一行的数据写入的时候，可能就需要 “跳跃式” 的将每一行每一列的值写入到不同的区块，写入次数明显比行存储多，再加上磁头需要在盘片上移动和定位花费的时间，实际时间消耗会更大。所以，行存储在写入上占有很大的优势。</p></li><li><p><strong>数据修改</strong></p><p>还有数据修改,这实际也是一次写入过程。不同的是，数据修改是对磁盘上的记录做删除标记。行存储是在指定位置写入一次，列存储是将磁盘定位到多个列上分别写入，这个过程仍是行存储的列数倍。所以，数据修改也是以行存储占优。 </p></li><li><p><strong>数据读取</strong></p><p>数据读取时，行存储通常将一行数据完全读出，如果只需要其中几列数据的情况，就会存在冗余列，出于缩短处理时间的考量，消除冗余列的过程通常是在内存中进行的。</p><p>列存储每次读取的数据是集合的一段或者全部，如果读取多列时，就需要移动磁头，再次定位到下一列的位置继续读取。</p></li><li><p><strong>数据删除</strong></p><p>无论是在行数据库还是列数据库中，在删除一条记录时, 都会出现一个物理存储空间上不连续的空洞。</p><p>在行数据库中, 随着一段时间的增删操作, 这些空洞会越来越多, 越来越大。这一方面会导致物理存储空间的闲置和浪费, 另一方面会使得访问数据库的效率下降。因此, 行数据库管理员为了填补这些空洞、消除空洞带来的负面影响, 经常在维护时要做的事情是把数据全部导出来, 再重新导回去。列数据库因为在每一列上都采用了轻量的稀疏索引, 在插入删除数据时, 利用这些索引可以把空洞尽量减小, 免除了数据库管理员的大量导入、导出工作。</p></li><li><p><strong>压缩优势</strong></p><p><font color='grey'>列数据库按列存储的结构, 便于在列上对数据进行轻量级的压缩, 列上多个相同的值只需要存储一份。压缩能够大量地降低存储成本。</font></p></li></ol><h2 id="HBase-架构"><a href="#HBase-架构" class="headerlink" title="HBase 架构"></a>HBase 架构</h2><p>HBase 架构包括 HMaster、HRegionSever等。HBase底层依赖 HDFS，通过 DFS Cilent 进行 HDFS 操作。HMaster 负责把 HRegion 分配给HRegionServer，每一个 HRegionServer 可以包含多个 HRegion，多个 HRegion 共享HLog，HLog 用来做灾难恢复。每一个 HRegion 由一个或多个 Store 组成，一个 Store 对应表的一个列族，每个 Store中包含与其对应的 MemStore 以及一个或多个 StoreFile（是实际数据存储文件HFile的轻量级封装），MemStore是在内存中的，保存了修改的数据，MemStore中的数据写到文件中就是StoreFile。</p><img src="/images/hbase1.png" alt="" style="zoom:60%;" /><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p><strong>客户端包含访问 HBase 的接口，是整个 HBase 系统的入口，使用者直接通过客户端操作 HBase。客户端使用 HBase 的 RPC 机制与 HMaster 和 RegionServer 进行通信。</strong></p><p>在一般情况下，客户端与 HMaster 进行管理类操作的通信，在获取 RegionServer 的信息后，直接与 RegionServer 进行数据读写类操作。而且客户端获取 Region 的位置信息后会缓存下来，用来加速后续数据的访问过程。</p><p>客户端可以用 Java 语言来实现，也可以使用 Thrift、Rest 等客户端模式，甚至 MapReduce 也可以算作一种客户端。</p><h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><p><strong>HMaster 是 HBase 集群中的主服务器，负责监控集群中所有 RegionServer，并且是所有元数据更改的接口</strong></p><p>在分布式集群中，HMaster 服务器通常运行在 HDFS 的 NameNode 上，HMaster 通过 ZooKeeper来避免单点故障，在集群中可以启动多个 HMaster，但 ZooKeeper 的选举机制能够保证同时只有一个 HMaster 处于 Active 状态，其他的 HMaster 处于热备份状态。</p><p><strong>HMaster 主要负责表和 Region 的管理工作。</strong></p><ol><li>管理用户对表的增、删、改、查操作。</li><li>管理 RegionServer 的负载均衡，调整 Region 的分配。</li><li>Region 的分配和移除</li><li>处理 RegionServer 的故障转移。</li></ol><h3 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h3><p>ZooKeeper 是一个高性能、集中化、分布式应用程序协调服务，主要是用来解决分布式应用中用户经常遇到的一些数据管理问题，例如，数据发布/订阅、命名服务、分布式协调通知、集群管理、Master 选举、分布式锁和分布式队列等功能。其中，Master 选举是 ZooKeeper 最典型的应用场景。</p><p>在 Hadoop 中，ZooKeeper 主要用于实现高可靠性（High Availability, HA），包括 HDFS 的 NameNode 和 YARN 的 ResourceManager 的 HA。 以 HDFS 为例，NameNode 作为 HDFS 的主节点，负责管理文件系统的命名空间以及客户端对文件的访问，同时需要监控整个 HDFS 中每个 DataNode 的状态，实现负载均衡和容错。</p><p>为了实现 HA，必须有多个 NameNode 并存，并且只有一个 NameNode 处于活跃状态，其他的则处于备用状态。当活跃的 NameNode 无法正常工作时， 处于备用状态的 NameNode 会通过竞争选举产生新的活跃节点来保证 HDFS 集群的高可靠性。</p><p><strong>ZooKeeper 在 HBase 中的负责协调的任务如下：</strong></p><ul><li><p><strong>Master 选举</strong></p><blockquote><p>同 HDFS 的 HA 机制一样，HBase 集群中有多个 HMaster 并存，通过竞争选举机制保证同一时刻只有一个 HMaster 处于活跃状态，一旦这个 HMaster 无法使用，则从备用节点中选出一个顶上，保证集群的高可靠性。</p></blockquote></li><li><p><strong>系统容错</strong></p><blockquote><p>在 HBase 启动时，每个 RegionServer 在加入集群时都需要到 ZooKeeper 中进行注册，创建一个状态节点，ZooKeeper 会实时监控每个 RegionServer 的状态，同时 HMaster 会监听注册的 RegionServer。</p></blockquote><blockquote><p>当某个 RegionServer 挂断的时候，ZooKeeper 会因为一段时间内接收不到它的心跳信息而删除该 RegionServer 对应的状态节点，并且给 HMaster 发送节点删除的通知。这时，HMaster 获知集群中某节点断开，会立即调度其他节点开启容错机制。</p></blockquote></li><li><p><strong>Region 元数据管理</strong></p><blockquote><p> 在 HBase 集群中，Region 元数据被存储在 Meta 表中。每次客户端发起新的请求时，需要查询 Meta 表来获取 Region 的位置，而 Meta 表是存在 ZooKeeper 中的。</p></blockquote><blockquote><p>当 Region 发生变化时，例如，Region 的手工移动、进行负载均衡的移动或 Region 所在的 RegionServer 出现故障等，就能够通过 ZooKeeper 来感知到这一变化，保证客户端能够获得正确的 Region 元数据信息。</p></blockquote></li><li><p><strong>Region 状态管理</strong></p><blockquote><p>HBase 集群中 Region 会经常发生变更，其原因可能是系统故障，配置修改，或者是 Region 的分裂和合并。只要 Region 发生变化，就需要让集群的所有节点知晓，否则就会出现某些事务性的异常。</p></blockquote><blockquote><p>而对于 HBase 集群，Region 的数量会达到 10 万，甚至更多。如此规模的 Region 状态管理如果直接由 HMaster 来实现，则 HMaster 的负担会很重，因此只有依靠 ZooKeeper 系统来完成。</p></blockquote></li><li><p><strong>提供 Meta 表存储位置</strong></p><blockquote><p>在 HBase 集群中，数据库表信息、列族信息及列族存储位置信息都属于元数据。这些元数据存储在 Meta 表中，而 Meta 表的位置入口由 ZooKeeper 来提供。</p></blockquote></li></ul><h3 id="RegionServer"><a href="#RegionServer" class="headerlink" title="RegionServer"></a>RegionServer</h3><p>在 HDFS 中，DataNode 负责存储实际数据。RegionServer 主要负责响应用户的请求，向 HDFS 读写数据。一般在分布式集群中，RegionServer 运行在 DataNode 服务器上，实现数据的本地性。</p><p>RegionServer 是 HBase 中最核心的模块，其内部管理了一系列 Region 对象，每个 Region 由多个 HStore 组成，每个 HStore 对应表中一个列族的存储。</p><p>HBase 是按列进行存储的，将列族作为一个集中的存储单元，并且 HBase 将具备相同 I/O 特性的列存储到一个列族中，这样可以保证读写的高效性。</p><p>每个 RegionServer 包含多个 Region，它负责的功能如下：</p><ul><li><strong>处理分批给它的 Region。</strong></li><li><strong>处理客户端读写请求。</strong></li><li><strong>刷新缓存到 HDFS 中。</strong></li><li><strong>处理 Region 分片。</strong></li><li><strong>执行压缩。</strong></li></ul><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p>HBase 是一种列存储模式与键值对存储模式结合的 NoSQL 数据库，它具有灵活的数据模型，不仅可以基于键进行快速查询，还可以实现基于值、列名等的全文遍历和检索。</p><p>HBase 可以实现自动的数据分片，用户不需要知道数据存储在哪个节点上，只要说明检索的要求，系统会自动进行数据的查询和反馈</p><p>HBase 不支持关系模型，它可以根据用户的需求提供更灵活和可扩展的表设计。与传统的关系型数据库类似，HBase 也是以表的方式组织数据，应用程序将数据存于 HBase 的表中，HBase 的表也由行和列组成。</p><img src="/images/hbase2.png" alt="" style="zoom:60%;" /><h3 id="行键"><a href="#行键" class="headerlink" title="行键"></a><strong>行键</strong></h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>在 HBase 表里，每一行代表一个数据对象，每一行都以行键（Row Key）来进行唯一标识。</p><p>在 HBase 内部，行键是不可分割的字节数组，并且按照字典排序由低到高存储在表中的。</p><p>在 HBase 中可以针对行键建立索引，提高检索数据的速度。</p><h4 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h4><ul><li><p><strong>rowkey 长度原则</strong></p><p>rowkey 是一个二进制数组，可以是任意字符串，最大长度 64kb。实际应用中一般为 10-100 bytes，以byte[] 形式保存，一般设计成定长。建议越短越好，不要超过16个字节，原因如下：</p><ul><li><p>目前操作系统都是64位系统，内存 8 字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。</p></li><li><p>hbase 将部分数据加载到内存当中，如果 rowkey 过长，内存的有效利用率就会下降</p></li></ul></li><li><p><strong>rowkey 散列原则</strong></p><p>建议将 rowkey 的高位字节采用散列字段处理，由程序随即生成。低位放时间字段，这样将提高数据均衡分布，各个 regionServer 负载均衡的几率。</p><p>如果 rowkey 按照时间戳的方式递增，不进行散列处理，首字段直接使用时间信息，所有该时段的数据都将集中到一个 regionServer 当中，这样当检索数据时，负载会集中到个别 regionServer 上，造成热点问题，会降低查询效率。</p></li><li><p><strong>rowkey 唯一原则</strong></p><p> 必须在设计上保证其唯一性</p></li></ul><h3 id="列族-amp-列"><a href="#列族-amp-列" class="headerlink" title="列族 &amp; 列"></a><strong>列族</strong> &amp; 列</h3><p>HBase 中的列族是一些列的集合，列族支持动态扩展，用户可以很轻松地添加一个列族或列，无须预定义列的数量以及类型。</p><p>所有列均以字符串形式存储，用户在使用时需要自行进行数据类型转换。</p><h2 id="单元格"><a href="#单元格" class="headerlink" title="单元格"></a>单元格</h2><p>每一个行键、列族、列标识共同确定一个单元格。</p><p>单元格的内容没有特定的数据类型，以二进制字节来存储。</p><p>每个单元格保存着同一份数据的多个版本，不同时间版本的数据按照时间先后顺序排序，最新的数据排在最前面。</p><p>单元格可以用 &lt;RowKey,Column Family: Column Qualifier,Timestamp&gt; 元组来进行访问。</p><h2 id="时间戳"><a href="#时间戳" class="headerlink" title="时间戳"></a>时间戳</h2><p>在默认情况下，每一个单元格插入数据时都会用时间戳来进行版本标识，如果没有设置时间戳，默认使用当前时间.读取单元格数据时，如果时间戳没有被指定，则默认返回最新的数据；</p><p>每一个列族的单元格版本数量都被 HBase 单独维护，默认情况下 HBase 保留 3 个版本数据。</p><h1 id="HBase-故障处理"><a href="#HBase-故障处理" class="headerlink" title="HBase 故障处理"></a>HBase 故障处理</h1><p>宕机分为 HMaster 宕机和 HRegionServer 宕机。</p><h3 id="HRegionServer-宕机"><a href="#HRegionServer-宕机" class="headerlink" title="HRegionServer 宕机"></a>HRegionServer 宕机</h3><p>如果是 HRegionServer 宕机，HMaster 会将其所管理的 region 重新分布到其他活动的 RegionServer 上，由于数据和日志都持久在 HDFS 中，该操作不会导致数据丢失，所以数据的一致性和安全性是有保障的。</p><ol><li><p>ZooKeeper 会监控 HRegionServer 的上下线情况，当 ZooKeeper 发现某个 HRegionServer 宕机之后会通知 HMaster 进行失效备援</p></li><li><p>HRegionServer 会停止对外提供服务，就是它所负责的 region 暂时停止对外提供服务</p></li><li><p>HMaster 会将该 HRegionServer 所负责的 region 转移到其他 HRegionServer 上，并且会对HRegionServer 上存在 Memstore 中还未持久化到磁盘中的数据进行恢复；这个恢复的工作是由 WAL 重播来完成。</p><p>这个过程如下：对应 RegionServer 宕机发生时，读取该 RegionServer 所对应的路径 /hbase/WAL/ 下的 WAL 文件，然后根据不同的 region 切分成不同的临时文件 [recover.edits] 当 region 被分配到新的 RegionServer 中，RegionServer 读取 region 时会进行是否存在 recover.edits，如果有则进行恢复</p></li></ol><h3 id="HMaster-宕机"><a href="#HMaster-宕机" class="headerlink" title="HMaster 宕机"></a>HMaster 宕机</h3><p>HMaster 没有单点问题， HBase 中可以启动多个 HMaster，通过 Zookeeper 的 Master Election 机制保证总有一个 Master 运行。即 ZooKeeper 会保证总会有一个 HMaster 在对外提供服务。</p>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Region Spilt 机制</title>
      <link href="2019/02/22/HBase-Region%20Spilt(1)/"/>
      <url>2019/02/22/HBase-Region%20Spilt(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 Hbase 中 split 是一个很重要的功能，Hbase是通过把数据分配到一定数量的region来达到负载均衡的。一个table会被分配到一个或多个region中，这些region会被分配到一个或者多个regionServer中。在自动split策略中，当一个region达到一定的大小就会自动split成两个region。table在region中是按照row key来排序的，并且一个row key所对应的行只会存储在一个region中，这一点保证了Hbase的强一致性 。</p><a id="more"></a><p>Region 拆分是 HBase 能够拥有良好扩展性的最重要因素。一旦 Region 的负载过大或者超过阈值时，它就会被分裂成两个新的 Region</p><h2 id="预分区"><a href="#预分区" class="headerlink" title="预分区"></a><strong>预分区</strong></h2><p>HBase表在刚刚被创建时，只有1个分区（region），当一个region过大，达到hbase.hregion.max.filesize属性中定义的阈值，默认10GB）时，表将会进行 split，分裂为2个分区。表在进行 split 的时候，会耗费大量的资源，频繁的分区对 HBase 的性能有巨大的影响。</p><p>HBase提供了预分区功能，即用户可以在创建表的时候对表按照一定的规则分区。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;f1&#x27;</span>, SPLITS =&gt; [<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;20&#x27;</span>, <span class="string">&#x27;30&#x27;</span>, <span class="string">&#x27;40&#x27;</span>]</span><br><span class="line">create <span class="string">&#x27;t1&#x27;</span>, &#123;NAME =&gt;<span class="string">&#x27;f1&#x27;</span>, TTL =&gt; <span class="number">180</span>&#125;, SPLITS =&gt; [<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;20&#x27;</span>, <span class="string">&#x27;30&#x27;</span>, <span class="string">&#x27;40&#x27;</span>]</span><br><span class="line">create <span class="string">&#x27;t1&#x27;</span>, &#123;NAME =&gt;<span class="string">&#x27;f1&#x27;</span>, TTL =&gt; <span class="number">180</span>&#125;, &#123;NAME =&gt; <span class="string">&#x27;f2&#x27;</span>, TTL =&gt; <span class="number">240</span>&#125;, SPLITS =&gt; [<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;20&#x27;</span>, <span class="string">&#x27;30&#x27;</span>, <span class="string">&#x27;40&#x27;</span>]</span><br><span class="line">create <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;f1&#x27;</span>, SPLITS_FILE =&gt; <span class="string">&#x27;/home/hadmin/hbase-1.3.1/txt/splits.txt&#x27;</span></span><br><span class="line">create <span class="string">&#x27;t1&#x27;</span>, &#123;NAME =&gt;<span class="string">&#x27;f1&#x27;</span>, TTL =&gt; <span class="number">180</span>&#125;, SPLITS_FILE =&gt; <span class="string">&#x27;/home/hadmin/hbase-1.3.1/txt/splits.txt&#x27;</span></span><br><span class="line">create <span class="string">&#x27;t1&#x27;</span>, &#123;NAME =&gt;<span class="string">&#x27;f1&#x27;</span>, TTL =&gt; <span class="number">180</span>&#125;, &#123;NAME =&gt; <span class="string">&#x27;f2&#x27;</span>, TTL =&gt; <span class="number">240</span>&#125;, SPLITS_FILE =&gt; <span class="string">&#x27;/home/hadmin/hbase-1.3.1/txt/splits.txt&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="自动分区"><a href="#自动分区" class="headerlink" title="自动分区"></a><strong>自动分区</strong></h2><h3 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h3><p>当一个reion达到一定的大小，他会自动split称两个region，HBase 配置文件中定义全局的拆分策略，设置 HBase.regionserver.region.split.policy 的值即可，也可以在创建和修改表时候指定。</p><ol><li><p><strong>IncreasingToUpperBoundRegionSplitPolicy</strong></p><p>0.94.0 默认 region split 策略。根据公式 min(r^2*flushSize，maxFileSize)确定split的maxFileSize，其中r为在线region个数，maxFileSize由hbase.hregion.max.filesize指定。</p><p>根据根据公式min(r^2*flushSize，maxFileSize)确定split的maxFileSize，这里假设flushSize为128M：</p><p>第一次拆分大小为：min(10G，1<em>1</em>128M)=128M</p><p>第二次拆分大小为：min(10G，2<em>2</em>128M)=512M</p><p>第三次拆分大小为：min(10G，3<em>3</em>128M)=3200M </p></li><li><p><strong>ConstantSizeRegionSplitPolicy</strong></p><p>当 region 大小超过常量值（hbase.hregion.max.filesize大小）时，进行拆分</p></li><li><p><strong>DelimitedKeyPrefixRegionSplitPolicy</strong></p><p>保证以分隔符前面的前缀为 splitPoint，保证相同 RowKey 前缀的数据在一个 Region 中</p></li><li><p><strong>KeyPrefixRegionSplitPolicy</strong></p><p>可以保证相同的前缀的 row 保存在同一个region中。</p><p>指定 rowkey 前缀位数划分region，通过读取 KeyPrefixRegionSplitPolicy.prefix_length  属性，该属性为数字类型，表示前缀长度，在进行split时，按此长度对splitPoint进行截取。</p><p>此种策略比较适合固定前缀的 rowkey。当 table 中没有设置该属性，指定此策略效果等同与使用IncreasingToUpperBoundRegionSplitPolicy</p></li></ol><h3 id="分区步骤"><a href="#分区步骤" class="headerlink" title="分区步骤"></a>分区步骤</h3><ol><li>RegionServer 先获得一个 table 的 read 共享锁，避免 schema 在 split 处理期间发生修改。然后在zookeeper的znone上创建一个节点/hbase/region-in-transition/region-name，状态标识为splitting 。</li><li>Master 节点会监听 zookeeper 的 region-in-transition 节点下所有子节点的变化</li><li>RegionServer 在 hdfs 待 split 的 region (parent region) 目录下创建一个名为 “.splits” 的子目录</li><li>RegionServer 关闭 parent region。强制 flush 缓存，并且在本地数据结构中标记region为下线状态。如果这个时候客户端刚好请求到parent region，会抛出NotServingRegionException。这时客户端会进行补偿性重试。</li><li>接着，RegionServer在.splits目录下生成子daughter A 和B，并创建必须的数据结构。然后就开始splits store files 。就某种意义而已，只是对每个store file 创建两个 Reference files 并指向parent region’s files。</li><li>接着，RegionServer在HDFS上创建真实的新daughter目录A 和B ，与parent平级。并将第5步中的reference files分别move到daughter A 和 region B中。</li><li>然后，RegionServer 就发送请求去更新.meta table信息，设置parent 为offline，同时增加新的子region信息 ，如图中[7]箭头指向行 splitA和splitB信息。</li><li>同时并行的打开新的 daughter A 和 daughter B region 。</li><li>接着，RegionServer 添加daughters A and B 到 .META.如图中[]箭头指向的两行。</li><li>此时，这两个region的状态是online 。这是clients可以发现新的region，同时更新自己的.meta.缓存。</li><li>最后，RegionServer 更新znode节点 /hbase/region-in-transition/region-name为SPLIT。如此，master可以学习到。负载均衡时，可以指向到新的子region。</li></ol><h2 id="强制分区"><a href="#强制分区" class="headerlink" title="强制分区"></a><strong>强制分区</strong></h2><p>Hbase 允许客户端强制执行 split,在 hbase shell 中执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">split &#39;forced_table&#39;, &#39;b&#39; &#x2F;&#x2F;其中 forced_table 为要 split 的 table , ‘b’ 为 split 点</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Region Spilt 机制</title>
      <link href="2019/02/22/HBase-Region%20Spilt/"/>
      <url>2019/02/22/HBase-Region%20Spilt/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 Hbase 中 split 是一个很重要的功能，Hbase 是通过把数据分配到一定数量的 region 来达到负载均衡的。一个table 会被分配到一个或多个 region 中，这些region会被分配到一个或者多个regionServer中。在自动split策略中，当一个region达到一定的大小就会自动split成两个region。table在region中是按照row key来排序的，并且一个row key所对应的行只会存储在一个region中，这一点保证了Hbase的强一致性 。</p><a id="more"></a><p>Region 拆分是 HBase 能够拥有良好扩展性的最重要因素。一旦 Region 的负载过大或者超过阈值时，它就会被分裂成两个新的 Region</p><h2 id="1-预分区"><a href="#1-预分区" class="headerlink" title="1. 预分区"></a><strong>1. 预分区</strong></h2><p>HBase 表在刚刚被创建时，只有 1 个分区(region)，当一个 region 过大，达到 <code>hbase.hregion.max.filesize</code> 属性中定义的阈值，默认10GB) 时，表将会进行 split，分裂为 2 个分区。表在进行 split 的时候，会耗费大量的资源，频繁的分区对 HBase 的性能有巨大的影响。</p><p>HBase 提供了预分区功能，即用户可以在创建表的时候对表按照一定的规则分区。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;f1&#x27;</span>, SPLITS =&gt; [<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;20&#x27;</span>, <span class="string">&#x27;30&#x27;</span>, <span class="string">&#x27;40&#x27;</span>]</span><br><span class="line">create <span class="string">&#x27;t1&#x27;</span>, &#123;NAME =&gt;<span class="string">&#x27;f1&#x27;</span>, TTL =&gt; <span class="number">180</span>&#125;, SPLITS =&gt; [<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;20&#x27;</span>, <span class="string">&#x27;30&#x27;</span>, <span class="string">&#x27;40&#x27;</span>]</span><br><span class="line">create <span class="string">&#x27;t1&#x27;</span>, &#123;NAME =&gt;<span class="string">&#x27;f1&#x27;</span>, TTL =&gt; <span class="number">180</span>&#125;, &#123;NAME =&gt; <span class="string">&#x27;f2&#x27;</span>, TTL =&gt; <span class="number">240</span>&#125;, SPLITS =&gt; [<span class="string">&#x27;10&#x27;</span>, <span class="string">&#x27;20&#x27;</span>, <span class="string">&#x27;30&#x27;</span>, <span class="string">&#x27;40&#x27;</span>]</span><br><span class="line">create <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;f1&#x27;</span>, SPLITS_FILE =&gt; <span class="string">&#x27;/home/hadmin/hbase-1.3.1/txt/splits.txt&#x27;</span></span><br><span class="line">create <span class="string">&#x27;t1&#x27;</span>, &#123;NAME =&gt;<span class="string">&#x27;f1&#x27;</span>, TTL =&gt; <span class="number">180</span>&#125;, SPLITS_FILE =&gt; <span class="string">&#x27;/home/hadmin/hbase-1.3.1/txt/splits.txt&#x27;</span></span><br><span class="line">create <span class="string">&#x27;t1&#x27;</span>, &#123;NAME =&gt;<span class="string">&#x27;f1&#x27;</span>, TTL =&gt; <span class="number">180</span>&#125;, &#123;NAME =&gt; <span class="string">&#x27;f2&#x27;</span>, TTL =&gt; <span class="number">240</span>&#125;, SPLITS_FILE =&gt; <span class="string">&#x27;/home/hadmin/hbase-1.3.1/txt/splits.txt&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="2-自动分区"><a href="#2-自动分区" class="headerlink" title="2. 自动分区"></a><strong>2. 自动分区</strong></h2><h3 id="2-1-分区策略"><a href="#2-1-分区策略" class="headerlink" title="2.1. 分区策略"></a>2.1. 分区策略</h3><p>当一个 region 达到一定的大小，会自动 split 称两个 region，HBase 配置文件中定义全局的拆分策略，设置 <code>HBase.regionserver.region.split.policy</code> 的值即可，也可以在创建和修改表时候指定。</p><ol><li><p><strong>IncreasingToUpperBoundRegionSplitPolicy</strong></p><p>0.94.0 默认 region split 策略。根据公式 min(r^2*flushSize，maxFileSize)确定split的maxFileSize，其中r为在线region个数，maxFileSize由hbase.hregion.max.filesize指定。</p><p>根据根据公式min(r^2*flushSize，maxFileSize)确定split的maxFileSize，这里假设flushSize为128M：</p><p>第一次拆分大小为：min(10G，1<em>1</em>128M)=128M</p><p>第二次拆分大小为：min(10G，2<em>2</em>128M)=512M</p><p>第三次拆分大小为：min(10G，3<em>3</em>128M)=3200M </p></li><li><p><strong>ConstantSizeRegionSplitPolicy</strong></p><p>当 region 大小超过常量值（hbase.hregion.max.filesize大小）时，进行拆分</p></li><li><p><strong>DelimitedKeyPrefixRegionSplitPolicy</strong></p><p>保证以分隔符前面的前缀为 splitPoint，保证相同 RowKey 前缀的数据在一个 Region 中</p></li><li><p><strong>KeyPrefixRegionSplitPolicy</strong></p><p>可以保证相同的前缀的 row 保存在同一个region中。</p><p>指定 rowkey 前缀位数划分region，通过读取 KeyPrefixRegionSplitPolicy.prefix_length  属性，该属性为数字类型，表示前缀长度，在进行split时，按此长度对splitPoint进行截取。</p><p>此种策略比较适合固定前缀的 rowkey。当 table 中没有设置该属性，指定此策略效果等同与使用IncreasingToUpperBoundRegionSplitPolicy</p></li></ol><h3 id="2-2-分区步骤"><a href="#2-2-分区步骤" class="headerlink" title="2.2. 分区步骤"></a>2.2. 分区步骤</h3><ol><li>RegionServer 先获得一个 table 的 read 共享锁，避免 schema 在 split 处理期间发生修改。然后在zookeeper的znone上创建一个节点/hbase/region-in-transition/region-name，状态标识为splitting 。</li><li>Master 节点会监听 zookeeper 的 region-in-transition 节点下所有子节点的变化</li><li>RegionServer 在 hdfs 待 split 的 region (parent region) 目录下创建一个名为 “.splits” 的子目录</li><li>RegionServer 关闭 parent region。强制 flush 缓存，并且在本地数据结构中标记region为下线状态。如果这个时候客户端刚好请求到parent region，会抛出NotServingRegionException。这时客户端会进行补偿性重试。</li><li>接着，RegionServer在.splits目录下生成子daughter A 和B，并创建必须的数据结构。然后就开始splits store files 。就某种意义而已，只是对每个store file 创建两个 Reference files 并指向parent region’s files。</li><li>接着，RegionServer在HDFS上创建真实的新daughter目录A 和B ，与parent平级。并将第5步中的reference files分别move到daughter A 和 region B中。</li><li>然后，RegionServer 就发送请求去更新.meta table信息，设置parent 为offline，同时增加新的子region信息 ，如图中[7]箭头指向行 splitA和splitB信息。</li><li>同时并行的打开新的 daughter A 和 daughter B region 。</li><li>接着，RegionServer 添加daughters A and B 到 .META.如图中[]箭头指向的两行。</li><li>此时，这两个region的状态是online 。这是clients可以发现新的region，同时更新自己的.meta.缓存。</li><li>最后，RegionServer 更新znode节点 /hbase/region-in-transition/region-name为SPLIT。如此，master可以学习到。负载均衡时，可以指向到新的子region。</li></ol><h2 id="强制分区"><a href="#强制分区" class="headerlink" title="强制分区"></a><strong>强制分区</strong></h2><p>Hbase 允许客户端强制执行 split,在 hbase shell 中执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">split &#39;forced_table&#39;, &#39;b&#39; &#x2F;&#x2F;其中 forced_table 为要 split 的 table , ‘b’ 为 split 点</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Region 负载均衡</title>
      <link href="2019/02/20/HBase-Region%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1(1)/"/>
      <url>2019/02/20/HBase-Region%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 Hbase 中 split 是一个很重要的功能，Hbase 是通过把数据分配到一定数量的 region 来达到负载均衡的。一个table 会被分配到一个或多个 region 中，这些 region 会被分配到一个或者多个 regionServer 中。在自动 split 策略中，当一个 region 达到一定的大小就会自动 split 成两个 region。table 在 region 中是按照 row key 来排序的，并且一个 row key 所对应的行只会存储在一个 region 中，这一点保证了 Hbase 的强一致性 。</p><a id="more"></a><p><strong>当 Region 分裂之后，Region 服务器之间的 Region 数量差距变大，Master 便会执行负载均衡来调整部分 Region 的位置，使每个 Region 服务器的 Region 数量保持在合理范围之内，负载均衡会引起 Region 的重新定位，使涉及的 Region 不具备数据本地性。</strong></p><p>Region 的负载均衡由 Master 来完成，Master 有一个内置的负载均衡器，在默认情况下，均衡器每 5 分钟运行一次，用户可以配置。负载均衡操作分为两步进行：首先生成负载均衡计划表， 然后按照计划表执行 Region 的分配。执行负载均衡前要明确，在以下几种情况时，Master 是不会执行负载均衡的。</p><ul><li>均衡负载开关关闭。</li><li>Master 没有初始化。</li><li>当前有 Region 处于拆分状态。</li><li>当前集群中有 Region 服务器出现故障。</li><li>Master 内部使用一套集群负载评分的算法，来评估 HBase 某一个表的 Region 是否需要进行重新分配。这套算法分别从 Region 服务器中 Region 的数目、表的 Region 数、MenStore 大小、 StoreFile 大小、数据本地性等几个维度来对集群进行评分，评分越低代表集群的负载越合理。</li></ul><h2 id="负载均衡策略"><a href="#负载均衡策略" class="headerlink" title="负载均衡策略"></a>负载均衡策略</h2><p>确定需要负载均衡后，再根据不同策略选择 Region 进行分配，负载均衡策略有三种</p><table><thead><tr><th>RandomRegionPicker</th><th>随机选出两个 Region 服务器下的 Region 进行交换</th></tr></thead><tbody><tr><td>LoadPicker</td><td>获取 Region 数目最多或最少的两个 Region 服务器，使两个 Region 服务器最终的 Region 数目更加平均</td></tr><tr><td>LocalityBasedPicker</td><td>选择本地性最强的 Region</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Region 负载均衡</title>
      <link href="2019/02/20/HBase-Region%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
      <url>2019/02/20/HBase-Region%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>在 Hbase 中 split 是一个很重要的功能，Hbase是通过把数据分配到一定数量的region来达到负载均衡的。一个table会被分配到一个或多个region中，这些region会被分配到一个或者多个regionServer中。在自动split策略中，当一个region达到一定的大小就会自动split成两个region。table在region中是按照row key来排序的，并且一个row key所对应的行只会存储在一个region中，这一点保证了Hbase的强一致性 。</p><a id="more"></a><p><strong>当 Region 分裂之后，Region 服务器之间的 Region 数量差距变大，Master 便会执行负载均衡来调整部分 Region 的位置，使每个 Region 服务器的 Region 数量保持在合理范围之内，负载均衡会引起 Region 的重新定位，使涉及的 Region 不具备数据本地性。</strong></p><p>Region 的负载均衡由 Master 来完成，Master 有一个内置的负载均衡器，在默认情况下，均衡器每 5 分钟运行一次，用户可以配置。负载均衡操作分为两步进行：首先生成负载均衡计划表， 然后按照计划表执行 Region 的分配。执行负载均衡前要明确，在以下几种情况时，Master 是不会执行负载均衡的。</p><ul><li>均衡负载开关关闭。</li><li>Master 没有初始化。</li><li>当前有 Region 处于拆分状态。</li><li>当前集群中有 Region 服务器出现故障。</li><li>Master 内部使用一套集群负载评分的算法，来评估 HBase 某一个表的 Region 是否需要进行重新分配。这套算法分别从 Region 服务器中 Region 的数目、表的 Region 数、MenStore 大小、 StoreFile 大小、数据本地性等几个维度来对集群进行评分，评分越低代表集群的负载越合理。</li></ul><h2 id="负载均衡策略"><a href="#负载均衡策略" class="headerlink" title="负载均衡策略"></a>负载均衡策略</h2><p>确定需要负载均衡后，再根据不同策略选择 Region 进行分配，负载均衡策略有三种</p><table><thead><tr><th>RandomRegionPicker</th><th>随机选出两个 Region 服务器下的 Region 进行交换</th></tr></thead><tbody><tr><td>LoadPicker</td><td>获取 Region 数目最多或最少的两个 Region 服务器，使两个 Region 服务器最终的 Region 数目更加平均</td></tr><tr><td>LocalityBasedPicker</td><td>选择本地性最强的 Region</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Compaction 机制</title>
      <link href="2019/02/20/HBase%20-Compaction(1)/"/>
      <url>2019/02/20/HBase%20-Compaction(1)/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>每个 RegionServer 包含多个 Region，而每个 Region 又对应多个 Store，每一个 Store 对应表中一个列族的存储，且每个 Store 由一个 MemStore 和多个 StoreFile 文件组成。</p><p>StoreFile 在底层文件系统中由 HFile 实现，也可以把 Store 看作由一个 MemStore 和多个 HFile 文件组成。久而久之，每个 Store 中的 HFile 文件会越来越多，I/O 操作的速度也随之变慢，每次的 Memstore Flush 都会为每个 CF 创建一个 HFile。频繁的 Flush 就会创建大量的 HFile。这样 HBase 在检索的时候，就不得不读取大量的 HFile，读性能会受很大影响。因此，需要对 HFile 文件进行合并，让文件更紧凑，让系统更有效率</p><img src="/Users/joker/Documents/chen_blog/images/hbase/截屏2021-05-17 上午10.49.42.png" alt="截屏2021-05-17 上午10.49.42" style="zoom:50%;" /><a id="more"></a><h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><p>HBase Compaction 分为两种：Minor Compaction 与 Major Compaction，通常我们简称为小合并、大合并。</p><h3 id="Minor-Compaction"><a href="#Minor-Compaction" class="headerlink" title="Minor Compaction"></a>Minor Compaction</h3><p>Minor Compaction 是把多个小 HFile 合并生成一个大的 HFile。**</p><p>执行合并时，HBase 读出已有的多个 HFile 的内容，把记录写入一个新文件中。然后把新文件设置为激活状态，并标记旧文件为删除。</p><p><strong><font color='red'>在 Minor 合并中，这些标记为删除的旧文件是没有被移除的，仍然会出现在 HFile 中，只有在进行 Major 合并时才会移除这些旧文件。</font></strong></p><p>对需要进行 Minor 合并的文件的选择是触发式的，当达到触发条件才会进行 Minor 合并HBase触发Compaction的条件有三种：memstore Flush、后台线程周期性检查、手动触发。</p><ol><li><p>memstore flush</p><p>HBase 每次 flush 之后，都会判断是否要进行 compaction，一旦满足 minor compaction 或major compaction 的条件便会触发执行。</p></li><li><p>后台线程周期性检查</p><p>后台线程 CompactionChecker 会定期检查是否需要执行compaction，检查周期为<code>hbase.server.thread.wakefrequency</code> * <code>hbase.server.compactchecker.interval.multiplier</code>，这里主要考虑的是一段时间内没有写入请求仍然需要做 compact 检查。</p><p>其中参数 hbase.server.thread.wakefrequency 默认值 10000 即 10s，是HBase服务端线程唤醒时间间隔，用于log roller、memstore flusher等操作周期性检查；参数 hbase.server.compactchecker.interval.multiplier 默认值1000，是compaction操作周期性检查乘数因子。10 * 1000 s 时间上约等于2hrs, 46mins, 40sec。</p></li><li><p>手动触发：是指通过HBase Shell、Master UI界面或者HBase API等任一种方式 执行 compact、major_compact等命令。</p></li></ol><p>另外对选择合并的 HFile 也是有条件的，如下表所示。</p><table><thead><tr><th>参数名</th><th>配置项</th><th>默认值</th><th align="center">备注</th></tr></thead><tbody><tr><td>minFileToCompact</td><td>hbase.hstore.compaction.min</td><td>3</td><td align="center">至少需要三个满足条件的 HFile 才启动合并</td></tr><tr><td>maxFileToCompact</td><td>hbase.hstore.compaction.max</td><td>10</td><td align="center">一次合并最多选择 10 个</td></tr><tr><td>maxCompactSize</td><td>hbase.hstore.compaction.max.size</td><td></td><td align="center">HFile 大于此值时被排除合并，避免对大文件的合并</td></tr><tr><td>minCompactSize</td><td>hbase.hstore.compaction.min.size</td><td></td><td align="center">HFile 小于 MemStore 的默认值时被加入合并队列</td></tr></tbody></table><h3 id="Major-Compaction"><a href="#Major-Compaction" class="headerlink" title="Major Compaction"></a>Major Compaction</h3><p>Major 合并针对的是给定 Region 的一个列族的所有 HFile，它将 Store 中的所有 HFile 合并成一个大文件，有时也会对整个表的同一列族的 HFile 进行合并，这是一个耗时和耗费资源的操作，会影响集群性能。</p><p><strong><font color='red'>注：一般情况下都是做 Minor 合并，不少集群是禁止 Major 合并的，只有在集群负载较小时进行手动 Major 合并操作，或者配置 Major 合并周期，默认为 7 天。另外，Major 合并时会清理 Minor 合并中被标记为删除的 HFile。</font></strong></p><p>HBase 中通过 hbase.hregion.majorcompaction=0 来关闭 major 合并操作</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase.hregion.majorcompaction=0</span><br></pre></td></tr></table></figure><h2 id="Compaction-策略"><a href="#Compaction-策略" class="headerlink" title="Compaction 策略"></a>Compaction 策略</h2><p>HBase的compaction policy 准确的说有4种</p><ol><li>RatioBasedCompactionPolicy</li><li>ExploringCompactionPolicy</li><li>FIFOCompactionPolicy</li><li>StripeCompactionPolicy。</li></ol><p>其中，HBase使用的 compaction 策略主要就是前两种，HBase 0.96.x版本之前，默认的 compaction 策略是RatioBasedCompactionPolicy，HBase 0.96.x以及更新版本中，默认为ExploringCompactionPolicy。ExploringCompactionPoliy要比旧版本中的RatioBasedCompactionPolicy 性能更高，因此一般情况下也不建议改变默认配置。</p><p>如果在HBase 0.96.x之后仍想配置RatioBasedCompactionPolicy策略，可以通过修改hbase-site.xml添加hbase.hstore.defaultengine.compactionpolicy.class配置项，配置值为RatioBasedCompactionPolicy，恢复默认配置只需移除该配置项即可。</p><h2 id="Compaction-对读写请求的影响"><a href="#Compaction-对读写请求的影响" class="headerlink" title="Compaction 对读写请求的影响"></a>Compaction 对读写请求的影响</h2><ol><li><p><strong>存储上的写入放大</strong></p><p>HBase Compaction会带来写入放大，特别是在写多读少的场景下，写入放大就会比较明显，随着minor compaction 以及 major Compaction 的发生，可以看到，这条数据被反复读取/写入了多次，这是导致写放大的一个关键原因，这里的写放大，涉及到网络IO与磁盘IO，因为数据在HDFS中默认有三个副本。</p></li><li><p><strong>读路径上的延时毛刺</strong></p><p>HBase 执行 compaction 操作结果会使文件数基本稳定，进而 IO 次数相对稳定，延迟就会稳定在一定范围。然而，compaction 操作会带来很大的带宽压力以及短时间 IO 压力。因此 compaction 就是使用短时间的 IO 消耗以及带宽消耗换取后续查询的低延迟。这种短时间的压力就会造成读请求在延时上会有比较大的毛刺。</p></li><li><p><strong>写请求上的短暂阻塞</strong></p><p>Compaction 对写请求也会有比较大的影响。主要体现在 HFile 比较多的场景下，HBase 会限制写请求的速度。如果底层 HFile 数量超过 <code>hbase.hstore.blockingStoreFiles</code> 配置值，默认10，flush操作将会受到阻塞，阻塞时间为 <code>hbase.hstore.blockingWaitTime</code>，默认90000，即 1.5分钟，在这段时间内，如果 compaction 操作使得 HFile 下降到 <code>blockingStoreFiles</code> 配置值，则停止阻塞。另外阻塞超过时间后，也会恢复执行 flush 操作。这样做可以有效地控制大量写请求的速度，但同时这也是影响写请求速度的主要原因之一。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Compaction 机制</title>
      <link href="2019/02/20/HBase%20-Compaction/"/>
      <url>2019/02/20/HBase%20-Compaction/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>每个 RegionServer 包含多个 Region，而每个 Region 又对应多个 Store，每一个 Store 对应表中一个列族的存储，且每个 Store 由一个 MemStore 和多个 StoreFile 文件组成。</p><p>StoreFile 在底层文件系统中由 HFile 实现，也可以把 Store 看作由一个 MemStore 和多个 HFile 文件组成。久而久之，每个 Store 中的 HFile 文件会越来越多，I/O 操作的速度也随之变慢，每次的 Memstore Flush 都会为每个 CF 创建一个 HFile。频繁的 Flush 就会创建大量的 HFile。这样 HBase 在检索的时候，就不得不读取大量的 HFile，读性能会受很大影响。因此，需要对 HFile 文件进行合并，让文件更紧凑，让系统更有效率</p><a id="more"></a><h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><p>HBase Compaction 分为两种：Minor Compaction 与 Major Compaction，通常我们简称为小合并、大合并。</p><h3 id="Minor-Compaction"><a href="#Minor-Compaction" class="headerlink" title="Minor Compaction"></a>Minor Compaction</h3><p>Minor Compaction 是把多个小 HFile 合并生成一个大的 HFile。</p><p>执行合并时，HBase 读出已有的多个 HFile 的内容，把记录写入一个新文件中。然后把新文件设置为激活状态，并标记旧文件为删除。</p><p><strong><font color='red'>在 Minor 合并中，这些标记为删除的旧文件是没有被移除的，仍然会出现在 HFile 中，只有在进行 Major 合并时才会移除这些旧文件。</font></strong></p><p>对需要进行 Minor 合并的文件的选择是触发式的，当达到触发条件才会进行 Minor 合并HBase触发Compaction的条件有三种：memstore Flush、后台线程周期性检查、手动触发。</p><ol><li><p>memstore flush</p><p>HBase 每次 flush 之后，都会判断是否要进行 compaction，一旦满足 minor compaction 或major compaction 的条件便会触发执行。</p></li><li><p>后台线程周期性检查</p><p>后台线程 CompactionChecker 会定期检查是否需要执行 compaction，检查周期为<code>hbase.server.thread.wakefrequency</code> * <code>hbase.server.compactchecker.interval.multiplier</code>，这里主要考虑的是一段时间内没有写入请求仍然需要做 compact 检查。</p><blockquote><p>其中参数 hbase.server.thread.wakefrequency 默认值 10000 即 10s，是HBase服务端线程唤醒时间间隔，用于log roller、memstore flusher等操作周期性检查；参数 hbase.server.compactchecker.interval.multiplier 默认值1000，是compaction操作周期性检查乘数因子。10 * 1000 s 时间上约等于2hrs, 46mins, 40sec。</p></blockquote></li><li><p>手动触发：是指通过 HBase Shell、Master UI 界面或者 HBase API 等任一种方式 执行 compact、major_compact等命令。</p></li></ol><p>另外对选择合并的 HFile 也是有条件的，如下表所示。</p><table><thead><tr><th>参数名</th><th>配置项</th><th>默认值</th><th align="center">备注</th></tr></thead><tbody><tr><td>minFileToCompact</td><td>hbase.hstore.compaction.min</td><td>3</td><td align="center">至少需要三个满足条件的 HFile 才启动合并</td></tr><tr><td>maxFileToCompact</td><td>hbase.hstore.compaction.max</td><td>10</td><td align="center">一次合并最多选择 10 个</td></tr><tr><td>maxCompactSize</td><td>hbase.hstore.compaction.max.size</td><td></td><td align="center">HFile 大于此值时被排除合并，避免对大文件的合并</td></tr><tr><td>minCompactSize</td><td>hbase.hstore.compaction.min.size</td><td></td><td align="center">HFile 小于 MemStore 的默认值时被加入合并队列</td></tr></tbody></table><h3 id="Major-Compaction"><a href="#Major-Compaction" class="headerlink" title="Major Compaction"></a>Major Compaction</h3><p>Major 合并针对的是给定 Region 的一个列族的所有 HFile，它将 Store 中的所有 HFile 合并成一个大文件，有时也会对整个表的同一列族的 HFile 进行合并，这是一个耗时和耗费资源的操作，会影响集群性能。</p><p><strong><font color='red'>注：一般情况下都是做 Minor 合并，不少集群是禁止 Major 合并的，只有在集群负载较小时进行手动 Major 合并操作，或者配置 Major 合并周期，默认为 7 天。另外，Major 合并时会清理 Minor 合并中被标记为删除的 HFile。</font></strong></p><p>HBase 中通过 hbase.hregion.majorcompaction=0 来关闭 major 合并操作</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase.hregion.majorcompaction=0</span><br></pre></td></tr></table></figure><h2 id="Compaction-策略"><a href="#Compaction-策略" class="headerlink" title="Compaction 策略"></a>Compaction 策略</h2><p>HBase的compaction policy 准确的说有4种</p><ol><li>RatioBasedCompactionPolicy</li><li>ExploringCompactionPolicy</li><li>FIFOCompactionPolicy</li><li>StripeCompactionPolicy。</li></ol><p>其中，HBase 使用的 compaction 策略主要就是前两种，HBase 0.96.x 版本之前，默认的 compaction 策略是RatioBasedCompactionPolicy，HBase 0.96.x以及更新版本中，默认为ExploringCompactionPolicy。ExploringCompactionPoliy要比旧版本中的RatioBasedCompactionPolicy 性能更高，因此一般情况下也不建议改变默认配置。</p><p>如果在HBase 0.96.x之后仍想配置RatioBasedCompactionPolicy策略，可以通过修改hbase-site.xml添加hbase.hstore.defaultengine.compactionpolicy.class配置项，配置值为RatioBasedCompactionPolicy，恢复默认配置只需移除该配置项即可。</p><h2 id="Compaction-对读写请求的影响"><a href="#Compaction-对读写请求的影响" class="headerlink" title="Compaction 对读写请求的影响"></a>Compaction 对读写请求的影响</h2><ol><li><p><strong>存储上的写入放大</strong></p><p>HBase Compaction 会带来写入放大，特别是在写多读少的场景下，写入放大就会比较明显，随着 minor compaction 以及 major Compaction 的发生，可以看到，这条数据被反复读取/写入了多次，这是导致写放大的一个关键原因，这里的写放大，涉及到网络 IO 与磁盘 IO，因为数据在 HDFS 中默认有三个副本。</p></li><li><p><strong>读路径上的延时毛刺</strong></p><p>HBase 执行 compaction 操作结果会使文件数基本稳定，进而 IO 次数相对稳定，延迟就会稳定在一定范围。然而，compaction 操作会带来很大的带宽压力以及短时间 IO 压力。因此 compaction 就是使用短时间的 IO 消耗以及带宽消耗换取后续查询的低延迟。这种短时间的压力就会造成读请求在延时上会有比较大的毛刺。</p></li><li><p><strong>写请求上的短暂阻塞</strong></p><p>Compaction 对写请求也会有比较大的影响。主要体现在 HFile 比较多的场景下，HBase 会限制写请求的速度。如果底层 HFile 数量超过 <code>hbase.hstore.blockingStoreFiles</code> 配置值，默认 10，flush 操作将会受到阻塞，阻塞时间为 <code>hbase.hstore.blockingWaitTime</code>，默认90000，即 1.5分钟，在这段时间内，如果 compaction 操作使得 HFile 下降到 <code>blockingStoreFiles</code> 配置值，则停止阻塞。另外阻塞超过时间后，也会恢复执行 flush 操作。这样做可以有效地控制大量写请求的速度，但同时这也是影响写请求速度的主要原因之一。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> HBase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(2) 基于K最近邻的协同过滤推荐</title>
      <link href="2019/02/15/02_%E5%9F%BA%E4%BA%8EK%E6%9C%80%E8%BF%91%E9%82%BB%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/"/>
      <url>2019/02/15/02_%E5%9F%BA%E4%BA%8EK%E6%9C%80%E8%BF%91%E9%82%BB%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于K最近邻的协同过滤推荐"><a href="#基于K最近邻的协同过滤推荐" class="headerlink" title="基于K最近邻的协同过滤推荐"></a>基于K最近邻的协同过滤推荐</h2><p>基于K最近邻的协同过滤推荐其实本质上就是MemoryBased CF，只不过在选取近邻的时候，加上K最近邻的限制。</p><p>这里我们直接根据MemoryBased CF的代码实现</p><p>修改以下地方</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CollaborativeFiltering</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    based = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, k=<span class="number">40</span>, rules=None, use_cache=False, standard=None</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param k: 取K个最近邻来进行预测</span></span><br><span class="line"><span class="string">        :param rules: 过滤规则，四选一，否则将抛异常：&quot;unhot&quot;, &quot;rated&quot;, [&quot;unhot&quot;,&quot;rated&quot;], None</span></span><br><span class="line"><span class="string">        :param use_cache: 相似度计算结果是否开启缓存</span></span><br><span class="line"><span class="string">        :param standard: 评分标准化方法，None表示不使用、mean表示均值中心化、zscore表示Z-Score标准化</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.k = <span class="number">40</span></span><br><span class="line">        self.rules = rules</span><br><span class="line">        self.use_cache = use_cache</span><br><span class="line">        self.standard = standard</span><br></pre></td></tr></table></figure><p>修改所有的选取近邻的地方的代码，根据相似度来选取K个最近邻</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">similar_users = self.similar[uid].drop([uid]).dropna().sort_values(ascending=<span class="literal">False</span>)[:self.k]</span><br><span class="line"></span><br><span class="line">similar_items = self.similar[iid].drop([iid]).dropna().sort_values(ascending=<span class="literal">False</span>)[:self.k]</span><br></pre></td></tr></table></figure><p>但由于我们的原始数据较少，这里我们的KNN方法的效果会比纯粹的MemoryBasedCF要差</p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(4)  基于矩阵分解的 CF 算法</title>
      <link href="2019/02/15/04_%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/"/>
      <url>2019/02/15/04_%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于矩阵分解的CF算法"><a href="#基于矩阵分解的CF算法" class="headerlink" title="基于矩阵分解的CF算法"></a>基于矩阵分解的CF算法</h2><h4 id="矩阵分解发展史"><a href="#矩阵分解发展史" class="headerlink" title="矩阵分解发展史"></a>矩阵分解发展史</h4><p><strong>Traditional SVD:</strong></p><p>通常SVD矩阵分解指的是SVD（奇异值）分解技术，在这我们姑且将其命名为Traditional SVD（传统并经典着）其公式如下：</p><p><img src="/img/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A31.jpg" alt="img"></p><p>Traditional SVD分解的形式为3个矩阵相乘，中间矩阵为奇异值矩阵。如果想运用SVD分解的话，有一个前提是要求矩阵是稠密的，即矩阵里的元素要非空，否则就不能运用SVD分解。</p><p>很显然我们的数据其实绝大多数情况下都是稀疏的，因此如果要使用Traditional SVD，一般的做法是先用均值或者其他统计学方法来填充矩阵，然后再运用Traditional SVD分解降维，但这样做明显对数据的原始性造成一定影响。</p><p><strong>FunkSVD（LFM）</strong></p><p>刚才提到的Traditional SVD首先需要填充矩阵，然后再进行分解降维，同时存在计算复杂度高的问题，因为要分解成3个矩阵，所以后来提出了Funk SVD的方法，它不在将矩阵分解为3个矩阵，而是分解为2个用户-隐含特征，项目-隐含特征的矩阵，Funk SVD也被称为最原始的LFM模型</p><p><img src="/img/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A32.jpg" alt="img"></p><p>借鉴线性回归的思想，通过最小化观察数据的平方来寻求最优的用户和项目的隐含向量表示。同时为了避免过度拟合（Overfitting）观测数据，又提出了带有L2正则项的FunkSVD，上公式：</p><p><img src="/img/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A33.jpg" alt="img"></p><p>以上两种最优化函数都可以通过梯度下降或者随机梯度下降法来寻求最优解。</p><p><strong>BiasSVD:</strong></p><p>在FunkSVD提出来之后，出现了很多变形版本，其中一个相对成功的方法是BiasSVD，顾名思义，即带有偏置项的SVD分解：</p><p><img src="/img/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A34.jpg" alt="img"></p><p>它基于的假设和Baseline基准预测是一样的，但这里将Baseline的偏置引入到了矩阵分解中</p><p><strong>SVD++:</strong></p><p>人们后来又提出了改进的BiasSVD，被称为SVD++，该算法是在BiasSVD的基础上添加了用户的隐式反馈信息：</p><p><img src="/img/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A35.jpg" alt="img"></p><p>显示反馈指的用户的评分这样的行为，隐式反馈指用户的浏览记录、购买记录、收听记录等。</p><p>SVD++是基于这样的假设：在BiasSVD基础上，认为用户对于项目的历史浏览记录、购买记录、收听记录等可以从侧面反映用户的偏好。</p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(5) 基于矩阵分解的CF算法实现（一）：LFM</title>
      <link href="2019/02/15/05_LFM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
      <url>2019/02/15/05_LFM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于矩阵分解的CF算法实现（一）：LFM"><a href="#基于矩阵分解的CF算法实现（一）：LFM" class="headerlink" title="基于矩阵分解的CF算法实现（一）：LFM"></a>基于矩阵分解的CF算法实现（一）：LFM</h2><p>LFM也就是前面提到的Funk SVD矩阵分解</p><h4 id="LFM原理解析"><a href="#LFM原理解析" class="headerlink" title="LFM原理解析"></a>LFM原理解析</h4><p>LFM(latent factor model)隐语义模型核心思想是通过隐含特征联系用户和物品，如下图：</p><p><img src="/img/LFM%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E5%9B%BE%E8%A7%A3.png"></p><ul><li>P矩阵是User-LF矩阵，即用户和隐含特征矩阵。LF有三个，表示共总有三个隐含特征。</li><li>Q矩阵是LF-Item矩阵，即隐含特征和物品的矩阵</li><li>R矩阵是User-Item矩阵，有P*Q得来</li><li>能处理稀疏评分矩阵</li></ul><p>利用矩阵分解技术，将原始User-Item的评分矩阵（稠密/稀疏）分解为P和Q矩阵，然后利用$P*Q$还原出User-Item评分矩阵$R$。整个过程相当于降维处理，其中：</p><ul><li><p>矩阵值$P_{11}$表示用户1对隐含特征1的权重值</p></li><li><p>矩阵值$Q_{11}$表示隐含特征1在物品1上的权重值</p></li><li><p>矩阵值$R_{11}​$就表示预测的用户1对物品1的评分，且$R_{11}=\vec{P_{1,k}}\cdot \vec{Q_{k,1}}​$</p><p><img src="/img/LFM%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E5%9B%BE%E8%A7%A32.png"></p></li></ul><p>利用LFM预测用户对物品的评分，$k​$表示隐含特征数量：<br>$$<br>\begin{split}<br>\hat {r}<em>{ui} &amp;=\vec {p</em>{uk}}\cdot \vec {q_{ik}}<br>\&amp;={\sum_{k=1}}^k p_{uk}q_{ik}<br>\end{split}<br>$$<br>因此最终，我们的目标也就是要求出P矩阵和Q矩阵及其当中的每一个值，然后再对用户-物品的评分进行预测。</p><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>同样对于评分预测我们利用平方差来构建损失函数：<br>$$<br>\begin{split}<br>Cost &amp;= \sum_{u,i\in R} (r_{ui}-\hat{r}<em>{ui})^2<br>\&amp;=\sum</em>{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})^2<br>\end{split}<br>$$<br>加入L2正则化：<br>$$<br>Cost = \sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)<br>$$<br>对损失函数求偏导：<br>$$<br>\begin{split}<br>\cfrac {\partial}{\partial p_{uk}}Cost &amp;= \cfrac {\partial}{\partial p_{uk}}[\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]<br>\&amp;=2\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}<br>\\<br>\cfrac {\partial}{\partial q_{ik}}Cost &amp;= \cfrac {\partial}{\partial q_{ik}}[\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]<br>\&amp;=2\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})(-p_{uk}) + 2\lambda q_{ik}<br>\end{split}<br>$$</p><h4 id="随机梯度下降法优化"><a href="#随机梯度下降法优化" class="headerlink" title="随机梯度下降法优化"></a>随机梯度下降法优化</h4><p>梯度下降更新参数$p_{uk}​$：<br>$$<br>\begin{split}<br>p_{uk}&amp;:=p_{uk} - \alpha\cfrac {\partial}{\partial p_{uk}}Cost<br>\&amp;:=p_{uk}-\alpha [2\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}]<br>\&amp;:=p_{uk}+\alpha [\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda p_{uk}]<br>\end{split}<br>$$<br> 同理：<br>$$<br>\begin{split}<br>q_{ik}&amp;:=q_{ik} + \alpha[\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda q_{ik}]<br>\end{split}<br>$$<br><strong>随机梯度下降：</strong> 向量乘法 每一个分量相乘 求和<br>$$<br>\begin{split}<br>&amp;p_{uk}:=p_{uk}+\alpha [(r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda_1 p_{uk}]<br>\&amp;q_{ik}:=q_{ik} + \alpha[(r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda_2 q_{ik}]<br>\end{split}<br>$$<br>由于P矩阵和Q矩阵是两个不同的矩阵，通常分别采取不同的正则参数，如$\lambda_1​$和$\lambda_2​$</p><p><strong>算法实现</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">LFM Model</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评分预测    1-5</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LFM</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, alpha, reg_p, reg_q, number_LatentFactors=<span class="number">10</span>, number_epochs=<span class="number">10</span>, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        self.alpha = alpha <span class="comment"># 学习率</span></span><br><span class="line">        self.reg_p = reg_p    <span class="comment"># P矩阵正则</span></span><br><span class="line">        self.reg_q = reg_q    <span class="comment"># Q矩阵正则</span></span><br><span class="line">        self.number_LatentFactors = number_LatentFactors  <span class="comment"># 隐式类别数量</span></span><br><span class="line">        self.number_epochs = number_epochs    <span class="comment"># 最大迭代次数</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        fit dataset</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        self.dataset = pd.DataFrame(dataset)</span><br><span class="line"></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([list])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([list])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line"></span><br><span class="line">        self.globalMean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line"></span><br><span class="line">        self.P, self.Q = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_matrix</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化P和Q矩阵，同时为设置0，1之间的随机值作为初始值</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># User-LF</span></span><br><span class="line">        P = dict(zip(</span><br><span class="line">            self.users_ratings.index,</span><br><span class="line">            np.random.rand(len(self.users_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="comment"># Item-LF</span></span><br><span class="line">        Q = dict(zip(</span><br><span class="line">            self.items_ratings.index,</span><br><span class="line">            np.random.rand(len(self.items_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="keyword">return</span> P, Q</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        使用随机梯度下降，优化结果</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        P, Q = self._init_matrix()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span>%i)</span><br><span class="line">            error_list = []</span><br><span class="line">            <span class="keyword">for</span> uid, iid, r_ui <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                <span class="comment"># User-LF P</span></span><br><span class="line">                <span class="comment">## Item-LF Q</span></span><br><span class="line">                v_pu = P[uid] <span class="comment">#用户向量</span></span><br><span class="line">                v_qi = Q[iid] <span class="comment">#物品向量</span></span><br><span class="line">                err = np.float32(r_ui - np.dot(v_pu, v_qi))</span><br><span class="line"></span><br><span class="line">                v_pu += self.alpha * (err * v_qi - self.reg_p * v_pu)</span><br><span class="line">                v_qi += self.alpha * (err * v_pu - self.reg_q * v_qi)</span><br><span class="line">                </span><br><span class="line">                P[uid] = v_pu </span><br><span class="line">                Q[iid] = v_qi</span><br><span class="line"></span><br><span class="line">                <span class="comment"># for k in range(self.number_of_LatentFactors):</span></span><br><span class="line">                <span class="comment">#     v_pu[k] += self.alpha*(err*v_qi[k] - self.reg_p*v_pu[k])</span></span><br><span class="line">                <span class="comment">#     v_qi[k] += self.alpha*(err*v_pu[k] - self.reg_q*v_qi[k])</span></span><br><span class="line"></span><br><span class="line">                error_list.append(err ** <span class="number">2</span>)</span><br><span class="line">            print(np.sqrt(np.mean(error_list)))</span><br><span class="line">        <span class="keyword">return</span> P, Q</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        <span class="comment"># 如果uid或iid不在，我们使用全剧平均分作为预测结果返回</span></span><br><span class="line">        <span class="keyword">if</span> uid <span class="keyword">not</span> <span class="keyword">in</span> self.users_ratings.index <span class="keyword">or</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">return</span> self.globalMean</span><br><span class="line"></span><br><span class="line">        p_u = self.P[uid]</span><br><span class="line">        q_i = self.Q[iid]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> np.dot(p_u, q_i)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;预测测试集数据&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> testset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pred_rating = self.predict(uid, iid)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                print(e)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">yield</span> uid, iid, real_rating, pred_rating</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=range(<span class="number">3</span>), dtype=dict(dtype))</span><br><span class="line"></span><br><span class="line">    lfm = LFM(<span class="number">0.02</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">10</span>, <span class="number">100</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    lfm.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = input(<span class="string">&quot;uid: &quot;</span>)</span><br><span class="line">        iid = input(<span class="string">&quot;iid: &quot;</span>)</span><br><span class="line">        print(lfm.predict(int(uid), int(iid)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(6) 基于矩阵分解的CF算法实现之BiasSvd</title>
      <link href="2019/02/15/06_BiasSVD%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
      <url>2019/02/15/06_BiasSVD%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于矩阵分解的CF算法实现（二）：BiasSvd"><a href="#基于矩阵分解的CF算法实现（二）：BiasSvd" class="headerlink" title="基于矩阵分解的CF算法实现（二）：BiasSvd"></a>基于矩阵分解的CF算法实现（二）：BiasSvd</h2><p>BiasSvd其实就是前面提到的Funk SVD矩阵分解基础上加上了偏置项。</p><h4 id="BiasSvd"><a href="#BiasSvd" class="headerlink" title="BiasSvd"></a>BiasSvd</h4><p>利用BiasSvd预测用户对物品的评分，$k$表示隐含特征数量：<br>$$<br>\begin{split}<br>\hat {r}<em>{ui} &amp;=\mu + b_u + b_i + \vec {p</em>{uk}}\cdot \vec {q_{ki}}<br>\&amp;=\mu + b_u + b_i + {\sum_{k=1}}^k p_{uk}q_{ik}<br>\end{split}<br>$$</p><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>同样对于评分预测我们利用平方差来构建损失函数：<br>$$<br>\begin{split}<br>Cost &amp;= \sum_{u,i\in R} (r_{ui}-\hat{r}<em>{ui})^2<br>\&amp;=\sum</em>{u,i\in R} (r_{ui}-\mu - b_u - b_i -{\sum_{k=1}}^k p_{uk}q_{ik})^2<br>\end{split}<br>$$<br>加入L2正则化：<br>$$<br>Cost = \sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)<br>$$<br>对损失函数求偏导：<br>$$<br>\begin{split}<br>\cfrac {\partial}{\partial p_{uk}}Cost &amp;= \cfrac {\partial}{\partial p_{uk}}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]<br>\&amp;=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}<br>\\<br>\cfrac {\partial}{\partial q_{ik}}Cost &amp;= \cfrac {\partial}{\partial q_{ik}}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]<br>\&amp;=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-p_{uk}) + 2\lambda q_{ik}<br>\end{split}<br>$$</p><p>$$<br>\begin{split}<br>\cfrac {\partial}{\partial b_u}Cost &amp;= \cfrac {\partial}{\partial b_u}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]<br>\&amp;=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-1) + 2\lambda b_u<br>\\<br>\cfrac {\partial}{\partial b_i}Cost &amp;= \cfrac {\partial}{\partial b_i}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]<br>\&amp;=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-1) + 2\lambda b_i<br>\end{split}<br>$$</p><h4 id="随机梯度下降法优化"><a href="#随机梯度下降法优化" class="headerlink" title="随机梯度下降法优化"></a>随机梯度下降法优化</h4><p>梯度下降更新参数$p_{uk}$：<br>$$<br>\begin{split}<br>p_{uk}&amp;:=p_{uk} - \alpha\cfrac {\partial}{\partial p_{uk}}Cost<br>\&amp;:=p_{uk}-\alpha [2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}]<br>\&amp;:=p_{uk}+\alpha [\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda p_{uk}]<br>\end{split}<br>$$<br> 同理：<br>$$<br>\begin{split}<br>q_{ik}&amp;:=q_{ik} + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda q_{ik}]<br>\end{split}<br>$$</p><p>$$<br>b_u:=b_u + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda b_u]<br>$$</p><p>$$<br>b_i:=b_i + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda b_i]<br>$$</p><p><strong>随机梯度下降：</strong><br>$$<br>\begin{split}<br>&amp;p_{uk}:=p_{uk}+\alpha [(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda_1 p_{uk}]<br>\&amp;q_{ik}:=q_{ik} + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda_2 q_{ik}]<br>\end{split}<br>$$</p><p>$$<br>b_u:=b_u + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda_3 b_u]<br>$$</p><p>$$<br>b_i:=b_i + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda_4 b_i]<br>$$</p><p>由于P矩阵和Q矩阵是两个不同的矩阵，通常分别采取不同的正则参数，如$\lambda_1$和$\lambda_2$</p><p><strong>算法实现</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">BiasSvd Model</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BiasSvd</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, alpha, reg_p, reg_q, reg_bu, reg_bi, number_LatentFactors=<span class="number">10</span>, number_epochs=<span class="number">10</span>, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        self.alpha = alpha <span class="comment"># 学习率</span></span><br><span class="line">        self.reg_p = reg_p</span><br><span class="line">        self.reg_q = reg_q</span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        self.number_LatentFactors = number_LatentFactors  <span class="comment"># 隐式类别数量</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        fit dataset</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        self.dataset = pd.DataFrame(dataset)</span><br><span class="line"></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([list])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([list])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        self.globalMean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line"></span><br><span class="line">        self.P, self.Q, self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_matrix</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化P和Q矩阵，同时为设置0，1之间的随机值作为初始值</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># User-LF</span></span><br><span class="line">        P = dict(zip(</span><br><span class="line">            self.users_ratings.index,</span><br><span class="line">            np.random.rand(len(self.users_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="comment"># Item-LF</span></span><br><span class="line">        Q = dict(zip(</span><br><span class="line">            self.items_ratings.index,</span><br><span class="line">            np.random.rand(len(self.items_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="keyword">return</span> P, Q</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        使用随机梯度下降，优化结果</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        P, Q = self._init_matrix()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = dict(zip(self.users_ratings.index, np.zeros(len(self.users_ratings))))</span><br><span class="line">        bi = dict(zip(self.items_ratings.index, np.zeros(len(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span>%i)</span><br><span class="line">            error_list = []</span><br><span class="line">            <span class="keyword">for</span> uid, iid, r_ui <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                v_pu = P[uid]</span><br><span class="line">                v_qi = Q[iid]</span><br><span class="line">                err = np.float32(r_ui - self.globalMean - bu[uid] - bi[iid] - np.dot(v_pu, v_qi))</span><br><span class="line"></span><br><span class="line">                v_pu += self.alpha * (err * v_qi - self.reg_p * v_pu)</span><br><span class="line">                v_qi += self.alpha * (err * v_pu - self.reg_q * v_qi)</span><br><span class="line">                </span><br><span class="line">                P[uid] = v_pu </span><br><span class="line">                Q[iid] = v_qi</span><br><span class="line">                </span><br><span class="line">                bu[uid] += self.alpha * (err - self.reg_bu * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (err - self.reg_bi * bi[iid])</span><br><span class="line"></span><br><span class="line">                error_list.append(err ** <span class="number">2</span>)</span><br><span class="line">            print(np.sqrt(np.mean(error_list)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> P, Q, bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> uid <span class="keyword">not</span> <span class="keyword">in</span> self.users_ratings.index <span class="keyword">or</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">return</span> self.globalMean</span><br><span class="line"></span><br><span class="line">        p_u = self.P[uid]</span><br><span class="line">        q_i = self.Q[iid]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.globalMean + self.bu[uid] + self.bi[iid] + np.dot(p_u, q_i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=range(<span class="number">3</span>), dtype=dict(dtype))</span><br><span class="line"></span><br><span class="line">    bsvd = BiasSvd(<span class="number">0.02</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">    bsvd.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = input(<span class="string">&quot;uid: &quot;</span>)</span><br><span class="line">        iid = input(<span class="string">&quot;iid: &quot;</span>)</span><br><span class="line">        print(bsvd.predict(int(uid), int(iid)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(7)  基于内容的推荐算法（Content-Based）</title>
      <link href="2019/02/15/07_%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
      <url>2019/02/15/07_%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于内容的推荐算法（Content-Based）"><a href="#基于内容的推荐算法（Content-Based）" class="headerlink" title="基于内容的推荐算法（Content-Based）"></a>基于内容的推荐算法（Content-Based）</h2><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>基于内容的推荐方法是非常直接的，它以物品的内容描述信息为依据来做出的推荐，本质上是基于对物品和用户自身的特征或属性的直接分析和计算。</p><p>例如，假设已知电影A是一部喜剧，而恰巧我们得知某个用户喜欢看喜剧电影，那么我们基于这样的已知信息，就可以将电影A推荐给该用户。</p><h4 id="基于内容的推荐实现步骤"><a href="#基于内容的推荐实现步骤" class="headerlink" title="基于内容的推荐实现步骤"></a>基于内容的推荐实现步骤</h4><ul><li><p><strong>画像构建</strong>。顾名思义，画像就是刻画物品或用户的特征。本质上就是给用户或物品贴标签。</p><ul><li><p><strong>物品画像</strong>：例如给电影《战狼2》贴标签，可以有哪些？</p><p><img src="/img/%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%901.png"></p><p>“动作”、”吴京”、”吴刚”、”张翰”、”大陆电影”、”国产”、”爱国”、”军事”等等一系列标签是不是都可以贴上</p></li><li><p><strong>用户画像</strong>：例如已知用户的观影历史是：”《战狼1》”、”《战狼2》”、”《建党伟业》”、”《建军大业》”、”《建国大业》”、”《红海行动》”、”《速度与激情1-8》”等，我们是不是就可以分析出该用户的一些兴趣特征如：”爱国”、”战争”、”赛车”、”动作”、”军事”、”吴京”、”韩三平”等标签。</p></li></ul></li></ul><h6 id="问题：物品的标签来自哪儿？"><a href="#问题：物品的标签来自哪儿？" class="headerlink" title="问题：物品的标签来自哪儿？"></a>问题：物品的标签来自哪儿？</h6><ol><li>PGC    物品画像–冷启动<ul><li>物品自带的属性（物品一产生就具备的）：如电影的标题、导演、演员、类型等等</li><li>服务提供方设定的属性（服务提供方为物品附加的属性）：如短视频话题、微博话题（平台拟定）</li><li>其他渠道：如爬虫</li></ul></li><li>UGC    冷启动问题<ul><li>用户在享受服务过程中提供的物品的属性：如用户评论内容，微博话题（用户拟定）</li></ul></li></ol><p>根据PGC内容构建的物品画像的可以解决物品的冷启动问题</p><h6 id="基于内容推荐的算法流程："><a href="#基于内容推荐的算法流程：" class="headerlink" title="基于内容推荐的算法流程："></a>基于内容推荐的算法流程：</h6><ul><li>根据PGC/UGC内容构建物品画像</li><li>根据用户行为记录生成用户画像</li><li>根据用户画像从物品中寻找最匹配的TOP-N物品进行推荐</li></ul><h6 id="物品冷启动处理："><a href="#物品冷启动处理：" class="headerlink" title="物品冷启动处理："></a>物品冷启动处理：</h6><ul><li>根据PGC内容构建物品画像</li><li>利用物品画像计算物品间两两相似情况</li><li>为每个物品产生TOP-N最相似的物品进行相关推荐：如与该商品相似的商品有哪些？与该文章相似文章有哪些？</li></ul>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(8)  基于内容的电影推荐：物品画像</title>
      <link href="2019/02/15/08_%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90(ContentBased)_%E7%89%A9%E5%93%81%E7%94%BB%E5%83%8F/"/>
      <url>2019/02/15/08_%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90(ContentBased)_%E7%89%A9%E5%93%81%E7%94%BB%E5%83%8F/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于内容的电影推荐：物品画像"><a href="#基于内容的电影推荐：物品画像" class="headerlink" title="基于内容的电影推荐：物品画像"></a>基于内容的电影推荐：物品画像</h2><p>物品画像构建步骤：</p><ul><li>利用tags.csv中每部电影的标签作为电影的候选关键词</li><li>利用TF·IDF计算每部电影的标签的tfidf值，选取TOP-N个关键词作为电影画像标签</li><li>将电影的分类词直接作为每部电影的画像标签</li></ul><h2 id="基于TF-IDF的特征提取技术"><a href="#基于TF-IDF的特征提取技术" class="headerlink" title="基于TF-IDF的特征提取技术"></a>基于TF-IDF的特征提取技术</h2><p>前面提到，物品画像的特征标签主要都是指的如电影的导演、演员、图书的作者、出版社等结构话的数据，也就是他们的特征提取，尤其是体征向量的计算是比较简单的，如直接给作品的分类定义0或者1的状态。</p><p>但另外一些特征，比如电影的内容简介、电影的影评、图书的摘要等文本数据，这些被称为非结构化数据，首先他们本应该也属于物品的一个特征标签，但是这样的特征标签进行量化时，也就是计算它的特征向量时是很难去定义的。</p><p>因此这时就需要借助一些自然语言处理、信息检索等技术，将如用户的文本评论或其他文本内容信息的非结构化数据进行量化处理，从而实现更加完善的物品画像/用户画像。</p><p>TF-IDF算法便是其中一种在自然语言处理领域中应用比较广泛的一种算法。可用来提取目标文档中，并得到关键词用于计算对于目标文档的权重，并将这些权重组合到一起得到特征向量。</p><h4 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h4><p>TF-IDF自然语言处理领域中计算文档中词或短语的权值的方法，是<strong>词频</strong>（Term Frequency，TF）和逆转文档频率（Inverse Document Frequency，IDF）的乘积。TF指的是某一个给定的词语在该文件中出现的次数。这个数字通常会被正规化，以防止它偏向长的文件（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）。IDF是一个词语普遍重要性的度量，某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。</p><p>TF-IDF算法基于一个这样的假设：若一个词语在目标文档中出现的频率高而在其他文档中出现的频率低，那么这个词语就可以用来区分出目标文档。这个假设需要掌握的有两点：</p><ul><li>在本文档出现的频率高；</li><li>在其他文档出现的频率低。</li></ul><p>因此，TF-IDF算法的计算可以分为词频（Term Frequency，TF）和逆转文档频率（Inverse Document Frequency，IDF）两部分，由TF和IDF的乘积来设置文档词语的权重。</p><p>TF指的是一个词语在文档中的出现频率。假设文档集包含的文档数为$$N​$$，文档集中包含关键词$$k_i​$$的文档数为$$n_i​$$，$$f_{ij}​$$表示关键词$$k_i​$$在文档$$d_j​$$中出现的次数，$$f_{dj}​$$表示文档$$d_j​$$中出现的词语总数，$$k_i​$$在文档dj中的词频$$TF_{ij}​$$定义为：$$TF_{ij}=\frac {f_{ij}}{f_{dj}}​$$。并且注意，这个数字通常会被正规化，以防止它偏向长的文件（指同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）。</p><p>IDF是一个词语普遍重要性的度量。表示某一词语在整个文档集中出现的频率，由它计算的结果取对数得到关键词$$k_i​$$的逆文档频率$$IDF_i​$$：$$IDF_i=log\frac {N}{n_i}​$$</p><p>由TF和IDF计算词语的权重为：$$w_{ij}=TF_{ij}$$<strong>·</strong>$$IDF_{i}=\frac {f_{ij}}{f_{dj}}$$<strong>·</strong>$$log\frac {N}{n_i}$$</p><p><strong>结论：TF-IDF与词语在文档中的出现次数成正比，与该词在整个文档集中的出现次数成反比。</strong></p><p><strong>用途：在目标文档中，提取关键词(特征标签)的方法就是将该文档所有词语的TF-IDF计算出来并进行对比，取其中TF-IDF值最大的k个数组成目标文档的特征向量用以表示文档。</strong></p><p>注意：文档中存在的停用词（Stop Words），如“是”、“的”之类的，对于文档的中心思想表达没有意义的词，在分词时需要先过滤掉再计算其他词语的TF-IDF值。</p><h4 id="算法举例"><a href="#算法举例" class="headerlink" title="算法举例"></a>算法举例</h4><p>对于计算影评的TF-IDF，以电影“加勒比海盗：黑珍珠号的诅咒”为例，假设它总共有1000篇影评，其中一篇影评的总词语数为200，其中出现最频繁的词语为“海盗”、“船长”、“自由”，分别是20、15、10次，并且这3个词在所有影评中被提及的次数分别为1000、500、100，就这3个词语作为关键词的顺序计算如下。</p><ol><li><p>将影评中出现的停用词过滤掉，计算其他词语的词频。以出现最多的三个词为例进行计算如下：</p><ul><li>“海盗”出现的词频为20/200＝0.1</li><li>“船长”出现的词频为15/200=0.075</li><li>“自由”出现的词频为10/200=0.05；</li></ul></li><li><p>计算词语的逆文档频率如下：</p><ul><li>“海盗”的IDF为：log(1000/1000)=0</li><li>“船长”的IDF为：log(1000/500)=0.3<br>“自由”的IDF为：log(1000/100)=1</li></ul></li><li><p>由1和2计算的结果求出词语的TF-IDF结果，“海盗”为0，“船长”为0.0225，“自由”为0.05。</p></li></ol><p>通过对比可得，该篇影评的关键词排序应为：“自由”、“船长”、“海盗”。把这些词语的TF-IDF值作为它们的权重按照对应的顺序依次排列，就得到这篇影评的特征向量，我们就用这个向量来代表这篇影评，向量中每一个维度的分量大小对应这个属性的重要性。</p><p>将总的影评集中所有的影评向量与特定的系数相乘求和，得到这部电影的综合影评向量，与电影的基本属性结合构建视频的物品画像，同理构建用户画像，可采用多种方法计算物品画像和用户画像之间的相似度，为用户做出推荐。</p><h4 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">- 利用tags.csv中每部电影的标签作为电影的候选关键词</span></span><br><span class="line"><span class="string">- 利用TF·IDF计算每部电影的标签的tfidf值，选取TOP-N个关键词作为电影画像标签</span></span><br><span class="line"><span class="string">- 并将电影的分类词直接作为每部电影的画像标签</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_dataset</span>():</span></span><br><span class="line">    <span class="comment"># 加载基于所有电影的标签</span></span><br><span class="line">    <span class="comment"># all-tags.csv来自ml-latest数据集中</span></span><br><span class="line">    <span class="comment"># 由于ml-latest-small中标签数据太多，因此借助其来扩充</span></span><br><span class="line">    _tags = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/all-tags.csv&quot;</span>, usecols=range(<span class="number">1</span>, <span class="number">3</span>)).dropna()</span><br><span class="line">    tags = _tags.groupby(<span class="string">&quot;movieId&quot;</span>).agg(list)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载电影列表数据集</span></span><br><span class="line">    movies = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/movies.csv&quot;</span>, index_col=<span class="string">&quot;movieId&quot;</span>)</span><br><span class="line">    <span class="comment"># 将类别词分开</span></span><br><span class="line">    movies[<span class="string">&quot;genres&quot;</span>] = movies[<span class="string">&quot;genres&quot;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment"># 为每部电影匹配对应的标签数据，如果没有将会是NAN</span></span><br><span class="line">    movies_index = set(movies.index) &amp; set(tags.index)</span><br><span class="line">    new_tags = tags.loc[list(movies_index)]</span><br><span class="line">    ret = movies.join(new_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建电影数据集，包含电影Id、电影名称、类别、标签四个字段</span></span><br><span class="line">    <span class="comment"># 如果电影没有标签数据，那么就替换为空列表</span></span><br><span class="line">    <span class="comment"># map(fun,可迭代对象)</span></span><br><span class="line">    movie_dataset = pd.DataFrame(</span><br><span class="line">        map(</span><br><span class="line">            <span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], x[<span class="number">2</span>]+x[<span class="number">3</span>]) <span class="keyword">if</span> x[<span class="number">3</span>] <span class="keyword">is</span> <span class="keyword">not</span> np.nan <span class="keyword">else</span> (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], []), ret.itertuples())</span><br><span class="line">        , columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tags&quot;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    movie_dataset.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_dataset</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">print(movie_dataset)</span><br></pre></td></tr></table></figure><h4 id="基于TF·IDF提取TOP-N关键词，构建电影画像"><a href="#基于TF·IDF提取TOP-N关键词，构建电影画像" class="headerlink" title="基于TF·IDF提取TOP-N关键词，构建电影画像"></a>基于TF·IDF提取TOP-N关键词，构建电影画像</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset: </span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    <span class="comment"># 根据数据集建立词袋，并统计词频，将所有词放入一个词典，使用索引进行获取</span></span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    <span class="comment"># 根据将每条数据，返回对应的词索引和词频</span></span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line">    <span class="comment"># 训练TF-IDF模型，即计算TF-IDF值</span></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    movie_profile = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i, mid <span class="keyword">in</span> enumerate(movie_dataset.index):</span><br><span class="line">        <span class="comment"># 根据每条数据返回，向量</span></span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        <span class="comment"># 按照TF-IDF值得到top-n的关键词</span></span><br><span class="line">        movie_tags = sorted(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        <span class="comment"># 根据关键词提取对应的名称</span></span><br><span class="line">        movie_profile[mid] = dict(map(<span class="keyword">lambda</span> x:(dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">pprint(create_movie_profile(movie_dataset))</span><br></pre></td></tr></table></figure><h4 id="完善画像关键词"><a href="#完善画像关键词" class="headerlink" title="完善画像关键词"></a>完善画像关键词</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    <span class="comment"># 根据数据集建立词袋，并统计词频，将所有词放入一个词典，使用索引进行获取</span></span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    <span class="comment"># 根据将每条数据，返回对应的词索引和词频</span></span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line">    <span class="comment"># 训练TF-IDF模型，即计算TF-IDF值</span></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    _movie_profile = []</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(movie_dataset.itertuples()):</span><br><span class="line">        mid = data[<span class="number">0</span>]</span><br><span class="line">        title = data[<span class="number">1</span>]</span><br><span class="line">        genres = data[<span class="number">2</span>]</span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        movie_tags = sorted(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        topN_tags_weights = dict(map(<span class="keyword">lambda</span> x: (dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line">        <span class="comment"># 将类别词的添加进去，并设置权重值为1.0</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">            topN_tags_weights[g] = <span class="number">1.0</span></span><br><span class="line">        topN_tags = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> topN_tags_weights.items()]</span><br><span class="line">        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))</span><br><span class="line"></span><br><span class="line">    movie_profile = pd.DataFrame(_movie_profile, columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;profile&quot;</span>, <span class="string">&quot;weights&quot;</span>])</span><br><span class="line">    movie_profile.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">pprint(create_movie_profile(movie_dataset))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为了根据指定关键词迅速匹配到对应的电影，因此需要对物品画像的标签词，建立<strong>倒排索引</strong></p><p><strong>倒排索引介绍</strong></p><p>通常数据存储数据，都是以物品的ID作为索引，去提取物品的其他信息数据</p><p>而倒排索引就是用物品的其他数据作为索引，去提取它们对应的物品的ID列表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">建立tag-物品的倒排索引</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_inverted_table</span>(<span class="params">movie_profile</span>):</span></span><br><span class="line">    inverted_table = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> mid, weights <span class="keyword">in</span> movie_profile[<span class="string">&quot;weights&quot;</span>].iteritems():</span><br><span class="line">        <span class="keyword">for</span> tag, weight <span class="keyword">in</span> weights.items():</span><br><span class="line">            <span class="comment">#到inverted_table dict 用tag作为Key去取值 如果取不到就返回[]</span></span><br><span class="line">            _ = inverted_table.get(tag, [])</span><br><span class="line">            _.append((mid, weight))</span><br><span class="line">            inverted_table.setdefault(tag, _)</span><br><span class="line">    <span class="keyword">return</span> inverted_table</span><br><span class="line"></span><br><span class="line">inverted_table = create_inverted_table(movie_profile)</span><br><span class="line">pprint(inverted_table)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(5)：可靠性保障</title>
      <link href="2019/02/15/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(5)%EF%BC%9A%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E9%9A%9C/"/>
      <url>2019/02/15/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(5)%EF%BC%9A%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E9%9A%9C/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-副本"><a href="#1-副本" class="headerlink" title="1. 副本"></a>1. 副本</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1. 概述"></a>1.1. 概述</h2><h2 id="1-2-失效副本"><a href="#1-2-失效副本" class="headerlink" title="1.2. 失效副本"></a>1.2. 失效副本</h2><blockquote></blockquote><h3 id="1-2-1-失效副本判定"><a href="#1-2-1-失效副本判定" class="headerlink" title="1.2.1.失效副本判定"></a>1.2.1.失效副本判定</h3><p>从 Kafka 0.9.x 版本开始通过唯一的一个参数 <code>replica.lag.time.max.ms</code>[默认大小为10,000]来控制，当 ISR 中的一个 follower 副本滞后 leader 副本的时间超过参数 replica.lag.time.max.ms 指定的值时即判定为副本失效，需要将此 follower 副本剔出 ISR 。</p><ul><li><p><strong><font color = 'red'>注意</font></strong></p><p>在 Kafka 0.9.x 版本之前还有另一个 Broker 级别的参数 replica.lag.max.messages（默认大小为4000）也是用来判定失效副本的，当一个 follower 副本滞后 leader 副本的消息数超过replica.lag.max.messages 的大小时则判定此follower副本为失效副本。它与replica.lag.time.max.ms 参数判定出的失败副本去并集组成一个失效副本的集合，从而进一步剥离出ISR。不过这个 replica.lag.max.messages 参数很难给定一个合适的值，若设置的太大则这个参数本身就没有太多意义，若设置的太小则会让 follower 副本反复的处于同步、未同步、同步的死循环中，进而又会造成ISR的频繁变动。而且这个参数是 Broker 级别的，也就是说对 Broker 中的所有 topic 都生效，就以默认的值4000来说，对于消息流入速度很低的topic来说，比如TPS=10，这个参数并无用武之地；而对于消息流入速度很高的topic来说，比如TPS=20,000，这个参数的取值又会引入ISR的频繁变动，所以从0.9.x版本开始就彻底移除了这一参数</p></li></ul><p>当follower副本将leader副本的LEO（Log End Offset，每个分区最后一条消息的位置）之前的日志全部同步时，则认为该follower副本已经追赶上leader副本，此时更新该副本的lastCaughtUpTimeMs标识。Kafka的副本管理器（ReplicaManager）启动时会启动一个副本过期检测的定时任务，而这个定时任务会定时检查当前时间与副本的lastCaughtUpTimeMs差值是否大于参数replica.lag.time.max.ms指定的值。千万不要错误的认为follower副本只要拉取leader副本的数据就会更新lastCaughtUpTimeMs，试想当leader副本的消息流入速度大于follower副本的拉取速度时，follower副本一直不断的拉取leader副本的消息也不能与leader副本同步，如果还将此follower副本置于ISR中，那么当leader副本失效，而选取此follower副本为新的leader副本，那么就会有严重的消息丢失。</p><h2 id="1-3-ISR"><a href="#1-3-ISR" class="headerlink" title="1.3. ISR"></a>1.3. ISR</h2><p>分区中所有副本统称为 AR(Assign Replicas) 所有和 leader 副本保持一定程度同步的副本[包括leader 副本在内]组成LSR</p><p>LSR 集合是 AR 集合的一个子集</p><p>消息会首先发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步，同步期内 follower副本 相较 leader 副本 有一定的滞后，这个滞后在可忍受的滞后范围，这个范围可以通过参数进行配置</p><p>与leader 副本滞后过多的副本组成 OSR </p><p>在正常情况下，所有的 follower 副本都应该与 leader 副本保持一定程度的同步,即 AR=ISR, OR集合为空</p><h2 id="1-3-1-维护"><a href="#1-3-1-维护" class="headerlink" title="1.3.1. 维护"></a>1.3.1. 维护</h2><p><strong>leader 副本负责维护和跟踪</strong> ISR 集合中所有 follower 副本的滞后状态，当follower副本落后太多或失效时，leader副本会把它从 ISR 集合中剔除。如果 OSR 集合中所有follower副本“追上”了leader副本，那么leader副本会把它从 OSR 集合转移至 ISR 集合。默认情况下，当leader副本发生故障时，只有在 ISR 集合中的follower副本才有资格被选举为新的leader，而在 OSR 集合中的副本则没有任何机会（不过这个可以通过配置来改变）。</p><h2 id="1-3-2-ISR-缩减"><a href="#1-3-2-ISR-缩减" class="headerlink" title="1.3.2. ISR 缩减"></a>1.3.2. ISR 缩减</h2><ul><li><p>isr-expiration定时任务会周期性的检测每个分区是否需要缩减其ISR集合，当检测到ISR中有是失效的副本的时候，就会缩减 ISR 集合；</p></li><li><p><strong>将变更后的数据记录到 ZooKeeper 对应 /brokers/topics//partition//state 节点；</strong></p></li><li><p><strong>ISR 集合发生变更时将变更后的数据缓存到 isrChangeSet</strong></p></li><li><p>isr-change-propagation 定时任务会周期性（固定值为2500ms）地检查 isrChangeSet，在 zk 中的 /isr_change_notification 节点下创建 isr_change 开头的持久顺序节点，并保存 isrChangeSet 的数据</p></li><li><p>kafka控制器为 /isr_change_notification 添加了一个 Watcher，当这个节点中有子节点发生变化的时候会触发 Watcher 动作，以此通知控制器<strong>更新相关的元数据信息</strong>并向它管理的 broker 节点发送更新元数据信息的请求。最<strong>后删除 /isr_change_notification 的路径下已经处理过的节点</strong>。</p><ul><li><p><strong><font color='red'>注意</font></strong></p><blockquote><p>频繁的触发 Watcher 会影响 kafka 控制器，zookeeper 甚至其他的 broker 性能。为了避免这种情况，kafka 添加了指定的条件，当检测到分区 ISR 集合发生变化的时候，还需要检查一下两个条件：</p></blockquote><ul><li>上一次 ISR 集合发生变化距离现在已经超过5秒，</li><li>上一次写入zookeeper的时候距离现在已经超过60秒。</li></ul><blockquote><p>满足以上两个条件之一者可以将 ISR 写入集合的变化的目标节点。</p></blockquote></li></ul></li></ul><h3 id="1-3-3-ISR-增加"><a href="#1-3-3-ISR-增加" class="headerlink" title="1.3.3. ISR 增加"></a>1.3.3. ISR 增加</h3><blockquote><p>随着 follower 副本不断进行消息同步，follower    副本 LEO 也会逐渐后移，并且最终赶上 leader 副本，此时 follower 副本就有资格进入 ISR 集合，追赶上leader 副本的判定准侧是<strong>此副本的 LEO 是否大于等于 leader 副本 HW</strong>。更新 ZooKeeper 中的 /broker/topics//partition//state 节点和 isrChangeSet，之后的操作同 ISR  集合的缩减。</p></blockquote><h2 id="1-4-副本同步"><a href="#1-4-副本同步" class="headerlink" title="1.4. 副本同步"></a>1.4. 副本同步</h2><h3 id="1-4-1-相关概念"><a href="#1-4-1-相关概念" class="headerlink" title="1.4.1. 相关概念"></a>1.4.1. 相关概念</h3><p><strong>LEO [Log End Offset]，标识当前日志文件中下一条待写入的消息的 offset</strong>。上图中 offset 为 9 的位置即为当前日志文件的 LEO</p><p><strong>LEO 的大小相当于当前日志分区中最后一条消息的 offset 值加 1</strong></p><p>分区 ISR  集合中的每个副本都会维护自身的 LEO ，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息。</p><p><strong>HW</strong> 是 High Watermark 的缩写，俗称高水位，水印，它标识了一个特定的消息偏移量[Offset],消费者只能拉取到这个 Offset 之前的消息。LSR 队列中的最小 LEO。</p><p>Leader副本 发生故障之后，从 LSR 中选出一个新的 Leader副本，为保证多个副本之间的数据一致性，其余的 Follower副本会从各自的日志文件中高于 HW 的部分截掉，然后从新的Leader副本同步数据。</p><img src="/Users/zxc/Documents/big_data/Kafka/resources/未命名.png" alt="未命名" style="zoom:72%;" /><h3 id="1-4-2-过程"><a href="#1-4-2-过程" class="headerlink" title="1.4.2. 过程"></a>1.4.2. 过程</h3><p>某个分区有3个副本分别位于 broker0、broker1 和 broker2 节点中，假设 broker0 上的副本1为当前分区的 leader 副本，那么副本2和副本3就是 follower 副本，整个消息追加的过程可以概括如下：</p><ul><li>生产者客户端发送消息至 leader 副本中。</li><li>消息被追加到 leader 副本的本地日志，并且会更新日志的偏移量。</li><li>follower 副本（副本2和副本3）向 leader 副本请求同步数据。</li><li>leader 副本所在的服务器读取本地日志，并更新对应拉取的 follower 副本的信息。</li><li>leader 副本所在的服务器将拉取结果返回给 follower 副本。</li><li>follower 副本收到 leader 副本返回的拉取结果，将消息追加到本地日志中，并更新日志的偏移量信息。</li></ul><p>某一时刻，leader 副本的 LEO 增加至5，并且所有副本的 HW 还都为0。</p><p><strong>之后 follower 副本 向 leader 副本 拉取消息，在拉取的请求中会带有自身的 LEO 信息</strong>[这个 LEO 信息对应的是 FetchRequest 请求中的 fetch_offset]。<strong>leader 副本返回给 follower 副本相应的消息，并且还带有自身的 HW 信息</strong></p><p><strong>follower 副本 各自拉取到了消息，并更新各自的 LEO 为3和4。与此同时，follower 副本 还会更新自己的 HW</strong>，更新 HW 的算法是比较当前 LEO 和 leader 副本 中传送过来的 HW 的值，取较小值作为自己的 HW 值。当前两个 follower 副本的 HW 都等于0</p><p><strong>接下来 follower 副本 再次请求拉取 leader 副本中的消息。</strong></p><p><strong>leader 副本 收到来自 follower 副本 的 FetchRequest 请求，其中带有 LEO 的相关信息，选取其中的最小值作为新的 HW即 min(15,3,4)=3，然后连同消息和 HW 一起返回 FetchResponse 给 follower 副本。</strong> leader 副本 的 HW 是一个很重要的东西，因为它直接影响了分区数据对消费者的可见性。</p><p>两个 follower 副本 在收到新的消息之后更新 LEO 并且更新自己的 HW 为<strong>3</strong> [min(LEO,3)=3]。</p><h2 id="1-4-Leader-Epoch"><a href="#1-4-Leader-Epoch" class="headerlink" title="1.4. Leader Epoch"></a>1.4. Leader Epoch</h2><p>leader epoch 代表 leader 的纪元信息（epoch），初始值为0。每当 leader 变更一次，leader epoch 的值就会加1，相当于为 leader 增设了一个版本号。<br>每个副本中还会增设一个矢量 &lt;LeaderEpoch =&gt; StartOffset&gt;，其中 StartOffset 表示当前 LeaderEpoch 下写入的第一条消息的偏移量。</p><h2 id="1-6-日志同步"><a href="#1-6-日志同步" class="headerlink" title="1.6. 日志同步"></a>1.6. 日志同步</h2>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐算法基础(3)  基于回归模型的协同过滤推荐</title>
      <link href="2019/02/15/03_%E5%9F%BA%E4%BA%8E%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/"/>
      <url>2019/02/15/03_%E5%9F%BA%E4%BA%8E%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="基于回归模型的协同过滤推荐"><a href="#基于回归模型的协同过滤推荐" class="headerlink" title="基于回归模型的协同过滤推荐"></a>基于回归模型的协同过滤推荐</h2><p>如果我们将评分看作是一个连续的值而不是离散的值，那么就可以借助线性回归思想来预测目标用户对某物品的评分。其中一种实现策略被称为Baseline（基准预测）。</p><h4 id="Baseline：基准预测"><a href="#Baseline：基准预测" class="headerlink" title="Baseline：基准预测"></a>Baseline：基准预测</h4><p>Baseline设计思想基于以下的假设：</p><ul><li>有些用户的评分普遍高于其他用户，有些用户的评分普遍低于其他用户。比如有些用户天生愿意给别人好评，心慈手软，比较好说话，而有的人就比较苛刻，总是评分不超过3分（5分满分）</li><li>一些物品的评分普遍高于其他物品，一些物品的评分普遍低于其他物品。比如一些物品一被生产便决定了它的地位，有的比较受人们欢迎，有的则被人嫌弃。</li></ul><p>这个用户或物品普遍高于或低于平均值的差值，我们称为偏置(bias)</p><p><strong>Baseline目标：</strong></p><ul><li>找出每个用户普遍高于或低于他人的偏置值$b_u​$</li><li>找出每件物品普遍高于或低于其他物品的偏置值$b_i$</li><li>我们的目标也就转化为寻找最优的$b_u$和$b_i$</li></ul><p>使用Baseline的算法思想预测评分的步骤如下：</p><ul><li><p>计算所有电影的平均评分$\mu$（即全局平均评分）</p></li><li><p>计算每个用户评分与平均评分$\mu$的偏置值$b_u$</p></li><li><p>计算每部电影所接受的评分与平均评分$\mu$的偏置值​$b_i$</p></li><li><p>预测用户对电影的评分：<br>$$<br>\hat{r}<em>{ui} = b</em>{ui} = \mu + b_u + b_i<br>$$</p></li></ul><p>举例：</p><p>​    比如我们想通过Baseline来预测用户A对电影“阿甘正传”的评分，那么首先计算出整个评分数据集的平均评分$\mu$是3.5分；而用户A是一个比较苛刻的用户，他的评分比较严格，普遍比平均评分低0.5分，即用户A的偏置值$b_i$是-0.5；而电影“阿甘正传”是一部比较热门而且备受好评的电影，它的评分普遍比平均评分要高1.2分，那么电影“阿甘正传”的偏置值$b_i$是+1.2，因此就可以预测出用户A对电影“阿甘正传”的评分为：$3.5+(-0.5)+1.2$，也就是4.2分。</p><p>对于所有电影的平均评分$\mu$是直接能计算出的，因此问题在于要测出每个用户的$b_u$值和每部电影的$b_i$的值。对于线性回归问题，我们可以利用平方差构建损失函数如下：<br>$$<br>\begin{split}<br>Cost &amp;= \sum_{u,i\in R}(r_{ui}-\hat{r}<em>{ui})^2<br>\&amp;=\sum</em>{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2<br>\end{split}<br>$$<br><img src="/img/%E5%81%8F%E7%BD%AE.png"></p><p>加入L2正则化：<br>$$<br>Cost=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)<br>$$<br>公式解析：</p><ul><li>公式第一部分$ \sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2$是用来寻找与已知评分数据拟合最好的$b_u$和$b_i$</li><li>公式第二部分$\lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)​$是正则化项，用于避免过拟合现象</li></ul><p>对于最小过程的求解，我们一般采用<strong>随机梯度下降法</strong>或者<strong>交替最小二乘法</strong>来优化实现。</p><h4 id="方法一：随机梯度下降法优化"><a href="#方法一：随机梯度下降法优化" class="headerlink" title="方法一：随机梯度下降法优化"></a>方法一：随机梯度下降法优化</h4><p>使用随机梯度下降优化算法预测Baseline偏置值</p><h6 id="step-1：梯度下降法推导"><a href="#step-1：梯度下降法推导" class="headerlink" title="step 1：梯度下降法推导"></a>step 1：梯度下降法推导</h6><p>损失函数：<br>$$<br>\begin{split}<br>&amp;J(\theta)=Cost=f(b_u, b_i)\<br>\<br>&amp;J(\theta)=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)<br>\end{split}<br>$$<br>梯度下降参数更新原始公式：<br>$$<br>\theta_j:=\theta_j-\alpha\cfrac{\partial }{\partial \theta_j}J(\theta)<br>$$<br>梯度下降更新$b_u​$:</p><p>​    损失函数偏导推导：<br>$$<br>\begin{split}<br>\cfrac{\partial}{\partial b_u} J(\theta)&amp;=\cfrac{\partial}{\partial b_u} f(b_u, b_i)<br>\&amp;=2\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)(-1) + 2\lambda{b_u}<br>\&amp;=-2\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + 2\lambda<em>b_u<br>\end{split}<br>$$<br>​    $b_u$更新(因为alpha可以人为控制，所以2可以省略掉)：<br>$$<br>\begin{split}<br>b_u&amp;:=b_u - \alpha</em>(-\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + \lambda * b_u)\<br>&amp;:=b_u + \alpha*(\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) - \lambda* b_u)<br>\end{split}<br>$$<br>同理可得，梯度下降更新$b_i​$:<br>$$<br>b_i:=b_i + \alpha*(\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) -\lambda*b_i)<br>$$</p><h6 id="step-2：随机梯度下降"><a href="#step-2：随机梯度下降" class="headerlink" title="step 2：随机梯度下降"></a>step 2：随机梯度下降</h6><p>由于<strong>随机梯度下降法</strong>本质上利用<strong>每个样本的损失</strong>来更新参数，而不用每次求出全部的损失和，因此使用SGD时：</p><p>单样本损失值：<br>$$<br>\begin{split}<br>error &amp;=r_{ui}-\hat{r}<em>{ui}<br>\&amp;= r</em>{ui}-(\mu+b_u+b_i)<br>\&amp;= r_{ui}-\mu-b_u-b_i<br>\end{split}<br>$$<br>参数更新：<br>$$<br>\begin{split}<br>b_u&amp;:=b_u + \alpha*((r_{ui}-\mu-b_u-b_i) -\lambda<em>b_u)  \<br>&amp;:=b_u + \alpha</em>(error - \lambda<em>b_u) \<br>\<br>b_i&amp;:=b_i + \alpha</em>((r_{ui}-\mu-b_u-b_i) -\lambda<em>b_i)\<br>&amp;:=b_i + \alpha</em>(error -\lambda*b_i)<br>\end{split}<br>$$</p><h6 id="step-3：算法实现"><a href="#step-3：算法实现" class="headerlink" title="step 3：算法实现"></a>step 3：算法实现</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFBySGD</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, alpha, reg, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># 学习率</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="comment"># 正则参数</span></span><br><span class="line">        self.reg = reg</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([list])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([list])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = dict(zip(self.users_ratings.index, np.zeros(len(self.users_ratings))))</span><br><span class="line">        bi = dict(zip(self.items_ratings.index, np.zeros(len(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                error = real_rating - (self.global_mean + bu[uid] + bi[iid])</span><br><span class="line"></span><br><span class="line">                bu[uid] += self.alpha * (error - self.reg * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (error - self.reg * bi[iid])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=range(<span class="number">3</span>), dtype=dict(dtype))</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFBySGD(<span class="number">20</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = int(input(<span class="string">&quot;uid: &quot;</span>))</span><br><span class="line">        iid = int(input(<span class="string">&quot;iid: &quot;</span>))</span><br><span class="line">        print(bcf.predict(uid, iid))</span><br></pre></td></tr></table></figure><h6 id="Step-4-准确性指标评估"><a href="#Step-4-准确性指标评估" class="headerlink" title="Step 4: 准确性指标评估"></a>Step 4: 准确性指标评估</h6><ul><li>添加test方法，然后使用之前实现accuary方法计算准确性指标</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span>(<span class="params">data_path, x=<span class="number">0.8</span>, random=False</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    切分数据集， 这里为了保证用户数量保持不变，将每个用户的评分数据按比例进行拆分</span></span><br><span class="line"><span class="string">    :param data_path: 数据集路径</span></span><br><span class="line"><span class="string">    :param x: 训练集的比例，如x=0.8，则0.2是测试集</span></span><br><span class="line"><span class="string">    :param random: 是否随机切分，默认False</span></span><br><span class="line"><span class="string">    :return: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    print(<span class="string">&quot;开始切分数据集...&quot;</span>)</span><br><span class="line">    <span class="comment"># 设置要加载的数据字段的类型</span></span><br><span class="line">    dtype = &#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32, <span class="string">&quot;rating&quot;</span>: np.float32&#125;</span><br><span class="line">    <span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">    ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    testset_index = []</span><br><span class="line">    <span class="comment"># 为了保证每个用户在测试集和训练集都有数据，因此按userId聚合</span></span><br><span class="line">    <span class="keyword">for</span> uid <span class="keyword">in</span> ratings.groupby(<span class="string">&quot;userId&quot;</span>).any().index:</span><br><span class="line">        user_rating_data = ratings.where(ratings[<span class="string">&quot;userId&quot;</span>]==uid).dropna()</span><br><span class="line">        <span class="keyword">if</span> random:</span><br><span class="line">            <span class="comment"># 因为不可变类型不能被 shuffle方法作用，所以需要强行转换为列表</span></span><br><span class="line">            index = list(user_rating_data.index)</span><br><span class="line">            np.random.shuffle(index)    <span class="comment"># 打乱列表</span></span><br><span class="line">            _index = round(len(user_rating_data) * x)</span><br><span class="line">            testset_index += list(index[_index:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 将每个用户的x比例的数据作为训练集，剩余的作为测试集</span></span><br><span class="line">            index = round(len(user_rating_data) * x)</span><br><span class="line">            testset_index += list(user_rating_data.index.values[index:])</span><br><span class="line"></span><br><span class="line">    testset = ratings.loc[testset_index]</span><br><span class="line">    trainset = ratings.drop(testset_index)</span><br><span class="line">    print(<span class="string">&quot;完成数据集切分...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuray</span>(<span class="params">predict_results, method=<span class="string">&quot;all&quot;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    准确性指标计算方法</span></span><br><span class="line"><span class="string">    :param predict_results: 预测结果，类型为容器，每个元素是一个包含uid,iid,real_rating,pred_rating的序列</span></span><br><span class="line"><span class="string">    :param method: 指标方法，类型为字符串，rmse或mae，否则返回两者rmse和mae</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> round(np.sqrt(_rmse_sum / length), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _mae_sum += abs(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> round(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse_mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse和mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse, mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">            _mae_sum += abs(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> round(np.sqrt(_rmse_sum / length), <span class="number">4</span>), round(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> method.lower() == <span class="string">&quot;rmse&quot;</span>:</span><br><span class="line">        rmse(predict_results)</span><br><span class="line">    <span class="keyword">elif</span> method.lower() == <span class="string">&quot;mae&quot;</span>:</span><br><span class="line">        mae(predict_results)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> rmse_mae(predict_results)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFBySGD</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, alpha, reg, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># 学习率</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="comment"># 正则参数</span></span><br><span class="line">        self.reg = reg</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([list])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([list])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = dict(zip(self.users_ratings.index, np.zeros(len(self.users_ratings))))</span><br><span class="line">        bi = dict(zip(self.items_ratings.index, np.zeros(len(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                error = real_rating - (self.global_mean + bu[uid] + bi[iid])</span><br><span class="line"></span><br><span class="line">                bu[uid] += self.alpha * (error - self.reg * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (error - self.reg * bi[iid])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;评分预测&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;无法预测用户&lt;&#123;uid&#125;&gt;对电影&lt;&#123;iid&#125;&gt;的评分，因为训练集中缺失&lt;&#123;iid&#125;&gt;的数据&quot;</span>.format(uid=uid, iid=iid))</span><br><span class="line"></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;预测测试集数据&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> testset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pred_rating = self.predict(uid, iid)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                print(e)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">yield</span> uid, iid, real_rating, pred_rating</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    trainset, testset = data_split(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, random=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFBySGD(<span class="number">20</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(trainset)</span><br><span class="line"></span><br><span class="line">    pred_results = bcf.test(testset)</span><br><span class="line"></span><br><span class="line">    rmse, mae = accuray(pred_results)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;rmse: &quot;</span>, rmse, <span class="string">&quot;mae: &quot;</span>, mae)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="方法二：交替最小二乘法优化"><a href="#方法二：交替最小二乘法优化" class="headerlink" title="方法二：交替最小二乘法优化"></a>方法二：交替最小二乘法优化</h4><p>使用交替最小二乘法优化算法预测Baseline偏置值</p><h6 id="step-1-交替最小二乘法推导"><a href="#step-1-交替最小二乘法推导" class="headerlink" title="step 1: 交替最小二乘法推导"></a>step 1: 交替最小二乘法推导</h6><p>最小二乘法和梯度下降法一样，可以用于求极值。</p><p><strong>最小二乘法思想：对损失函数求偏导，然后再使偏导为0</strong></p><p>同样，损失函数：<br>$$<br>J(\theta)=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)<br>$$<br>对损失函数求偏导：<br>$$<br>\cfrac{\partial}{\partial b_u} f(b_u, b_i) =-2 \sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + 2\lambda * b_u<br>$$<br>令偏导为0，则可得：<br>$$<br>\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) = \lambda* b_u<br>\\sum_{u,i\in R}(r_{ui}-\mu-b_i) = \sum_{u,i\in R} b_u+\lambda * b_u<br>$$<br>为了简化公式，这里令$\sum_{u,i\in R} b_u \approx |R(u)|*b_u$，即直接假设每一项的偏置都相等，可得：<br>$$<br>b_u := \cfrac {\sum_{u,i\in R}(r_{ui}-\mu-b_i)}{\lambda_1 + |R(u)|}<br>$$<br>其中$|R(u)|$表示用户$u​$的有过评分数量</p><p>同理可得：<br>$$<br>b_i := \cfrac {\sum_{u,i\in R}(r_{ui}-\mu-b_u)}{\lambda_2 + |R(i)|}<br>$$<br>其中$|R(i)|$表示物品$i​$收到的评分数量</p><p>$b_u$和$b_i​$分别属于用户和物品的偏置，因此他们的正则参数可以分别设置两个独立的参数</p><h6 id="step-2-交替最小二乘法应用"><a href="#step-2-交替最小二乘法应用" class="headerlink" title="step 2: 交替最小二乘法应用"></a>step 2: 交替最小二乘法应用</h6><p>通过最小二乘推导，我们最终分别得到了$b_u$和$b_i$的表达式，但他们的表达式中却又各自包含对方，因此这里我们将利用一种叫交替最小二乘的方法来计算他们的值：    </p><ul><li>计算其中一项，先固定其他未知参数，即看作其他未知参数为已知</li><li>如求$b_u$时，将$b_i$看作是已知；求$b_i$时，将$b_u$看作是已知；如此反复交替，不断更新二者的值，求得最终的结果。这就是<strong>交替最小二乘法（ALS）</strong></li></ul><h6 id="step-3-算法实现"><a href="#step-3-算法实现" class="headerlink" title="step 3: 算法实现"></a>step 3: 算法实现</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFByALS</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, reg_bu, reg_bi, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># bu的正则参数</span></span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        <span class="comment"># bi的正则参数</span></span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([list])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([list])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.als()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">als</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = dict(zip(self.users_ratings.index, np.zeros(len(self.users_ratings))))</span><br><span class="line">        bi = dict(zip(self.items_ratings.index, np.zeros(len(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> iid, uids, ratings <span class="keyword">in</span> self.items_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _sum = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> uid, rating <span class="keyword">in</span> zip(uids, ratings):</span><br><span class="line">                    _sum += rating - self.global_mean - bu[uid]</span><br><span class="line">                bi[iid] = _sum / (self.reg_bi + len(uids))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> uid, iids, ratings <span class="keyword">in</span> self.users_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _sum = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> iid, rating <span class="keyword">in</span> zip(iids, ratings):</span><br><span class="line">                    _sum += rating - self.global_mean - bi[iid]</span><br><span class="line">                bu[uid] = _sum / (self.reg_bu + len(iids))</span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=range(<span class="number">3</span>), dtype=dict(dtype))</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFByALS(<span class="number">20</span>, <span class="number">25</span>, <span class="number">15</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = int(input(<span class="string">&quot;uid: &quot;</span>))</span><br><span class="line">        iid = int(input(<span class="string">&quot;iid: &quot;</span>))</span><br><span class="line">        print(bcf.predict(uid, iid))</span><br></pre></td></tr></table></figure><h6 id="Step-4-准确性指标评估-1"><a href="#Step-4-准确性指标评估-1" class="headerlink" title="Step 4: 准确性指标评估"></a>Step 4: 准确性指标评估</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span>(<span class="params">data_path, x=<span class="number">0.8</span>, random=False</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    切分数据集， 这里为了保证用户数量保持不变，将每个用户的评分数据按比例进行拆分</span></span><br><span class="line"><span class="string">    :param data_path: 数据集路径</span></span><br><span class="line"><span class="string">    :param x: 训练集的比例，如x=0.8，则0.2是测试集</span></span><br><span class="line"><span class="string">    :param random: 是否随机切分，默认False</span></span><br><span class="line"><span class="string">    :return: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    print(<span class="string">&quot;开始切分数据集...&quot;</span>)</span><br><span class="line">    <span class="comment"># 设置要加载的数据字段的类型</span></span><br><span class="line">    dtype = &#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32, <span class="string">&quot;rating&quot;</span>: np.float32&#125;</span><br><span class="line">    <span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">    ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    testset_index = []</span><br><span class="line">    <span class="comment"># 为了保证每个用户在测试集和训练集都有数据，因此按userId聚合</span></span><br><span class="line">    <span class="keyword">for</span> uid <span class="keyword">in</span> ratings.groupby(<span class="string">&quot;userId&quot;</span>).any().index:</span><br><span class="line">        user_rating_data = ratings.where(ratings[<span class="string">&quot;userId&quot;</span>]==uid).dropna()</span><br><span class="line">        <span class="keyword">if</span> random:</span><br><span class="line">            <span class="comment"># 因为不可变类型不能被 shuffle方法作用，所以需要强行转换为列表</span></span><br><span class="line">            index = list(user_rating_data.index)</span><br><span class="line">            np.random.shuffle(index)    <span class="comment"># 打乱列表</span></span><br><span class="line">            _index = round(len(user_rating_data) * x)</span><br><span class="line">            testset_index += list(index[_index:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 将每个用户的x比例的数据作为训练集，剩余的作为测试集</span></span><br><span class="line">            index = round(len(user_rating_data) * x)</span><br><span class="line">            testset_index += list(user_rating_data.index.values[index:])</span><br><span class="line"></span><br><span class="line">    testset = ratings.loc[testset_index]</span><br><span class="line">    trainset = ratings.drop(testset_index)</span><br><span class="line">    print(<span class="string">&quot;完成数据集切分...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuray</span>(<span class="params">predict_results, method=<span class="string">&quot;all&quot;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    准确性指标计算方法</span></span><br><span class="line"><span class="string">    :param predict_results: 预测结果，类型为容器，每个元素是一个包含uid,iid,real_rating,pred_rating的序列</span></span><br><span class="line"><span class="string">    :param method: 指标方法，类型为字符串，rmse或mae，否则返回两者rmse和mae</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> round(np.sqrt(_rmse_sum / length), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _mae_sum += abs(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> round(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse_mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse和mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse, mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">            _mae_sum += abs(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> round(np.sqrt(_rmse_sum / length), <span class="number">4</span>), round(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> method.lower() == <span class="string">&quot;rmse&quot;</span>:</span><br><span class="line">        rmse(predict_results)</span><br><span class="line">    <span class="keyword">elif</span> method.lower() == <span class="string">&quot;mae&quot;</span>:</span><br><span class="line">        mae(predict_results)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> rmse_mae(predict_results)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFByALS</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, reg_bu, reg_bi, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># bu的正则参数</span></span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        <span class="comment"># bi的正则参数</span></span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([list])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([list])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.als()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">als</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = dict(zip(self.users_ratings.index, np.zeros(len(self.users_ratings))))</span><br><span class="line">        bi = dict(zip(self.items_ratings.index, np.zeros(len(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> iid, uids, ratings <span class="keyword">in</span> self.items_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _sum = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> uid, rating <span class="keyword">in</span> zip(uids, ratings):</span><br><span class="line">                    _sum += rating - self.global_mean - bu[uid]</span><br><span class="line">                bi[iid] = _sum / (self.reg_bi + len(uids))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> uid, iids, ratings <span class="keyword">in</span> self.users_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _sum = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> iid, rating <span class="keyword">in</span> zip(iids, ratings):</span><br><span class="line">                    _sum += rating - self.global_mean - bi[iid]</span><br><span class="line">                bu[uid] = _sum / (self.reg_bu + len(iids))</span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;评分预测&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;无法预测用户&lt;&#123;uid&#125;&gt;对电影&lt;&#123;iid&#125;&gt;的评分，因为训练集中缺失&lt;&#123;iid&#125;&gt;的数据&quot;</span>.format(uid=uid, iid=iid))</span><br><span class="line"></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;预测测试集数据&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> testset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pred_rating = self.predict(uid, iid)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                print(e)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">yield</span> uid, iid, real_rating, pred_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    trainset, testset = data_split(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, random=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFByALS(<span class="number">20</span>, <span class="number">25</span>, <span class="number">15</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(trainset)</span><br><span class="line"></span><br><span class="line">    pred_results = bcf.test(testset)</span><br><span class="line"></span><br><span class="line">    rmse, mae = accuray(pred_results)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;rmse: &quot;</span>, rmse, <span class="string">&quot;mae: &quot;</span>, mae)</span><br></pre></td></tr></table></figure><p>函数求导：</p><p><img src="/img/%E5%B8%B8%E8%A7%81%E5%87%BD%E6%95%B0%E6%B1%82%E5%AF%BC.png"></p><p><img src="/img/%E5%AF%BC%E6%95%B0%E7%9A%84%E5%9B%9B%E5%88%99%E8%BF%90%E7%AE%97.png"></p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 电影推荐系统算法综合实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(3)：消费者</title>
      <link href="2019/02/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(3)%EF%BC%9A%E6%B6%88%E8%B4%B9%E8%80%85/"/>
      <url>2019/02/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(3)%EF%BC%9A%E6%B6%88%E8%B4%B9%E8%80%85/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-消费者和消费者组"><a href="#1-消费者和消费者组" class="headerlink" title="1. 消费者和消费者组"></a>1. 消费者和消费者组</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1. 概述"></a>1.1. 概述</h2><p>Kafka 消费者从属于消费者组。一个消费者组里的消费者订阅的为同一主题。每个消费者接受主题一部分分区的消息。</p><p><strong>向消费者组里增加消费者是横向伸缩消费能力的主要方式</strong>。</p><blockquote><p>Kafka 消费者在做一些高延迟的操作，如向 HDFS 或数据库中写入数据，或者使用数据进行一些耗时的计算操作。在这些情况下，单个消费者无法跟上数据的生成速度，此时可以增加消费者，以分担负载，每个消费者只处理部分分区上的消息，这就是横向伸缩的主要手段,有必要为主题创建大量分区，负载增长时可以增加更多的消费者</p></blockquote><p><font color = 'red'><strong>注意：</strong> 一个主题的同一个分区同时只能供同一个消费者组里的一个消费者消费数据，因此不要让消费者的数量超过主题分区的数量，多于的消费者只会被闲置。</font></p><img src="/Users/joker/Desktop/截屏2021-03-08 下午8.04.20.png" alt="截屏2021-03-08 下午8.04.20" style="zoom:35%;" /><h2 id="1-2-消费方式"><a href="#1-2-消费方式" class="headerlink" title="1.2. 消费方式"></a>1.2. 消费方式</h2><p>由于 Push 模式 很难适应消费速率不同的消费者，因此消息发送速率是由 broker 决定的。它的目标是尽可能的以最快的速度传递消息， 但是这样容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。== 所以kafka采用 pull 模式，根据消费者的能力以适当的速率消费消息。</p><p><strong>Pull 模式的不足之处是如果 kafka 中没有数据，消费者可能会陷入循环中，一直返回空数据，针对这一点，Kafka 的消费者在消费数据时会传入一个时长参数 timeout，如果当前没有数据可供消费，consumer 会等待一段时间在返回，这段时长即为timeout。</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ConsumerRecords&lt;K, V&gt; <span class="title">poll</span><span class="params">(<span class="keyword">final</span> Duration timeout)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> poll(timeout.toMillis(), <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-3-特定偏移处消费数据"><a href="#1-3-特定偏移处消费数据" class="headerlink" title="1.3. 特定偏移处消费数据"></a>1.3. 特定偏移处消费数据</h2><p>使用 poll() 开始消费每个分区中最后一个已经发生的偏移量的消息，并继续按顺序处理所有消息。</p><h2 id="1-4-独立消费者"><a href="#1-4-独立消费者" class="headerlink" title="1.4. 独立消费者"></a>1.4. 独立消费者</h2><p>单一的消费者总是需要从主题中的所有分区读取数据，或者从一个主题特定分区读取数据。在这种情况下没有理由需要组或负载均衡，只是订阅特定的主题或分区，偶尔使用消息和提交偏移量。</p><h2 id="1-5-多线程消费者"><a href="#1-5-多线程消费者" class="headerlink" title="1.5. 多线程消费者"></a>1.5. 多线程消费者</h2><p>KafkaProducer 是线程安全的，而 KafkaConsumer 是非线程安全的，多线程需要处理好线程同步，多线程的实现方式有多种，这里介绍一种：<strong>每个线程各自实例化一个KakfaConsumer对象</strong>，这种方式的缺点是：当这些线程属于同一个消费组时，线程的数量受限于分区数，当消费者线程的数量大于分区数时，就有一部分消费线程一直处于空闲状态</p><h2 id="1-6-退出"><a href="#1-6-退出" class="headerlink" title="1.6. 退出"></a>1.6. 退出</h2><p>如果确定要退出循环，需要通过另一个线程调用 consumer.wakeup() 方法。</p><p>如果循环运行在主线程里，可以在 ShutdownHook 里调用该方法。consumer.wakeup() 是消费者唯一一个可以从其他线程里安全调用的方法。</p><p>ShutdownHook运行在单独的线程里，所以退出循环最安全的方式只能是调用 consumer.wakeup()</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread() &#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Starting exit...&quot;</span>);</span><br><span class="line">    consumer.wakeup();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      mainThread.join();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>调用 consumer.wakeup() 可以退出 poll() ，并抛出 WakeupException异常，或者如果调用consumer.wakeup() 时线程没有等待轮询，那么异常将在下一轮调用 poll() 时抛出。不需要处理WakeupException,因为它只是用于跳出循环的一种方式。不过，在退出线程之前调用 consumer.close()是很有必要的，它会提交任何还没有提交的东西，并向群组协调器发送消息，告知自己要离开群组，接下来就会触发再均衡，而不需要等待会话超时。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">    ConsumerRecords records = movingAvg.consumer.poll(<span class="number">1000</span>);</span><br><span class="line">    System.out.println(System.currentTimeMillis() + <span class="string">&quot; -- waiting for data...&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span>(ConsumerRecord record : records) &#123;</span><br><span class="line">      System.out.printf(<span class="string">&quot;offset = %d, key = %s, value = %s\n&quot;</span>,</span><br><span class="line">                        record.offset(), record.key(), record.value());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(TopicPartition tp: consumer.assignment())&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Committing offset at position:&quot;</span> + consumer.position(tp));</span><br><span class="line">    &#125;</span><br><span class="line">    movingAvg.consumer.commitSync();</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span>(WakeupException e) &#123;</span><br><span class="line">    <span class="comment">// ignore for shutdown</span></span><br><span class="line">&#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">  <span class="comment">//在退出之前，确保你已经完全关闭了消费者</span></span><br><span class="line">    consumer.close();</span><br><span class="line">    System.out.println(<span class="string">&quot;Closed consumer and we are done&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="2-分区分配"><a href="#2-分区分配" class="headerlink" title="2. 分区分配"></a>2. 分区分配</h1><p>群组里的消费者共同读取主题的分区，一个新的消费者加入群组时，它读取的是原本由其他消费者读取的消息。</p><p>当一个消费者被关闭或发生崩溃时，它就离开群组，原本由它读取的分区将由群组里的其他消费者来读取。在主题发生变化时，比如管理员添加了新的分区，会发生分区重分配。</p><h2 id="3-1-再均衡"><a href="#3-1-再均衡" class="headerlink" title="3.1. 再均衡"></a>3.1. 再均衡</h2><h3 id="3-1-1-概述"><a href="#3-1-1-概述" class="headerlink" title="3.1.1. 概述"></a>3.1.1. 概述</h3><p><font color = 'blue'><strong>分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡</strong></font></p><p>再均衡为消费者群组带来了<strong>高可用</strong>和<strong>伸缩性。</strong></p><p>再均衡期间，消费者无法读取消息，造成整个消费者组段时间内的不可用。此外，当分区被重新分配给另一个消费者时，消费者当前的读取状态会丢失，它还有可能还需要去刷新缓存，在它重新恢复状态之前会拖慢应用程序。<br>当消费者要加入群组时，会向群组协调器发送一个 JoinGroup 请求。第一个加入群组的消费者将成为群主。群主从协调器那里获取群组的成员列表，列表包含了最近发送过心跳的消费者，并负责给每一个消费者分配分区。<br>PartitionAssignor 接口的类决定哪些分区被分配给哪些消费者</p><h3 id="3-1-2-条件"><a href="#3-1-2-条件" class="headerlink" title="3.1.2. 条件"></a>3.1.2. 条件</h3><ol><li><p>消费者组中新<strong>添加消费者</strong>读取到原本是其他消费者读取的消息</p></li><li><p><strong>消费者关闭或崩溃</strong>之后离开群组，原本由它读取的  partition 将由群组里其他消费者读取</p></li><li><p>当向一个 Topic <strong>添加新的 partition</strong>，会发生 partition 在消费者中的重新分配</p></li></ol><h3 id="3-1-3-再均衡监听器"><a href="#3-1-3-再均衡监听器" class="headerlink" title="3.1.3.  再均衡监听器"></a>3.1.3.  再均衡监听器</h3><p>在为消费者分配新的partition或者移除旧的partition时，可以通过消费者API执行一些应用程序代码，在使用<strong>subscribe</strong>()方法时传入一个<strong>ConsumerRebalanceListener</strong>实例。</p><p><strong>ConsumerRebalanceListener</strong>需要实现的两个方法</p><ul><li><p><strong>public void onPartitionRevoked(Collection<TopicPartition> partitions)</strong></p><p>该方法会在<strong>再均衡开始之前</strong>和<strong>消费者停止读取消息之后</strong>被调用。如果在这里提交偏移量，下一个接管partition的消费者就知道该从哪里开始读取了。</p></li><li><p><strong>public void onPartitionAssigned(Collection<TopicPartition> partitions)</strong></p><p>该方法会在<strong>重新分配partition之后</strong>和<strong>消费者开始读取消息之前</strong>被调用。</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; currentOffsets = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">HandleRebalance</span> <span class="keyword">implements</span> <span class="title">ConsumerRebalanceListener</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class="line">       <span class="comment">//如果发生再均衡，要在即将失去partition所有权时提交偏移量。</span></span><br><span class="line">       <span class="comment">//调用commitSync方法，确保在再均衡发生之前提交偏移量</span></span><br><span class="line">        consumer.commitSync(currentOffsets);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">      consumer.subscribe(topics, <span class="keyword">new</span> HandleRebalance());</span><br><span class="line">      <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">          ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">          <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">              currentOffsets.put(<span class="keyword">new</span> TopicPartition(record.topic(), record.partition()), </span><br><span class="line">                                 <span class="keyword">new</span> OffsetAndMetadata(record.offset() + <span class="number">1</span>, “no matadata”));</span><br><span class="line">          &#125;</span><br><span class="line">          consumer.commitAsync(currentOffsets, <span class="keyword">null</span>);</span><br><span class="line">  &#125; <span class="keyword">catch</span>(WakeupException e) &#123;</span><br><span class="line">      <span class="comment">//忽略异常，正在关闭消费者</span></span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      log.error(<span class="string">&quot;unexpected error&quot;</span>, e);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">try</span>&#123;</span><br><span class="line">          consumer.commitSync(currentOffsets);</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          consumer.close();</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h2 id="3-2-分区分配"><a href="#3-2-分区分配" class="headerlink" title="3.2. 分区分配"></a>3.2. 分区分配</h2><p>在 Kafka 中，存在着三种分区分配策略。一种是 RangeAssignor 分配策略(范围分区)，另一种是 RoundRobinAssignor 分配策略(轮询分区)。默认采用 Range 范围分区。</p><p>Kafka 提供了消费者客户端参数 partition.assignment.strategy 用来设置消费者与订阅主题之间的分区分配策略。默认情况下，此参数的值为：org.apache.kafka.clients.consumer.RangeAssignor，即采用 RangeAssignor 分配策略。</p><p><img src="https://img-blog.csdnimg.cn/20200105211408449.png" alt="在这里插入图片描述"></p><h3 id="3-2-1-RangeAssignor"><a href="#3-2-1-RangeAssignor" class="headerlink" title="3.2.1. RangeAssignor"></a>3.2.1. RangeAssignor</h3><p><strong>RangeAssignor 策略的原理是按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。对于每一个topic，RangeAssignor 策略会将消费组内所有订阅这个 topic 的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区。</strong></p><ul><li>topic下的所有有效分区平铺</li><li>消费者按照字典排序</li><li>分区数除以消费者数，得到 n</li><li>分区数对消费者数取余，得到 m</li><li>消费者集合中，前 m 个消费者能够分配到 n+1 个分区，而剩余的消费者只能分配到 n 个分区</li></ul><p>按照 Kafka 默认的消费逻辑设定，一个分区只能被同一个消费组内的一个消费者消费。假设目前某消费组内只有一个消费者C0，订阅了一个topic，这个 topic 包含 5 个分区，也就是说这个消费者 C1 订阅了 5 个分区</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-10 下午5.16.09.png" alt="截屏2021-03-10 下午5.16.09" style="zoom:50%;" /><p>此时消费组内又加入了一个新的消费者C2，按照既定的逻辑需要将原来消费者 C1 的部分分区分配给消费者 C2 消费</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-10 下午5.17.08.png" alt="截屏2021-03-10 下午5.17.08" style="zoom:50%;" /><p>接着消费组内又加入了一个新的消费者C3，如此消费者 C1、C2 和 C3 各自负责消费所分配到的分区。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-10 下午5.18.00.png" alt="截屏2021-03-10 下午5.18.00" style="zoom:50%;" /><p>如果消费者过多，出现了消费者的数量大于分区的数量的情况，就会有消费者分配不到任何分区。参考下图，一共有 6 个消费者，5 个分区，那么最后的消费者 C6 由于分配不到任何分区进而就无法消费任何消息。 </p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-10 下午5.20.31.png" alt="截屏2021-03-10 下午5.20.31" style="zoom:50%;" /><h3 id="3-2-2-RoundRobinAssignor"><a href="#3-2-2-RoundRobinAssignor" class="headerlink" title="3.2.2. RoundRobinAssignor"></a>3.2.2. <strong>RoundRobinAssignor</strong></h3><p><strong>RoundRobin 轮询分区策略，是把所有的 partition 和所有的 consumer 都列出来，然后按照 hashcode 进行排序，最后通过轮询算法来分配 partition 给到各个消费者。</strong></p><ul><li>消费者按照字典排序，例如C0, C1, C2… …，并构造环形迭代器。</li><li>topic 名称按照字典排序，并得到每个 topic 的所有分区，从而得到所有分区集合。</li><li>遍历第2步所有分区集合，同时轮询消费者。</li><li>如果轮询到的消费者订阅的topic不包括当前遍历的分区所属topic，则跳过；否则分配给当前消费者，并继续第3步。</li></ul><h3 id="3-2-3-StickyAssignor"><a href="#3-2-3-StickyAssignor" class="headerlink" title="3.2.3. StickyAssignor"></a>3.2.3. <strong>StickyAssignor</strong></h3><p>Kafka 从 0.11.x 版本开始引入 StickyAssignor 分配策略，它主要有两个目的：分区的分配要尽可能的均匀和分区的分配尽可能的与上次分配的保持相同。当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个目标，StickyAssignor 策略的具体实现要比 RangeAssignor 和RoundRobinAssignor 这两种分配策略要复杂很多。</p><h2 id="4-提交和偏移量-Offset"><a href="#4-提交和偏移量-Offset" class="headerlink" title="4. 提交和偏移量 Offset"></a>4. 提交和偏移量 Offset</h2><p>调用 poll() 时，返回由生产者写入 Kafka 但还没有被消费者读取过的记录</p><h4 id="4-1-Offset-的维护"><a href="#4-1-Offset-的维护" class="headerlink" title="4.1. Offset 的维护"></a>4.1. Offset 的维护</h4><p>由于 consumer 在消费过程中可能会出现断电等故障，consumer恢复之后，需要从故障前的位置继续消费，所以 consumer 需要记录自己消费位置，以便故障恢复后继续消费。 </p><p>Kafka 0.9 版本之前， comsumer 默认将 offset 保存在 Zookeeper中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 3] ls /</span><br><span class="line">[cluster, controller, brokers, zookeeper, admin, isr_change_notification, dubbo, log_dir_event_notification, controller_epoch, kafka-manager, consumers, hive_zookeeper_namespace_hive, latest_producer_id_block, config, hbase]</span><br><span class="line"></span><br><span class="line">[zk: localhost:2181(CONNECTED) 16] ls /consumers/console-consumer-37662/offsets/test_kafka</span><br><span class="line">[44, 45, 46, 47, 48, 49, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]</span><br><span class="line"></span><br><span class="line">[zk: localhost:2181(CONNECTED) 19] ls /consumers/console-consumer-37662/offsets/test_kafka/0</span><br><span class="line">[]</span><br></pre></td></tr></table></figure><p>从0.9 版本开始， consumer 默认将 offset 保存在 kafka __consumer_offsets主题中。</p><img src="https://img-blog.csdnimg.cn/20200105165739847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_13,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" /><h4 id="2-2-自动提交偏移量"><a href="#2-2-自动提交偏移量" class="headerlink" title="2.2. 自动提交偏移量"></a>2.2. 自动提交偏移量</h4><p>将enable.auto.commit 设为true，则每过5秒，消费者会自动把从 poll() 方法接受到的最大偏移量提交上去。提交时间由auto.commit.interval.ms控制，默认值为5秒</p><ul><li><p>自动提交偏移量不足</p><p>假设我们使用默认的5秒提交时间间隔，在最近一次提交之后的3秒发生了再均衡，再均衡之后，消费者从最后一次提交的偏移量位置开始读取消息。这个时候偏移量已经落后了3秒，所以这3秒内到达的消息将会被重复处理。<br>**<font color='red'>注：可以通过修改提交时间间隔来频繁提交偏移量，减少可能出现重复消息的时间窗，不过这种情况无法完全避免。</font>**</p><h4 id="2-3-手动提交偏移量"><a href="#2-3-手动提交偏移量" class="headerlink" title="2.3. 手动提交偏移量"></a>2.3. 手动提交偏移量</h4><p>把 enable.auto.commit 设为 false，让应用程序决定何时提交偏移量。使用 commitSync() 提交偏移量最简单也最可靠。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(3)：消费者</title>
      <link href="2019/02/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(3)%EF%BC%9A%E6%B6%88%E8%B4%B9%E8%80%85_%E4%BD%8D%E7%A7%BB%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/"/>
      <url>2019/02/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(3)%EF%BC%9A%E6%B6%88%E8%B4%B9%E8%80%85_%E4%BD%8D%E7%A7%BB%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>GroupMetadata 管理消费者组的提交位移（Committed Offsets），主要包括添加和移除位移值</p><a id="more"></a><h1 id="1-offsets-字段"><a href="#1-offsets-字段" class="headerlink" title="1. offsets 字段"></a>1. offsets 字段</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> offsets = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">TopicPartition</span>, <span class="type">CommitRecordMetadataAndOffset</span>]</span><br></pre></td></tr></table></figure><p>offsets 是 HashMap 类型，Key 是 TopicPartition 类型，表示一个主题分区，而 Value 是 CommitRecordMetadataAndOffset 类型。该类封装了位移提交消息的位移值。</p><p>消费者组需要向 Coordinator 提交已消费消息的进度，在 Kafka 中叫作提交位移。Kafka 使用它来定位消费者组要消费的下一条消息。</p><h1 id="2-CommitRecordMetadataAndOffset"><a href="#2-CommitRecordMetadataAndOffset" class="headerlink" title="2. CommitRecordMetadataAndOffset"></a>2. CommitRecordMetadataAndOffset</h1><h2 id="1-1-transitionTo"><a href="#1-1-transitionTo" class="headerlink" title="1.1. transitionTo"></a>1.1. transitionTo</h2><p>transitionTo 方法的作用是将消费者组状态变更成给定状态。在变更前，代码需要确保这次变更必须是合法的状态转换。这是依靠每个 GroupState 实现类定义的 validPreviousStates 集合来完成的。只有在这个集合中的状态，才是合法的前置状态。简单来说，只有集合中的这些状态，才能转换到当前状态。同时，该方法还会更新状态变更的时间戳字段。Kafka 有个定时任务，会定期清除过期的消费者组位移数据，它就是依靠这个时间戳字段，来判断过期与否的。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// GroupMetadata.scala</span></span><br><span class="line"><span class="comment">// 设置/更新状态</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transitionTo</span></span>(groupState: <span class="type">GroupState</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  assertValidTransition(groupState) <span class="comment">// 确保是合法的状态转换</span></span><br><span class="line">  state = groupState  <span class="comment">// 设置状态到给定状态</span></span><br><span class="line">  currentStateTimestamp = <span class="type">Some</span>(time.milliseconds() <span class="comment">// 更新状态变更时间戳</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-2-canRebalance"><a href="#1-2-canRebalance" class="headerlink" title="1.2. canRebalance"></a>1.2. canRebalance</h2><p>用于判断消费者组是否能够开启 Rebalance 操作。判断依据是，当前状态是否是 PreparingRebalance 状态的合法前置状态。只有 Stable、CompletingRebalance 和 Empty 这 3 类状态的消费者组，才有资格开启 Rebalance。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 消费者组能否 Rebalance 的条件是当前状态是PreparingRebalance状态的合法前置状态</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">canRebalance</span> </span>= <span class="type">PreparingRebalance</span>.validPreviousStates.contains(state)</span><br></pre></td></tr></table></figure><h2 id="1-3-is-和-not"><a href="#1-3-is-和-not" class="headerlink" title="1.3. is 和 not"></a>1.3. is 和 not</h2><p>至于 is 和 not 方法，它们分别判断消费者组的状态与给定状态吻合还是不吻合，主要被用于执行状态校验。特别是 is 方法，被大量用于上层调用代码中，执行各类消费者组管理任务的前置状态校验工作。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//判断消费者组状态是指定状态</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is</span></span>(groupState: <span class="type">GroupState</span>) = state == groupState</span><br><span class="line"><span class="comment">// 判断消费者组状态不是指定状态</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">not</span></span>(groupState: <span class="type">GroupState</span>) = state != groupState</span><br></pre></td></tr></table></figure><h1 id="2-成员管理方法"><a href="#2-成员管理方法" class="headerlink" title="2. 成员管理方法"></a>2. 成员管理方法</h1><p>GroupMetadata 中使用 members 字段保存所有的成员信息。该字段是一个 HashMap，Key 是成员的 member ID 字段，Value 是 MemberMetadata 类型，该类型保存了成员的元数据信息。所谓的管理成员，也就是添加成员(add 方法)、移除成员(remove 方法)和查询成员(has、get、size 方法等)</p><h2 id="2-1-添加成员"><a href="#2-1-添加成员" class="headerlink" title="2.1. 添加成员"></a>2.1. 添加成员</h2><p>add 方法的主要逻辑，是将成员对象添加到 members 字段，同时更新其他一些必要的元数据，比如 Leader 成员字段、分区分配策略支持票数等</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(member: <span class="type">MemberMetadata</span>, callback: <span class="type">JoinCallback</span> = <span class="literal">null</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 如果是要添加的第一个消费者组成员</span></span><br><span class="line">  <span class="keyword">if</span> (members.isEmpty)</span><br><span class="line">    <span class="comment">// 就把该成员的procotolType设置为消费者组的protocolType</span></span><br><span class="line">    <span class="keyword">this</span>.protocolType = <span class="type">Some</span>(member.protocolType)</span><br><span class="line">  <span class="comment">// 确保成员元数据中的groupId和组Id相同</span></span><br><span class="line">  assert(groupId == member.groupId)</span><br><span class="line">  <span class="comment">// 确保成员元数据中的protoclType和组protocolType相同</span></span><br><span class="line">  assert(<span class="keyword">this</span>.protocolType.orNull == member.protocolType)</span><br><span class="line">  <span class="comment">// 确保该成员选定的分区分配策略与组选定的分区分配策略相匹配</span></span><br><span class="line">  assert(supportsProtocols(member.protocolType, <span class="type">MemberMetadata</span>.plainProtocolSet(member.supportedProtocols)))</span><br><span class="line">  <span class="comment">// 如果尚未选出Leader成员</span></span><br><span class="line">  <span class="keyword">if</span> (leaderId.isEmpty)</span><br><span class="line">    <span class="comment">// 把该成员设定为Leader成员</span></span><br><span class="line">    leaderId = <span class="type">Some</span>(member.memberId)</span><br><span class="line">  <span class="comment">// 将该成员添加进members</span></span><br><span class="line">  members.put(member.memberId, member)</span><br><span class="line">  <span class="comment">// 更新分区分配策略支持票数</span></span><br><span class="line">  member.supportedProtocols.foreach&#123; <span class="keyword">case</span> (protocol, _) =&gt; supportedProtocols(protocol) += <span class="number">1</span> &#125;</span><br><span class="line">  <span class="comment">// 设置成员加入组后的回调逻辑</span></span><br><span class="line">  member.awaitingJoinCallback = callback</span><br><span class="line">  <span class="comment">// 更新已加入组的成员数</span></span><br><span class="line">  <span class="keyword">if</span> (member.isAwaitingJoin)</span><br><span class="line">    numMembersAwaitingJoin += <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>add 方法要判断 members 字段是否包含已有成员。如果没有，就说明要添加的成员是该消费者组的第一个成员，那么，就令该成员协议类型(protocolType)成为组的 protocolType。对于普通的消费者而言，protocolType 就是字符串”consumer”。如果不是首个成员，就进入到下一步。</li><li>add 方法会连续进行三次校验，分别确保待添加成员的组 ID、protocolType 和组配置一致，以及该成员选定的分区分配策略与组选定的分区分配策略相匹配。如果这些校验有任何一个未通过，就会立即抛出异常。</li><li>判断消费者组的 Leader 成员是否已经选出了。如果还没有选出，就将该成员设置成 Leader 成员</li><li>更新消费者组分区分配策略支持票数。关于 supportedProtocols 字段的含义</li><li>设置成员加入组后的回调逻辑，同时更新已加入组的成员数</li></ol><h3 id="2-2-移除成员"><a href="#2-2-移除成员" class="headerlink" title="2.2. 移除成员"></a>2.2. 移除成员</h3><p>有 add 方法，自然也就有 remove 方法</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove</span></span>(memberId: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 从members中移除给定成员</span></span><br><span class="line">  members.remove(memberId).foreach &#123; member =&gt;</span><br><span class="line">    <span class="comment">// 更新分区分配策略支持票数</span></span><br><span class="line">    member.supportedProtocols.foreach&#123; <span class="keyword">case</span> (protocol, _) =&gt; supportedProtocols(protocol) -= <span class="number">1</span> &#125;</span><br><span class="line">    <span class="comment">// 更新已加入组的成员数</span></span><br><span class="line">    <span class="keyword">if</span> (member.isAwaitingJoin)</span><br><span class="line">      numMembersAwaitingJoin -= <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 如果该成员是Leader，选择剩下成员列表中的第一个作为新的Leader成员</span></span><br><span class="line">  <span class="keyword">if</span> (isLeader(memberId))</span><br><span class="line">    leaderId = members.keys.headOption</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-查询成员"><a href="#2-3-查询成员" class="headerlink" title="2.3. 查询成员"></a>2.3. 查询成员</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">has</span></span>(memberId: <span class="type">String</span>) = members.contains(memberId)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get</span></span>(memberId: <span class="type">String</span>) = members(memberId)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">size</span> </span>= members.size</span><br></pre></td></tr></table></figure><ol><li>has 方法，判断消费者组是否包含指定成员</li><li>get 方法，获取指定成员对象</li><li>size 方法，统计总成员数。</li></ol><img src="/Users/joker/Documents/Kafka/消费者元数据.png" alt="消费者元数据" style="zoom:200%;" />]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(3)：消费者</title>
      <link href="2019/02/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(3)%EF%BC%9A%E6%B6%88%E8%B4%B9%E8%80%85_%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%85%83%E6%95%B0%E6%8D%AE/"/>
      <url>2019/02/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(3)%EF%BC%9A%E6%B6%88%E8%B4%B9%E8%80%85_%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%85%83%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="1-消费者和消费者组"><a href="#1-消费者和消费者组" class="headerlink" title="1. 消费者和消费者组"></a>1. 消费者和消费者组</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1. 概述"></a>1.1. 概述</h2><p>Kafka 消费者从属于消费者组。一个消费者组里的消费者订阅的为同一主题。每个消费者接受主题一部分分区的消息。</p><p><strong>向消费者组里增加消费者是横向伸缩消费能力的主要方式</strong>。</p><blockquote><p>Kafka 消费者在做一些高延迟的操作，如向 HDFS 或数据库中写入数据，或者使用数据进行一些耗时的计算操作。在这些情况下，单个消费者无法跟上数据的生成速度，此时可以增加消费者，以分担负载，每个消费者只处理部分分区上的消息，这就是横向伸缩的主要手段,有必要为主题创建大量分区，负载增长时可以增加更多的消费者</p></blockquote><p><font color = 'red'><strong>注意：</strong> 一个主题的同一个分区同时只能供同一个消费者组里的一个消费者消费数据，因此不要让消费者的数量超过主题分区的数量，多于的消费者只会被闲置。</font></p><p><img src="/Users/joker/Desktop/截屏2021-03-08 下午8.04.20.png" alt="截屏2021-03-08 下午8.04.20" style="zoom:35%;" /><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-12 下午7.41.39.png" alt="截屏2021-03-12 下午7.41.39" style="zoom:50%;" /></p><h2 id="1-2-消费方式"><a href="#1-2-消费方式" class="headerlink" title="1.2. 消费方式"></a>1.2. 消费方式</h2><p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-12 下午7.27.33.png" alt="截屏2021-03-12 下午7.27.33" style="zoom:50%;" />由于 Push 模式 很难适应消费速率不同的消费者，因此消息发送速率是由 broker 决定的。它的目标是尽可能的以最快的速度传递消息， 但是这样容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。== 所以kafka采用 pull 模式，根据消费者的能力以适当的速率消费消息。</p><p><strong>Pull 模式的不足之处是如果 kafka 中没有数据，消费者可能会陷入循环中，一直返回空数据，针对这一点，Kafka 的消费者在消费数据时会传入一个时长参数 timeout，如果当前没有数据可供消费，consumer 会等待一段时间在返回，这段时长即为timeout。</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ConsumerRecords&lt;K, V&gt; <span class="title">poll</span><span class="params">(<span class="keyword">final</span> Duration timeout)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> poll(timeout.toMillis(), <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-3-特定偏移处消费数据"><a href="#1-3-特定偏移处消费数据" class="headerlink" title="1.3. 特定偏移处消费数据"></a>1.3. 特定偏移处消费数据</h2><p>使用 poll() 开始消费每个分区中最后一个已经发生的偏移量的消息，并继续按顺序处理所有消息。</p><h2 id="1-4-独立消费者"><a href="#1-4-独立消费者" class="headerlink" title="1.4. 独立消费者"></a>1.4. 独立消费者</h2><p>单一的消费者总是需要从主题中的所有分区读取数据，或者从一个主题特定分区读取数据。在这种情况下没有理由需要组或负载均衡，只是订阅特定的主题或分区，偶尔使用消息和提交偏移量。</p><h2 id="1-5-多线程消费者"><a href="#1-5-多线程消费者" class="headerlink" title="1.5. 多线程消费者"></a>1.5. 多线程消费者</h2><p>KafkaProducer 是线程安全的，而 KafkaConsumer 是非线程安全的，多线程需要处理好线程同步，多线程的实现方式有多种，这里介绍一种：<strong>每个线程各自实例化一个KakfaConsumer对象</strong>，这种方式的缺点是：当这些线程属于同一个消费组时，线程的数量受限于分区数，当消费者线程的数量大于分区数时，就有一部分消费线程一直处于空闲状态</p><h2 id="1-6-退出"><a href="#1-6-退出" class="headerlink" title="1.6. 退出"></a>1.6. 退出</h2><p>如果确定要退出循环，需要通过另一个线程调用 consumer.wakeup() 方法。</p><p>如果循环运行在主线程里，可以在 ShutdownHook 里调用该方法。consumer.wakeup() 是消费者唯一一个可以从其他线程里安全调用的方法。</p><p>ShutdownHook运行在单独的线程里，所以退出循环最安全的方式只能是调用 consumer.wakeup()</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread() &#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Starting exit...&quot;</span>);</span><br><span class="line">    consumer.wakeup();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      mainThread.join();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>调用 consumer.wakeup() 可以退出 poll() ，并抛出 WakeupException异常，或者如果调用consumer.wakeup() 时线程没有等待轮询，那么异常将在下一轮调用 poll() 时抛出。不需要处理WakeupException,因为它只是用于跳出循环的一种方式。不过，在退出线程之前调用 consumer.close()是很有必要的，它会提交任何还没有提交的东西，并向群组协调器发送消息，告知自己要离开群组，接下来就会触发再均衡，而不需要等待会话超时。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">    ConsumerRecords records = movingAvg.consumer.poll(<span class="number">1000</span>);</span><br><span class="line">    System.out.println(System.currentTimeMillis() + <span class="string">&quot; -- waiting for data...&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span>(ConsumerRecord record : records) &#123;</span><br><span class="line">      System.out.printf(<span class="string">&quot;offset = %d, key = %s, value = %s\n&quot;</span>,</span><br><span class="line">                        record.offset(), record.key(), record.value());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(TopicPartition tp: consumer.assignment())&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Committing offset at position:&quot;</span> + consumer.position(tp));</span><br><span class="line">    &#125;</span><br><span class="line">    movingAvg.consumer.commitSync();</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span>(WakeupException e) &#123;</span><br><span class="line">    <span class="comment">// ignore for shutdown</span></span><br><span class="line">&#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">  <span class="comment">//在退出之前，确保你已经完全关闭了消费者</span></span><br><span class="line">    consumer.close();</span><br><span class="line">    System.out.println(<span class="string">&quot;Closed consumer and we are done&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="2-分区分配"><a href="#2-分区分配" class="headerlink" title="2. 分区分配"></a>2. 分区分配</h1><p>群组里的消费者共同读取主题的分区，一个新的消费者加入群组时，它读取的是原本由其他消费者读取的消息。</p><p>当一个消费者被关闭或发生崩溃时，它就离开群组，原本由它读取的分区将由群组里的其他消费者来读取。在主题发生变化时，比如管理员添加了新的分区，会发生分区重分配。</p><h2 id="3-1-再均衡"><a href="#3-1-再均衡" class="headerlink" title="3.1. 再均衡"></a>3.1. 再均衡</h2><h3 id="3-1-1-概述"><a href="#3-1-1-概述" class="headerlink" title="3.1.1. 概述"></a>3.1.1. 概述</h3><p><font color = 'blue'><strong>分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡</strong></font></p><p>再均衡为消费者群组带来了<strong>高可用</strong>和<strong>伸缩性。</strong></p><p>再均衡期间，消费者无法读取消息，造成整个消费者组段时间内的不可用。此外，当分区被重新分配给另一个消费者时，消费者当前的读取状态会丢失，它还有可能还需要去刷新缓存，在它重新恢复状态之前会拖慢应用程序。<br>当消费者要加入群组时，会向群组协调器发送一个 JoinGroup 请求。第一个加入群组的消费者将成为群主。群主从协调器那里获取群组的成员列表，列表包含了最近发送过心跳的消费者，并负责给每一个消费者分配分区。<br>PartitionAssignor 接口的类决定哪些分区被分配给哪些消费者</p><h3 id="3-1-2-条件"><a href="#3-1-2-条件" class="headerlink" title="3.1.2. 条件"></a>3.1.2. 条件</h3><ol><li><p>消费者组中新<strong>添加消费者</strong>读取到原本是其他消费者读取的消息</p></li><li><p><strong>消费者关闭或崩溃</strong>之后离开群组，原本由它读取的  partition 将由群组里其他消费者读取</p></li><li><p>当向一个 Topic <strong>添加新的 partition</strong>，会发生 partition 在消费者中的重新分配</p></li></ol><h3 id="3-1-3-再均衡监听器"><a href="#3-1-3-再均衡监听器" class="headerlink" title="3.1.3.  再均衡监听器"></a>3.1.3.  再均衡监听器</h3><p>在为消费者分配新的partition或者移除旧的partition时，可以通过消费者API执行一些应用程序代码，在使用<strong>subscribe</strong>()方法时传入一个<strong>ConsumerRebalanceListener</strong>实例。</p><p><strong>ConsumerRebalanceListener</strong>需要实现的两个方法</p><ul><li><p><strong>public void onPartitionRevoked(Collection<TopicPartition> partitions)</strong></p><p>该方法会在<strong>再均衡开始之前</strong>和<strong>消费者停止读取消息之后</strong>被调用。如果在这里提交偏移量，下一个接管partition的消费者就知道该从哪里开始读取了。</p></li><li><p><strong>public void onPartitionAssigned(Collection<TopicPartition> partitions)</strong></p><p>该方法会在<strong>重新分配partition之后</strong>和<strong>消费者开始读取消息之前</strong>被调用。</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; currentOffsets = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">HandleRebalance</span> <span class="keyword">implements</span> <span class="title">ConsumerRebalanceListener</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsAssigned</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onPartitionsRevoked</span><span class="params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>&#123;</span><br><span class="line">       <span class="comment">//如果发生再均衡，要在即将失去partition所有权时提交偏移量。</span></span><br><span class="line">       <span class="comment">//调用commitSync方法，确保在再均衡发生之前提交偏移量</span></span><br><span class="line">        consumer.commitSync(currentOffsets);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">      consumer.subscribe(topics, <span class="keyword">new</span> HandleRebalance());</span><br><span class="line">      <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">          ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">          <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">              currentOffsets.put(<span class="keyword">new</span> TopicPartition(record.topic(), record.partition()), </span><br><span class="line">                                 <span class="keyword">new</span> OffsetAndMetadata(record.offset() + <span class="number">1</span>, “no matadata”));</span><br><span class="line">          &#125;</span><br><span class="line">          consumer.commitAsync(currentOffsets, <span class="keyword">null</span>);</span><br><span class="line">  &#125; <span class="keyword">catch</span>(WakeupException e) &#123;</span><br><span class="line">      <span class="comment">//忽略异常，正在关闭消费者</span></span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      log.error(<span class="string">&quot;unexpected error&quot;</span>, e);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">try</span>&#123;</span><br><span class="line">          consumer.commitSync(currentOffsets);</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          consumer.close();</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h2 id="3-2-分区分配"><a href="#3-2-分区分配" class="headerlink" title="3.2. 分区分配"></a>3.2. 分区分配</h2><p>在 Kafka 中，存在着三种分区分配策略。一种是 RangeAssignor 分配策略(范围分区)，另一种是 RoundRobinAssignor 分配策略(轮询分区)。默认采用 Range 范围分区。</p><p>Kafka 提供了消费者客户端参数 partition.assignment.strategy 用来设置消费者与订阅主题之间的分区分配策略。默认情况下，此参数的值为：org.apache.kafka.clients.consumer.RangeAssignor，即采用 RangeAssignor 分配策略。</p><p><img src="https://img-blog.csdnimg.cn/20200105211408449.png" alt="在这里插入图片描述"></p><h3 id="3-2-1-RangeAssignor"><a href="#3-2-1-RangeAssignor" class="headerlink" title="3.2.1. RangeAssignor"></a>3.2.1. RangeAssignor</h3><p><strong>RangeAssignor 策略的原理是按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。对于每一个topic，RangeAssignor 策略会将消费组内所有订阅这个 topic 的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区。</strong></p><ul><li>topic下的所有有效分区平铺</li><li>消费者按照字典排序</li><li>分区数除以消费者数，得到 n</li><li>分区数对消费者数取余，得到 m</li><li>消费者集合中，前 m 个消费者能够分配到 n+1 个分区，而剩余的消费者只能分配到 n 个分区</li></ul><p>按照 Kafka 默认的消费逻辑设定，一个分区只能被同一个消费组内的一个消费者消费。假设目前某消费组内只有一个消费者C0，订阅了一个topic，这个 topic 包含 5 个分区，也就是说这个消费者 C1 订阅了 5 个分区</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-10 下午5.16.09.png" alt="截屏2021-03-10 下午5.16.09" style="zoom:50%;" /><p>此时消费组内又加入了一个新的消费者C2，按照既定的逻辑需要将原来消费者 C1 的部分分区分配给消费者 C2 消费</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-10 下午5.17.08.png" alt="截屏2021-03-10 下午5.17.08" style="zoom:50%;" /><p>接着消费组内又加入了一个新的消费者C3，如此消费者 C1、C2 和 C3 各自负责消费所分配到的分区。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-10 下午5.18.00.png" alt="截屏2021-03-10 下午5.18.00" style="zoom:50%;" /><p>如果消费者过多，出现了消费者的数量大于分区的数量的情况，就会有消费者分配不到任何分区。参考下图，一共有 6 个消费者，5 个分区，那么最后的消费者 C6 由于分配不到任何分区进而就无法消费任何消息。 </p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-10 下午5.20.31.png" alt="截屏2021-03-10 下午5.20.31" style="zoom:50%;" /><h3 id="3-2-2-RoundRobinAssignor"><a href="#3-2-2-RoundRobinAssignor" class="headerlink" title="3.2.2. RoundRobinAssignor"></a>3.2.2. <strong>RoundRobinAssignor</strong></h3><p><strong>RoundRobin 轮询分区策略，是把所有的 partition 和所有的 consumer 都列出来，然后按照 hashcode 进行排序，最后通过轮询算法来分配 partition 给到各个消费者。</strong></p><ul><li>消费者按照字典排序，例如C0, C1, C2… …，并构造环形迭代器。</li><li>topic 名称按照字典排序，并得到每个 topic 的所有分区，从而得到所有分区集合。</li><li>遍历第2步所有分区集合，同时轮询消费者。</li><li>如果轮询到的消费者订阅的topic不包括当前遍历的分区所属topic，则跳过；否则分配给当前消费者，并继续第3步。</li></ul><h3 id="3-2-3-StickyAssignor"><a href="#3-2-3-StickyAssignor" class="headerlink" title="3.2.3. StickyAssignor"></a>3.2.3. <strong>StickyAssignor</strong></h3><p>Kafka 从 0.11.x 版本开始引入 StickyAssignor 分配策略，它主要有两个目的：分区的分配要尽可能的均匀和分区的分配尽可能的与上次分配的保持相同。当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个目标，StickyAssignor 策略的具体实现要比 RangeAssignor 和RoundRobinAssignor 这两种分配策略要复杂很多。</p><h2 id="4-提交和偏移量-Offset"><a href="#4-提交和偏移量-Offset" class="headerlink" title="4. 提交和偏移量 Offset"></a>4. 提交和偏移量 Offset</h2><p>调用 poll() 时，返回由生产者写入 Kafka 但还没有被消费者读取过的记录</p><h4 id="4-1-Offset-的维护"><a href="#4-1-Offset-的维护" class="headerlink" title="4.1. Offset 的维护"></a>4.1. Offset 的维护</h4><p>由于 consumer 在消费过程中可能会出现断电等故障，consumer恢复之后，需要从故障前的位置继续消费，所以 consumer 需要记录自己消费位置，以便故障恢复后继续消费。 </p><p>Kafka 0.9 版本之前， comsumer 默认将 offset 保存在 Zookeeper中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 3] ls /</span><br><span class="line">[cluster, controller, brokers, zookeeper, admin, isr_change_notification, dubbo, log_dir_event_notification, controller_epoch, kafka-manager, consumers, hive_zookeeper_namespace_hive, latest_producer_id_block, config, hbase]</span><br><span class="line"></span><br><span class="line">[zk: localhost:2181(CONNECTED) 16] ls /consumers/console-consumer-37662/offsets/test_kafka</span><br><span class="line">[44, 45, 46, 47, 48, 49, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]</span><br><span class="line"></span><br><span class="line">[zk: localhost:2181(CONNECTED) 19] ls /consumers/console-consumer-37662/offsets/test_kafka/0</span><br><span class="line">[]</span><br></pre></td></tr></table></figure><p>从0.9 版本开始， consumer 默认将 offset 保存在 kafka __consumer_offsets主题中。</p><img src="https://img-blog.csdnimg.cn/20200105165739847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA4MDk4NA==,size_13,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" /><h4 id="2-2-自动提交偏移量"><a href="#2-2-自动提交偏移量" class="headerlink" title="2.2. 自动提交偏移量"></a>2.2. 自动提交偏移量</h4><p>将enable.auto.commit 设为true，则每过5秒，消费者会自动把从 poll() 方法接受到的最大偏移量提交上去。提交时间由auto.commit.interval.ms控制，默认值为5秒</p><ul><li><p>自动提交偏移量不足</p><p>假设我们使用默认的5秒提交时间间隔，在最近一次提交之后的3秒发生了再均衡，再均衡之后，消费者从最后一次提交的偏移量位置开始读取消息。这个时候偏移量已经落后了3秒，所以这3秒内到达的消息将会被重复处理。<br>**<font color='red'>注：可以通过修改提交时间间隔来频繁提交偏移量，减少可能出现重复消息的时间窗，不过这种情况无法完全避免。</font>**</p><h4 id="2-3-手动提交偏移量"><a href="#2-3-手动提交偏移量" class="headerlink" title="2.3. 手动提交偏移量"></a>2.3. 手动提交偏移量</h4><p>把 enable.auto.commit 设为 false，让应用程序决定何时提交偏移量。使用 commitSync() 提交偏移量最简单也最可靠。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(3)：消费者</title>
      <link href="2019/02/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(3)%EF%BC%9A%E6%B6%88%E8%B4%B9%E8%80%85_%E7%AE%A1%E7%90%86%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%85%83%E6%95%B0%E6%8D%AE/"/>
      <url>2019/02/13/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(3)%EF%BC%9A%E6%B6%88%E8%B4%B9%E8%80%85_%E7%AE%A1%E7%90%86%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%85%83%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Kafka 元数据的类型不同，管理策略也就不一样。从消费者组状态、成员、位移和分区分配策略四个维度了解下 Kafka 管理元数据。</p><a id="more"></a><h1 id="1-消费者组状态管理"><a href="#1-消费者组状态管理" class="headerlink" title="1. 消费者组状态管理"></a>1. 消费者组状态管理</h1><p>Kafka 管理消费者组元数据的方法定义在 MemberMetadata 和 GroupMetadata 这两个类中。</p><h2 id="1-1-transitionTo"><a href="#1-1-transitionTo" class="headerlink" title="1.1. transitionTo"></a>1.1. transitionTo</h2><p>transitionTo 方法的作用是将消费者组状态变更成给定状态。在变更前，代码需要确保这次变更必须是合法的状态转换。这是依靠每个 GroupState 实现类定义的 validPreviousStates 集合来完成的。只有在这个集合中的状态，才是合法的前置状态。简单来说，只有集合中的这些状态，才能转换到当前状态。同时，该方法还会更新状态变更的时间戳字段。Kafka 有个定时任务，会定期清除过期的消费者组位移数据，它就是依靠这个时间戳字段，来判断过期与否的。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// GroupMetadata.scala</span></span><br><span class="line"><span class="comment">// 设置/更新状态</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transitionTo</span></span>(groupState: <span class="type">GroupState</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  assertValidTransition(groupState) <span class="comment">// 确保是合法的状态转换</span></span><br><span class="line">  state = groupState  <span class="comment">// 设置状态到给定状态</span></span><br><span class="line">  currentStateTimestamp = <span class="type">Some</span>(time.milliseconds() <span class="comment">// 更新状态变更时间戳</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-2-canRebalance"><a href="#1-2-canRebalance" class="headerlink" title="1.2. canRebalance"></a>1.2. canRebalance</h2><p>用于判断消费者组是否能够开启 Rebalance 操作。判断依据是，当前状态是否是 PreparingRebalance 状态的合法前置状态。只有 Stable、CompletingRebalance 和 Empty 这 3 类状态的消费者组，才有资格开启 Rebalance。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 消费者组能否 Rebalance 的条件是当前状态是PreparingRebalance状态的合法前置状态</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">canRebalance</span> </span>= <span class="type">PreparingRebalance</span>.validPreviousStates.contains(state)</span><br></pre></td></tr></table></figure><h2 id="1-3-is-和-not"><a href="#1-3-is-和-not" class="headerlink" title="1.3. is 和 not"></a>1.3. is 和 not</h2><p>至于 is 和 not 方法，它们分别判断消费者组的状态与给定状态吻合还是不吻合，主要被用于执行状态校验。特别是 is 方法，被大量用于上层调用代码中，执行各类消费者组管理任务的前置状态校验工作。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//判断消费者组状态是指定状态</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is</span></span>(groupState: <span class="type">GroupState</span>) = state == groupState</span><br><span class="line"><span class="comment">// 判断消费者组状态不是指定状态</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">not</span></span>(groupState: <span class="type">GroupState</span>) = state != groupState</span><br></pre></td></tr></table></figure><h1 id="2-成员管理方法"><a href="#2-成员管理方法" class="headerlink" title="2. 成员管理方法"></a>2. 成员管理方法</h1><p>GroupMetadata 中使用 members 字段保存所有的成员信息。该字段是一个 HashMap，Key 是成员的 member ID 字段，Value 是 MemberMetadata 类型，该类型保存了成员的元数据信息。所谓的管理成员，也就是添加成员(add 方法)、移除成员(remove 方法)和查询成员(has、get、size 方法等)</p><h2 id="2-1-添加成员"><a href="#2-1-添加成员" class="headerlink" title="2.1. 添加成员"></a>2.1. 添加成员</h2><p>add 方法的主要逻辑，是将成员对象添加到 members 字段，同时更新其他一些必要的元数据，比如 Leader 成员字段、分区分配策略支持票数等</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(member: <span class="type">MemberMetadata</span>, callback: <span class="type">JoinCallback</span> = <span class="literal">null</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 如果是要添加的第一个消费者组成员</span></span><br><span class="line">  <span class="keyword">if</span> (members.isEmpty)</span><br><span class="line">    <span class="comment">// 就把该成员的procotolType设置为消费者组的protocolType</span></span><br><span class="line">    <span class="keyword">this</span>.protocolType = <span class="type">Some</span>(member.protocolType)</span><br><span class="line">  <span class="comment">// 确保成员元数据中的groupId和组Id相同</span></span><br><span class="line">  assert(groupId == member.groupId)</span><br><span class="line">  <span class="comment">// 确保成员元数据中的protoclType和组protocolType相同</span></span><br><span class="line">  assert(<span class="keyword">this</span>.protocolType.orNull == member.protocolType)</span><br><span class="line">  <span class="comment">// 确保该成员选定的分区分配策略与组选定的分区分配策略相匹配</span></span><br><span class="line">  assert(supportsProtocols(member.protocolType, <span class="type">MemberMetadata</span>.plainProtocolSet(member.supportedProtocols)))</span><br><span class="line">  <span class="comment">// 如果尚未选出Leader成员</span></span><br><span class="line">  <span class="keyword">if</span> (leaderId.isEmpty)</span><br><span class="line">    <span class="comment">// 把该成员设定为Leader成员</span></span><br><span class="line">    leaderId = <span class="type">Some</span>(member.memberId)</span><br><span class="line">  <span class="comment">// 将该成员添加进members</span></span><br><span class="line">  members.put(member.memberId, member)</span><br><span class="line">  <span class="comment">// 更新分区分配策略支持票数</span></span><br><span class="line">  member.supportedProtocols.foreach&#123; <span class="keyword">case</span> (protocol, _) =&gt; supportedProtocols(protocol) += <span class="number">1</span> &#125;</span><br><span class="line">  <span class="comment">// 设置成员加入组后的回调逻辑</span></span><br><span class="line">  member.awaitingJoinCallback = callback</span><br><span class="line">  <span class="comment">// 更新已加入组的成员数</span></span><br><span class="line">  <span class="keyword">if</span> (member.isAwaitingJoin)</span><br><span class="line">    numMembersAwaitingJoin += <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>add 方法要判断 members 字段是否包含已有成员。如果没有，就说明要添加的成员是该消费者组的第一个成员，那么，就令该成员协议类型(protocolType)成为组的 protocolType。对于普通的消费者而言，protocolType 就是字符串”consumer”。如果不是首个成员，就进入到下一步。</li><li>add 方法会连续进行三次校验，分别确保待添加成员的组 ID、protocolType 和组配置一致，以及该成员选定的分区分配策略与组选定的分区分配策略相匹配。如果这些校验有任何一个未通过，就会立即抛出异常。</li><li>判断消费者组的 Leader 成员是否已经选出了。如果还没有选出，就将该成员设置成 Leader 成员</li><li>更新消费者组分区分配策略支持票数。关于 supportedProtocols 字段的含义</li><li>设置成员加入组后的回调逻辑，同时更新已加入组的成员数</li></ol><h3 id="2-2-移除成员"><a href="#2-2-移除成员" class="headerlink" title="2.2. 移除成员"></a>2.2. 移除成员</h3><p>有 add 方法，自然也就有 remove 方法</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove</span></span>(memberId: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 从members中移除给定成员</span></span><br><span class="line">  members.remove(memberId).foreach &#123; member =&gt;</span><br><span class="line">    <span class="comment">// 更新分区分配策略支持票数</span></span><br><span class="line">    member.supportedProtocols.foreach&#123; <span class="keyword">case</span> (protocol, _) =&gt; supportedProtocols(protocol) -= <span class="number">1</span> &#125;</span><br><span class="line">    <span class="comment">// 更新已加入组的成员数</span></span><br><span class="line">    <span class="keyword">if</span> (member.isAwaitingJoin)</span><br><span class="line">      numMembersAwaitingJoin -= <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 如果该成员是Leader，选择剩下成员列表中的第一个作为新的Leader成员</span></span><br><span class="line">  <span class="keyword">if</span> (isLeader(memberId))</span><br><span class="line">    leaderId = members.keys.headOption</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-查询成员"><a href="#2-3-查询成员" class="headerlink" title="2.3. 查询成员"></a>2.3. 查询成员</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">has</span></span>(memberId: <span class="type">String</span>) = members.contains(memberId)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get</span></span>(memberId: <span class="type">String</span>) = members(memberId)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">size</span> </span>= members.size</span><br></pre></td></tr></table></figure><ol><li>has 方法，判断消费者组是否包含指定成员</li><li>get 方法，获取指定成员对象</li><li>size 方法，统计总成员数。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(2)：生产者</title>
      <link href="2019/02/12/Kafka%20%E7%94%9F%E4%BA%A7%E8%80%85%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%B8%8D%E4%B8%A2%E5%A4%B1%EF%BC%8C%E4%B8%8D%E9%87%8D%E5%A4%8D?/"/>
      <url>2019/02/12/Kafka%20%E7%94%9F%E4%BA%A7%E8%80%85%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%B8%8D%E4%B8%A2%E5%A4%B1%EF%BC%8C%E4%B8%8D%E9%87%8D%E5%A4%8D?/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>生产者丢数据，即发送的数据根本没有保存到 Broker 端。出现这个情况的原因可能是，网络抖动，导致消息压根就没有发送到 Broker 端；也可能是消息本身不合格导致 Broker 拒绝接收（比如消息太大了，超过了 Broker 的承受能力）等等。</p><p>上面所说比如网络原因导致消息没有成功发送到 broker 端，很简单的一个<strong>重试配置</strong>，基本就可以解决这种网络瞬时抖动问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(<span class="string">&quot;retries&quot;</span>, <span class="number">10</span>);</span><br></pre></td></tr></table></figure><p>当然还有很多其他原因导致的，不能只依靠 kafka 的配置来做处理，kafka 提供了两个方法的，通常会出问题的方法是那个简单的 send，没有 callback(回调)。简单的 send 发送后不会去管它的结果是否成功，而 callback 能准确地告诉消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。</p><p><font color='red'><strong>因此，一定要使用带有回调通知的 send 方法。</strong></font></p><p>Kafka 集群通过多 Broker 达到高可用的效果，所以对于生产者程序来说，也不能简单的认为发送到一台就算成功，如果只满足于一台，机器如果损坏了，那消息必然会丢失。设置 <strong>acks = all</strong>，表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”，这样可以达到高可用的效果。</p><p>考虑到 producer,broker,consumer 之间都有可能造成消息重复，所以要求接收端需要支持消息去重的功能，借助业务消息本身的幂等性来做。<br>举例：</p><blockquote><p>在华泰证券中Kafka的幂等性是如何保证的？在接收端，启动专门的消费者拉取 kafka 数据存入 hbase。hbase 的 rowkey 的设计主要包括 SecurityId（股票id）和 timestamp（行情数据时间）。消费线程从 kafka 拉取数据后反序列化，然后批量插入 hbase，只有插入成功后才往 kafka 中持久化 offset。这样的好处是，如果在中间任意一个阶段发生报错，程序恢复后都会从上一次持久化 offset 的位置开始消费数据，而不会造成数据丢失。如果中途有重复消费的数据，则插入 hbase 的 rowkey 是相同的，数据只会覆盖不会重复，最终达到数据一致。</p></blockquote><p><strong>在0.11之前主要是通过下游系统具有幂等性来保证 Exactly Once。但是这样有几个缺陷：</strong></p><blockquote><p>要求下游系统支持幂等操作，限制了Kafka的适用场景</p></blockquote><blockquote><p>实现门槛相对较高，需要用户对 Kafka 的工作机制非常了解</p></blockquote><blockquote><p>对于 Kafka Stream 而言，Kafka Producer 本身就是“下游”系统，能让 Producer 具有幂等处理特性，那就可以让Kafka Stream在一定程度上支持Exactly once语义。</p></blockquote><p><strong>0.11之后的版本，引入了 <code>Producer ID（PID）</code>和 <code>Sequence Number</code> 实现 <code>Producer </code>的幂等语义。</strong></p><blockquote><p>Producer ID：每个新的 Producer 在初始化的时候会被分配一个唯一的PID</p></blockquote><blockquote><p>Sequence Number：对于每个 PID，该 Producer 发送数据的每个 &lt;Topic, Partition&gt; 都对应一个从0开始单调递增的Sequence Number。</p></blockquote><p>Broker端也会为每个&lt;PID, Topic, Partition&gt;维护一个序号，对于接收的每条消息，如果其序号比 Broker 维护的序号(即最后一次Commit的消息的序号)大 1，则 Broker 会接受它，否则将其丢弃</p><blockquote><p>如果消息序号比 Broker 维护的序号大一以上，说明中间有数据尚未写入，也即乱序，此时 Broker 拒绝该消息，Producer 抛出InvalidSequenceNumber</p></blockquote><blockquote><p>如果消息序号小于等于 Broker 维护的序号，说明该消息已被保存，即为重复消息，Broker 直接丢弃该消息，Producer 抛出 DuplicateSequenceNumber</p></blockquote><p>这种机制很好的解决了数据重复和数据乱序的问题。</p><h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka 消息系统源码深度剖析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(1)：初识Kafka</title>
      <link href="2019/02/12/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(1)%EF%BC%9AZookeeper%E5%9C%A8kafka%E4%B8%AD%E4%BD%9C%E7%94%A8/"/>
      <url>2019/02/12/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(1)%EF%BC%9AZookeeper%E5%9C%A8kafka%E4%B8%AD%E4%BD%9C%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用间是如何传递的。</p><a id="more"></a><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p><strong>Zookeeper 是一个开放源码的、高性能的分布式协调服务，它用于 Kafka 的分布式应用。Zookeeper 主要用来跟踪 Kafka 集群中的节点状态, 以及 Kafka Topic, message 等等其他信息. 同时, Kafka 依赖于Zookeeper, 没有Zookeeper 是不能运行起来 Kafka 的.</strong></p><p>ZooKeeper 是整个 Kafka 集群元数据的 “真理之源(Source of Truth)”</p><h2 id="2-Broker-注册"><a href="#2-Broker-注册" class="headerlink" title="2. Broker 注册"></a>2. <strong>Broker 注册</strong></h2><p>zookeeper 记录了所有 broker 的存活状态，broker 会向 zookeeper 发送心跳请求来上报自己的状态。</p><p>zookeeper 维护了一个正在运行并且属于集群的 broker 列表。</p><h2 id="3-Topic-注册"><a href="#3-Topic-注册" class="headerlink" title="3. Topic 注册"></a>3. <strong>Topic 注册</strong></h2><p>在 Kafka 中，同一个 <strong>Topic 的消息会被分成多个分区</strong>并将其分布在多个 Broker 上，<strong>这些分区信息及与 Broker 的对应关系</strong>也都是由 Zookeeper 在维护，由专门的节点来记录</p><h2 id="4-控制器选举"><a href="#4-控制器选举" class="headerlink" title="4. 控制器选举"></a>4. 控制器选举</h2><p>Kafka 集群中有多个 Broker，其中有一个会被选举为控制器 Controller。</p><p>控制器负责管理整个集群所有分区和副本的状态，例如某个分区的 leader 故障了，控制器会选举新的 leader。</p><p>从多个 broker 中选出控制器，这个工作就是 zookeeper 负责的。</p><p>在一个 Kafka 集群中，某段时间内只能有一台 Broker 被选举为 Controller。随着时间的推移，可能会有不同的 Broker 陆续担任过 Controller 的角色，但是在某一时刻，Controller 只能由一个 Broker 担任。</p><h3 id="4-1-选举过程"><a href="#4-1-选举过程" class="headerlink" title="4.1. 选举过程"></a>4.1. 选举过程</h3><p>Controller 的选举过程依赖 ZooKeeper 完成。ZooKeeper 除了扮演集群元数据的“真理之源”角色，还定义了 <code>/controller</code> 临时节点(Ephemeral Node)，以协助完成 Controller 的选举。一旦 Broker 与 ZooKeeper 的会话终止，该节点就会消失。Controller 选举就依靠了这个特性。每个 Broker 都会监听 <code>/controller</code> 节点随时准备应聘 Controller 角色。</p><img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-03-08 下午5.03.56.png" alt="截屏2021-03-08 下午5.03.56" style="zoom:30%;" /><p>集群上所有的 Broker 都在实时监听 ZooKeeper 上的这个节点。</p><ol><li>监听这个节点是否存在。倘若发现这个节点不存在，Broker 会立即 “抢注该节点，即创建 <code>/controller</code> 节点。创建成功的那个 Broker，即当选为新一届的 Controller。</li><li>监听这个节点数据是否发生了变更。同样，一旦发现该节点的内容发生了变化，Broker 也会立即启动新一轮的 Controller 选举。</li></ol><h2 id="5-记录-ISR-信息"><a href="#5-记录-ISR-信息" class="headerlink" title="5. 记录 ISR 信息"></a>5. 记录 ISR 信息</h2><p>zookeeper 记录着 ISR 的信息，而且是实时更新的，只要发现其中有成员不正常，马上移除。</p><h2 id="6-topic-配置"><a href="#6-topic-配置" class="headerlink" title="6. topic 配置"></a>6. topic 配置</h2><p>  zookeeper 保存了 topic 相关配置，例如 topic 列表、每个 topic 的 partition 数量、副本的位置等等。</p><ol start="6"><li><p>consumer</p><ul><li><p>offset</p><blockquote><p>kafka 老版本中，consumer 的消费偏移量是默认存储在 zookeeper 中的。</p></blockquote><blockquote><p>新版本中，逐渐弱化了 zookeeper 的作用。新的 consumer 使用了 kafka 内部的group coordination 协议，也减少了对zookeeper的依赖，工作由 kafka 自己做了，kafka 专门做了一个 offset manager。</p></blockquote></li><li><p>注册</p><blockquote><p>和 broker 一样，consumer 也需要注册。</p><p>consumer 会自动注册，注册的方式也是创建一个临时节点，consumer down 了之后就会自动销毁。</p></blockquote></li></ul></li><li><p><strong>分区注册</strong></p><blockquote><p>kafka 的每个 partition 只能被消费组中的一个 consumer 消费，kafka 必须知道所有 partition 与 consumer 的关系。</p></blockquote></li></ol><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h2><h5 id="Kafka-分区数可以增加或减少吗？为什么？"><a href="#Kafka-分区数可以增加或减少吗？为什么？" class="headerlink" title="Kafka 分区数可以增加或减少吗？为什么？"></a><font color='blue'>Kafka 分区数可以增加或减少吗？为什么？</font></h5><p>我们可以使用 bin/kafka-topics.sh 命令对 Kafka 增加 Kafka 的分区数据，但是 Kafka 不支持减少分区数。<br>Kafka 分区数据不支持减少是由很多原因的，比如减少的分区其数据放到哪里去？是删除，还是保留？删除的话，那么这些没消费的消息不就丢了。如果保留这些消息如何放到其他分区里面？追加到其他分区后面的话那么就破坏了 Kafka 单个分区的有序性。如果要保证删除分区数据插入到其他分区保证有序性，那么实现起来逻辑就会非常复杂。</p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka 消息系统源码深度剖析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(1)：初识Kafka</title>
      <link href="2019/02/12/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(1)%EF%BC%9A%E5%88%9D%E8%AF%86Kafka/"/>
      <url>2019/02/12/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(1)%EF%BC%9A%E5%88%9D%E8%AF%86Kafka/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用间是如何传递的。</p><a id="more"></a><h1 id="1-消息系统"><a href="#1-消息系统" class="headerlink" title="1.消息系统"></a>1.消息系统</h1><p>一个消息系统负责将数据从一个应用传递到另外一个应用，应用只需关注于数据，无需关注数据在两个或多个应用间是如何传递的。</p><ol><li><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>分布式消息传递基于可靠的消息队列，在客户端应用和消息系统之间异步传递消息。有两种主要的消息传递模式：<strong>点对点传递模式、发布-订阅模式</strong>。大部分的消息系统选用发布-订阅模式。<strong>Kafka就是一种发布-订阅模式</strong>。</p></li><li><h4 id="点对点传递模式"><a href="#点对点传递模式" class="headerlink" title="点对点传递模式"></a>点对点传递模式</h4><p>在点对点消息系统中，消息持久化到一个队列中。此时，将有一个或多个消费者消费队列中的数据。但是一条消息只能被消费一次。当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。</p></li><li><h4 id="发布-订阅模式"><a href="#发布-订阅模式" class="headerlink" title="发布-订阅模式"></a>发布-订阅模式</h4><p>在发布-订阅消息系统中，消息被持久化到一个 topic 中。与点对点消息系统不同的是，消费者可以订阅一个或多个 topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除。在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。</p></li></ol><h1 id="2-Kafka"><a href="#2-Kafka" class="headerlink" title="2.Kafka"></a>2.Kafka</h1><h2 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1.概述"></a>2.1.概述</h2><p>Kafka 是<strong>分布式发布-订阅消息系统</strong>，它最初是由 LinkedIn 公司开发的，之后成为 Apache 项目的一部分，<strong>Kafka是一个分布式，可划分的，冗余备份的持久性的日志服务，它主要用于处理流式数据</strong>。</p><h2 id="2-2-特征"><a href="#2-2-特征" class="headerlink" title="2.2. 特征"></a>2.2. 特征</h2><ol><li><p><strong>支持多个生产者</strong></p><p>Kafka 可以无缝地支持多个生产者，不管客户端在使用单个主题还是多个主题。所以它很适合用来从多个前端系统收集数据，并以统一的格式对外提供数据。例如，一个包含了多个微服务的网站，可以为页面视图创建一个单独的主题，所有服务都以相同的消息格式向该主题写入数据。消费者应用程序会获得统一的页面视图，而无需协调来自不同生产者的数据流。</p></li><li><p><strong>支持多个消费者</strong></p><p>Kafka 也支持多个消费者从一个单独的消息流上读取数据，而且消费者之间直不影响。这与其他队列系统不同，其他队列系统的消息一旦被一个客户端读取，其他客户端就无法再读取它。另外，多个消费者可以组成一个群组，它们共享一个悄息流，并保证整个群组对每个给定的消息只处理一次。</p></li><li><p><strong>基于磁盘存储</strong></p><p>消费者可能会因为处理速度慢或突发的流量高峰导致无陆及时读取消息，而持久化数据可以保证数据不会丢失。消费者可以在进行应用程序维护时离线一小段时间，而无需担心消息丢失或堵塞在生产者端。消费者可以被关闭，但消息会继续保留在Kafka 里。消费者可以从上次中断的地方继续处理消息。</p></li><li><p><strong>可伸缩，高性能</strong></p><p>通过横向扩展生产者、消费者和 broker, Kafka 可以轻松处理巨大的消息流。在处理大量数据的同时，它还能保证亚秒级的消息延迟。</p></li></ol><h2 id="2-3-应用场景"><a href="#2-3-应用场景" class="headerlink" title="2.3.应用场景"></a>2.3.应用场景</h2><ul><li><p><strong>日志收集</strong></p><blockquote><p>一个公司可以用 Kafka 可以收集各种服务的 log，通过 Kafka 以统一接口服务的方式开放给各种consumer，例如 Hadoop、Hbase 等</p></blockquote></li><li><p><strong>消息系统</strong></p><blockquote><p>解耦和生产者和消费者、缓存消息等</p></blockquote></li><li><p><strong>用户活动跟踪</strong></p><blockquote><p>Kafka 经常被用来记录 web 用户或者 app 用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到 Kafka 的 topic 中，然后订阅者通过订阅这些 topic 来做实时的监控分析，或者装载到 Hadoop、数据仓库中做离线分析和挖掘</p></blockquote></li><li><p><strong>运营指标</strong></p><blockquote><p>Kafka 也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告</p></blockquote></li><li><p><strong>流式处理</strong></p><blockquote><p>比如 spark streaming 和 storm</p></blockquote></li></ul><h1 id="3-架构"><a href="#3-架构" class="headerlink" title="3. 架构"></a>3. 架构</h1><p>一个典型的 Kafka 体系架构包括若干Producer [可以是服务器日志，业务数据，页面前端产生的page view等等]，若干broker [Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高]，若干Consumer (Group)，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。</p><p>Producer 使用 <strong>push[推]</strong> 模式将消息发布到broker</p><p>Consumer 使用 **pull[拉] **模式从broker订阅并消费消息。</p><p>Pull 模式下，consumer 可以自主决定是否批量的从 broker 拉取数据。Push 模式必须在不知道下游consumer 消费能力和消费策略的情况下决定是立即推送每条消息还是缓存之后批量推送。如果为了避免consumer 崩溃而采用较低的推送速率，将可能导致一次只推送较少的消息而造成浪费。</p><p>Pull 模式下，consumer 就可以根据自己的消费能力去决定这些策略</p><p>Pull 模式有个缺点是，如果 broker 没有可供消费的消息，将导致 consumer 不断在循环中轮询，直到新消息到达。为了避免这点，Kafka 有个参数可以让 consumer 阻塞知道新消息到达[当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发]</p><h2 id="3-1-Broker"><a href="#3-1-Broker" class="headerlink" title="3.1. Broker"></a>3.1. Broker</h2><p><strong>Kafka 集群包含一个或多个服务器，服务器节点称为 broker。</strong></p><p><strong>broker 存储 topic 的数据。如果某 topic 有 N 个partition，集群有 N 个broker，那么每个broker 存储该 topic 的一个 partition。</strong></p><ol><li><p><strong>Topic</strong></p><p>每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个 broker 上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处类似于数据库的表名</p></li><li><p><strong>Partition</strong></p></li></ol><p>topic 中的数据分割为一个或多个 partition。每个 topic 至少有一个 partition。每个partition 中的数据使用多个 segment 文件存储。partition 中的数据是有序的，不同partition 间的数据丢失了数据的顺序。如果 topic 有多个 partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将 partition 数目设为1。</p><p>如果 Topic 不进行分区，而将 Topic 内的消息存储于一个 broker，那么关于该 Topic 的所有读写请求都将由这一个 broker 处理，吞吐量很容易陷入瓶颈，这显然是不符合高吞吐量应用场景的。</p><p>有了 Partition 概念以后，假设一个 Topic 被分为 10 个 Partitions，Kafka 会根据一定的算法将 10 个 Partition 尽可能均匀的分布到不同的 broker（服务器）上，当 producer 发布消息时，producer 客户端可以采用 random、key-hash 及 轮询 等算法选定目标 partition，若不指定，Kafka 也将根据一定算法将其置于某一分区上。Partiton 机制可以极大的提高吞吐量，并且使得系统具备良好的水平扩展能力。</p><p>如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。</p><p>如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。</p><h2 id="3-2-Producer"><a href="#3-2-Producer" class="headerlink" title="3.2.Producer"></a>3.2.Producer</h2><p>生产者即数据的发布者，该角色将消息发布到 Kafka 的 topic 中。broker 接收到生产者发送的消息后，broker 将该消息<strong>追加</strong>到当前用于追加数据的 segment 文件中。生产者发送的消息，存储到一个partition 中，生产者也可以指定数据存储的 partition。</p><h2 id="3-3-Consumer-amp-Consumer-Group"><a href="#3-3-Consumer-amp-Consumer-Group" class="headerlink" title="3.3.Consumer &amp; Consumer Group"></a>3.3.Consumer &amp; Consumer Group</h2><p>消费者可以从 Broker 中读取数据。消费者可以消费多个 topic 中的数据。</p><p>每个 Consumer 属于一个特定的 Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。这是 Kafka 用来实现一个 topic 消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个 topic 可以有多个 CG。topic 的消息会复制给 consumer。如果需要实现广播，只要每个 consumer 有一个独立的 CG 就可以了。要实现单播只要所有的 consumer 在同一个 CG。用CG还可以将 consumer 进行自由的分组而不需要多次发送消息到不同的topic。</p><h2 id="3-4-Zookeeper"><a href="#3-4-Zookeeper" class="headerlink" title="3.4.Zookeeper"></a>3.4.Zookeeper</h2><h3 id="3-4-1-概述"><a href="#3-4-1-概述" class="headerlink" title="3.4.1. 概述"></a>3.4.1. 概述</h3><p><strong>Zookeeper 是一个开放源码的、高性能的分布式协调服务，它用于 Kafka 的分布式应用。Zookeeper 主要用来跟踪 Kafka 集群中的节点状态, 以及 Kafka Topic, message 等等其他信息. 同时, Kafka 依赖于Zookeeper, 没有Zookeeper 是不能运行起来 Kafka 的.</strong></p><p>Zookeeper 存储了一些关于 consumer 和 broker 的信息，那么就从这两方面说明 zookeeper 的作用。</p><ol><li><p><strong>Broker 注册</strong></p><p>zookeeper 记录了所有 broker 的存活状态，broker 会向 zookeeper 发送心跳请求来上报自己的状态。</p><p>zookeeper 维护了一个正在运行并且属于集群的 broker 列表。</p></li><li><p><strong>Topic 注册</strong></p><p>在 Kafka 中，同一个 <strong>Topic 的消息会被分成多个分区</strong>并将其分布在多个 Broker 上，<strong>这些分区信息及与 Broker 的对应关系</strong>也都是由 Zookeeper 在维护，由专门的节点来记录</p></li><li><p>控制器选举</p><p>Kafka 集群中有多个 Broker，其中有一个会被选举为控制器。</p><p>控制器负责管理整个集群所有分区和副本的状态，例如某个分区的 leader 故障了，控制器会选举新的 leader。</p><p>从多个 broker 中选出控制器，这个工作就是 zookeeper 负责的。</p></li><li><p>记录 ISR 信息</p><p> zookeeper 记录着 ISR 的信息，而且是实时更新的，只要发现其中有成员不正常，马上移除。</p></li><li><p>topic 配置</p><p>zookeeper 保存了 topic 相关配置，例如 topic 列表、每个 topic 的 partition 数量、副本的位置等等。</p></li><li><p>consumer</p><ul><li><p>offset</p><blockquote><p>kafka 老版本中，consumer 的消费偏移量是默认存储在 zookeeper 中的。</p></blockquote><blockquote><p>新版本中，逐渐弱化了 zookeeper 的作用。新的 consumer 使用了 kafka 内部的group coordination 协议，也减少了对zookeeper的依赖，工作由 kafka 自己做了，kafka 专门做了一个 offset manager。</p></blockquote></li><li><p>注册</p><blockquote><p>和 broker 一样，consumer 也需要注册。</p><p>consumer 会自动注册，注册的方式也是创建一个临时节点，consumer down 了之后就会自动销毁。</p></blockquote></li></ul></li><li><p><strong>分区注册</strong></p><blockquote><p>kafka 的每个 partition 只能被消费组中的一个 consumer 消费，kafka 必须知道所有 partition 与 consumer 的关系。</p></blockquote></li></ol><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h2><h5 id="Kafka-分区数可以增加或减少吗？为什么？"><a href="#Kafka-分区数可以增加或减少吗？为什么？" class="headerlink" title="Kafka 分区数可以增加或减少吗？为什么？"></a><font color='blue'>Kafka 分区数可以增加或减少吗？为什么？</font></h5><p>我们可以使用 bin/kafka-topics.sh 命令对 Kafka 增加 Kafka 的分区数据，但是 Kafka 不支持减少分区数。<br>Kafka 分区数据不支持减少是由很多原因的，比如减少的分区其数据放到哪里去？是删除，还是保留？删除的话，那么这些没消费的消息不就丢了。如果保留这些消息如何放到其他分区里面？追加到其他分区后面的话那么就破坏了 Kafka 单个分区的有序性。如果要保证删除分区数据插入到其他分区保证有序性，那么实现起来逻辑就会非常复杂。</p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka 消息系统源码深度剖析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息系统-Kafka(2)：生产者</title>
      <link href="2019/02/12/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(2)%EF%BC%9A%E7%94%9F%E4%BA%A7%E8%80%85/"/>
      <url>2019/02/12/%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F-Kafka(2)%EF%BC%9A%E7%94%9F%E4%BA%A7%E8%80%85/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>生产者即数据的发布者，该角色将消息发布到 Kafka 的 topic 中。broker 接收到生产者发送的消息后，broker 将该消息<strong>追加</strong>到当前用于追加数据的 segment 文件中。生产者发送的消息，存储到一个partition 中，生产者也可以指定数据存储的 partition。</p><a id="more"></a><h1 id="1-生产者概览"><a href="#1-生产者概览" class="headerlink" title="1.生产者概览"></a>1.生产者概览</h1><p>生产者即数据的发布者，该角色将消息发布到 Kafka 的 topic 中。broker 接收到生产者发送的消息后，将该消息<strong>追加</strong>到当前用于追加数据的 segment 文件中。生产者发送的消息，存储到一个partition 中，生产者也可以指定数据存储的 partition。</p><h2 id="1-1-创建生产者"><a href="#1-1-创建生产者" class="headerlink" title="1.1.创建生产者"></a>1.1.创建生产者</h2><p>ProductRecord 对象还可以指定键或分区。</p><p>在发送 ProductRecord 对象时，生产者要把键和值对象序列化为字节数组，这样才可以在网络上进行传输。接下来，数据被传给分区器。如果在 ProductRecord 对象里指定了分区，分区器直接将指定的分区返回。如果没有指定分区，分区器会根据 ProductRecord 对象的键选择一个分区。如果选定分区以后，生产者就知道向哪个主题和分区发送这条记录。<br>紧接着，这条记录被添加到一个记录批次里，这个批次里的所有消息被发送到相同主题和分区。(有一个独立的线程负责把这些记录批次发送到相应的 broker 上)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Create a record with no key</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> topic The topic this record should be sent to</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> value The record contents</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, V value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(topic, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, value, <span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>服务器在收到这些消息时会返回一个响应。如果消息成功写入 Kafka ，返回一个 RecordMetaData对象，包含了主题和分区信息，以及记录在分区的偏移量。如果写入失败，则会返回一个错误。生产者收到错误之后会尝试重新发送消息，几次之后如果还是失败，就返回错误信息。</p><img src="../images/kafka2.png" alt="" style="zoom:50%;" /><h2 id="2-创建生产者"><a href="#2-创建生产者" class="headerlink" title="2.创建生产者"></a>2.创建生产者</h2><p>向 Kafka 写入消息，首先要创建一个生产者对象，并设置一些属性。Kafka 生产者有3个必选的属性</p><ul><li><p>bootstrap.servers</p><p> 指定 broker 的地址清单</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;master:9092,data1:9092,data2:9092,data3:9092,data4:9092,data5:9092&quot;</span>);</span><br></pre></td></tr></table></figure></li><li><p>key.serializer</p><p>broker 希望接受到的消息的键和值都是字节数组。生产者接口允许使用参数化类型。因此可以把 Java 对象作为键和值发送给 broker(这样代码具有良好的可读性)</p></li><li><p>value.serializer </p></li></ul><h1 id="3-拦截器"><a href="#3-拦截器" class="headerlink" title="3.拦截器"></a>3.拦截器</h1><h2 id="3-1-概述"><a href="#3-1-概述" class="headerlink" title="3.1.概述"></a>3.1.概述</h2><p>对于生产者而言，拦截器使用户在消息发送前以及 Producer 回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，生产者允许用户指定多个拦截器按序作用于同一条消息从而形成一个拦截链(interceptor chain)。<br>Intercetpor 的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A plugin interface that allows you to intercept (and possibly mutate) the records received by the producer before</span></span><br><span class="line"><span class="comment"> * they are published to the Kafka cluster.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ProducerInterceptor</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Configurable</span></span></span><br></pre></td></tr></table></figure><ul><li><p><strong>onSend(ProducerRecord)</strong></p><p>生产者确保消息被序列化以及计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响目标分区的计算。</p></li><li><p><strong>onAcknowledgement(RecordMetadata, Exception)</strong></p><p>该方法会在消息被应答之前或消息发送失败时调用，并且通常都是在生产者回调逻辑触发之前。onAcknowledgement运行在生产者的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢生产者的消息发送效率</p></li></ul><ul><li><p><strong>close</strong></p><p>关闭interceptor，主要用于执行一些资源清理工作</p></li></ul><h2 id="3-2-拦截器实现"><a href="#3-2-拦截器实现" class="headerlink" title="3.2. 拦截器实现"></a>3.2. 拦截器实现</h2><p>实现一个简单的双 interceptor组成的拦截链。</p><ul><li>第一个interceptor会在消息发送前将时间戳信息加到消息前面；</li><li>第二个interceptor会在消息发送后更新成功发送消息数或失败发送消息数。</li></ul><h3 id="3-2-1-时间拦截器实现"><a href="#3-2-1-时间拦截器实现" class="headerlink" title="3.2.1.  时间拦截器实现"></a>3.2.1.  时间拦截器实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TimerInterceptor</span> <span class="keyword">implements</span> <span class="title">ProducerInterceptor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;&#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class="line">        String value = System.currentTimeMillis() + <span class="string">&quot;---&quot;</span> + record.value();</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ProducerRecord&lt;&gt;(record.topic(), record.partition(), record.key(), value);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;&#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-2-计数拦截器实现"><a href="#3-2-2-计数拦截器实现" class="headerlink" title="3.2.2.  计数拦截器实现"></a>3.2.2.  计数拦截器实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CountInterceptor</span> <span class="keyword">implements</span> <span class="title">ProducerInterceptor</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> success;</span><br><span class="line">    <span class="keyword">int</span> error;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;&#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="title">onSend</span><span class="params">(ProducerRecord&lt;String, String&gt; record)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> record;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onAcknowledgement</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(metadata != <span class="keyword">null</span>)&#123;</span><br><span class="line">            success ++;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            error++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;success:    &quot;</span> + success);</span><br><span class="line">        System.out.println(<span class="string">&quot;error:    &quot;</span> + error);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-3-配置拦截器"><a href="#3-2-3-配置拦截器" class="headerlink" title="3.2.3.  配置拦截器"></a>3.2.3.  配置拦截器</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ArrayList&lt;String&gt; interceptors = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">interceptors.add(<span class="string">&quot;api.interceptor.TimerInterceptor&quot;</span>);</span><br><span class="line">interceptors.add(<span class="string">&quot;api.interceptor.CountInterceptor&quot;</span>);</span><br><span class="line"></span><br><span class="line">properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</span><br></pre></td></tr></table></figure><h2 id="4-序列化器"><a href="#4-序列化器" class="headerlink" title="4. 序列化器"></a>4. 序列化器</h2><p>创建Kafka 生产者时必须指定序列化器。Kafka 除提供默认的字符串序列化器 org.apache.kafka.common.serialization.StringSerializer，还提供了整形和字节数组序列化器等。</p><h2 id="5-分区器"><a href="#5-分区器" class="headerlink" title="5.分区器"></a>5.分区器</h2><h3 id="5-1-分区原因"><a href="#5-1-分区原因" class="headerlink" title="5.1.分区原因"></a>5.1.分区原因</h3><ul><li>方便在集群中扩展，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic 又可以存在多个Partition</li><li>提高并发。</li></ul><h3 id="5-2-分区原则"><a href="#5-2-分区原则" class="headerlink" title="5.2.分区原则"></a>5.2.分区原则</h3><p>kafka 中默认分区器为 <strong>org.apache.kafka.clients.producer.internals.DefaultPartitioner，</strong>其实现了 org.apache.kafka.clients.producer.Partitioner 接口。默认分区原则为:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">* The <span class="keyword">default</span> partitioning strategy:</span><br><span class="line">* &lt;ul&gt;</span><br><span class="line">* &lt;li&gt;If a partition is specified in the record, use it</span><br><span class="line">* &lt;li&gt;If no partition is specified but a key is present choose a partition based on a hash of the key</span><br><span class="line">* &lt;li&gt;If no partition or key is present choose a partition in a round-robin fashion</span><br></pre></td></tr></table></figure><ol><li><p><strong>指明 partition 的情况下</strong></p><p>直接将指明的值直接作为 partition 的值</p></li><li><p><strong>没有指明 partition 值但是有 key</strong> </p><p>将 key 的 hash 值 与 topic 的 partition 数 进行取余 得到 partition 值</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// hash the keyBytes to choose a partition</span></span><br><span class="line"><span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 将 number 转换为正数。 </span></span><br><span class="line"><span class="comment">// 当 number 为正时，返回原始值。 </span></span><br><span class="line"><span class="comment">// 当 number 为负数时，返回原始值位与0x7fffffff的绝对值之和。 0x7FFFFFFF 的二进制表示就是除了首位是 0，其余都是1, </span></span><br><span class="line"><span class="comment">// 即最大的整型数 int</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">toPositive</span><span class="params">(<span class="keyword">int</span> number)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> number &amp; <span class="number">0x7fffffff</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>没有指定 partition 值又没有 key 值</strong></p><p>*round-robin** 既第一次调用时随即生成一个整数(后面每次调用在这个整数上进行自增)，将这个值与 topic 可用的 partition 总数取余，得到 partition 值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">int</span> nextValue = nextValue(topic);</span><br><span class="line"><span class="comment">// broker 集群中 topic 主题可以利用的分区数</span></span><br><span class="line">List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line"><span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> part = Utils.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">    <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// no partitions are available, give a non-available partition</span></span><br><span class="line">    <span class="keyword">return</span> Utils.toPositive(nextValue) % numPartitions;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ConcurrentMap&lt;String, AtomicInteger&gt; topicCounterMap = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class="line">  </span><br><span class="line"> <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">nextValue</span><span class="params">(String topic)</span> </span>&#123;</span><br><span class="line">     AtomicInteger counter = topicCounterMap.get(topic);</span><br><span class="line">     <span class="comment">// 如果是第一次分区，随机生成一个数</span></span><br><span class="line">     <span class="keyword">if</span> (<span class="keyword">null</span> == counter) &#123;</span><br><span class="line">         counter = <span class="keyword">new</span> AtomicInteger(ThreadLocalRandom.current().nextInt());</span><br><span class="line">         AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);</span><br><span class="line">         <span class="keyword">if</span> (currentCounter != <span class="keyword">null</span>) &#123;</span><br><span class="line">             counter = currentCounter;</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="comment">// 不是第一次分区， 则++</span></span><br><span class="line">     <span class="keyword">return</span> counter.getAndIncrement();</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li></ol><h1 id="6-原理"><a href="#6-原理" class="headerlink" title="6.原理"></a>6.原理</h1><h2 id="6-1-整体架构"><a href="#6-1-整体架构" class="headerlink" title="6.1.整体架构"></a>6.1.整体架构</h2><p>在生产者将消息发往 Kafka之前，有可能需要经历拦截器、序列化器和分区器等一系列的作用，随后才真正进入消息发送流程。</p><img src="../images/kafka1.png" alt="" style="zoom:50%;" /><h3 id="6-1-1-消息累加器-RecordAccumulator"><a href="#6-1-1-消息累加器-RecordAccumulator" class="headerlink" title="6.1.1. 消息累加器 RecordAccumulator"></a>6.1.1. 消息累加器 RecordAccumulator</h3><p>整个生产者客户端由两个线程协调运行，这两个线程分别为 <strong>主线程</strong> 和 <strong>Sender线程</strong>[发送线程]。</p><p>在主线程中由 KafkaProducer 创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器 [RecordAccumulator，也称为消息收集器]。</p><p>Sender 线程负责从 RecordAccumulator 中获取消息并将其发送到 Kafka 中。</p><ol><li><p>RecordAccumulator 主要用来缓存消息，以便 Sender 线程可以批量发送，进而减少网络传输的资源消耗提升性能。</p></li><li><p>RecordAccumulator 缓存的大小可以通过生产者客户端参数 <code>buffer.memory</code> 的配置，默认值为32MB。如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这个时候 KafkaProducer 的 send() 方法调用要么被阻塞，要么抛出异常，这个取决于参数 <code>max.block.ms</code> 的配置，此参数的默认值为60000，即60秒。</p></li></ol><h3 id="6-1-2-ProducerBatch"><a href="#6-1-2-ProducerBatch" class="headerlink" title="6.1.2.ProducerBatch"></a>6.1.2.ProducerBatch</h3><p><strong>在 RecordAccumulator 的内部为每个分区都维护了一个双端队列</strong></p><p>主线程中发送过来的消息都会被追回到 RecordAccumulator 的某个双端队列 [Deque]中，</p><p>队列中的内容就是 ProducerBatch,即 Deque<ProducerBatch>。</p><p>消息写入缓存时，追回到双端队列的尾部；Sender 读取消息时，从双端队列的头部读取。</p><ul><li><p><strong><font color='red'>注意</font></strong></p><ol><li><p><strong>ProducerBatch 不是 ProducerRecord</strong></p><blockquote><p>ProducerBatch 是指一个消息批次，ProducerRecord 会被包含在 ProducerBatch 中，这样可以使字节的使用更加紧凑。与此同时，将较小的 ProducerRecord 拼凑成一个较大的ProducerBatch 可以减少网络请求的次数以提升整体的吞量。如果生产者客户端需要向很多分区发送消息，则可以将 buffer.memory 参数适当调大以增加整体的吞吐量。</p></blockquote></li><li><p><strong>ProducerBatch 的大小和 batch.size 参数有着密切的关系。</strong></p><blockquote><p>当一条消息 [ProducerRecord] 流入 RecordAccumulator 时，会先寻找与消息分区所对应的双端队列,如果没有则创建，再从这个双端队列的尾部获取一个 ProducerBatch[如果没有则创建]，查看 ProducerBatch 中是否还可以写入这个 ProdcucerRecord，如果可以则写入，如果不可以则需要创建一个新的 ProducerBatch。</p></blockquote><blockquote><p>在新建 ProducerBatch 时评估这条消息的大小是否超过 batch.size 参数的大小，如果不超过，那么就以 batch.size 参数的大小来创建 ProducerBatch，这样在使用完这段内存区域后，可以通过 BufferPool 的管理来进行复用；如果超过，那么就以评估的大小创建ProducerBatch，这段内存区域不会被复用。</p></blockquote></li></ol></li></ul><h3 id="6-1-3-BufferPool"><a href="#6-1-3-BufferPool" class="headerlink" title="6.1.3. BufferPool"></a>6.1.3. BufferPool</h3><p>消息在网络上都是以字节[Byte]的形式传输的，在发送之前需要创建一块内存区域来保存对应的消息。在 Kafka 生产者客户端中，通过 java.io.ByteBuffer 实现消息内存的创建和释放。不过频繁的创建和释放是比较耗费资源的，在RecordAccumulator 的内部还有一个 BufferPool，它主要是用来实现 ByteBuffer 的复用，以实现缓存的高效利用。</p><p>不过 BufferPool 只针对特定大小的 ByteBuffer 进行管理，而其它大小的 ByteBuffer 不会缓存进 BufferPool 中，这个特定的大小由 batch.size 参数指定，默认值为 64KB，可以适当地调大 batch.size 参数以便多缓存一些消息。</p><p>Sender 从 RecordAccumulator 中获取缓存的消息之后，会进一步将原本 <strong><code>&lt;分区，Deque&lt;ProducerBatch&gt;&gt;</code></strong> 的保存形式转变成 <strong><code>&lt;Node, List&lt;ProducerBatch&gt;&gt;</code></strong> 的形式</p><p>在转换成 <strong>&lt;Node, List<ProducerBatch>&gt;</strong> 的形式之后，Sender 还会进一步封装成 <strong>&lt;Node, Request&gt;</strong> 的形式，将 Request 请求发往各个 Node</p><blockquote><p>这里的 Request 是指 Kafka 的各种协议请求，对于消息发送而言就是指具体的ProducerRequest。</p></blockquote><h3 id="6-1-4-InFlightRequest"><a href="#6-1-4-InFlightRequest" class="headerlink" title="6.1.4. InFlightRequest"></a>6.1.4. InFlightRequest</h3><p>请求在从 Sender 线程发往 Kafka 之前还会保存到 InFlightRequests 中，InFlightRequest 保存对象的具体形式为Map&lt;NodeId, Deque<Request>&gt;</p><p>它的主要作用是缓存已经发出去但还没有收到响应的请求</p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka 消息系统源码深度剖析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scilab 云化改造(3)_Xcos仿真流程分析</title>
      <link href="2018/04/05/Xcos%E4%BB%BF%E7%9C%9F%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/"/>
      <url>2018/04/05/Xcos%E4%BB%BF%E7%9C%9F%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Xcos 是基于 Java 图形界面程序的可视化模拟仿真功能组件。Xcos 的运行必须依赖于 Java 的虚拟机环境。Xcos 的所有可视化的组件和相应控件都是由 Java 代码所编写(包括 Scilab 的可视化界面也都是由 Java 代码编写)。但是 Scilab 的核心代码是由 Fortran 和 C/C++ 编写，所以存在 Java 与其他编程语言的交互问题，开发者利用了 JNI 的方式在 Java 和其他代码之间进行数据和信息交互的。</p><a id="more"></a><p>Xcos 是基于图形界面程序的可视化模拟仿真功能组件</p><p>Scilab 一共有4种工作模式</p><ol><li>API: Scilab 作为API接口供外部程序调用。</li><li>STD: 标准的Scilab模式（包括图形界面和绘制图表功能）。</li><li>NW:以命令行的模式运行Scilab，没有标准的图形界面，但可以进行图表绘制。</li><li>NWNI: 完全以命令行的模式运行Scilab，没有任何图形界面。</li></ol><p>在 Scilab 以 NWNI 和 API 模式运行时，是不能加载 Xcos 模块，即不能运行模拟仿真的功能。</p><h2 id="Xcos-模型的模拟仿真流程"><a href="#Xcos-模型的模拟仿真流程" class="headerlink" title="Xcos 模型的模拟仿真流程"></a>Xcos 模型的模拟仿真流程</h2><p>一个仿真模型的模拟仿真分为以下几个步骤如图所示：</p><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午1.27.48.png" alt="截屏2021-01-19 下午1.27.48" style="zoom:70%;" /><p>在分析过后，我们发现，Xcos 对于仿真模型的基本操作是一致的，即编译，仿真，输出结果的操作流程是一样的。</p><p>下面简单介绍建模过程。在 Xcos 下建模，就是根据已有的模型，在 Xcos 的组件盘中选取合适的模块，在工作区中进行正确的端口连接。</p><p>Xcos是一个可视化的仿真组件，所以，Xcos有自己的文件格式：.xcos/.zcos。.xcos文件可以当做文本文件打开，如图5.4打开其实可以发现，其实.xcos文件就是一个类xml文件，其中包含了当前模型的所有的信息。</p><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午1.29.09.png" alt="截屏2021-01-19 下午1.29.09" style="zoom:70%;" /><p>.zcos 文件是为了 Xcos 的批处理而做出的特殊文件格式，即，zcos 就是多个 xcos 文件的集合，即相当于一个压缩文件夹的作用。</p><p>xcos文件中已经包含了一个仿真的所有信息。建模过程：从组件盘中向仿真工作区间进行拖拽仿真模块的操作、模块端口连接操作，实质上就是在编写这样的一个xml文件。建模的过程的实质是建立仿真信息的xml文件。</p><p>另外，可以在仿真的建模过程中通过打开菜单栏中的 “查看” 按钮下拉中的“图表浏览器”选项，来实时查看当前建模的组织关系树状图。</p><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午1.29.57.png" alt="截屏2021-01-19 下午1.29.57" style="zoom:70%;" /><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午1.30.37.png" alt="截屏2021-01-19 下午1.30.37" style="zoom:50%;" /><p>Xcos 是可视化的 Java 代码界面，所以存在如何从 Java 代码与 Scilab 核心层的交互以及在核心层如何实现模拟仿真的。接下来，分两部分说明一个模型是如何成为机器代码去运行的。为简要说明，假设 Scilab 是在 NW 模式下运行的。</p><h2 id="Xcos-的仿真模型的解析"><a href="#Xcos-的仿真模型的解析" class="headerlink" title="Xcos 的仿真模型的解析"></a>Xcos 的仿真模型的解析</h2><p>Xcos 的模型都是一些可视化的控件块，对于这些控件块的操作(比如移动动作，按下编译，运行操作等操作)都在Java代码层进行执行。现单纯的就“编译按钮”进行说明。</p><p>Java 代码将 Xcos 的行为分成了很多类包，比如动作，日志，事件监听等。很明显，按钮是一个控件，而按下按钮是一个事件，这个事件触发后会链接到该控件所绑定的动作上。所以，在xcos的动作类包中找到 “编译” 动作。</p><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午1.34.46.png" alt="截屏2021-01-19 下午1.34.46" style="zoom:50%;" /><p>打开所找到的 Java 源文件，找到动作执行的方法 actionPerformed 中，Java 通过 JNI 的方式向 Scilab 发送了一条Scilab 语言类型的命令。</p><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午1.35.28.png" alt="截屏2021-01-19 下午1.35.28" style="zoom:50%;" /><p>现在，Scilab 收到了这条消息，现在回到 Scilab 的 C/C++，Fortran 源代码进行分析。</p><p>Scilab 收到这条发送到控制台的指令后要进行解析，将它进行分解，然后在 Scilab 的动态库当中寻找合适的代码去解析它，执行它。大致流程如图5.9所示。</p><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午1.36.51.png" alt="截屏2021-01-19 下午1.36.51" style="zoom:50%;" /><p>针对这条”编译指令” 首先控制台收到了 Java 程序发来的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cpr = xcos_compile(scs_m)；</span><br></pre></td></tr></table></figure><p>这是一条在控制台的Sci语言的命令。</p><p>在控制台会有事件监听程序在运行，收到这条指令后，Scilab会在控制台运行相应的事件响应函数GetCommandLine()调用getCmdLine()获取在控制台的字符流，然后通过bexec()将Scilab语言解析成所需参数，然后调用相应的函数进行运算执行。实际上，最后这条指令的结果是将scs_m中所含的编译信息储存到了变量cpr中。</p><blockquote><p>注：在 Scilab 中是通过每个模块函数的 ID 并利用 callFunctionFromGateway() 获取所需具体函数的位置并执行调用，函数具体 ID 在每个模块的 sci_gateway 文件夹下的 xxx_gateway.xml 文件下可查。</p></blockquote><p>至此，已经完整分析了从 Xcos 中是怎么与控制台交互信息以及如何让控制台进行对 Sci 语言指令响应的过程。下面，我们针对仿真过程在 Sci 中是如何运作的。</p><h2 id="Xcos-编译器"><a href="#Xcos-编译器" class="headerlink" title="Xcos 编译器"></a>Xcos 编译器</h2><p>Xcos 的编译器其实就是将 .xcos 文件解析成需要的仿真信息，就目前来看，其实转化成 Sci 语言就是通过如下 3 条指令进行的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">importXcosDiagram()</span><br><span class="line">cpr = xcos_compile(scs_m)</span><br><span class="line">xcos_simulate(scs_m, <span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>importXcosDiagram() 函数是将.xcos文件中的所有模型的信息储存到变量scs_m中，以供编译和模拟仿真执行。</p><p>xcos_compile(scs_m) 函数是检查模型链接中的错误以及将变量 scs_m 中所包含的信息转化成仿真执行的所需要的信息，包括仿真调度表，解算器以及各种模型仿真信息，并将信息储存入 <code>%cpr</code> 变量中。关于 <code>%cpr</code> 中调度表的具体信息可以查看《Scilab/Scicos在建模与仿真中的应用》一书的附录 A.2 章节详细介绍。</p><p>xcos_simulate(scs_m, 4) 函数是将模型进行仿真的的起始指令，其中隐含调用了 <code>xcos_compile()</code> 函数，在遵循 <code>%cpr</code> 的调度表的情况下进行对模拟仿真的执行并求解结果。</p><h2 id="Xcos-仿真过程分析"><a href="#Xcos-仿真过程分析" class="headerlink" title="Xcos 仿真过程分析"></a>Xcos 仿真过程分析</h2><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午1.40.44.png" alt="截屏2021-01-19 下午1.40.44" style="zoom:50%;" />]]></content>
      
      
      <categories>
          
          <category> Scilab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scilab 仿真云化改造 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scilab 云化改造(4)_Xcos工具箱功能包挂载</title>
      <link href="2018/03/30/Xcos%E5%B7%A5%E5%85%B7%E7%AE%B1%E5%8A%9F%E8%83%BD%E5%8C%85%E6%8C%82%E8%BD%BD/"/>
      <url>2018/03/30/Xcos%E5%B7%A5%E5%85%B7%E7%AE%B1%E5%8A%9F%E8%83%BD%E5%8C%85%E6%8C%82%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>为实现 Scilab 扩展功能的增加和挂载，将 C/C++/Fortran 语言实现的功能添加到 Scilab 平台，并在 Scilab 平台中对该类函数实现的功能进行调用。Scilab 提供了工具箱的模式对此类功能进行管理。</p><a id="more"></a><h1 id="工具箱概述"><a href="#工具箱概述" class="headerlink" title="工具箱概述"></a>工具箱概述</h1><h2 id="工具箱结构"><a href="#工具箱结构" class="headerlink" title="工具箱结构"></a>工具箱结构</h2><p>scilab 工具箱有专门的层次结构和概念，包括以下几部分：</p><ol><li><p><strong>script</strong></p><p>script 是一个扩展名为.sce的脚本文件，用于实现Scilab批处理代码。</p></li><li><p><strong>macro</strong></p><p>macro是用Scilab代码编写的Scilab函数，是一些具体功能的实现，其文件扩展名为.sci。</p></li><li><p><strong>primitive</strong></p><p>primitive是Scilab可调用的外部函数，该类函数的原型可以是C/C ++/Fortran语言编写的。该类型的函数需要通过sci_gateway的方式实现调用。</p></li><li><p><strong>sci_gateway</strong></p><p>sci_gateway是调用外部函数的模式方法，其方法使用C或C ++编写，遵循一定的原则，调用外部的功能实现函数，使其可以从Scilab中直接调用。一旦在builder脚本中声明了网关函数，构建并加载了其所对应的功能函数，就可以直接从Scilab中使用Scilab的方法使用这些外部实现函数。</p></li><li><p><strong>builder</strong></p><p>builder文件是用于构建工具箱的Scilab脚本，即对工具箱源码进行编译并生成对应的库文件。sci文件生成对应的bin文件，C/C++/Fortran文件生成对应的dll/so等动态库文件。以及符合Scilab加载的loader脚本文件、卸载的unloader脚本，以及清理生成文件的cleaner脚本。</p></li><li><p><strong>loader</strong></p><p>loader是Scilab脚本，它在Scilab中加载工具箱组件（或整个工具箱）。加载程序名称包含加载程序* .sce（示例：loader.sce，loadhelp.sce，…）。该文件由对应的builder文件生成。</p></li><li><p><strong>Toolbox start &amp; quit</strong></p><p>每个通过ATOMS安装的工具箱都在Scilab启动时自动加载启动脚本，在Scilab退出时自动执行工具箱卸载脚本。</p></li></ol><p>Scilab 的工具箱构建时一般遵循以下结构：</p><table><thead><tr><th>目录</th><th>内容</th><th>备注</th></tr></thead><tbody><tr><td>macros</td><td>macros(.sci)，builder(buildmacros.sce)</td><td>必需</td></tr><tr><td>src</td><td>源代码文件（.c，.cpp，.f，…）和builder脚本（builder*.sce）和加载脚本（loader * .sce，由builder脚本产生）</td><td>必需</td></tr><tr><td>sci_gateway</td><td>网关（.c或.cpp）以及网关builder脚本（.sce）的源代码文件</td><td>可选，如果没有使用其他语言实现的功能时，可忽略(如celestlab)</td></tr><tr><td>jar</td><td>java包和帮助文件（.jar）</td><td>不需构建，由builder运行时自动生成帮助文档的jar</td></tr><tr><td>help</td><td>XML帮助文件（.xml）</td><td>可选，但建议添加必要的帮助说明</td></tr><tr><td>etc</td><td>启动脚本（.start）和退出（.quit）脚本</td><td>必需</td></tr><tr><td>tests</td><td>模块测试脚本（.tst）</td><td>可选</td></tr><tr><td>demos</td><td>脚本实例</td><td>可选，但建议添加必要的示例</td></tr><tr><td>includes</td><td>要与模块一起发布的头文件（.h）</td><td>可选，如果想让别的程序调用本工具箱的功能，可以通过该方法进行分享</td></tr></tbody></table><h2 id="工具箱加载方式"><a href="#工具箱加载方式" class="headerlink" title="工具箱加载方式"></a>工具箱加载方式</h2><p>工具箱加载时需要两类脚本：一个是编译脚本(builder.sce)，用于编译工具箱; 另一个是加载脚本(loader.sce)，在Scilab 中加载该工具箱时运行。两者都是 Scilab 的批处理脚本文件（.sce文件）。</p><p>编译工具箱时，运行 builder.sce 文件，在编译过程中，该脚本将去各个源码目录下执行各自的builder脚本，完成各个源码的编译工作。编译完成后，可以使用加载脚本（loader.sce），在Scilab中加载模块。加载过程中，加载脚本会去工具箱/etc/目录下执行工具箱的启动脚本.start。</p><h2 id="工具箱示例"><a href="#工具箱示例" class="headerlink" title="工具箱示例"></a>工具箱示例</h2><p>本小节将以 Scilab 自带的一个骨架式工具包为示例。</p><p><strong>最外层builder.sce</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">mode(-1);</span><br><span class="line"></span><br><span class="line">lines(0);</span><br><span class="line"></span><br><span class="line">try getversion(&#39;scilab&#39;);</span><br><span class="line"></span><br><span class="line">catch error(gettext(&#39;Scilab 5.0 or more is required.&#39;));</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line">if ~with_module(&#39;development_tools&#39;) then </span><br><span class="line"></span><br><span class="line">error(msprintf(gettext(&#39;%s module not installed.&#39;),&#39;development_tools&#39;));</span><br><span class="line"></span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">TOOLBOX_NAME &#x3D; &#39;toolbox_skeleton&#39;;TOOLBOX_TITLE &#x3D; &#39;Toolbox Skeleton&#39;;</span><br><span class="line"></span><br><span class="line">toolbox_dir&#x3D;get_absolute_file_path(&#39;builder.sce&#39;);</span><br><span class="line"></span><br><span class="line">tbx_builder_macros(toolbox_dir);</span><br><span class="line"></span><br><span class="line">tbx_builder_src(toolbox_dir);</span><br><span class="line"></span><br><span class="line">tbx_builder_gateway(toolbox_dir);</span><br><span class="line"></span><br><span class="line">tbx_builder_help(toolbox_dir);</span><br><span class="line"></span><br><span class="line">tbx_build_loader(TOOLBOX_NAME, toolbox_dir);</span><br><span class="line"></span><br><span class="line">clear toolbox_dir TOOLBOX_NAME TOOLBOX_TITLE;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><p>很显然，builder的作用就是去个级目录下执行各自的builder.sce脚本，关于以上使用的函数可以参考scilab的帮助页面中关于”Modules manager”一节中进行查看。在执行完脚本后，将会生成工具箱的加载脚本(各个需要加载的源码目录下)。</p><p><strong>生成的最外层loader.sce**</strong>内容如下：**</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">oldmode &#x3D; mode(); </span><br><span class="line"></span><br><span class="line">mode(-1);</span><br><span class="line"></span><br><span class="line">oldlines &#x3D; lines()(2); lines(0);</span><br><span class="line"></span><br><span class="line">try</span><br><span class="line"></span><br><span class="line">exec(get_absolute_file_path(&quot;loader.sce&quot;)+&quot;etc&#x2F;&quot;+&quot;xcos_toolbox_skeleton.start&quot;);</span><br><span class="line"></span><br><span class="line">catch</span><br><span class="line"></span><br><span class="line">  [errmsg, tmp, nline, func] &#x3D; lasterror()</span><br><span class="line"></span><br><span class="line">  msg &#x3D; &quot;%s: error on line #%d: &quot;&quot;%s&quot;&quot;\n&quot;</span><br><span class="line"></span><br><span class="line">  msg &#x3D; msprintf(msg, func, nline, errmsg)</span><br><span class="line"></span><br><span class="line">  lines(oldlines)</span><br><span class="line"></span><br><span class="line">  mode(oldmode);</span><br><span class="line"></span><br><span class="line">  clear oldlines oldmode tmp nline func</span><br><span class="line"></span><br><span class="line">  error(msg);</span><br><span class="line"></span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">lines(oldlines);</span><br><span class="line"></span><br><span class="line">mode(oldmode);</span><br><span class="line"></span><br><span class="line">clear oldlines oldmode;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><p>显然生成的loader脚本是去调用了工具箱目录下的/etc/目录下的启动脚本(.start)</p><p><strong>/etc/toolbox_skeleton.start</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">function toolbox_skeletonlib &#x3D; startModule()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  TOOLBOX_NAME &#x3D; &quot;toolbox_skeleton&quot;;</span><br><span class="line"></span><br><span class="line">  TOOLBOX_TITLE &#x3D; &quot;Toolbox Skeleton&quot;;</span><br><span class="line"></span><br><span class="line"> mprintf(&quot;Start &quot; + TOOLBOX_TITLE + &quot;\n&quot;);</span><br><span class="line"></span><br><span class="line"> if isdef(&quot;toolbox_skeletonlib&quot;) then</span><br><span class="line"></span><br><span class="line">  warning(&quot;Toolbox skeleton library is already loaded&quot;);</span><br><span class="line"></span><br><span class="line">  return;</span><br><span class="line"></span><br><span class="line"> end</span><br><span class="line"> etc_tlbx &#x3D; get_absolute_file_path(&quot;toolbox_skeleton.start&quot;);</span><br><span class="line"></span><br><span class="line"> etc_tlbx &#x3D; getshortpathname(etc_tlbx);</span><br><span class="line"></span><br><span class="line"> root_tlbx &#x3D; strncpy( etc_tlbx, length(etc_tlbx)-length(&quot;\etc\&quot;) );</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;Load functions library</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line"> mprintf(&quot;\tLoad macros\n&quot;);</span><br><span class="line"></span><br><span class="line"> pathmacros &#x3D; pathconvert( root_tlbx ) + &quot;macros&quot; + filesep();</span><br><span class="line"></span><br><span class="line"> toolbox_skeletonlib &#x3D; lib(pathmacros);</span><br><span class="line">&#x2F;&#x2F; load gateways and Java libraries</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line"> verboseMode &#x3D; ilib_verbose();</span><br><span class="line"></span><br><span class="line"> ilib_verbose(0);</span><br><span class="line"></span><br><span class="line"> mprintf(&quot;\tLoad gateways\n&quot;);</span><br><span class="line"></span><br><span class="line"> exec(pathconvert(root_tlbx+&quot;&#x2F;sci_gateway&#x2F;loader_gateway.sce&quot;,%f));</span><br><span class="line"></span><br><span class="line"> mprintf(&quot;\tLoad Java libraries\n&quot;);</span><br><span class="line"></span><br><span class="line"> exec(pathconvert(root_tlbx+&quot;&#x2F;src&#x2F;java&#x2F;loader.sce&quot;,%f));</span><br><span class="line"></span><br><span class="line"> ilib_verbose(verboseMode); </span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; load localization</span><br><span class="line"></span><br><span class="line"> addlocalizationdomain(TOOLBOX_NAME, root_tlbx + &quot;&#x2F;locales&quot;);</span><br><span class="line">&#x2F;&#x2F; Load and add help chapter</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line"> if or(getscilabmode() &#x3D;&#x3D; [&quot;NW&quot;;&quot;STD&quot;]) then</span><br><span class="line"></span><br><span class="line">  mprintf(&quot;\tLoad help\n&quot;);</span><br><span class="line"></span><br><span class="line">  path_addchapter &#x3D; pathconvert(root_tlbx+&quot;&#x2F;jar&quot;);</span><br><span class="line"></span><br><span class="line">  if ( isdir(path_addchapter) &lt;&gt; [] ) then</span><br><span class="line"></span><br><span class="line">   add_help_chapter(TOOLBOX_NAME, path_addchapter, %F);</span><br><span class="line"></span><br><span class="line">  end</span><br><span class="line"></span><br><span class="line"> end</span><br><span class="line">&#x2F;&#x2F; Load demos</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line"> if or(getscilabmode() &#x3D;&#x3D; [&quot;NW&quot;;&quot;STD&quot;]) then</span><br><span class="line"></span><br><span class="line">  mprintf(&quot;\tLoad demos\n&quot;);</span><br><span class="line"></span><br><span class="line">  pathdemos &#x3D; pathconvert(root_tlbx+&quot;&#x2F;demos&#x2F;toolbox_skeleton.dem.gateway.sce&quot;, %F, %T);</span><br><span class="line"></span><br><span class="line">  add_demo(TOOLBOX_TITLE, pathdemos);</span><br><span class="line"></span><br><span class="line"> end</span><br><span class="line">&#x2F;&#x2F; Load Preferences GUI</span><br><span class="line">&#x2F;&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line"> if getscilabmode() &#x3D;&#x3D; &quot;STD&quot; then</span><br><span class="line"></span><br><span class="line">  addModulePreferences(TOOLBOX_TITLE, root_tlbx, etc_tlbx + &quot;toolbox_skeleton_preferences.xml&quot;);</span><br><span class="line"></span><br><span class="line"> end</span><br><span class="line">endfunction</span><br><span class="line"></span><br><span class="line">toolbox_skeletonlib &#x3D; startModule();</span><br><span class="line"></span><br><span class="line">clear startModule; &#x2F;&#x2F; remove startModule on stack</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><h1 id="功能包概述"><a href="#功能包概述" class="headerlink" title="功能包概述"></a>功能包概述</h1><h2 id="功能包结构"><a href="#功能包结构" class="headerlink" title="功能包结构"></a>功能包结构</h2><p>Scilab的软件架构是模块化结构，即每一类功能都类似于插件。现对源码中的层次架构进行说明 。SiROS</p><p>在最上面的文件层次中，如图所示，层级目录中有10个文件夹。每个文件夹都有具体的含义，因为本文档针对的是对功能包的挂载，所以在本报告中需要关注的是modules文件夹，其中共有77个子文件夹，每一个子文件夹代表了其实现的一种功能，即每个子文件夹都是基本上代表了一类功能包。</p><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午1.53.13.png" alt="截屏2021-01-19 下午1.53.13" style="zoom:50%;" /><p>现对功能组件包进行层级说明，以一般功能包为例。</p><p>Scilab 功能包构建层次说明</p><table><thead><tr><th>目录</th><th>内容</th><th>备注</th></tr></thead><tbody><tr><td>demos</td><td>模块的演示，显示模块的功能</td><td></td></tr><tr><td>etc</td><td>模块配置（初始化和配置）</td><td></td></tr><tr><td>example</td><td>示例（readme.txt）</td><td></td></tr><tr><td>help</td><td>功能包的帮助（SiROS帮助说明）</td><td></td></tr><tr><td>includes</td><td>可以在外部使用的头文件（其他功能包或第三方程序）</td><td></td></tr><tr><td>locales</td><td>本地化文件</td><td></td></tr><tr><td>macros</td><td>模块的宏脚本文件</td><td></td></tr><tr><td>sci_getway</td><td>链接外部程序到SiROS中</td><td>子目录应为(sci_getway/c/ sci_getway/fortran/…)</td></tr><tr><td>src</td><td>功能包的核心源码</td><td>子目录应为(src/c/ src/fortran/…包括一些本地.h头文件)</td></tr><tr><td>tests/unit_tests</td><td>单一测试文件</td><td></td></tr><tr><td>tests/nonreg_tests</td><td>非递归测试文件</td><td></td></tr><tr><td>tests/benchmarks</td><td>基准测试文件</td><td></td></tr></tbody></table><p>其中在一个功能包中，所必须的文件包括：</p><ol><li>changelog.txt</li><li>licence.txt</li><li>Makefile.am</li><li>Makefile.in (generated from Makefile.am by automake)</li><li>xxxx.vcproj</li><li>version.xml</li><li>readme.txt</li><li>etc/<module>.start</li><li>etc/<module>.quit</li><li>includes/gw_<module>.h</li><li>sci_gateway/xxx/gw_<module>.c</li><li>sci_gateway/<module>_gateway.xml</li></ol><p>可选项为：</p><p>locales/en_US/<module>.po</p><p>需要遵守的原则为：</p><p>如果它们是模块的native函数，则应在src / <language> /生成函数的.h头文件。如果可以从其他模块使用该函数，则应将其头文件放入includes /。</p><p>应该尽量避免使用extern字段。可以使用头文件（.h）以实现相同的功能。</p><p>当创建可以由fortran调用的C函数时，需要在函数名称前添加宏C2F，并需要引入 machine.h 头文件。</p><h2 id="功能包加载方式"><a href="#功能包加载方式" class="headerlink" title="功能包加载方式"></a>功能包加载方式</h2><p>功能包的加载方式，由于其是与源码一起编译生成相应的 dll/so 文件，所以其加载方式是在 Scilab 启动时，直接自动加载其对应的 dll/so 文件或者在需要时由 Scilab 决定其加载与否。所以我们需要关注的是其编译的过程而非加载过程。</p><p>下一小节将以 xcos 实现编译的 Makefile 文件为例，进行说明。</p><h2 id="功能包示例"><a href="#功能包示例" class="headerlink" title="功能包示例"></a>功能包示例</h2><p><strong>src/modules/xcos/Makefile.am</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br></pre></td><td class="code"><pre><span class="line">#&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">\#### Target ######</span><br><span class="line"></span><br><span class="line">modulename&#x3D;xcos</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">\#### xcos : Conf files ####</span><br><span class="line"></span><br><span class="line">libscixcos_la_rootdir &#x3D; $(mydatadir)</span><br><span class="line"></span><br><span class="line">libscixcos_la_root_DATA &#x3D; license.txt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\#### xcos : init scripts ####</span><br><span class="line"></span><br><span class="line">libscixcos_la_etcdir &#x3D; $(mydatadir)&#x2F;etc</span><br><span class="line"></span><br><span class="line">libscixcos_la_etc_DATA &#x3D; \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;xcos.quit \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;xcos.start \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;Xcos-style.xml \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;XcosFile.xsd \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;xcos.xml \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;XcosConfiguration.xsd \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;palettes.xml \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;PaletteConfiguration.xsd \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;Modelica.xsd \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;XConfiguration-xcos.xsl \</span><br><span class="line"></span><br><span class="line">​    etc&#x2F;XConfiguration-xcos.xml</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">XCOS_CXX_SOURCES &#x3D;  \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;Xcos.cpp \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;Xcos.hxx \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;XcosCellFactory.cpp \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;XcosCellFactory.hxx \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;Palette.cpp \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;Palette.hxx \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;Modelica.cpp \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;Modelica.hxx \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;JavaController_wrap.cxx \</span><br><span class="line"></span><br><span class="line">  src&#x2F;cpp&#x2F;xcosUtilities.cpp \</span><br><span class="line"></span><br><span class="line">  src&#x2F;cpp&#x2F;loadStatus.cpp \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;JavaXMIResource_wrap.cxx</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">GIWS_WRAPPERS &#x3D; \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;Xcos.giws.xml \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;XcosCellFactory.giws.xml \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;Palette.giws.xml \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;Modelica.giws.xml</span><br><span class="line"></span><br><span class="line">SWIG_WRAPPERS &#x3D; \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;JavaController.i \</span><br><span class="line"></span><br><span class="line">  src&#x2F;jni&#x2F;JavaXMIResource.i</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">\# FORCE directors due to a bug into swig</span><br><span class="line"></span><br><span class="line">SWIG_OPTIONS&#x3D;-c++ -directors</span><br><span class="line"></span><br><span class="line">BUILT_SOURCES&#x3D;</span><br><span class="line"></span><br><span class="line">if GIWS</span><br><span class="line"></span><br><span class="line">BUILT_SOURCES+&#x3D;giws</span><br><span class="line"></span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">if SWIG</span><br><span class="line"></span><br><span class="line">BUILT_SOURCES+&#x3D;swig</span><br><span class="line"></span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">GATEWAY_C_SOURCES &#x3D;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">GATEWAY_CXX_SOURCES &#x3D; \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_Xcos.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_warnBlockByUID.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_closeXcosFromScilab.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosCellCreated.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosUpdateBlock.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosDiagramToScilab.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosPalLoad.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosPalCategoryAdd.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosPalDelete.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosPalMove.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosPalEnable.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosPalDisable.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosPalGenerateIcon.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosPalGet.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosConfigureXmlFile.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosAddToolsMenu.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_loadXcos.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosDiagramToSiROS.cpp \</span><br><span class="line"></span><br><span class="line">​    sci_gateway&#x2F;cpp&#x2F;sci_xcosSimulationStarted.cpp</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">libscixcos_la_CPPFLAGS &#x3D; \</span><br><span class="line"></span><br><span class="line">  -I$(srcdir)&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(srcdir)&#x2F;src&#x2F;jni&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(srcdir)&#x2F;src&#x2F;cpp&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(srcdir)&#x2F;src&#x2F;c&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;scicos&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;scicos_blocks&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;scicos_blocks&#x2F;src&#x2F;jni&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;dynamic_link&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;string&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;ast&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;exps&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;operations&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;parse&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;symbol&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;system_env&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;types&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;analysis&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;threads&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;console&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;jvm&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;output_stream&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;commons&#x2F;src&#x2F;jni&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;localization&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;fileio&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;api_scilab&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  $(XML_FLAGS) \</span><br><span class="line"></span><br><span class="line">  $(JAVA_JNI_INCLUDE) \</span><br><span class="line"></span><br><span class="line">  $(AM_CPPFLAGS)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">\# Without the xcos module</span><br><span class="line"></span><br><span class="line">libscixcos_disable_la_CPPFLAGS &#x3D; \</span><br><span class="line"></span><br><span class="line">  -I$(srcdir)&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;ast&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;exps&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;operations&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;parse&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;symbol&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;system_env&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;ast&#x2F;includes&#x2F;types&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;localization&#x2F;includes&#x2F; \</span><br><span class="line"></span><br><span class="line">  -I$(top_srcdir)&#x2F;modules&#x2F;output_stream&#x2F;includes \</span><br><span class="line"></span><br><span class="line">  $(XML_FLAGS) \</span><br><span class="line"></span><br><span class="line">  $(AM_CPPFLAGS)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">XCOS_DISABLE_C_SOURCES &#x3D; src&#x2F;noxcos&#x2F;noxcos.c</span><br><span class="line"></span><br><span class="line">libscixcos_disable_la_SOURCES &#x3D; $(XCOS_DISABLE_C_SOURCES)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">pkglib_LTLIBRARIES &#x3D; libscixcos-disable.la</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">if XCOS</span><br><span class="line"></span><br><span class="line">if GUI</span><br><span class="line"></span><br><span class="line">noinst_LTLIBRARIES &#x3D; libscixcos-algo.la</span><br><span class="line"></span><br><span class="line">pkglib_LTLIBRARIES +&#x3D; libscixcos.la</span><br><span class="line"></span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">libscixcos_algo_la_SOURCES &#x3D; $(XCOS_C_SOURCES) $(XCOS_CXX_SOURCES)</span><br><span class="line"></span><br><span class="line">libscixcos_la_SOURCES &#x3D; $(GATEWAY_C_SOURCES) $(GATEWAY_CXX_SOURCES)</span><br><span class="line"></span><br><span class="line">libscixcos_algo_la_CPPFLAGS &#x3D; $(libscixcos_la_CPPFLAGS)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">\# For the code check (splint)</span><br><span class="line"></span><br><span class="line">CHECK_SRC&#x3D; $(XCOS_C_SOURCES) $(GATEWAY_C_SOURCES)</span><br><span class="line"></span><br><span class="line">INCLUDE_FLAGS &#x3D; $(libscixcos_la_CPPFLAGS)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">libscixcos_la_LIBADD &#x3D; libscixcos-algo.la \</span><br><span class="line"></span><br><span class="line">​       $(top_builddir)&#x2F;modules&#x2F;scicos&#x2F;libsciscicos.la \</span><br><span class="line"></span><br><span class="line">​       $(top_builddir)&#x2F;modules&#x2F;commons&#x2F;libscicommons.la \</span><br><span class="line"></span><br><span class="line">​       $(top_builddir)&#x2F;modules&#x2F;jvm&#x2F;libscijvm.la \</span><br><span class="line"></span><br><span class="line">​       $(LIBXML_LIBS)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">\#### xcos : gateway declaration ####</span><br><span class="line"></span><br><span class="line">libscixcos_la_sci_gatewaydir &#x3D; $(mydatadir)&#x2F;sci_gateway</span><br><span class="line"></span><br><span class="line">libscixcos_la_sci_gateway_DATA &#x3D; sci_gateway&#x2F;xcos_gateway.xml</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">\#### xcos : images files ####</span><br><span class="line"></span><br><span class="line">\#</span><br><span class="line"></span><br><span class="line">\# Generated with:</span><br><span class="line"></span><br><span class="line">\#  $ find images&#x2F; -type f -printf &quot;%p \\\\\n&quot; -name *.svg -or -name *.gif -or -name *.jpg -or -name *.png -not -name *_pal.jpg -not -name gui |sort |awk &#39;$0 !~ &#x2F;gui&#x2F;&#123;print;&#125;&#39; |awk &#39;$0 !~ &#x2F;_pal.jpg&#x2F;&#123;print;&#125;&#39;</span><br><span class="line"></span><br><span class="line">libscixcos_la_imagesdir&#x3D;$(mydatadir)&#x2F;</span><br><span class="line"></span><br><span class="line">nobase_libscixcos_la_images_DATA &#x3D; \</span><br><span class="line"></span><br><span class="line">images&#x2F;blocks&#x2F;3DSCOPE.svg \</span><br><span class="line"></span><br><span class="line">images&#x2F;blocks&#x2F;ANDBLK.svg \</span><br><span class="line"></span><br><span class="line">images&#x2F;icons&#x2F;16x16&#x2F;actions&#x2F;align-horizontal-center.png \</span><br><span class="line"></span><br><span class="line">images&#x2F;icons&#x2F;16x16&#x2F;actions&#x2F;align-horizontal-left.png \</span><br><span class="line"></span><br><span class="line">images&#x2F;palettes&#x2F;ABS_VALUE.png \</span><br><span class="line"></span><br><span class="line">images&#x2F;palettes&#x2F;AFFICH_m.png \</span><br><span class="line"></span><br><span class="line">...##省略一些重复的图片信息</span><br><span class="line"></span><br><span class="line">if XCOS</span><br><span class="line"></span><br><span class="line">if GUI</span><br><span class="line"></span><br><span class="line">USEANT&#x3D;1</span><br><span class="line"></span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">include $(top_srcdir)&#x2F;Makefile.incl.am</span><br><span class="line"></span><br><span class="line">\#&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br></pre></td></tr></table></figure><p>另外在添加或移除功能包时，亦需要修改</p><p>src/modules/Makefile.am</p><p>src/Makefile.am</p><p>src/configure.ac</p><p>这三项文件，然后在源码所在目录下的终端执行以下命令：</p><p><strong>[user@localhost src] autoconf</strong></p><p>此命令根据configure.ac生成configure文件</p><p><strong>[user@localhost src] automake</strong></p><p>此命令根据Makefile.am生成Makefile.in文件</p><p><strong>[user@localhost src] ./configure &amp;&amp; make &amp;&amp; make install</strong></p><p>此命令对源码进行重新编译。</p><h1 id="功能包与工具箱对比"><a href="#功能包与工具箱对比" class="headerlink" title="功能包与工具箱对比"></a>功能包与工具箱对比</h1><p>工具箱加载时，运行主构建器文件（builder.sce），由主构建器文件调用个文件夹中的构建器文件（builder_**.sce），分别生成各加载文件，等待各加载文件构建成功后，再加载主加载文件，将工具箱加载到Scilab平台。</p><p>Scilab工具箱的层次结构十分严谨，src文件夹内的函数需要与sci_gateway文件夹内的网关函数紧密对应；各文件夹内的builder文件（builder*.sce）需要与各自文件夹内的文件对应，尤其是src中的c文件和sci_gateway中的c文件。</p><p>实际上，功能包和工具箱的结构类似，实现的本质上是一样的。这是都是因为基于Scilab是一个模块化架构的软件。也就是说，功能包和工具箱是可以相互转化的。功能包可以按照工具箱的加载方式进行加载。工具箱也可以根据功能包的方式实现与Scilab内联，即成为Scilab基本的一部分。</p>]]></content>
      
      
      <categories>
          
          <category> Scilab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scilab 仿真云化改造 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scilab 云化改造(2)_XCOS 模块结构</title>
      <link href="2018/03/25/Xcos%E6%A8%A1%E5%9D%97%E7%BB%93%E6%9E%84/"/>
      <url>2018/03/25/Xcos%E6%A8%A1%E5%9D%97%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Scilab 在 Windows 下是以 bin 文件夹中 WScilex.exe 开始的，然后在进行初始化配置（包括选择模式、绘制界面、绑定相关按钮功能）后，调用相关的动态库（dll文件/由编译过程生成）完成所有的任务和功能。在 Linux 下运行亦相仿，启动文件为 bin 文件夹目录下的名为 scilab 的二进制可执行文件脚本，调用的动态库文件为.so文件</p><a id="more"></a><h2 id="XCOS-模块结构"><a href="#XCOS-模块结构" class="headerlink" title="XCOS 模块结构"></a>XCOS 模块结构</h2><p>按照 Scilab 官网上的一篇文章（<a href="https://wiki.scilab.org/ScilabWithinEclipse%EF%BC%89%E6%8F%90%E4%BE%9B%E7%9A%84%E6%AD%A5%E9%AA%A4%E8%BF%9B%E8%A1%8C%E5%90%8E%E7%BB%AD%E8%B0%83%E8%AF%95%E3%80%82%E4%B8%80%E5%85%B1%E5%AF%BC%E5%85%A5%E4%BA%8623%E4%B8%AA%E6%A8%A1%E5%9D%97%EF%BC%8C%E5%85%B6%E4%B8%AD">https://wiki.scilab.org/ScilabWithinEclipse）提供的步骤进行后续调试。一共导入了23个模块，其中</a> Xcos 需要 Scilab 中 10 个模块的依赖，分别是 <code>commons</code>、<code>localization</code>、<code>graph</code>、<code>types</code>、<code>gui</code>、<code>action_bindings</code>、<code>core</code>、<code>helptools</code>、<code>javasci</code> 及 <code>xcos</code></p><p>Scilab 中 Xcos 的依赖模块架构模型进行分解</p><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午1.18.11.png" alt="截屏2021-01-19 下午1.18.11" style="zoom:50%;" /><p>Scilab 中 Xcos 的依赖块有 10 个</p><p>**Model **类下有5个，分别是：</p><ol><li><code>commons</code>：软件运行过程时的一些相关[工具、接口]；</li><li><code>localization</code>：软件默认初始化相关参数；</li><li><code>graph</code>：软件运行过程中所生成，应用的图像，图片，图形；</li><li><code>types</code>：软件运行过程中的一些变量数据[enum，boolean，list，string等]；</li><li><code>xcos</code>：Xcos运行过程中的关键包，包含Xcos相关方法，接口，默认参数等。</li></ol><p>**View **类下只有1个：</p><p><code>gui</code>：实现人机交互的应用界面。 </p><p>**Controller **类下有4个，分别是：</p><ol><li><p><code>action_bindings</code>：为执行动作提供反馈或者接口；</p></li><li><p><code>core</code>：实现控制台指令和控制命令；</p></li><li><p><code>helptools</code>：链接到帮助文档，在线帮助，说明文档；</p></li><li><p><code>javasci</code>：调用Scilab，Sciab的相关操作及接口。</p></li></ol><p>xcos 模块是 Xcos 运行过程中的关键模块，Xcos 运行过程中的操作是由 xcos 模块的 java 源代码编译后实现的。通过把 Scilab 的 java 源代码导入到 eclipse，在 eclipse 的 package presentation 上选择用 Hierarchical 显示，即层次关系显示，就可以清楚地看到 xcos 模块的 java 源代码是由 14 个不同的子模块组成的。</p><p>这 14 个子模块是由 11 个大类及 3 个java文件组成的，分别是：<code>actions</code>、<code>block</code>、<code>configuration</code>、<code>graph</code>、<code>io</code>、<code>link</code>、<code>modelica</code>、<code>palette</code>、<code>port</code>、<code>preferences</code>、<code>utils</code>、<code>ViewPortTab.java</code>、<code>Xcos.java</code>、<code>XcosTab.java</code>。每个大类下又有若干个 <code>java</code> 文件。</p><p>xcos 模块的结构图如图所示：</p><img src="/Users/joker/Documents/chen_blog/source/images/clip_image004.png" alt="img" style="zoom:100%;" /><p>xcos 模块详细层次目录及各 java 文件的说明如下：</p><ul><li>Java 平台核心模块存放目录<ul><li>actions Xcos 菜单动作<ul><li>dialog 对话信息管理<ul><li>DebugLevelDialog.java 调试等级对话日志信息</li><li>SetContextDialog.java 设置关联数据对话日志信息</li><li>SetupDialog.java 仿真设置对话日志信息</li></ul></li></ul></li></ul></li></ul><p>​       1.1.2—AboutXcosAction.java Xcos的关于组件的生成及显示动作</p><p>​             —CloseAction.java 使用管理权限行使关闭组件动作指令</p><p>​             —CompileAction.java xcos的编译动作指令</p><p>​             —DebugLevelAction.java 调试等级指令动作响应</p><p>​             —DiagramBackgroundAction.java 图表背景颜色设置动作</p><p>​            —DumpAction.java 组件倾斜动作</p><p>—EditFromatAction.java 组件参数设置动作</p><p>—ExportAction.java 结果导出动作(当前组件仿真)</p><p>—ExportAllAction.java 结果导出动作(所有组件仿真)</p><p>—ExternalAction.java 引入外部组件动作</p><p>—FitDiagramToViewAction.java 组件大小调整动作响应</p><p>—InitModelicaAction.java 初始化Modelica编译动作指令</p><p>—NewDiagramAction.java 新建图表动作</p><p>—NormalViewAction.java 还原正常视图动作</p><p>—OpenAction.java 打开组件动作指令</p><p>—OpenInSciAction.java 在sci编辑器里打开sci文件</p><p>—PrintAction.java 打印动作</p><p>—QuitAction.java 关闭xcos动作指令</p><p>—RecentFileAction.java 最近处理过的文件显示</p><p>—SaveAction.java 保存当前仿真框图至默认目录</p><p>—SaveAsAction.java 将当前仿真框图另存至用户目录</p><p>—SetContextAction.java 关联数据到模块</p><p>—SetupAction.java 模块仿真设置</p><p>—ShowHideShadowAction.java 显示隐藏组件动作</p><p>—SimulationNotRunningAction.java 仿真运行标记动作</p><p>—StartAction.java 开始仿真指令</p><p>—StopAction0.java 停止仿真指令</p><p>—ViewDiagramBrowserAction.java 切换图表浏览窗口视图动作</p><p>—ViewGridAction.java 切换网格视图动作</p><p>—ViewViewportAction.java 视图窗口视图动作</p><p>—XcosDemonstrationsAction.java Xcos组件应用示范动作</p><p>—XcosDocumentationAction.java Xcos组件说明文档动作</p><p>1.2—block Xcos组件</p><p>​       1.2.1—action 模块动作</p><p>​          1.2.1.1—alignement 模块对齐</p><p>​              1.2.1.1.1—AlignBlockAction.java 模块对齐动作</p><p>​                  —AlignBlockActionBottom.java 模块底部对齐</p><p>​                  —AlignBlockActionCenter.java 模块中心对齐</p><p>​                  —AlignBlockActionLeft.java 模块左对齐</p><p>​                  —AlignBlockActionMiddle.java 模块居中对齐</p><p>​                  —AlignBlockActionRight.java 模块右对齐</p><p>​                  —AlignBlockActionTop.java 模块顶部对齐</p><p>​          1.2.1.2—BlockDocumentationAction.java 组件功能说明帮助</p><p>文档动作</p><p>​             —BlockParamtersAction.java 组件参数设置动作</p><p>​             —BorderColorAction.java 组件边界颜色变化动作</p><p>​             —CodeGenerationAction.java 代码自动生成动作</p><p>​             —FilledColorAction.java 填充组件颜色动作</p><p>​             —FlipAction.java 组件翻转动作</p><p>​             —MirrorAction.java 组件镜像翻转动作</p><p>​             —RegionToSuperblockAction.java 组件合并动作</p><p>​             —RotateAction.java 组件旋转动作</p><p>​             —ShowParentAction.java 显示父组件动作</p><p>​             —SuperblockMaskCreateAction.java 集合组件显示生成</p><p>​             —SuperblockMaskCustomizeAction.java 定制化集合组</p><p>件显示</p><p>​             —SuperblockMaskRemoveAction.java 移除集合组件显示</p><p>​             —SuperblockSelectedAction.java 集合组件被选中动作响应</p><p>​             —ViewDetailsAction.java 细节视图动作</p><p>​      1.2.2—io 数据输入输出</p><p>​          1.2.2.1—ContextUpdate.java 关联数据更新</p><p>​             —EventInBlock.java 组件输入事件</p><p>​             —EventOutBlock.java 组件输出事件</p><p>​             —ExplicitInBlock.java 组件显式输入</p><p>​             —ExplicitOutBlock.java 组件显式输出</p><p>​             —ImplicitInBlock.java 组件隐式输入</p><p>​             —ImplicitOutBlock.java 组件隐式输出</p><p>​       1.2.3—listener 监听</p><p>​          1.2.3.1—ProPortLabelingListener.java 分支标签端口监听</p><p>​             —SumPortLabelingListener.java 汇总标签端口监听</p><p>​       1.2.4—positionning 定位</p><p>​          1.2.4.1—BigSom.java 在实例实现SumPortLabelingListener</p><p>的连接(通过BIGSOM_f函数)</p><p>​             —GroundBlock.java  构造新的单输入组件</p><p>​             —Product.java 在实例实现与ProPortLabelingListener </p><p>的连接(通过PRODUCT_f函数)</p><p>​             —RoundBlock.java 实现一个有输入的循环组件</p><p>​             —Summation.java 在实例实现SumPortLabelingListener</p><p>的连接(通过SUMMATION函数) </p><p>​             —VoltageSensorBlock.java  构造新的多输入组件</p><p>​       1.2.5—AfficheBlock.java 实现一个可显示的组件</p><p>​         —BasicBlock.java 实现一个基本组件</p><p>​         —BlockFactory.java 组件的工厂设计模式</p><p>​         —SplitBlock.java 用于组件之间的相互连接</p><p>​         —SuperBlock.java 操作集合组件属性的方法</p><p>​         —TextBlock.java 用于注释的文本组件</p><p>   1.3—configuration 配置</p><p>​       1.3.1—model 模块</p><p>​          1.3.1.1—DocumentType.java 解析xml文件</p><p>​             —ObjectFactory.java 对象工厂化</p><p>​             —SettingType.java 修改或添加新的xml文件</p><p>​       1.3.2—utils 功能</p><p>​          1.3.2.1—ConfigurationConstants.java 常规配置类</p><p>​       1.3.3—ConfigurationManager.java    配置管理器类</p><p>1.4—graph 图表</p><p>​       1.4.1—swing Swing处理</p><p>​          1.4.1.1—handler</p><p>​               1.4.1.1.1—ConnectionHandler.java 用于处理多点链接的</p><p>连接处理程序</p><p>​                    —ConnectPreview.java 用于处理连接预览的程序</p><p>​                    —GraphHandler.java 用于处理双击图片的程序</p><p>​                    —SelectionCellsHandler.java 清除子处理程序释放内存</p><p>​          1.4.1.2—GraphComponent.java 实现Xcos与mxGraphComponent</p><p>的接口</p><p>​       1.4.2—CompilationEngineStatus.java 控制当前Scicos引擎的状态</p><p>​         —DiagramComparator.java 将所有图表按照距离根图表的距</p><p>离进行排序</p><p>​         —PaletteDiagram.java 组件图设置</p><p>​         —ScicosParameters.java Scicos参数设置</p><p>​         —SuperBlockDiagram.java 集合组件图表设置</p><p>​         —XcosDiagram.java Xcos图表及参数设置</p><p>   1.5—io 输入输出</p><p>​       1.5.1—codec 自动编码</p><p>​          1.5.1.1—BasicBlockCodec.java 基本组件代码</p><p>​             —BasicLinkCodec.java 基本链接代码</p><p>​             —BasicPortCodec.java 端口连接代码</p><p>​             —OrientationCodec.java 连接方向代码</p><p>​             —XcosCodec.java 注册Xcos使用的所有软件包，用于</p><p>序列化/反序列化</p><p>​             —XcosDiagramCodec.java 将例程与XcosDiagram连接</p><p>​             — XcosObjectCodec.java Xcos实例化对象代码      </p><p>​       1.5.2—scicos Scicos方法</p><p>​          1.5.2.1—AbstractElement.java 为一些抽象类提供方法</p><p>​             —BasicBlockInfo.java 将基本对象个性化</p><p>​        —BlockElement.java 在Scicos和Xcos之间执行块转换</p><p>​             —BlockGraphicElement.java 将对象进行包装保护(Graphic化)</p><p>​             —BlockModelElement.java 将对象进行包装保护(Model化)</p><p>​             —BlockPartsElement.java 为组件对象提供公共方法</p><p>​             —DiagramElement.java 在Scicos和Xcos之间执行图表</p><p>转换</p><p>​             —Element.java 为所有读/写scicos元素的元素对象提供</p><p>方法</p><p>​             —Handler.java 处理Xcos相关的属性</p><p>​             —InputPortElement.java 处理Scicos与Xcos之间输入</p><p>端口的转化</p><p>​             —LableElement.java 处理Scicos与Xcos之间属性标签</p><p>的转化</p><p>​             —LinkElement.java 处理Scicos与Xcos之间连接的转化</p><p>​             —OutputPortElement.java 处理Scicos与Xcos之间输出</p><p>端口的转化</p><p>​             —ScicosFormatException.java 用于处理Scicos元素默</p><p>认的抛出异常</p><p>​               —ScicosParametersElement.java 用于处理Scicos元素</p><p>默认的仿真参数</p><p>​             —ScilabDirectHandler.java 处理Scilab数据的直接访问</p><p>​       1.5.3—spec 规范</p><p>​          1.5.3.1—ContentEntry.java 用于处理特殊压缩文件内容</p><p>​             —DictionaryEntry.java 用于处理特殊压缩文件的地址</p><p>和文件清单</p><p>​             —Entry.java 从Xcos包中加载/储存ZipEntry文件</p><p>​             —XcosPackage.java 用于处理标准.zip格式的Xcos文件</p><p>​       1.5.4—XcosFileType.java 所有可被Xcos识别的文件类型</p><p>   1.6—link 连接</p><p>​       1.6.1—actions 动作</p><p>​          1.6.1.1—StyleAction.java 转换连接类型的基础类</p><p>​             —StyleHorizontalAction.java 设置水平连接动作</p><p>​        —StyleStraightAction.java 设置横向连接动作</p><p>​             —StyleVerticalAction.java 设置垂直连接动作</p><p>​             —TextAction.java 为连接设置文本说明</p><p>​       1.6.2—commandcontrol  指令控制</p><p>​          1.6.2.1—CommandControlLink.java 为控制端口和指令端口提</p><p>供连接</p><p>​       1.6.3—explicit 显式连接</p><p>​          1.6.3.1—ExplicitLink.java 为显式连接的输入输出提供连接</p><p>​       1.6.4—implicit 隐式连接</p><p>​          1.6.4.1—ImplicitLink.java 为隐式连接的输入输出提供连接</p><p>​       1.6.5—BasicLink.java 连接基础类</p><p>​          —LinkPortMap.java 枚举用于从ids获取链接和端口类</p><p>   1.7—modelica  Modelica语法规则</p><p>​       1.7.1—listener 监听类</p><p>​          1.7.1.1—FixDerivativesAction.java 规定当前模块的衍生类</p><p>​            —FixStatesAction.java 规定当前模块的动作状态</p><p>​             —SolveAction.java 模型求解</p><p>​             —StatisticsUpdater.java 当前模块在表事件改变时更</p><p>新统计信息</p><p>​       1.7.2—model 模块</p><p>​          1.7.2.1—Info.java 规定所有参数,状态,输入和输出的数据类</p><p>型和大小</p><p>​             —Model.java Modelica建模树状图</p><p>​             —ModelicaValue.java Modelica指定字符串</p><p>​             —ObjectFactory.java 对象工厂化公用方法</p><p>​             —Output.java 以Modelica的规范输出</p><p>​             —Struct.java 内容结构的部分树状化(并非节点分支)</p><p>​             —Terminal.java 结构化树的终端节点(总是节点分支)</p><p>​       1.7.3—view 视图</p><p>​          1.7.3.1—LableWithValue.java 具有坐标轴和标题的面板</p><p>​             —MainPanel.java Modelica模型的主要视图的初始化</p><p>​       1.7.4—Modelica.java 模型操作的主要类</p><p>​         —ModelicaController.java 用接口封装的模型控制器</p><p>​         —ModelicaMessages.java 包含当前包及子包的本地信息</p><p>​         —ModelStatistics.java 模型的函数统计</p><p>​         —TerminalAccessor.java 访问Terminal列表模型</p><p>​         —TerminalTableModel.java 建立Terminal列表模型</p><p>   1.8—palette 组件盘</p><p>​       1.8.1—actions 动作</p><p>​          1.8.1.1—ClosePalettesAction.java 关闭组件盘</p><p>​             —LoadAsPalAction.java 加载组件盘</p><p>​             —NewPaletteAction.java 新建组件盘</p><p>​             —ViewPaletteBrowserAction.java 组件盘浏览器视图动作，</p><p>管理组件盘选项卡</p><p>​       1.8.2—listener 监听</p><p>​          1.8.2.1—PaletteBlockMouseListener.java 组件盘组件的鼠标</p><p>操作监听</p><p>—PaletteManagerMouseListener.java 组件盘管理器的鼠标操作监听</p><p>​             —PaletteManagerTreeSelectionListener.java 监听组件盘组件</p><p>树管理被选中</p><p>​             —PaletteTreeTransferHandler.java 处理组件盘组件树</p><p>​       1.8.3—model 模块</p><p>​          1.8.3.1—Category.java 可包含子组件的父组件集合</p><p>​             —Custom.java 组件盘加载自定义组件图形</p><p>​             —ObjectFactory.java 对象工厂化实例通用方法</p><p>​             —Palette.java 在主视图中组件盘的显示</p><p>​             —PaletteBlock.java在主视图中组件(函数化)的图形显示</p><p>​             —PaletteNode.java 组件盘标记语言的Java类化</p><p>​             —PreLoaded.java 通过连接组件信息文件在组件盘中进</p><p>行预加载组件</p><p>​             —VariablePath.java 实时计算所需文件的绝对路径</p><p>​       1.8.4—view 视图</p><p>​          1.8.4.1—ModifiedFlowLayout.java 改良后的流动布局类(可在</p><p>JScrollPane中运行)</p><p>​             —PaletteBlockView.java 组件视图</p><p>​             —PaletteComponent.java 自定义默认组件</p><p>​             —PaletteConfiguratorListView.java 组件列表布局配置</p><p>​             —PaletteManagerPanel.java 组件盘窗口视图</p><p>​             —PaletteManagerView.java 实现组件的默认视图</p><p>​             —PaletteTreeModel.java 将组件节点绑定在处理启用标                                       志的特定模型上。</p><p>​             —PaletteView.java 实现组件块的视图</p><p>​       1.8.5—Palette.java 组件类</p><p>​         —PaletteBlockCtrl.java 用于在工作区上加载或放置组件</p><p>​         —PaletteManager.java 组件管理的主类</p><p>​         —PreLoadedElement.java 连接到预加载的组件时对组件进行解码</p><p>​         —StyleElement.java 对放置在工作区的组件进行解码</p><p>   1.9—port 端口</p><p>​       1.9.1—command 指令</p><p>​          1.9.1.1—CommandPort.java 用于将指令传达到受控的组件</p><p>​       1.9.2—control 控制</p><p>​          1.9.2.1—ControlPort.java 用于控制受控的组件</p><p>​       1.9.3—input 输入</p><p>​          1.9.3.1—ExplicitInputPort.java 显式输入端口公用方法</p><p>​             —ImplicitInputPort.java 隐式输入端口公用方法</p><p>​             —InputPort.java 输入端口(用于连接组件与内连函数)</p><p>​       1.9.4—output 输出</p><p>​          1.9.4.1— ExplicitOutputPort.java 显式输出端口公用方法</p><p>​             —ImplicitOutputPort.java 隐式输出端口公用方法</p><p>​             —OutputPort.java 输出端口(用于连接组件与内连函数)</p><p>​       1.9.5—BasicPort.java 端口的公共基础类</p><p>​         —Orientation.java 端口默认方向</p><p>​         —PortCheck.java 依据规则检查端口连接是否正确</p><p>   1.10—preferences 综合</p><p>​       1.10.1—XcosConfiguration.java Xcos的相关配置类</p><p>​          —XcosKeyMap.java Xcos的所有类的集合</p><p>​          —XcosOptions.java Xcos选项设置</p><p>   1.11—utils 功能</p><p>​       1.11.1—BlockChange.java 改变组件块</p><p>​          —BlockPositioning.java 组件块端口放置帮助类</p><p>​          —FileUtils.java 包含文件的一般处理</p><p>​          —PaletteComponent.java 默认组件盘样式</p><p>​          —XcosConstants.java 包含所有应用的默认常量</p><p>​          —XcosDelegates.java 包含Xcos所有引用的其他模块的函数</p><p>​          —XcosDialogs.java Xcos标准的对话框样式</p><p>​          —XcosEvent.java 所有Xcos的事件</p><p>​          —XcosMessages.java 所有Xcos要用到的本地化信息</p><p>   1.12—ViewPortTab.java Xcos的视图操作</p><p>   1.13—Xcos.java Xcos的入口类</p><p>   1.14—XcosTab.java Xcos的界面设计与事件动作绑定</p>]]></content>
      
      
      <categories>
          
          <category> Scilab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scilab 仿真云化改造 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cloudera平台搭建</title>
      <link href="2018/03/15/Cloudera%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/"/>
      <url>2018/03/15/Cloudera%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>数据集群包含两台专业服务器，通过XenServer服务器虚拟化软件把两台专业服务器虚拟化为五台虚拟服务器(1个master和4个slave)；五台虚拟服务器都安装了<code>CentOS7(Linux)</code>操作系统，在此基础上安装了 <code>Java</code>、<code>C/C++</code>、<code>Scala</code>等基本开发工具，以及<code>Hadoop(HDFS,YARN)</code>、<code>MySQL</code>、<code>ZooKeeper</code>、<code>Kafka</code> 、<code>Spark2</code></p><a id="more"></a><h1 id="1-服务器环境准备"><a href="#1-服务器环境准备" class="headerlink" title="1.服务器环境准备"></a>1.服务器环境准备</h1><h2 id="1-1-服务器环境概述"><a href="#1-1-服务器环境概述" class="headerlink" title="1.1 服务器环境概述"></a>1.1 服务器环境概述</h2><p><code>Hbase</code>、<code>Spark</code>等数据集群必须的大数据存储及处理软件。数据集群需要安装的软件及其层次关系如表1.1所示。数据集群除了安装 Hadoop、Spark、Hbase 等组件外，在 Master 节点和 data1 节点安装了 MySQL 数据库。</p><table><thead><tr><th>主机</th><th>所在服务器</th><th>密码</th></tr></thead><tbody><tr><td>192.168.10.96</td><td>192.168.10.90</td><td>123456</td></tr><tr><td>192.168.10.98</td><td>192.168.10.90</td><td>123456</td></tr><tr><td>192.168.10.100</td><td>192.168.10.90</td><td>123456</td></tr><tr><td>192.168.10.102</td><td>192.168.10.120</td><td>123456</td></tr><tr><td>192.168.10.104</td><td>192.168.10.120</td><td>123456</td></tr></tbody></table><h2 id="1-2-关闭防火墙"><a href="#1-2-关闭防火墙" class="headerlink" title="1.2 关闭防火墙"></a>1.2 关闭防火墙</h2><p>关闭五台虚拟主机防火墙，分别在主机上执行以下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br></pre></td></tr></table></figure><h2 id="1-3-关闭-selinux"><a href="#1-3-关闭-selinux" class="headerlink" title="1.3 关闭 selinux"></a>1.3 关闭 selinux</h2><p>三台机器在 root 用户下执行以下命令关闭 selinux</p><p>三台机器执行以下命令，关闭</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">selinuxvim /etc/selinux/config </span><br><span class="line"></span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure><h2 id="1-4-时间服务器"><a href="#1-4-时间服务器" class="headerlink" title="1.4 时间服务器"></a>1.4 时间服务器</h2><p>网络时间协议 <code>NTP(Network Time Protocol)</code>，可以用来同步网络中各个计算机的时间。<code>CentOS7</code>自带了<code>ntp</code>服务，这个服务不仅可以设置让本机和其他计算机做时间同步，还可以让本机扮演一个<code>time server</code>的角色，让局域网其他计算机和本机同步时间。修改配置文件<code>/etc/ntp.conf</code>可以把一台计算机设置为时间服务器，或与其他服务器同步时间。</p><p>以下设置<code>master</code> 为时间服务器，其他计算机 <code>(data1~data4)</code> 和 <code>master</code> 实现时间同步。以下以 <code>data1</code> (IP地址<code>192.168.10.98</code>)为例，介绍 <code>slave</code>  与 <code>master</code> 做时间同步。</p><h3 id="1-4-1-设置-master-基准时间"><a href="#1-4-1-设置-master-基准时间" class="headerlink" title="1.4.1 设置 master 基准时间"></a>1.4.1 设置 <code>master</code> 基准时间</h3><p>配置 <code>master</code> 做 <code>time server</code> ,<code>master</code> 本身不和其他机器时间同步，而是取本地硬件时间。所以，需要先把<code>master</code> 机器的时间调整准确。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master~] date -s 09/13/2017         //设定日期 </span><br><span class="line">[root@master~] date -s 11:12:00          //设定时间</span><br><span class="line">[root@master~] clock -w</span><br><span class="line">[root@master~] hwclock -w</span><br></pre></td></tr></table></figure><h3 id="1-4-2-设置-master-为时间服务器"><a href="#1-4-2-设置-master-为时间服务器" class="headerlink" title="1.4.2 设置 master 为时间服务器"></a>1.4.2 <strong>设置</strong> <code>master</code> 为时间服务器</h3><p>将master配置成一个time server，需要修改/etc/ntp.conf。</p><p>如果master连接Internet，则master可以与以下“上级时间服务器”进行同步。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">server 0.centos.pool.ntp.org iburst     </span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line">server 3.centos.pool.ntp.org </span><br></pre></td></tr></table></figure><h3 id="1-4-3-允许本机-ntpd-和本地硬件时间同步"><a href="#1-4-3-允许本机-ntpd-和本地硬件时间同步" class="headerlink" title="1.4.3. 允许本机 ntpd 和本地硬件时间同步"></a>1.4.3. 允许本机 <code>ntpd</code> 和本地硬件时间同步</h3><p>如果master与上级服务器同步失败，或master没有连接Internet，则和本地硬件时间同步。把以下带下划线内容添加到“上级服务器”的后面。如果master与上级服务器同步失败，和本地硬件时间同步。如图7-1所示。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure><h2 id="7-5-关闭chronyd"><a href="#7-5-关闭chronyd" class="headerlink" title="7.5 关闭chronyd"></a>7.5 关闭chronyd</h2><p><code>chronyd</code>也是与时间相关的服务，设置为开机自启动，这个服务会导致<code>ntp</code>无法开启开机自启动，所以需要关闭该进程。时间服务器和客户机都要关闭。</p><ul><li>查看<code>chronyd</code>状态</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~] systemctl status chronyd </span><br></pre></td></tr></table></figure><ul><li>关闭<code>chronyd</code>服务</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~] systemctl <span class="built_in">disable</span> chronyd.service  </span><br></pre></td></tr></table></figure><h2 id="7-6-CentOS7-设置开机自启动-ntp-服务"><a href="#7-6-CentOS7-设置开机自启动-ntp-服务" class="headerlink" title="7.6  CentOS7 设置开机自启动 ntp 服务"></a>7.6  <code>CentOS7</code> 设置开机自启动 <code>ntp</code> 服务</h2><p>局域网时间服务器和客户机都应启动开机自启动<code>ntp</code>服务。</p><ul><li>设置<code>master</code>开机自启动<code>ntp</code>服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~] systemctl enable ntpd.service </span><br></pre></td></tr></table></figure><ul><li>查看<code>ntpd</code>状态</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~] systemctl status ntpd  </span><br></pre></td></tr></table></figure><ul><li>设置<code>data1</code>开机自启动<code>ntp</code>服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@data1 ~] systemctl enable ntpd.service </span><br></pre></td></tr></table></figure><ul><li>查看<code>ntpd</code>状态</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@data1 ~] systemctl status ntpd</span><br></pre></td></tr></table></figure><h2 id="1-4-更改主机名"><a href="#1-4-更改主机名" class="headerlink" title="1.4 更改主机名"></a>1.4 更改主机名</h2><p>五台机器分别更改主机名</p><table><thead><tr><th>主机</th><th>主机名</th></tr></thead><tbody><tr><td>192.168.10.96</td><td>master</td></tr><tr><td>192.168.10.98</td><td>data1</td></tr><tr><td>192.168.10.100</td><td>data2</td></tr><tr><td>192.168.10.102</td><td>data3</td></tr><tr><td>192.168.10.104</td><td>data4</td></tr></tbody></table><h2 id="1-6-安装-JDK"><a href="#1-6-安装-JDK" class="headerlink" title="1.6 安装 JDK"></a>1.6 安装 JDK</h2><h3 id="1-6-1-卸载-JDK1-8"><a href="#1-6-1-卸载-JDK1-8" class="headerlink" title="1.6.1 卸载 JDK1.8"></a>1.6.1 卸载 JDK1.8</h3><blockquote><p>Centos 默认安装了  JDK1.8 ,但 JDK1.8 的可执行文件和众多库文件分布在不同目录下。给hadoop环境变量设置造成很多不便。因此，建议卸载系统默认安装的 JDK1.8 </p></blockquote><ul><li>查看 jdk 版本信息</li><li>查看已安装 jdk 组件</li><li>卸载 jdk 及其组件</li></ul><h3 id="1-6-2-重新安装-JDK1-8"><a href="#1-6-2-重新安装-JDK1-8" class="headerlink" title="1.6.2 重新安装 JDK1.8"></a>1.6.2 重新安装 JDK1.8</h3><ul><li><p>解压 jdk1.8</p></li><li><p>安装 jdk1.8</p></li><li><p>修改配置文件</p><ul><li><p>配置环境变量</p></li><li><p>使环境变量生效</p></li></ul></li></ul><h1 id="2-准备cloudera安装包"><a href="#2-准备cloudera安装包" class="headerlink" title="2.准备cloudera安装包"></a>2.准备cloudera安装包</h1><h2 id="2-1-Cloudera-Manager-5"><a href="#2-1-Cloudera-Manager-5" class="headerlink" title="2.1 Cloudera Manager 5"></a>2.1 Cloudera Manager 5</h2><blockquote><p>文件名: cloudera-manager-centos7-cm5.14.0_x86_64.tar.gz</p><p>下载地址: <a href="https://archive.cloudera.com/cm5/cm/5/">https://archive.cloudera.com/cm5/cm/5/</a></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">由于是离线部署，因此需要预先下载好需要的文件。</span><br><span class="line">需要准备的文件有:</span><br><span class="line"></span><br><span class="line">Cloudera Manager 5</span><br><span class="line">文件名: cloudera-manager-centos7-cm5.14.0_x86_64.tar.gz</span><br><span class="line">下载地址: https://archive.cloudera.com/cm5/cm/5/</span><br><span class="line">CDH安装包（Parecls包）</span><br><span class="line">版本号必须与Cloudera Manager相对应</span><br><span class="line">下载地址: https://archive.cloudera.com/cdh5/parcels/5.14.0/</span><br><span class="line">需要下载下面3个文件：</span><br><span class="line">CDH-5.14.0-1.cdh5.14.0.p0.23-el7.parcel</span><br><span class="line">CDH-5.14.0-1.cdh5.14.0.p0.23-el7.parcel.sha1</span><br><span class="line">manifest.json</span><br><span class="line">MySQL jdbc驱动</span><br><span class="line">文件名: mysql-connector-java-.tar.gz</span><br><span class="line">下载地址: https://dev.mysql.com/downloads/connector/j/</span><br><span class="line">解压出: mysql-connector-java-bin.jar</span><br></pre></td></tr></table></figure><h1 id="4-所有机器安装依赖包"><a href="#4-所有机器安装依赖包" class="headerlink" title="4.所有机器安装依赖包"></a>4.所有机器安装依赖包</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install chkconfig python bind-utils psmisc libxslt zlib sqlite cyrus-sasl-plain cyrus-sasl-gssapi fuse portmap fuse-libs redhat-lsb</span><br></pre></td></tr></table></figure><h1 id="5-安装mysql数据库"><a href="#5-安装mysql数据库" class="headerlink" title="5.安装mysql数据库"></a>5.安装mysql数据库</h1><p>在第二台机器上(随机选择的机器，计划在第一台机器上安装cloudera管理服务比较耗费资源,所以在第二台机器上安装mysql数据库)安装mysql数据库.</p><p>参考【MySQL安装之yum安装教程】</p><h1 id="6-安装cloudera服务端"><a href="#6-安装cloudera服务端" class="headerlink" title="6.安装cloudera服务端"></a>6.安装cloudera服务端</h1><h2 id="6-1-解压服务端管理安装包"><a href="#6-1-解压服务端管理安装包" class="headerlink" title="6.1 解压服务端管理安装包"></a>6.1 解压服务端管理安装包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">所有节点上传cloudera-manager-centos7-cm5.14.0_x86_64.tar.gz文件并解压</span></span><br><span class="line">[root@node01 ~]# tar -zxvf cloudera-manager-centos7-cm5.14.2_x86_64.tar.gz -C /opt</span><br><span class="line">[root@node02 ~]# tar -zxvf cloudera-manager-centos7-cm5.14.2_x86_64.tar.gz -C /opt</span><br><span class="line">[root@node03 ~]# tar -zxvf cloudera-manager-centos7-cm5.14.2_x86_64.tar.gz -C /opt</span><br></pre></td></tr></table></figure><p>解压完可以在/opt目录下看到文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~]# cd /opt/</span><br><span class="line">[root@node01 opt]# ll</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x. 4 1106 4001 36 Apr  3  2018 cloudera</span><br><span class="line">drwxr-xr-x. 9 1106 4001 88 Apr  3  2018 cm-5.14.2</span><br><span class="line">[root@node01 opt]# cd cloudera/</span><br><span class="line">[root@node01 cloudera]# ll</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x. 2 1106 4001 6 Apr  3  2018 csd</span><br><span class="line">drwxr-xr-x. 2 1106 4001 6 Apr  3  2018 parcel-repo</span><br><span class="line">[root@node01 cloudera]# </span><br></pre></td></tr></table></figure><h2 id="6-2-创建客户端运行目录"><a href="#6-2-创建客户端运行目录" class="headerlink" title="6.2 创建客户端运行目录"></a>6.2 创建客户端运行目录</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">所有节点手动创建文件夹</span></span><br><span class="line">[root@node01 ~]# mkdir /opt/cm-5.14.2/run/cloudera-scm-agent</span><br><span class="line">[root@node02 ~]# mkdir /opt/cm-5.14.2/run/cloudera-scm-agent</span><br><span class="line">[root@node03 ~]# mkdir /opt/cm-5.14.2/run/cloudera-scm-agent</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="6-3-创建cloudera-scm用户"><a href="#6-3-创建cloudera-scm用户" class="headerlink" title="6.3 创建cloudera-scm用户"></a>6.3 创建cloudera-scm用户</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">所有节点创建cloudera-scm用户</span></span><br><span class="line">useradd --system --home=/opt/cm-5.14.0/run/cloudera-scm-server --no-create-home --shell=/bin/false --comment &quot;Cloudera SCM User&quot; cloudera-scm</span><br></pre></td></tr></table></figure><h2 id="6-4-初始化数据库"><a href="#6-4-初始化数据库" class="headerlink" title="6.4 初始化数据库"></a>6.4 初始化数据库</h2><p>初始化数据库（只需要在Cloudera Manager Server节点执行）</p><p>将提供的msyql驱动包上传到第一台机器的root home目录下，然后将mysql jdbc驱动放入相应位置:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~]# cp mysql-connector-java.jar /opt/cm-5.14.2/share/cmf/lib/</span><br><span class="line">[root@node01 ~]#  /opt/cm-5.14.2/share/cmf/schema/scm_prepare_database.sh mysql -h node02 -uroot -p&#x27;!Qaz123456&#x27; --scm-host node01 scm scm &#x27;!Qaz123456&#x27;    </span><br><span class="line">JAVA_HOME=/usr/java/jdk1.8.0_211-amd64</span><br><span class="line">Verifying that we can write to /opt/cm-5.14.2/etc/cloudera-scm-server</span><br><span class="line">Creating SCM configuration file in /opt/cm-5.14.2/etc/cloudera-scm-server</span><br><span class="line">Executing:  /usr/java/jdk1.8.0_211-amd64/bin/java -cp /usr/share/java/mysql-connector-java.jar:/usr/share/java/oracle-connector-java.jar:/opt/cm-5.14.2/share/cmf/schema/../lib/* com.cloudera.enterprise.dbutil.DbCommandExecutor /opt/cm-5.14.2/etc/cloudera-scm-server/db.properties com.cloudera.cmf.db.</span><br><span class="line">[                          main] DbCommandExecutor              INFO  Successfully connected to database.</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">显示初始化成功</span></span><br><span class="line">All done, your SCM database is configured correctly!</span><br><span class="line">[root@node01 ~]# </span><br></pre></td></tr></table></figure><p>脚本参数说明:<br>${数据库类型} -h ${数据库所在节点ip/hostname} -u${数据库用户名} -p${数据库密码} –scm-host ${Cloudera Manager Server节点ip/hostname} scm(数据库)  scm(用户名) scm(密码)</p><h2 id="6-5-修改所有节点客户端配置"><a href="#6-5-修改所有节点客户端配置" class="headerlink" title="6.5 修改所有节点客户端配置"></a>6.5 修改<strong>所有节点</strong>客户端配置</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">将其中的server_host参数修改为Cloudera Manager Server节点的主机名</span></span><br><span class="line">[root@node01 ~]# vi /opt/cm-5.14.2/etc/cloudera-scm-agent/config.ini</span><br><span class="line">[root@node01 ~]# vi /opt/cm-5.14.2/etc/cloudera-scm-agent/config.ini </span><br><span class="line">[General]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将默认的server_host=localhost 修改成node01</span></span><br><span class="line">server_host=node01</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="6-6-上传CDH安装包"><a href="#6-6-上传CDH安装包" class="headerlink" title="6.6 上传CDH安装包"></a>6.6 上传CDH安装包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">将如下文件放到Server节点的/opt/cloudera/parcel-repo/目录中:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">CDH-5.14.2-1.cdh5.14.2.p0.3-el7.parcel</span></span><br><span class="line"><span class="meta">#</span><span class="bash">CDH-5.14.2-1.cdh5.14.2.p0.3-el7.parcel.sha1</span></span><br><span class="line"><span class="meta">#</span><span class="bash">manifest.json</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重命名sha1文件</span></span><br><span class="line">[root@node01 parcel-repo]# mv CDH-5.14.2-1.cdh5.14.2.p0.3-el7.parcel.sha1 CDH-5.14.2-1.cdh5.14.2.p0.3-el7.parcel.sha</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="6-7-更改安装目录用户组权限"><a href="#6-7-更改安装目录用户组权限" class="headerlink" title="6.7 更改安装目录用户组权限"></a>6.7 更改安装目录用户组权限</h2><p><strong>所有节点</strong>更改cm相关文件夹的用户及用户组</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~]# chown -R cloudera-scm:cloudera-scm /opt/cloudera</span><br><span class="line">[root@node01 ~]# chown -R cloudera-scm:cloudera-scm /opt/cm-5.14.2</span><br><span class="line">[root@node01 ~]# </span><br></pre></td></tr></table></figure><h2 id="6-8-启动Cloudera-Manager和agent"><a href="#6-8-启动Cloudera-Manager和agent" class="headerlink" title="6.8 启动Cloudera Manager和agent"></a>6.8 启动Cloudera Manager和agent</h2><p>Server(node01)节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~]# /opt/cm-5.14.2/etc/init.d/cloudera-scm-server start</span><br><span class="line">Starting cloudera-scm-server:                              [  OK  ]</span><br><span class="line">[root@node01 ~]# /opt/cm-5.14.2/etc/init.d/cloudera-scm-agent start </span><br><span class="line">Starting cloudera-scm-agent:                               [  OK  ]</span><br><span class="line">[root@node01 ~]# </span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="7-服务安装"><a href="#7-服务安装" class="headerlink" title="7.服务安装"></a>7.服务安装</h1><p>使用浏览器登录cloudera-manager的web界面,用户名和密码都是admin</p><p><img src="assets/1570789521954.png" alt="1570789521954"></p><p>登陆之后，在协议页面勾选接受协议,点击继续</p><p><img src="assets/1570790224972.png" alt="1570790224972"></p><p>选择免费版本，免费版本已经能够满足我们日常业务需求,选择免费版即可.点击继续</p><p><img src="assets/1570790460382.png" alt="1570790460382"></p><p>如下图，点击继续</p><p><img src="assets/1570790639728.png" alt="1570790639728"></p><p>如下图，点击当前管理的机器，然后选择机器，点击继续</p><p><img src="assets/1570790871033.png" alt="1570790871033"></p><p>如下图，然后选择你的parcel对应版本的包</p><p><img src="assets/1570790984431.png" alt="1570790984431"></p><p>点击后，进入安装页面，稍等片刻</p><p>如下图，集群安装中 </p><p><img src="assets/1570791090600.png" alt="1570791090600"></p><p>如下图，安装包分配成功，点击继续</p><p><img src="assets/1570793156892.png" alt="1570793156892"></p><p><img src="assets/1570793245342.png" alt="1570793245342"></p><p>针对这样的警告，需要在每一台机器输入如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;defrag</span><br><span class="line">echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled</span><br><span class="line">echo &#39;vm.swappiness&#x3D;10&#39;&gt;&gt; &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line">sysctl vm.swappiness&#x3D;10</span><br></pre></td></tr></table></figure><p>如下图，然后点击重新运行，不出以为，就不会在出现警告了，点击完成,进入hadoop生态圈服务组件的安装</p><p><img src="assets/1570793435494.png" alt="1570793435494"></p><p>如下图，选择自定义服务，我们先安装好最基础的服务组合。那么在安装之前，如果涉及到hive和oozie的安装，那么先去mysql中，自己创建数据库，并赋予权限；</p><p>因此：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> hive;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> oozie;</span><br><span class="line"></span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> hive <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">&#x27;!Qaz123456&#x27;</span>;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> oozie <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">&#x27;!Qaz123456&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果出现如下错误:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> grant all on *.* to oozie identified by <span class="string">&#x27;!Qaz123456&#x27;</span>;</span></span><br><span class="line">ERROR 1045 (28000): Access denied for user &#x27;root&#x27;@&#x27;localhost&#x27; (using password: YES)</span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> update mysql.user <span class="built_in">set</span> Grant_priv=<span class="string">&#x27;Y&#x27;</span>,Super_priv=<span class="string">&#x27;Y&#x27;</span> <span class="built_in">where</span> user = <span class="string">&#x27;root&#x27;</span> and host = <span class="string">&#x27;localhost&#x27;</span>;</span></span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> flush privileges;</span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> quit</span></span><br><span class="line">Bye</span><br><span class="line">You have new mail in /var/spool/mail/root</span><br><span class="line">[root@node02 ~]# systemctl restart mysqld.service</span><br><span class="line">[root@node02 ~]# mysql -u root -p                </span><br><span class="line">Enter password: </span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 3</span><br><span class="line">Server version: 5.7.27 MySQL Community Server (GPL)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> grant all on *.* to hive identified by <span class="string">&#x27;!Qaz123456&#x27;</span>;</span></span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> grant all on *.* to oozie identified by <span class="string">&#x27;!Qaz123456&#x27;</span>;</span></span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> </span></span><br></pre></td></tr></table></figure><p>这样再安装软件！</p><p>那么，选择自定义服务,如果我们后续需要其他服务时我们在进行添加</p><p><img src="assets/1570795590845.png" alt="1570795590845"></p><p>然后点击继续，进入选择服务添加分配页面，分配即可</p><p><img src="assets/1570795837600.png" alt="1570795837600"></p><p>选择完成后服务，如下图,可以点击按照主机查看服务分部情况</p><p><img src="assets/1570795867075.png" alt="1570795867075"></p><p><img src="assets/1570795808683.png" alt="1570795808683"></p><p>点击继续后，如下图，输入mysql数据库中数数据库scm，用户名scm，密码!Qaz123456,点击测试连接，大概等30s，显示成功，点击继续</p><p><img src="assets/1570796013065.png" alt="1570796013065"></p><p>一路点击继续,剩下的就是等待</p><p><img src="assets/1570796339035.png" alt="1570796339035"></p><p>如上图，如果等待时间过长，我们可以将manager所在机器(也就是node01)停止后把内存调整的大一些建议如果是笔记本4g以上，如果是云环境8g以上，我们这里先调整为4g以上，重新启node01机器后重新启动cloudera的server和agent</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~]# cd /opt/cm-5.14.2/etc/init.d</span><br><span class="line"><span class="meta">#</span><span class="bash">启动server</span></span><br><span class="line">[root@node01 init.d]# ./cloudera-scm-server start</span><br><span class="line"><span class="meta">#</span><span class="bash">启动agent</span></span><br><span class="line">[root@node01 init.d]# ./cloudera-scm-agent start</span><br></pre></td></tr></table></figure><h1 id="8-重新登录cloudera-manager"><a href="#8-重新登录cloudera-manager" class="headerlink" title="8.重新登录cloudera manager"></a>8.重新登录cloudera manager</h1><p>登录成功后，如下图，重新启动集群,接下来就是等待.</p><p><img src="assets/1570799640007.png" alt="1570799640007"></p><h1 id="9-集群测试"><a href="#9-集群测试" class="headerlink" title="9.集群测试"></a>9.集群测试</h1><h2 id="9-1-文件系统测试"><a href="#9-1-文件系统测试" class="headerlink" title="9.1 文件系统测试"></a>9.1 文件系统测试</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">切换hdfs用户对hdfs文件系统进行测试是否能够进行正常读写</span></span><br><span class="line">[root@node01 ~]# su hdfs</span><br><span class="line">[hdfs@node01 ~]# hadoop dfs -ls /</span><br><span class="line">DEPRECATED: Use of this script to execute hdfs command is deprecated.</span><br><span class="line">Instead use the hdfs command for it.</span><br><span class="line"></span><br><span class="line">Found 1 items</span><br><span class="line">d-wx------   - hdfs supergroup          0 2019-10-11 08:21 /tmp</span><br><span class="line">[hdfs@node01 ~]# touch test</span><br><span class="line">[hdfs@node01 ~]# vi test </span><br><span class="line">hello world</span><br><span class="line"></span><br><span class="line">[hdfs@node01 ~]$ hadoop dfs -put words /test</span><br><span class="line">[hdfs@node01 ~]$ hadoop dfs -ls /</span><br><span class="line">DEPRECATED: Use of this script to execute hdfs command is deprecated.</span><br><span class="line">Instead use the hdfs command for it.</span><br><span class="line"></span><br><span class="line">Found 2 items</span><br><span class="line">drwxr-xr-x   - hdfs supergroup          0 2019-10-11 09:09 /test</span><br><span class="line">d-wx------   - hdfs supergroup          0 2019-10-11 08:21 /tmp</span><br><span class="line">[hdfs@node01 ~]$ hadoop dfs -ls /test</span><br><span class="line">DEPRECATED: Use of this script to execute hdfs command is deprecated.</span><br><span class="line">Instead use the hdfs command for it.</span><br><span class="line"></span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   3 hdfs supergroup         12 2019-10-11 09:09 /test/words</span><br><span class="line">[hdfs@node01 ~]$ hadoop dfs -text /test/words</span><br><span class="line">DEPRECATED: Use of this script to execute hdfs command is deprecated.</span><br><span class="line">Instead use the hdfs command for it.</span><br><span class="line"></span><br><span class="line">hello world</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="9-2-yarn集群测试"><a href="#9-2-yarn集群测试" class="headerlink" title="9.2 yarn集群测试"></a>9.2 yarn集群测试</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">[hdfs@node01 ~]$ hadoop jar /opt/cloudera/parcels/CDH-5.14.2-1.cdh5.14.2.p0.3/jars/hadoop-mapreduce-examples-2.6.0-cdh5.14.2.jar wordcount /test/words /test/output</span><br><span class="line">19/10/11 22:47:59 INFO client.RMProxy: Connecting to ResourceManager at node03.kaikeba.com/192.168.52.120:8032</span><br><span class="line">19/10/11 22:47:59 INFO mapreduce.JobSubmissionFiles: Permissions on staging directory /user/hdfs/.staging are incorrect: rwx---rwx. Fixing permissions to correct value rwx------</span><br><span class="line">19/10/11 22:48:00 INFO input.FileInputFormat: Total input paths to process : 1</span><br><span class="line">19/10/11 22:48:00 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">19/10/11 22:48:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1570847238197_0001</span><br><span class="line">19/10/11 22:48:01 INFO impl.YarnClientImpl: Submitted application application_1570847238197_0001</span><br><span class="line">19/10/11 22:48:01 INFO mapreduce.Job: The url to track the job: http://node03.kaikeba.com:8088/proxy/application_1570847238197_0001/</span><br><span class="line">19/10/11 22:48:01 INFO mapreduce.Job: Running job: job_1570847238197_0001</span><br><span class="line">19/10/11 22:48:28 INFO mapreduce.Job: Job job_1570847238197_0001 running in uber mode : false</span><br><span class="line">19/10/11 22:48:28 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">19/10/11 22:50:10 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">19/10/11 22:50:17 INFO mapreduce.Job:  map 100% reduce 17%</span><br><span class="line">19/10/11 22:50:19 INFO mapreduce.Job:  map 100% reduce 33%</span><br><span class="line">19/10/11 22:50:21 INFO mapreduce.Job:  map 100% reduce 50%</span><br><span class="line">19/10/11 22:50:24 INFO mapreduce.Job:  map 100% reduce 67%</span><br><span class="line">19/10/11 22:50:25 INFO mapreduce.Job:  map 100% reduce 83%</span><br><span class="line">19/10/11 22:50:29 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">19/10/11 22:50:29 INFO mapreduce.Job: Job job_1570847238197_0001 completed successfully</span><br><span class="line">19/10/11 22:50:30 INFO mapreduce.Job: Counters: 49</span><br><span class="line">        File System Counters</span><br><span class="line">                FILE: Number of bytes read=144</span><br><span class="line">                FILE: Number of bytes written=1044048</span><br><span class="line">                FILE: Number of read operations=0</span><br><span class="line">                FILE: Number of large read operations=0</span><br><span class="line">                FILE: Number of write operations=0</span><br><span class="line">                HDFS: Number of bytes read=118</span><br><span class="line">                HDFS: Number of bytes written=16</span><br><span class="line">                HDFS: Number of read operations=21</span><br><span class="line">                HDFS: Number of large read operations=0</span><br><span class="line">                HDFS: Number of write operations=12</span><br><span class="line">        Job Counters </span><br><span class="line">                Launched map tasks=1</span><br><span class="line">                Launched reduce tasks=6</span><br><span class="line">                Data-local map tasks=1</span><br><span class="line">                Total time spent by all maps in occupied slots (ms)=100007</span><br><span class="line">                Total time spent by all reduces in occupied slots (ms)=24269</span><br><span class="line">                Total time spent by all map tasks (ms)=100007</span><br><span class="line">                Total time spent by all reduce tasks (ms)=24269</span><br><span class="line">                Total vcore-milliseconds taken by all map tasks=100007</span><br><span class="line">                Total vcore-milliseconds taken by all reduce tasks=24269</span><br><span class="line">                Total megabyte-milliseconds taken by all map tasks=102407168</span><br><span class="line">                Total megabyte-milliseconds taken by all reduce tasks=24851456</span><br><span class="line">        Map-Reduce Framework</span><br><span class="line">                Map input records=1</span><br><span class="line">                Map output records=2</span><br><span class="line">                Map output bytes=20</span><br><span class="line">                Map output materialized bytes=120</span><br><span class="line">                Input split bytes=106</span><br><span class="line">                Combine input records=2</span><br><span class="line">                Combine output records=2</span><br><span class="line">                Reduce input groups=2</span><br><span class="line">                Reduce shuffle bytes=120</span><br><span class="line">                Reduce input records=2</span><br><span class="line">                Reduce output records=2</span><br><span class="line">                Spilled Records=4</span><br><span class="line">                Shuffled Maps =6</span><br><span class="line">                Failed Shuffles=0</span><br><span class="line">                Merged Map outputs=6</span><br><span class="line">                GC time elapsed (ms)=581</span><br><span class="line">                CPU time spent (ms)=11830</span><br><span class="line">                Physical memory (bytes) snapshot=1466945536</span><br><span class="line">                Virtual memory (bytes) snapshot=19622957056</span><br><span class="line">                Total committed heap usage (bytes)=1150287872</span><br><span class="line">        Shuffle Errors</span><br><span class="line">                BAD_ID=0</span><br><span class="line">                CONNECTION=0</span><br><span class="line">                IO_ERROR=0</span><br><span class="line">                WRONG_LENGTH=0</span><br><span class="line">                WRONG_MAP=0</span><br><span class="line">                WRONG_REDUCE=0</span><br><span class="line">        File Input Format Counters </span><br><span class="line">                Bytes Read=12</span><br><span class="line">        File Output Format Counters </span><br><span class="line">                Bytes Written=16</span><br><span class="line">You have new mail in /var/spool/mail/root</span><br><span class="line">[hdfs@node01 ~]$ hdfs dfs -ls /test/output</span><br><span class="line">Found 7 items</span><br><span class="line">-rw-r--r--   3 hdfs supergroup          0 2019-10-11 22:50 /test/output/_SUCCESS</span><br><span class="line">-rw-r--r--   3 hdfs supergroup          0 2019-10-11 22:50 /test/output/part-r-00000</span><br><span class="line">-rw-r--r--   3 hdfs supergroup          8 2019-10-11 22:50 /test/output/part-r-00001</span><br><span class="line">-rw-r--r--   3 hdfs supergroup          0 2019-10-11 22:50 /test/output/part-r-00002</span><br><span class="line">-rw-r--r--   3 hdfs supergroup          0 2019-10-11 22:50 /test/output/part-r-00003</span><br><span class="line">-rw-r--r--   3 hdfs supergroup          0 2019-10-11 22:50 /test/output/part-r-00004</span><br><span class="line">-rw-r--r--   3 hdfs supergroup          8 2019-10-11 22:50 /test/output/part-r-00005</span><br><span class="line">[hdfs@node01 ~]$  hdfs dfs -text /test/output/part-r-00001</span><br><span class="line">world   1</span><br><span class="line">[hdfs@node01 ~]$  hdfs dfs -text /test/output/part-r-00005</span><br><span class="line">hello   1</span><br><span class="line">You have new mail in /var/spool/mail/root</span><br><span class="line">[hdfs@node01 ~]$ </span><br></pre></td></tr></table></figure><h1 id="10-手动添加Kafka服务"><a href="#10-手动添加Kafka服务" class="headerlink" title="10.手动添加Kafka服务"></a>10.手动添加Kafka服务</h1><p>我们以安装kafka为例进行演示</p><h2 id="10-1-检查kafka安装包"><a href="#10-1-检查kafka安装包" class="headerlink" title="10.1 检查kafka安装包"></a>10.1 检查kafka安装包</h2><p>首先检查是否已经存在Kafka的parcel安装包，如下图提示远程提供，说明我们下载的parcel安装包中不包含Kafka的parcel安装包，这时需要我们手动到官网上下载</p><p><img src="assets/1570850847758.png" alt="1570850847758"></p><h2 id="10-2-检查Kafka安装包版本"><a href="#10-2-检查Kafka安装包版本" class="headerlink" title="10.2 检查Kafka安装包版本"></a>10.2 检查Kafka安装包版本</h2><p>首先查看搭建cdh版本 和kafka版本，是否是支持的：</p><p>登录如下网址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;www.cloudera.com&#x2F;documentation&#x2F;enterprise&#x2F;release-notes&#x2F;topics&#x2F;rn_consolidated_pcm.html#pcm_kafka</span><br></pre></td></tr></table></figure><p>我的CDH版本是cdh5.14.0 ，我想要的kafka版本是1.0.1</p><p>因此选择：</p><p><img src="assets/1633376-20190508130456986-1658024926.png" alt="img"></p><h2 id="10-3-下载Kafka-parcel安装包"><a href="#10-3-下载Kafka-parcel安装包" class="headerlink" title="10.3 下载Kafka parcel安装包"></a>10.3 下载Kafka parcel安装包</h2><p>然后下载：<a href="http://archive.cloudera.com/kafka/parcels/3.1.0/">http://archive.cloudera.com/kafka/parcels/3.1.0/</a></p><p><img src="assets/1633376-20190508130549214-56463812.png" alt="img"></p><p>需要将下载的KAFKA-3.1.0-1.3.1.0.p0.35-el7.parcel.sha1 改成 KAFKA-3.1.0-1.3.1.0.p0.35-el7.parcel.sha</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~]# mv KAFKA-3.1.0-1.3.1.0.p0.35-el7.parcel.sha1 KAFKA-3.1.0-1.3.1.0.p0.35-el7.parcel.sha</span><br><span class="line">You have new mail in /var/spool/mail/root</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后将这三个文件，拷贝到parcel-repo目录下。如果有相同的文件，即manifest.json，只需将之前的重命名备份即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~] cd /opt/cloudera/parcel-repo/</span><br><span class="line">[root@node01 parcel-repo]# mv manifest.json bak_manifest.json </span><br><span class="line"><span class="meta">#</span><span class="bash">拷贝到parcel-repo目录下</span></span><br><span class="line">[root@node01 ~]# mv KAFKA-3.1.0-1.3.1.0.p0.35-el7.parcel* manifest.json /opt/cloudera/parcel-repo/</span><br><span class="line">[root@node01 ~]# ll</span><br><span class="line">total 989036</span><br><span class="line">-rw-------. 1 root root      1260 Apr 16 01:35 anaconda-ks.cfg</span><br><span class="line">-rw-r--r--. 1 root root 832469335 Oct 11 13:23 cloudera-manager-centos7-cm5.14.2_x86_64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 179439263 Oct 10 20:14 jdk-8u211-linux-x64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    848399 Oct 11 17:02 mysql-connector-java.jar</span><br><span class="line">-rw-r--r--  1 root root        12 Oct 11 21:01 words</span><br><span class="line">You have new mail in /var/spool/mail/root</span><br><span class="line">[root@node01 ~]# ll</span><br></pre></td></tr></table></figure><h2 id="10-4-分配激活Kafka"><a href="#10-4-分配激活Kafka" class="headerlink" title="10.4 分配激活Kafka"></a>10.4 分配激活Kafka</h2><p>如下图，在管理首页选择parcel</p><p><img src="assets/1570859081770.png" alt="1570859081770"></p><p>如下图，检查更新多点击几次，就会出现分配按钮</p><p><img src="assets/1570859361922.png" alt="1570859361922"></p><p>点击分配，等待分配按钮激活</p><p><img src="assets/1570859491074.png" alt="1570859491074"></p><p>如下图，正在分配中…</p><p><img src="assets/1570859524848.png" alt="1570859524848"></p><p>如下图按钮已经激活</p><p><img src="assets/1570859672818.png" alt="1570859672818"></p><p><img src="assets/1570859816399.png" alt="1570859816399"></p><p>如上两张图图，点击激活和确定，然后等待激活    </p><p>正在激活…</p><p><img src="assets/1570859868869.png" alt="1570859868869"></p><p>如下图，分配并激活成功</p><p><img src="assets/1570859891912.png" alt="1570859891912"></p><h2 id="10-5-添加Kafka服务"><a href="#10-5-添加Kafka服务" class="headerlink" title="10.5 添加Kafka服务"></a>10.5 添加Kafka服务</h2><p>点击cloudera manager回到主页</p><p><img src="assets/1570860017451.png" alt="1570860017451"></p><p>页面中点击下拉操作按钮，点击添加服务</p><p><img src="assets/1570849216563.png" alt="1570849216563"></p><p>如下图，点击选择kafka，点击继续</p><p><img src="assets/1570849280747.png" alt="1570849280747"></p><p>如下图，选择Kakka Broker在三个节点上安装，Kafka MirrorMaker安装在node03上，Gateway安装在node02上（服务选择安装，需要自己根据每台机器上健康状态而定,这里只是作为参考）</p><p><img src="assets/1570849433668.png" alt="1570849433668"></p><p>如下图，填写Destination Broker List和Source Broker List后点击继续</p><p><strong>注意:这里和上一步中选择的角色分配有关联,Kafka Broker选择的是三台机器Destination Broker List中就填写三台机器的主机名，中间使用逗号分开，如果选择的是一台机器那么久选择一台，一次类推.Source Broker List和Destination Broker List填写一样.</strong></p><p><img src="assets/1570861737283.png" alt="1570861737283"></p><p>如下图，添加服务，最终状态为已完成，启动过程中会出现错误不用管，这时因为CDH给默认将kafka的内存设置为50M,太小了， 后续需要我们手动调整,点击继续</p><p><img src="assets/1570862070794.png" alt="1570862070794"></p><p>如下图,点击完成.</p><p><img src="assets/1570862239690.png" alt="1570862239690"></p><p>如下图，添加成功的Kafka服务</p><p><img src="assets/1570862272925.png" alt="1570862272925"></p><h2 id="10-6-配置Kafka的内存"><a href="#10-6-配置Kafka的内存" class="headerlink" title="10.6 配置Kafka的内存"></a>10.6 配置Kafka的内存</h2><p>如下图，点击Kafka服务</p><p><img src="assets/1570862705339.png" alt="1570862705339"></p><p>如下图，点击实例，点击Kafka Broker（<strong>我们先配置node01节点的内存大小,node02和node03内存配置方式相同，需要按照此方式进行修改</strong>）</p><p><img src="assets/1570862765551.png" alt="1570862765551"></p><p>如上图，点击Kafka Broker之后，如下图所示，点击配置</p><p><img src="assets/1570862896070.png" alt="1570862896070"></p><p>右侧浏览器垂直滚动条往下找到broker_max_heap_size，修改值为256,点击保存更改</p><p><img src="assets/1570863035798.png" alt="1570863035798"></p><p><strong>node02和node03按照上述步骤进行同样修改.</strong></p><h2 id="10-7-重新启动kafka集群"><a href="#10-7-重新启动kafka集群" class="headerlink" title="10.7 重新启动kafka集群"></a>10.7 重新启动kafka集群</h2><p>点击启动</p><p><img src="assets/1570863234060.png" alt="1570863234060"></p><p>点击启动</p><p><img src="assets/1570863253382.png" alt="1570863253382"></p><p>启动成功</p><p><img src="assets/1570863458643.png" alt="1570863458643"></p><h1 id="11-手动添加服务"><a href="#11-手动添加服务" class="headerlink" title="11.手动添加服务"></a>11.手动添加服务</h1><p>请参考【10.手动添加Kafka服务】操作步骤.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Cloudera </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Scilab 云化改造(1)_Scilab/Xcos概述</title>
      <link href="2018/02/15/ScilabXcos%20%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E5%8F%8A%E8%BF%90%E8%A1%8C%E5%88%86%E6%9E%90/"/>
      <url>2018/02/15/ScilabXcos%20%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E5%8F%8A%E8%BF%90%E8%A1%8C%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="Scilab-Xcos-概述"><a href="#Scilab-Xcos-概述" class="headerlink" title="Scilab/Xcos 概述"></a>Scilab/Xcos 概述</h2><p>Scilab 是由法国国家信息、自动化研究院的科学家们开发的“开放源码”软件。Scilab作为一种科学工程计算软件，其数据类型丰富，可以很方便地实现各种矩阵运算与图形显示，能应用于科学计算、数学建模、信号处理、决策优化、线性、非线性控制等各个方面。</p><p>Scilab 最初叫做 Basile，是作为 Meta2 项目的一部分在 INRIA 开发的。更名为 Scilab 以后，其开发由来自 INRIA Metalau和ENPC的研究人员组成的研究小组继续进行。2004年起，Scilab 的开发由一个国际性组织负责。</p><p>目前有两大类的通用科学软件：进行符号运算的计算机代数系统；进行数值计算和专门为科学应用设计的通用数值系统。自由开源软件 Scilab 就属于第二类。</p><p>Scilab 是一种动态确定对象类型的解释性语言。Scilab 能以二进制的形式在 Unix/Linux 工作站、Windows和Mac OS X等主要平台上运行。用户可以通过源代码编译 Scilab，该过程非常直观。</p><p>Scilab 可以作为一种脚本语言进行算法测试或者数值计算，同时，它也是一种编程语言，标准的Scilab库包含大约2000多种Scilab函数。Scilab语法简单，而且相关专用函数和运算符的使用使得矩阵的计算变得更为简单。因此，Scilab的程序相当紧凑，一般比用C、C++、Java等语言编写的程序短小。</p><p>Scilab主要用于科学计算，极大地方便了线性代数、数值积分、最优化等数值计算。扩展Scilab环境也比较简单，可以利用静态或动态连接库从外部向Scilab中引入新的功能函数，也可以使用Scilab结构体定义新的数据类型，或者为新的数据类型加载标准操作。Scilab的官方网站上有大量的工具箱来扩展它的一些特殊功能。</p><p>Scilab同时提供了大量的可视化函数，如二维图形、三维图形、等高线、参数化绘图和动画等，由这些函数生成的图形能以gif、postscript等多种格式输出。</p><p>Scilab还提供可以满足不同工程与科学需要的工具箱，例如Xcos图形化建模仿真，信号处理工具箱，图与网络工具箱等。</p><h2 id="Xcos-介绍"><a href="#Xcos-介绍" class="headerlink" title="Xcos 介绍"></a>Xcos 介绍</h2><p>Xcos 是 Scilab 的核心组件,是一个图形动态系统建模器和模拟器，在 INRIA，巴黎 Rocquencourt 中心的 Metalau 项目中开发。使用 Xcos，用户可以创建框图来模拟混合动力系统的动态过程，并将模型编译为可执行代码。Xcos可用于信号处理，系统控制，以及研究物理和生物系统。在新的扩展中，允许使用 Modelica 语言生成基于组件的电气和液压电路的模型。</p><h2 id="Scilab-架构概述及模块组成"><a href="#Scilab-架构概述及模块组成" class="headerlink" title="Scilab 架构概述及模块组成"></a>Scilab 架构概述及模块组成</h2><p>Scilab 的模块可分成三大类：核心模块、扩展工具模块、可选模块。本节详细介绍三大类的模块，及各分类的模块的架构层次。对每个模块的详细功能进行了解释说明。</p><p>Scilab 的核心架构思想是每一个功能或者任务都可以分为一个个单独模块（module）。每个模块都执行各自对应的功能和任务，相互尽量不影响，以使得  模块之间相互的耦合性降到最低。在 VS2012 的调试环境中，就可以很清楚的看出 Scilab 是由 142 个模块(其中包括在 Windows下运行所需要的五个单独模块WScilex(程序入口函数)，Dumpexts(运行win7及以上版本的支持模块)，windows_tools(运行dos窗口模式的支持工具模块)，GetWindowsVersion(获取Windows版本信息并配置调试环境模块)，Scilex(Windows下无GUI模式控制模块))组成。</p><p>另外，Scilab 的底层开发语言是 Fortran 语言，早期的图形界面是用tcl/tk语言开发的，再后来为了便于开发，模块中还包括了很多调用Fortran语言代码的C++链接模块（例如core和core_f，Scilab的核心处理代码core_f是由Fortran语言写的，但是为了开发方便也写了调用这些Fortran代码的C++链接代码文件core），此外还有支持之前的tclsci模块（从Scilab源码的支持文件prerequirements-scilab中获取）。以及一些相关模块的管理/引入/缺失警告/单元测试项目模块（例如，graphic模块就包含了graphic_export(图表输出项目)，nographic_export(图表输出缺失警告项目)/graphic_JAVA_tests(图表输出Java单元测试)等），这些相似模块可以合成一类。</p><p>总结以上，Scilab中实际可分析的模块有73个。</p><p>在阅读源码和相关文献资料后，我们将这73个模块分成了<strong>核心模块</strong>，<strong>扩展工具模块</strong>，<strong>可选模块</strong>三大类。</p><img src="/Users/joker/Documents/chen_blog/source/images/Xnip2021-01-19_12-48-29.jpg" alt="Xnip2021-01-19_12-48-29" style="zoom:70%;" /><h3 id="核心模块"><a href="#核心模块" class="headerlink" title="核心模块"></a>核心模块</h3><p><strong>核心模块</strong>是包含 Scilab 所必需核心源码模块的，删减后会导致 Scilab 不能进行正常工作的，一共有56个</p><p>然后，根据其实现的结果，又分为两大类: 功能类和算法类。</p><h4 id="功能类"><a href="#功能类" class="headerlink" title="功能类"></a>功能类</h4><p>在功能类中根据其职能又细分为两小类: 控制类和工具类。</p><h5 id="控制类"><a href="#控制类" class="headerlink" title="控制类"></a>控制类</h5><p>主要是实现Scilab相关底层与计算机进行交互的功能：</p><ul><li>console</li><li>core</li><li>dynamic_link    </li><li>io</li><li>libjvm </li><li>localization</li><li>mpi</li><li>parallel </li><li>preferences  </li><li>scilab_windows </li></ul><h5 id="工具类"><a href="#工具类" class="headerlink" title="工具类"></a>工具类</h5><p>主要包括了 Scilab 一般操作的相关命令集合：</p><ul><li><p>action_binding  </p><p>事件绑定封装，调用工具</p></li><li><p>api-scilab  </p><p>Scilab 调用的常用接口 api</p></li><li><p>boolean    </p></li><li><p>call_scilab </p></li><li><p>data_structures</p></li><li><p>differential_equations  </p></li><li><p>external_objects </p></li><li><p>fileio  </p></li><li><p>functions  </p></li><li><p>grphic  </p></li><li><p>gui  </p></li><li><p>hdf5  </p></li><li><p>history_brower </p></li><li><p>integer  </p></li><li><p>intersci  </p></li><li><p>Javasci  </p></li><li><p>out_stream   </p></li><li><p>parameters </p></li><li><p>renderer  </p></li><li><p>scinotes  </p></li><li><p>SetupAltas  </p></li><li><p>spreadsheet  </p></li><li><p>string </p></li><li><p>double   </p></li><li><p>time   </p></li><li><p>types  </p></li><li><p>xml </p></li></ul><h4 id="算法类"><a href="#算法类" class="headerlink" title="算法类"></a>算法类</h4><p>基本功能算法和高级复杂算法。</p><h5 id="基本算法类"><a href="#基本算法类" class="headerlink" title="基本算法类"></a>基本算法类</h5><p>包括简单的科学计算方法：</p><ul><li>cacsd   </li><li>dcd_f   </li><li>eispack_f   </li><li>elementary_functions</li><li>interpolation  </li><li>linear_algebra  </li><li>linpack_f  </li><li>polynomialse </li><li>randlib  </li><li>slatec_f  </li><li>slicot_f   </li><li>statistics </li></ul><h5 id="高级复杂算法"><a href="#高级复杂算法" class="headerlink" title="高级复杂算法"></a>高级复杂算法</h5><p>提供了很多优秀的复杂计算方法(可提高计算性能)：</p><ul><li><p>arnoldi  </p></li><li><p>optimization  </p></li><li><p>singnal_processing  </p></li><li><p>special_functions </p></li><li><p>symbolic  </p></li><li><p>umfpack  </p></li><li><p>sparse</p><h1 id="Scilab-架构分析"><a href="#Scilab-架构分析" class="headerlink" title="Scilab 架构分析"></a>Scilab 架构分析</h1></li></ul><p>根据体系结构分层分析，Scilab 的依赖项关系图有如下生成：</p><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午12.57.23.png" alt="截屏2021-01-19 下午12.57.23" style="zoom:70%;" /><p>由图可知，一共有 157 个节点，1518 个链接，完整的显示了 Scilab 个项目之间的依赖关系。其中，箭头指向性为一个文件被另一个文件所依赖。</p><p>根据官网提供的一些资料支持，我们将上图简化，生成了下图的简易版依赖关系视图：</p><img src="/Users/joker/Documents/chen_blog/source/images/截屏2021-01-19 下午12.58.20.png" alt="截屏2021-01-19 下午12.58.20" style="zoom:70%;" /><p>图中共有 23 个节点，88 个链接。此图比较清晰完整的显示了 Scilab 主要模块之间的依赖关系。</p>]]></content>
      
      
      <categories>
          
          <category> Scilab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Scilab 仿真云化改造 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
