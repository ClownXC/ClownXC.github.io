<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Spark 存储模块 | 周晓晨</title><meta name="author" content="周晓晨"><meta name="copyright" content="周晓晨"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业[Job]，并将作业转化为计算任务[Task]，在各个 Executor 进程间协调任务的调度；后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver， 同时为需要持久化的 RDD 提供存储功能。由于 D">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark 存储模块">
<meta property="og:url" content="http://joccer.gitee.io/2019/11/22/Spark%20%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97/index.html">
<meta property="og:site_name" content="周晓晨">
<meta property="og:description" content="在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业[Job]，并将作业转化为计算任务[Task]，在各个 Executor 进程间协调任务的调度；后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver， 同时为需要持久化的 RDD 提供存储功能。由于 D">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2019-11-22T03:06:12.000Z">
<meta property="article:modified_time" content="2021-01-06T02:26:12.589Z">
<meta property="article:author" content="周晓晨">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://joccer.gitee.io/2019/11/22/Spark%20%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":1,"position":"top","messagePrev":"这篇文章已经发表","messageNext":"天了，其中某些内容可能已经过时～"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-01-06 10:26:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><link rel="stylesheet" href="/css/iconfont.css"><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/chen.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">101</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">11</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">14</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 项目实战</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/playlist/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-folder-open"></i><span> 视频资料</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 数值分析</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 编译原理</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 操作系统</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机组成</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机网络</span></a></li><li><a class="site-page" href="/teach/jvm/"><i class="fa-fw fas fa-video"></i><span> JVM</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> MySQL数据库</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Execuor-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">Execuor 内存模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A0%86%E5%86%85%E5%92%8C%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98"><span class="toc-number">1.1.</span> <span class="toc-text">堆内和堆外内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A0%86%E5%86%85%E5%86%85%E5%AD%98"><span class="toc-number">1.2.</span> <span class="toc-text">堆内内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98"><span class="toc-number">1.3.</span> <span class="toc-text">堆外内存</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4%E5%88%86%E9%85%8D"><span class="toc-number">2.</span> <span class="toc-text">内存空间分配</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%99%E6%80%81%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-number">2.1.</span> <span class="toc-text">静态内存管理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-number">2.2.</span> <span class="toc-text">统一内存管理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">存储内存管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">3.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD-%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6"><span class="toc-number">3.2.</span> <span class="toc-text">RDD 的持久化机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD%E7%9A%84%E7%BC%93%E5%AD%98%E8%BF%87%E7%A8%8B"><span class="toc-number">3.3.</span> <span class="toc-text">RDD的缓存过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%98%E6%B1%B0%E4%B8%8E%E8%90%BD%E7%9B%98"><span class="toc-number">3.4.</span> <span class="toc-text">淘汰与落盘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-number">3.5.</span> <span class="toc-text">执行内存管理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Shuffle-Write"><span class="toc-number">3.6.</span> <span class="toc-text">Shuffle Write</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Shuffle-Read"><span class="toc-number">3.7.</span> <span class="toc-text">Shuffle Read</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">4.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-Shuffle-%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8"><span class="toc-number">5.</span> <span class="toc-text">Spark Shuffle 内存使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#OOM"><span class="toc-number">6.</span> <span class="toc-text">OOM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#driver-OOM"><span class="toc-number">6.1.</span> <span class="toc-text">driver OOM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#executor-OOM"><span class="toc-number">6.2.</span> <span class="toc-text">executor OOM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E5%AF%BC%E8%87%B4%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA"><span class="toc-number">6.3.</span> <span class="toc-text">数据倾斜导致内存溢出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reduce-OOM"><span class="toc-number">6.4.</span> <span class="toc-text">Reduce OOM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#shuffle-%E5%90%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA"><span class="toc-number">6.5.</span> <span class="toc-text">shuffle 后内存溢出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#coalesce-%E8%B0%83%E7%94%A8%E5%AF%BC%E8%87%B4%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA"><span class="toc-number">6.6.</span> <span class="toc-text">coalesce 调用导致内存溢出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#standalone-%E6%A8%A1%E5%BC%8F%E4%B8%8B%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E4%B8%8D%E5%9D%87%E5%8C%80%E5%AF%BC%E8%87%B4%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA"><span class="toc-number">6.7.</span> <span class="toc-text">standalone 模式下资源分配不均匀导致内存溢出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#map-%E8%BF%87%E7%A8%8B%E4%BA%A7%E7%94%9F%E5%A4%A7%E9%87%8F%E5%AF%B9%E8%B1%A1%E5%AF%BC%E8%87%B4%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA"><span class="toc-number">6.8.</span> <span class="toc-text">map 过程产生大量对象导致内存溢出</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0"><span class="toc-number">7.</span> <span class="toc-text">参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-driver-memory"><span class="toc-number">7.1.</span> <span class="toc-text">spark.driver.memory</span></a></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">周晓晨</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 项目实战</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/playlist/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-folder-open"></i><span> 视频资料</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 数值分析</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 编译原理</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 操作系统</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机组成</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机网络</span></a></li><li><a class="site-page" href="/teach/jvm/"><i class="fa-fw fas fa-video"></i><span> JVM</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> MySQL数据库</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Spark 存储模块</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-11-22T03:06:12.000Z" title="发表于 2019-11-22 11:06:12">2019-11-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-01-06T02:26:12.589Z" title="更新于 2021-01-06 10:26:12">2021-01-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Spark/">Spark</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业[Job]，并将作业转化为计算任务[Task]，在各个 Executor 进程间协调任务的调度；后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver， 同时为需要持久化的 RDD 提供存储功能。由于 Driver 的内存管理相对来说较为简单，本节主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。</p>
<a id="more"></a>

<h2 id="Execuor-内存模型"><a href="#Execuor-内存模型" class="headerlink" title="Execuor 内存模型"></a>Execuor 内存模型</h2><h3 id="堆内和堆外内存"><a href="#堆内和堆外内存" class="headerlink" title="堆内和堆外内存"></a>堆内和堆外内存</h3><p>作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内 [On-heap]空间进行了更为详细的分配，以充分利用内存。</p>
<p>同时，Spark 引入了堆外[Off-heap]内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。</p>
<p><strong>堆内内存受到 JVM 统一管理，堆外内存是直接向操作系统进行内存的申请和释放。</strong></p>
<h3 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h3><p>堆内内存的大小，由 Spark 应用程序启动时的 –executor-memory 或 spark.executor.memory 参数配置。 </p>
<p>Executor 内运行的并发任务共享 JVM 堆内内存， Spark 对堆内内存的管理是一种逻辑上的“规划式”的管理，Executor 端的堆内内存区域在逻辑上被划分为以下四个区域。</p>
<ol>
<li><p>执行内存 (Execution Memory) : 主要用于存放 Shuffle、Join、Sort、Aggregation 等计算过程中的临时数据</p>
</li>
<li><p>存储内存 (Storage Memory) : 主要用于存储 spark 的 cache 数据，例如 RDD 的缓存、unroll 数据</p>
<p>主要用于存储 spark 的 cache 数据，例如 RDD 的缓存、广播（Broadcast）数据、和 unroll 数据。内存占比为 UsableMemory * spark.memory.fraction * spark.memory.storageFraction，Spark 2+ 中，默认初始状态下 Storage Memory 和 Execution Memory 均约占系统总内存的30%（1 * 0.6 * 0.5 = 0.3）。</p>
</li>
<li><p>用户内存（User Memory）: 主要用于存储 RDD 转换操作所需要的数据，例如 RDD 依赖等信息；</p>
</li>
<li><p>预留内存（Reserved Memory）: 系统预留内存，会用来存储 Spark 内部对象。</p>
<p>系统预留内存，用来存储 Spark 内部对象。其大小在代码中是写死的，其值等于 300MB，这个值是不能修改的</p>
</li>
</ol>
<h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>Spark 对于堆内内存的清理无法准确指定时间点，因此无法实现精确的释放。<strong>为了进一步优化内存的使用 Spark 引入了堆外内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。</strong>由于内存的申请和释放不再通过 JVM 机制，而是直接向操作系统申请，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说，堆外内存可以被精降低了管理的难度，也降低了误差。 </p>
<p>在默认情况下堆外内存并不启用，可通过配置 spark.memory.offHeap.enabled 参数启用，并由 spark.memory.offHeap.size 参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。</p>
<h2 id="内存空间分配"><a href="#内存空间分配" class="headerlink" title="内存空间分配"></a>内存空间分配</h2><h3 id="静态内存管理"><a href="#静态内存管理" class="headerlink" title="静态内存管理"></a>静态内存管理</h3><p>在 Spark 最初采用的静态内存管理机制下，**[存储内存]<strong>、</strong>[执行内存]<strong>和</strong>[其他内存]**的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置。</p>
<img src="../images/spark/009.png" alt="" style="zoom:90%;" />

<ul>
<li><p>可用的存储内存</p>
<p> systemMaxMemory * spark.storage.memoryFraction * spark.storage.safetyFraction</p>
</li>
<li><p>可用的执行内存</p>
<p>systemMaxMemory * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction</p>
</li>
</ul>
<p>其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。 </p>
<p>上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 [1-safetyFraction] 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险。</p>
<p>值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和”其它内存”一样交给了 JVM 去管理。</p>
<p><strong>Storage 内存和 Execution 内存都有预留空间，目的是防止 OOM ，因为 Spark 堆内内存大小的记录是不准确的，需要留出保险区域。</strong></p>
<p>堆外的空间分配较为简单，只有存储内存和执行内存。可用的执行内存和存储内存占用的空间大小直接由参数 spark.memory.storageFraction 决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域 </p>
<img src="../images/spark/12.png" alt="" style="zoom:90%;" />

<p>静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。</p>
<h3 id="统一内存管理"><a href="#统一内存管理" class="headerlink" title="统一内存管理"></a>统一内存管理</h3><p><strong>Spark1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于<font color='blue'>存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域</font></strong> </p>
<img src="../images/spark/10.png" alt="" style="zoom:90%;" />

<p>其中最重要的优化在于动态占用机制， 其规则如下：</p>
<img src="../images/spark/20.png" alt="" style="zoom:90%;" />

<ul>
<li><p>设定基本的存储内存和执行内存区域（spark.storage.storageFraction参数），该设定确定了双方各自拥有的空间的范围；</p>
</li>
<li><p>双方的空间都不足时，则存储到硬盘</p>
<p>若己方空间不足而对方空余时，可借用对方的空间; [注：存储空间不足是指不足以放下一个完整的Block]</p>
</li>
<li><p>执行内存的空间被对方占用后，可让对方将占用的部分转存到磁盘，然后”归还”借用的空间；</p>
</li>
<li><p>存储内存的空间被对方占用后，无法让对方 “归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。</p>
<p>Storage 内存的空间被对方占用后，目前的实现是无法让对方”归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂；而且 Shuffle 过程产生的文件在后面一定会被使用到，而 Cache 在内存的数据不一定在后面使用。在 <a target="_blank" rel="noopener" href="http://www.linuxprobe.com/wp-content/uploads/2017/04/unified-memory-management-spark-10000.pdf">Unified Memory Management in Spark 1.6</a> 中详细讲解了为何选择这种策略，简单总结如下:</p>
<ul>
<li>数据清除的开销 : 驱逐 storage 内存的开销取决于 storage level，MEMORY_ONLY 可能是最昂贵的，因为需要重新计算，MEMORY_AND_DISK_SER 正好相反，只涉及到磁盘IO。溢写 execution 内存到磁盘的开销并不昂贵，因为 execution 存储的数据格式紧凑(compact format)，序列化开销低。并且，清除的 storage 内存可能不会被用到，但是，可以预见的是，驱逐的 execution 内存是必然会再被读到内存的，频繁的驱除重读 execution 内存将导致昂贵的开销。</li>
<li>实现的复杂度 : storage 内存的驱逐是容易实现的，只需要使用已有的方法，drop 掉 block。execution 则复杂的多，首先，execution 以 page 为单位管理这部分内存，并且确保相应的操作至少有 one page ，如果把这 one page 内存驱逐了，对应的操作就会处于饥饿状态。此外，还需要考虑 execution 内存被驱逐的情况下，等待 cache 的 block 如何处理。</li>
</ul>
</li>
</ul>
<h2 id="存储内存管理"><a href="#存储内存管理" class="headerlink" title="存储内存管理"></a>存储内存管理</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block。</p>
<p>BlockManager 是 整个 Spark 底层负责数据存储与管理的一个组件 ， Driver 和 Executor 的所有数据都由对应的 BlockManager 进行管理。</p>
<p>Driver 端 BlockManager 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Executor 端的 BlockManager 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令， 例如新增或删除一个 RDD。</p>
<h3 id="RDD-的持久化机制"><a href="#RDD-的持久化机制" class="headerlink" title="RDD 的持久化机制"></a>RDD 的持久化机制</h3><p>Task 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 要执行多次 action 操作， 可以在第一次 action 操作中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。</p>
<blockquote>
<p>其中 cache 这个方法是个 Tranformation ,当第一次遇到 action 算子的时才会进行持久化</p>
<p>cache 内部调用了 persist(StorageLevel.MEMORY_ONLY)方法，所以执行 cache 算子其实就是执行了 persist 算子且持久化级别为 MEMORY_ONLY。 故缓存是一种特殊的持久化。堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理。</p>
</blockquote>
<p>RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。 </p>
<p>在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY 、MEMORY_AND_DISK 等 7 种不同的存储级别 ， 而存储级别是以下 5 个变量的组合：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StorageLevel</span> <span class="title">private</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useDisk: <span class="type">Boolean</span>, //磁盘</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useMemory: <span class="type">Boolean</span>, //这里其实是指堆内内存</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _useOffHeap: <span class="type">Boolean</span>, //堆外内存</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _deserialized: <span class="type">Boolean</span>, //是否为非序列化</span></span></span><br><span class="line"><span class="class"><span class="params">  private var _replication: <span class="type">Int</span> = 1 //副本个数</span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span></span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th>存储级别</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>MEMORY_ONLY</td>
<td>以非序列化的 Java 对象的方式持久化在 JVM 内存中。如果内存无法完全存储 RDD 所有的 partition，那么那些没有持久化的 partition 就会在下一次需要使用它们的时候，重新被计算</td>
</tr>
<tr>
<td>MEMORY_AND_DISK</td>
<td>同上，但是当 RDD 某些 partition 无法存储在内存中时，会持久化到磁盘中。下次需要使用这些 partition 时，需要从磁盘上读取</td>
</tr>
<tr>
<td>MEMORY_ONLY_SER</td>
<td>同 MEMORY_ONLY，但是会使用 Java 序列化方式，将 Java 对象序列化后进行持久化。可以减少内存开销，但是需要进行反序列化，因此会加大 CPU 开销</td>
</tr>
<tr>
<td>MEMORY_AND_DISK_SER</td>
<td>同 MEMORY_AND_DISK，但是使用序列化方式持久化 Java 对象</td>
</tr>
<tr>
<td>DISK_ONLY</td>
<td>使用非序列化 Java 对象的方式持久化，完全存储到磁盘上</td>
</tr>
<tr>
<td>MEMORY_ONLY_2  MEMORY_AND_DISK_2</td>
<td>如果是尾部加了 2 的持久化级别，表示将持久化数据复用一份，保存到其他节点，从而在数据丢失时，不需要再次计算，只需要使用备份数据即可</td>
</tr>
</tbody></table>
<h3 id="RDD的缓存过程"><a href="#RDD的缓存过程" class="headerlink" title="RDD的缓存过程"></a>RDD的缓存过程</h3><p>RDD 在缓存之前，数据项 [Record]的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一Partition 的不同数据项的存储空间并不连续。缓存到存储内存之后， Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为”展开” [Unroll] </p>
<p>Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别。非序列化的 Block 用一个数组存储所有的对象实例<strong>，序列化的 Block 则用字节缓冲区 ByteBuffer 来存储二进制数据。</strong></p>
<p>每个 Executor 的 Storage 模块用一个 LinkedHashMap 来管理堆内和堆外存储内存中所有的 Block ，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放。</p>
<p>因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。在静态内存管理时，Spark 在存储内存中专门划分了一块 Unroll 空间，其大小是固定的，统一内存管理时则没有对 Unroll 空间进行特别区分，对于序列化的 Partition ，其所需的 Unroll 空间可以直接累加计算，一次申请。</p>
<blockquote>
<p>对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。</p>
</blockquote>
<blockquote>
<p>对于非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。</p>
</blockquote>
<p>如果最终 Unroll 成功， 当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间 </p>
<img src="../images/spark/30.png" alt="" style="zoom:50%;" />

<h3 id="淘汰与落盘"><a href="#淘汰与落盘" class="headerlink" title="淘汰与落盘"></a>淘汰与落盘</h3><p><strong>由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中 的旧 Block 进行淘汰，而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘，否则直接删除该 Block。</strong></p>
<ul>
<li>被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存</li>
<li>新旧 Block 不能属于同一个RDD，避免循环淘汰</li>
<li>旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题</li>
<li>遍历 LinkedHashMap中 Block，按照最近最少使用 LRU 的顺序淘汰，直到满足新 Block 所需的空间。 其中 LRU 是 LinkedHashMap 的特性。</li>
</ul>
<h3 id="执行内存管理"><a href="#执行内存管理" class="headerlink" title="执行内存管理"></a>执行内存管理</h3><p>执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程， Shuffle 的 Write 和 Read 两阶段对执行内存的使用.</p>
<h3 id="Shuffle-Write"><a href="#Shuffle-Write" class="headerlink" title="Shuffle Write"></a>Shuffle Write</h3><p>在 map 端会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。</p>
<h3 id="Shuffle-Read"><a href="#Shuffle-Read" class="headerlink" title="Shuffle Read"></a>Shuffle Read</h3><ul>
<li>在对 reduce端的数据进行聚合时， 要将数据交给 Aggregator处理， 在内存中存储数据时占用堆内执行空间。</li>
<li>如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter处理，占用堆内执行空间</li>
</ul>
<p>在 ExternalSorter 和 Aggregator 中， Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据 ， 但在 Shuffle 过程中所有数据并不能都保存到该哈希表中， 当这个哈希表占用的内存会进行周期性地采样估算， 当其大到一定程度， 无法再从 MemoryManager 申请到新的执行内存时， Spark 就会将其全部内容存储到磁盘文件中， 这 个过程被称为溢存 [Spill] ， 溢存到磁盘的文件最后会被归 并 [Merge] </p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Spark 的存储内存和执行内存有着截然不同的管理方式</p>
<ul>
<li><p>对于存储内存来说，<strong>Spark</strong> 用一个 **LinkedHashMap **来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；</p>
</li>
<li><p>对于执行内存，Spark 用 <strong>AppendOnlyMap</strong> 来存储 Shuffle 过程中的数据， 在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制 。</p>
</li>
</ul>
<h2 id="Spark-Shuffle-内存使用"><a href="#Spark-Shuffle-内存使用" class="headerlink" title="Spark Shuffle 内存使用"></a>Spark Shuffle 内存使用</h2><p>在使用 Spark 进行计算时，我们经常会碰到作业 (Job) Out Of Memory(OOM) 的情况，而且很大一部分情况是发生在 Shuffle 阶段。那么在 Spark Shuffle 中具体是哪些地方会使用比较多的内存而有可能导致 OOM 呢？ 为此，本文将围绕以上问题梳理 Spark 内存管理和 Shuffle 过程中与内存使用相关的知识；然后，简要分析下在 Spark Shuffle 中有可能导致 OOM 的原因。</p>
<h2 id="OOM"><a href="#OOM" class="headerlink" title="OOM"></a>OOM</h2><p>内存不够，数据太多就会抛出 OOM 的 Exeception，主要有 driver OOM 和 executor OOM两种</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">java</span><span class="selector-class">.lang</span><span class="selector-class">.OutOfMemoryError</span>: <span class="selector-tag">Java</span> <span class="selector-tag">heap</span> <span class="selector-tag">space</span></span><br></pre></td></tr></table></figure>

<h3 id="driver-OOM"><a href="#driver-OOM" class="headerlink" title="driver OOM"></a><strong>driver OOM</strong></h3><ul>
<li><strong>用户在 Driver 端口生成大对象, 比如创建了一个大的集合数据结构</strong></li>
<li><strong>使用了collect 等操作，将所有 executor 的数据聚合到 driver 导致</strong></li>
</ul>
<p>一般是使用了collect 等操作，将所有 executor 的数据聚合到 driver 导致。尽量不要使用 collect 操作即可。</p>
<h3 id="executor-OOM"><a href="#executor-OOM" class="headerlink" title="executor OOM"></a><strong>executor OOM</strong></h3><h3 id="数据倾斜导致内存溢出"><a href="#数据倾斜导致内存溢出" class="headerlink" title="数据倾斜导致内存溢出"></a><strong>数据倾斜导致内存溢出</strong></h3><p>数据不平衡除了有可能导致内存溢出外，也有可能导致性能的问题，调用 repartition 重新分区</p>
<h3 id="Reduce-OOM"><a href="#Reduce-OOM" class="headerlink" title="Reduce OOM"></a>Reduce OOM</h3><p>reduce task 去 map 端获取数据，reduce一边拉取数据一边聚合，reduce端有一块聚合内存[executor memory * 0.2],也就是这块内存不够<br><strong>解决方法</strong></p>
<ul>
<li>增加 reduce 聚合操作的内存的比例</li>
<li>增加 Executor memory 的大小 <strong>–executor-memory 5G</strong></li>
<li>减少 reduce task 每次拉取的数据量 设置 spak.reducer.maxSizeInFlight 24m, 拉取的次数就多了，因此建立连接的次数增多，有可能会连接不上[正好赶上 map task 端进行GC]</li>
</ul>
<h3 id="shuffle-后内存溢出"><a href="#shuffle-后内存溢出" class="headerlink" title="shuffle 后内存溢出"></a><strong>shuffle 后内存溢出</strong></h3><p>shuffle 后单个文件过大导致内存溢出。在 Spark 中，join，reduceByKey 这一类型的过程，都会有shuffle 的过程，在 shuffle 的使用，需要传入一个 partitioner，大部分 Spark 中的 shuffle 操作，默认的 partitioner 都是 HashPatitioner，默认值是父 RDD 中最大的分区数,这个参数通过spark.default.parallelism 控制 [在spark-sql中用spark.sql.shuffle.partitions] </p>
<p>spark.default.parallelism 参数只对 HashPartitioner 有效，所以如果是别的 Partitioner 或者自己实现的 Partitioner 就不能使用 spark.default.parallelism 这个参数来控制 shuffle 的并发量了。如果是别的partitioner 导致的 shuffle 内存溢出，就需要从 partitioner 的代码增加 partitions 的数量</p>
<h3 id="coalesce-调用导致内存溢出"><a href="#coalesce-调用导致内存溢出" class="headerlink" title="coalesce 调用导致内存溢出"></a><strong>coalesce 调用导致内存溢出</strong></h3><p>因为 hdfs 中不适合存小问题，所以 Spark 计算后如果产生的文件太小，调用 coalesce 合并文件再存入 hdfs中。但会导致一个问题，例如在 coalesce 之前有100个文件，这也意味着能够有100个 Task，现在调用coalesce(10)，最后只产生10个文件，因为 coalesce 并不是 shuffle 操作，这意味着 coalesce并不是先执行100个 Task，再将 Task 的执行结果合并成10个，而是从头到位只有10个 Task 在执行，原本100个文件是分开执行的，现在每个 Task 同时一次读取10个文件，使用的内存是原来的10倍，这导致了OOM。</p>
<p>解决这个问题的方法是令程序按照我们想的先执行100个 Task 再将结果合并成10个文件，这个问题同样可以通过repartition 解决，调用 repartition(10)</p>
<h3 id="standalone-模式下资源分配不均匀导致内存溢出"><a href="#standalone-模式下资源分配不均匀导致内存溢出" class="headerlink" title="standalone 模式下资源分配不均匀导致内存溢出"></a><strong>standalone 模式下资源分配不均匀导致内存溢出</strong></h3><p>在 standalone 的模式下如果配置了 –total-executor-cores 和 –executor-memory 这两个参数，但是没有配置 –executor-cores 参数，有可能导致，每个 Executor 的 memory 是一样的，但是 cores 的数量不同，那么在 cores 数量多的 Executor 中，由于能够同时执行多个Task，就容易导致内存溢出的情况。</p>
<p>这种情况的解决方法就是同时配置–executor-cores或者spark.executor.cores参数，确保Executor资源分配均匀。</p>
<h3 id="map-过程产生大量对象导致内存溢出"><a href="#map-过程产生大量对象导致内存溢出" class="headerlink" title="map 过程产生大量对象导致内存溢出"></a><strong>map 过程产生大量对象导致内存溢出</strong></h3><p>这种溢出的原因是在单个 map 中产生了大量的对象导致的</p>
<p>例如：rdd.map(x=&gt;for(i &lt;- 1 to 10000) yield i.toString)，这个操作在rdd中，每个对象都产生了10000 个对象，这肯定很容易产生内存溢出的问题。</p>
<p>针对这种问题，在不增加内存的情况下，可以通过减少每个 Task 的大小，以便达到每个 Task 即使产生大量的对象 Executor 的内存也能够装得下。具体做法可以在会产生大量对象的 map 操作之前调用 repartition方法，分区成更小的块传入map。</p>
<p>例如：rdd.repartition(10000).map(x=&gt;for(i &lt;- 1 to 10000) yield i.toString)</p>
<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a><strong>参数</strong></h2><h3 id="spark-driver-memory"><a href="#spark-driver-memory" class="headerlink" title="spark.driver.memory"></a>spark.driver.memory</h3><p>用来设置 Driver 的内存。在 Spark 程序中，SparkContext，DAGScheduler 都是运行在Driver端的。对应Stage 切分也是在 Driver 端运行，如果用户自己写的程序有过多的步骤，切分出过多的 Stage，这部分信息消耗的是 Driver 的内存，这个时候就需要调大 Driver 的内存</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">周晓晨</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://joccer.gitee.io/2019/11/22/Spark%20%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97/">http://joccer.gitee.io/2019/11/22/Spark%20%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://joccer.gitee.io" target="_blank">周晓晨</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/image/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/image/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/image/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/image/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2019/11/22/Spark%20%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Spark 存储模块</div></div></a></div><div class="next-post pull-right"><a href="/2019/11/22/Spark%20%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Spark 存储模块</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2021 By 周晓晨</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const initData = {
      el: '#vcomment',
      appId: 'os3tR4qQtIEkoK1S8XDHyBwY-gzGzoHsz',
      appKey: 'obbNIfixVI0uj7WoAqKy0hUv',
      placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
      avatar: 'monsterid',
      meta: 'nick,mail'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }

    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/6d85e03d.js","daovoice")
</script><script>var isChatBtn = true
daovoice('init', {
  app_id: '6d85e03d',},{
  launcher: { 
     disableLauncherIcon: isChatBtn // 悬浮 ICON 是否显示
  },
});
daovoice('update');

if (isChatBtn) {
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      daovoice('show')
    });
  }
  chatBtnFn()
} else {
  if (false) {
    function chatBtnHide () {
      daovoice('update', {},{
        launcher: { 
        disableLauncherIcon: true // 悬浮 ICON 是否显示
        },
      });
    }
    function chatBtnShow () {
      daovoice('update', {},{
        launcher: { 
        disableLauncherIcon: false // 悬浮 ICON 是否显示
        },
      });
    }
  }
}</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>