<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Flink 内部保证 Exactly Once | 周晓晨</title><meta name="author" content="周晓晨"><meta name="copyright" content="周晓晨"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="在分布式场景下，应用程序随时可能出现任何形式的故障，例如：机器硬件故障、程序 OOM 等。当应用程序出现故障时，Flink 为了保证数据消费的 Exactly Once，需要有相应的故障容错能力。Flink 是通过周期性 Checkpoint 的方式来实现故障容错，这里使用的是基于 Chandy-Lamport 改进的算法。">
<meta property="og:type" content="article">
<meta property="og:title" content="Flink 内部保证 Exactly Once">
<meta property="og:url" content="http://joccer.gitee.io/2019/12/10/Flink%20%E5%86%85%E9%83%A8%E4%BF%9D%E8%AF%81%20Exactly%20Once/index.html">
<meta property="og:site_name" content="周晓晨">
<meta property="og:description" content="在分布式场景下，应用程序随时可能出现任何形式的故障，例如：机器硬件故障、程序 OOM 等。当应用程序出现故障时，Flink 为了保证数据消费的 Exactly Once，需要有相应的故障容错能力。Flink 是通过周期性 Checkpoint 的方式来实现故障容错，这里使用的是基于 Chandy-Lamport 改进的算法。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2019-12-10T02:06:07.000Z">
<meta property="article:modified_time" content="2021-05-24T06:09:23.420Z">
<meta property="article:author" content="周晓晨">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://joccer.gitee.io/2019/12/10/Flink%20%E5%86%85%E9%83%A8%E4%BF%9D%E8%AF%81%20Exactly%20Once/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":1,"position":"top","messagePrev":"这篇文章已经发表","messageNext":"天了，其中某些内容可能已经过时～"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-05-24 14:09:23'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><link rel="stylesheet" href="/css/iconfont.css"><meta name="generator" content="Hexo 5.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/chen.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">154</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">10</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">15</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 项目实战</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/playlist/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-folder-open"></i><span> 视频资料</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 数值分析</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 编译原理</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 操作系统</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机组成</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机网络</span></a></li><li><a class="site-page" href="/teach/jvm/"><i class="fa-fw fas fa-video"></i><span> JVM</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> MySQL数据库</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Flink-Checkpoint-%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">1. Flink Checkpoint 概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Flink-Checkpoint-%E4%BB%A5%E5%8F%8A-Checkpoint-%E5%A4%84%E6%81%A2%E5%A4%8D%E4%BB%BB%E5%8A%A1"><span class="toc-number">2.</span> <span class="toc-text">2. Flink Checkpoint 以及 Checkpoint 处恢复任务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%A4%9A%E5%B9%B6%E8%A1%8C%E5%BA%A6%E3%80%81%E5%A4%9A-Operator-%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8CCheckpoint-%E7%9A%84%E8%BF%87%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">3. 多并行度、多 Operator 情况下，Checkpoint 的过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Checkpoint-%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B"><span class="toc-number">3.1.</span> <span class="toc-text">3.1. Checkpoint 执行过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-barrier-%E5%AF%B9%E9%BD%90"><span class="toc-number">3.2.</span> <span class="toc-text">3.2. barrier 对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-barrier-%E4%B8%8D%E5%AF%B9%E9%BD%90"><span class="toc-number">3.3.</span> <span class="toc-text">3.3. barrier 不对齐</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-1-barrier-%E4%B8%8D%E5%AF%B9%E9%BD%90%EF%BC%8CCheckpoint-%E6%B5%81%E7%A8%8B"><span class="toc-number">3.3.1.</span> <span class="toc-text">3.3.1. barrier 不对齐，Checkpoint 流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-2-barrier-%E5%AF%B9%E9%BD%90%EF%BC%8CCheckpoint-%E6%B5%81%E7%A8%8B"><span class="toc-number">3.3.2.</span> <span class="toc-text">3.3.2. barrier 对齐，Checkpoint 流程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E7%AB%AF%E5%AF%B9%E7%AB%AF%E4%BF%9D%E8%AF%81-Exactly-Once"><span class="toc-number">4.</span> <span class="toc-text">3. 端对端保证 Exactly Once</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E6%80%A7%E5%86%99%E5%85%A5%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%AB%AF%E5%AF%B9%E7%AB%AF%E7%9A%84-Exactly-Once"><span class="toc-number">4.0.1.</span> <span class="toc-text">幂等性写入如何保证端对端的 Exactly Once</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TwoPhaseCommitSinkFunction-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E7%AB%AF%E5%AF%B9%E7%AB%AF%E7%9A%84-Exactly-Once"><span class="toc-number">4.0.2.</span> <span class="toc-text">TwoPhaseCommitSinkFunction 如何保证端对端的 Exactly Once</span></a></li></ol></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">周晓晨</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 项目实战</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/playlist/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-folder-open"></i><span> 视频资料</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 数值分析</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 编译原理</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 操作系统</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机组成</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机网络</span></a></li><li><a class="site-page" href="/teach/jvm/"><i class="fa-fw fas fa-video"></i><span> JVM</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> MySQL数据库</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Flink 内部保证 Exactly Once</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-12-10T02:06:07.000Z" title="发表于 2019-12-10 10:06:07">2019-12-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-05-24T06:09:23.420Z" title="更新于 2021-05-24 14:09:23">2021-05-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Flink/">Flink</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">9.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>30分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>在分布式场景下，应用程序随时可能出现任何形式的故障，例如：机器硬件故障、程序 OOM 等。当应用程序出现故障时，Flink 为了保证数据消费的 Exactly Once，需要有相应的故障容错能力。Flink 是通过周期性 Checkpoint 的方式来实现故障容错，这里使用的是基于 Chandy-Lamport 改进的算法。</p>
<a id="more"></a>

<p>Flink 官网定义是 Stateful Computations over Data Streams(数据流上的有状态计算)。幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生副作用。而计算 PV、UV 就属于有状态计算。实时计算 PV 时，每次都需要从某个存储介质的结果表中拿到之前的 PV 值，+1 后 set 到结果表中。有状态计算表示输出的结果跟之前的状态有关系，不符合幂等性，访问多次，PV 会增加。</p>
<h2 id="1-Flink-Checkpoint-概述"><a href="#1-Flink-Checkpoint-概述" class="headerlink" title="1. Flink Checkpoint 概述"></a>1. Flink Checkpoint 概述</h2><p><strong>Flink Checkpoint 机制的存在就是为了解决 Flink 任务在运行过程中由于各种原因导致任务失败后，能够正常恢复任务。</strong></p>
<p><strong>Checkpoint 是通过给程序做快照的方式使得将整个程序某些时刻的状态保存下来，当任务挂掉之后，默认从最近一次保存的完整快照处进行恢复任务。</strong></p>
<p>Flink 在数据中加了一个叫做 barrier ，下图中红圈处就是两个 barrier。</p>
<img src="/Users/joker/Documents/chen_blog/source/images/flink/00084.png" alt="截屏2021-05-24 上午10.01.07" style="zoom:30%;" />

<p>barrier 从 Source Task 处生成，一直流到 Sink Task，期间所有的 Task 只要碰到 barrier，就会触发自身进行快照。如图所示，Checkpoint barrier n-1 处做的快照就是指 Job 从开始处理到 barrier n-1 所有的状态数据，barrier n 处做的快照就是指从 Job 开始到处理到 barrier n 所有的状态数据。</p>
<p>Source Task 会把 barrier 和要处理的数据一块往下游发送，当 task 接收到 barrier 后，意味着 barrier 之前的数据已经被 task 处理完了，此时也会暂停处理 barrier 之后的数据，将自己内存中保存的信息保存到状态后端中。Flink 通过以上过程来保存快照的。</p>
<blockquote>
<p>上述过程中，barrier 的作用就是为了把数据区分开，barrier 之前的数据是本次 Checkpoint 之前必须处理完的数据，barrier 之后的数据在本次 Checkpoint 之前不能被处理。</p>
</blockquote>
<p>Checkpoint 同步做快照的过程中，不能处理 barrier 之后的数据。Checkpoint 将快照信息写入到磁盘后，为了保证快照信息的高可用，需要将快照上传到 HDFS，这个上传快照到 HDFS 的过程是异步进行的，这个过程也可以处理 barrier 之后的数据，处理 barrier 之后的数据不会影响到磁盘上的快照信息。</p>
<h2 id="2-Flink-Checkpoint-以及-Checkpoint-处恢复任务"><a href="#2-Flink-Checkpoint-以及-Checkpoint-处恢复任务" class="headerlink" title="2. Flink Checkpoint 以及 Checkpoint 处恢复任务"></a>2. Flink Checkpoint 以及 Checkpoint 处恢复任务</h2><p>计算各个 app 的 PV，把要统计的 app_id 做为 key，对应的 PV 值做为 value，将统计的结果放到一个 Map 集合中，从 Kafka 读取到一条条日志，由于要统计各 app 的 PV，所以需要从日志中解析出 app_id 字段，每来一条日志，只需要从 Map 集合将相应 app_id 的 PV 值拿出来，+1 后 put 到 Map 中，这样Map 中永远保存着所有 app 最新的 PV 数据。</p>
<blockquote>
<p>首先 JobManager 端会向所有 SourceTask 发送 Checkpoint，Source Task 会在数据流中安插 Checkpoint barrier。</p>
</blockquote>
<img src="/Users/joker/Documents/chen_blog/source/images/flink/000571.png" alt="截屏2021-05-24 上午10.05.38" style="zoom:30%;" />

<blockquote>
<p>Source Task 安插好 barrier 后，会将 barrier 跟数据一块发送给下游，然后自身开始做快照，并将快照信息 offset(0,60000) 发送到高可用的持久化存储介质，例如 HDFS 上。</p>
</blockquote>
<img src="/Users/joker/Documents/chen_blog/source/images/flink/000575.png" alt="截屏2021-05-24 上午10.06.32" style="zoom:30%;" />

<blockquote>
<p>下游的 PV task 接收到 barrier 后，也会做快照，并将快照信息 PV：(app1,50000) (app2,10000) 发送到 HDFS。</p>
</blockquote>
<img src="/Users/joker/Documents/chen_blog/source/images/flink/000576.png" alt="截屏2021-05-24 上午10.07.20" style="zoom:33%;" />

<blockquote>
<p>假设第 100 次 Checkpoint 完成后，一段时间后任务挂了，Flink 任务会自动从状态后端恢复任务。Source Task 去读取自己需要的状态信息 offset(0,60000)，并从 offset 为 60000 的位置接着开始消费数据，PV task 也会去读取需要的状态信息 PV：(app1,50000) (app2,10000)，并在该状态值的基础上，往上累积计算 PV 值。</p>
</blockquote>
<img src="/Users/joker/Documents/chen_blog/source/images/flink/0015.png" alt="截屏2021-05-24 上午10.54.27" style="zoom:30%;" />

<h2 id="3-多并行度、多-Operator-情况下，Checkpoint-的过程"><a href="#3-多并行度、多-Operator-情况下，Checkpoint-的过程" class="headerlink" title="3. 多并行度、多 Operator 情况下，Checkpoint 的过程"></a>3. 多并行度、多 Operator 情况下，Checkpoint 的过程</h2><p>生产环境中，一般都是多并行度，而且算子也会比较多，这种情况下 Checkpoint 的过程就会变得复杂。分布式状态容错面临的问题与挑战：</p>
<ul>
<li>如何确保状态拥有<strong>精确一次</strong>的容错保证？</li>
<li>如何在分布式场景下替多个拥有本地状态的算子产生<strong>一个全域一致的快照</strong>？</li>
<li>如何在<strong>不中断运算</strong>的前提下产生快照？</li>
</ul>
<h3 id="3-1-Checkpoint-执行过程"><a href="#3-1-Checkpoint-执行过程" class="headerlink" title="3.1. Checkpoint 执行过程"></a>3.1. Checkpoint 执行过程</h3><p>所有的 Operator 运行过程中接收到所有上游算子发送 barrier 后，对自身的状态进行一次快照，保存到相应状态后端。</p>
<img src="/Users/joker/Library/Application Support/typora-user-images/截屏2021-05-24 上午10.55.54.png" alt="截屏2021-05-24 上午10.55.54" style="zoom:25%;" />



<p>当任务从状态恢复时，每个 Operator 从状态后端读取自己相应的状态信息，数据源会从状态中保存的位置开始重新消费，后续的其他算子也会基于 Checkpoint 中保存的状态进行计算。</p>
<img src="/Users/joker/Documents/chen_blog/source/images/flink/000093.png" alt="截屏2021-05-24 上午10.56.51" style="zoom:25%;" />

<p>整个 Checkpoint 的过程跟之前单并行度类似，图中有 4 个带状态的 Operator 实例，相应的状态后端就可以想象成 4 个格子。整个 Checkpoint 的过程可以当做 Operator 实例填自己格子的过程，Operator 实例将自身的状态写到状态后端中相应的格子，当所有的格子填满可以简单地认为一次完整的 Checkpoint 做完了。</p>
<p>上面只是快照的过程，Checkpoint 执行过程如下：</p>
<ol>
<li><p>JobManager 端的 CheckPointCoordinator 向所有 Source Task 发送 CheckPointTrigger，Source Task 会在数据流中安插 Checkpoint barrier。</p>
</li>
<li><p>当 task 收到所有的 barrier 后，向自己的下游继续传递 barrier，然后自身执行快照，并将自己的状态<strong>异步写入到持久化存储</strong>中。</p>
</li>
</ol>
<ul>
<li>增量 CheckPoint 只是把最新的一部分数据更新写入到外部存储；</li>
<li>为了下游尽快开始做 CheckPoint，所以会先发送 barrier 到下游，自身再同步进行快照。</li>
</ul>
<ol start="3">
<li><p>当 task 对状态的快照信息完成备份后，会将备份数据的地址（state handle）通知给 JobManager 的 CheckPointCoordinator。</p>
<p>如果 Checkpoint 的持续时长超过了 Checkpoint 设定的超时时间，CheckPointCoordinator 还没有收集完所有的 State Handle，CheckPointCoordinator就会认为本次 Checkpoint 失败，会把这次 Checkpoint 产生的所有状态数据全部删除。</p>
</li>
<li><p>CheckPointCoordinator 把整个 StateHandle 封装成 completed Checkpoint Meta，写入到 HDFS，整个 Checkpoint 结束。</p>
</li>
</ol>
<h3 id="3-2-barrier-对齐"><a href="#3-2-barrier-对齐" class="headerlink" title="3.2. barrier 对齐"></a>3.2. barrier 对齐</h3><p>当前的 Operator 实例接收上游两个流的数据，一个是字母流，一个是数字流。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151558.jpg" alt="img"></p>
<p>当 Checkpoint 时，上游字母流和数字流都会往 Operator 实例发送 Checkpoint barrier，但是由于每个算子的执行速率不同，所以不可能保证上游两个流的 barrier 同时到达 Operator 实例，当一个 Operator 实例有多个输入流时，Operator 实例需要在做快照之前进行 barrier 对齐，等待所有输入流的 barrier 都到达。barrier 对齐的详细过程如下所示：</p>
<ol>
<li>对于一个有多个输入流的 Operator 实例，当 Operator 实例从其中一个输入流接收到 Checkpoint barrier n 时，就不能处理来自该流的任何数据记录了，直到它从其他所有输入流接收到 barrier n 为止，否则 <strong>Operator 实例 Checkpoint n 的快照会混入快照 n 的记录和快照 n+1 的记录</strong>。如上图中第 1 个小图所示，数字流的 barrier 先到达了。</li>
<li>接收到 barrier n 的流暂时被搁置，从这些流接收的记录不会被处理，而是放入输入缓冲区。图 2 中，可以看到虽然数字流对应的 barrier 已经到达了，但是 barrier 之后的 1、2、3 这些数据只能放到缓冲区中，等待字母流的 barrier 到达。</li>
<li>一旦最后所有输入流都接收到 barrier n，Operator 实例就会把 barrier 之前所有已经处理完成的数据和 barrier n 一块发送给下游。然后 Operator 实例就可以对状态信息进行快照。如图 3 所示，Operator 实例接收到上游所有流的 barrier n，此时 Operator 实例就可以将 barrier 和 barrier 之前的数据发送到下游，然后自身状态进行快照。</li>
<li>快照做完后，Operator 实例将继续处理缓冲区的记录，然后就可以处理输入流的数据。如图 4 所示，先处理完缓冲区数据，就可以正常处理输入流的数据了。</li>
</ol>
<h3 id="3-3-barrier-不对齐"><a href="#3-3-barrier-不对齐" class="headerlink" title="3.3. barrier 不对齐"></a>3.3. barrier 不对齐</h3><p>barrier 不对齐是指当还有其他流的 barrier 还没到达时，为了提高 Operator 实例的处理性能，Operator 实例会直接处理 barrier 之后的数据，等到所有流的barrier 都到达后，就可以对该 Operator 做 Checkpoint 快照了。</p>
<p>对应到图中就是，barrier 不对齐时会直接把 barrier 之后的数据 1、2、3 直接处理掉，而<strong>不是</strong>放到缓冲区中等待其他的输入流的 barrier 到达，当所有输入流的 barrier 都到达后，才开始对 Operator 实例的状态信息进行快照，这样会导致做快照之前，Operator 实例已经处理了一些 barrier n 之后的数据。</p>
<p>Checkpoint 的目的是为了保存快照信息，如果 barrier 不对齐，那么 Operator 实例在做第 n 次 Checkpoint 之前，已经处理了一些 barrier n 之后的数据，当程序从第 n 次 Checkpoint 恢复任务时，程序会从第 n 次 Checkpoint 保存的 offset 位置开始消费数据，就会导致一些数据被处理了两次，就出现了重复消费。如果进行 barrier 对齐，就不会出现这种重复消费的问题，所以，<strong>barrier 对齐就可以实现 Exactly Once，barrier 不对齐就变成了 At Least Once。</strong></p>
<blockquote>
<p>假设 topic 有 2 个 partittion，且计算的是平台的总 PV，也就是说不需要区分 app，每条一条数据，都需要将其 PV 值 +1 即可。如下图所示，Flink 应用程序有两个 Source Task，一个计算 PV 的 Task，这里计算 PV 的 Task 就出现了存在多个输入流的情况。</p>
</blockquote>
<img src="/Users/joker/Documents/chen_blog/source/images/flink/000830.png" alt="截屏2021-05-24 上午11.02.09" style="zoom:25%;" />

<h4 id="3-3-1-barrier-不对齐，Checkpoint-流程"><a href="#3-3-1-barrier-不对齐，Checkpoint-流程" class="headerlink" title="3.3.1. barrier 不对齐，Checkpoint 流程"></a>3.3.1. barrier 不对齐，Checkpoint 流程</h4><img src="/Users/joker/Documents/chen_blog/source/images/flink/0097.png" alt="截屏2021-05-24 上午11.03.32" style="zoom:30%;" />



<p>如左图所示，Source Subtask 0 和 Subtask 1 已经完成了快照操作，它们的状态信息为 offset(0,10000)(1,10005)，表示 partition0 消费到 offset 为 10000 的位置，partition 1 消费到 offset 为 10005 的位置。当 Source Subtask 1 的 barrier 到达 PV task 时，计算的 PV 结果为 20002，但 PV task 还没有接收到 Source Subtask 0 发送的 barrier，所以 PV task 还不能对自身状态信息进行快照。由于设置的 barrier 不对齐，所以此时 PV task 会继续处理 Source Subtask 0 和 Source Subtask 1 传来的数据。</p>
<p>很快，如右图所示，PV task 接收到 Source Subtask 0 发来的 barrier，但是 PV task 已经处理了 Source Subtask 1 barrier 之后的三条数据，所以 PV 值目前已经为 20008 了，这里的 PV=20008 实际上已经处理到 partition 1 offset 为 10008 的位置，此时 PV task 会对自身的状态信息(PV = 20008)做快照，整体的快照信息为 offset(0,10000)(1,10005) PV=20008。</p>
<p>接着程序在继续运行，过了 10 秒，由于某个服务器故障，导致 Operator 实例有一个挂了，所以 Flink 会从最近一次 Checkpoint 保存的状态恢复。</p>
<p>Flink 同样会起三个 Operator 实例， Source Subtask 0、Source Subtask 1 和 PV task。三个 Operator 会从状态后端读取保存的状态信息。</p>
<ol>
<li>Source Subtask 0 会从 partition 0 offset 为 10000 的位置开始消费，</li>
<li>Source Subtask 1 会从 partition 1 offset 为 10005 的位置开始消费，</li>
<li>PV task 会基于 PV=20008 进行累加统计。</li>
</ol>
<p>然后就会发现的 PV 值 20008 实际上已经包含了 partition 1 的offset 10005<del>10008 的数据，所以 partition 1 从 offset 10005 恢复任务时，partition1 的 offset 10005</del>10008 的数据被消费了两次，出现了重复消费的问题，所以 barrier 不对齐只能保证 At Least Once。</p>
<h4 id="3-3-2-barrier-对齐，Checkpoint-流程"><a href="#3-3-2-barrier-对齐，Checkpoint-流程" class="headerlink" title="3.3.2. barrier 对齐，Checkpoint 流程"></a>3.3.2. barrier 对齐，Checkpoint 流程</h4><p>如下图所示，当 PV task 接收到 Source Subtask 1 的 barrier 后，并不会处理 Source Subtask 1 barrier 之后的数据，而是把这些数据放到 PV task 的输入缓冲区中，直到等到 Source Subtask 0 的 barrier 到达后，PV task 才会对自身状态信息进行快照。</p>
<p>此时 PV task 会把 PV=20005 保存到快照信息中，整体的快照状态信息为 offset(0,10000)(1,10005) PV=20005，当任务从 Checkpoint 恢复时，Source Subtask 0 会从 partition 0 offset 为 10000 的位置开始消费，Source Subtask 1 会从 partition 1 offset 为 10005 的位置开始消费，PV task 会基于 PV=20005 进行累加统计，所以 barrier 对齐能保证 Flink 内部的 Exactly Once。</p>
<p>在 Flink 应用程序中，当 Checkpoint 语义设置 Exactly Once 或 At Least Once 时，唯一的区别就是 barrier 对不对齐。当设置为 Exactly Once 时，就会 barrier 对齐，当设置为 At Least Once 时，就会 barrier 不对齐。<img src="/Users/joker/Documents/chen_blog/source/images/flink/0060.png" alt="截屏2021-05-24 上午11.08.28" style="zoom:50%;" /></p>
<p>barrier 对齐其实是要付出代价的，从 barrier 对齐的过程可以看出，PV task 明明可以更高效的处理数据，但因为 barrier 对齐，导致 Source Subtask 1 barrier 之后的数据被放到缓冲区中，暂时性地没有被处理，假如生产环境中，Source Subtask 0 的 barrier 迟迟没有到达，比 Source Subtask 1 延迟了 30 秒，那么这 30 秒期间，Source Subtask 1 barrier 之后的数据不能被处理，所以 PV task 相当于被闲置了。</p>
<p>一些业务场景对 Exactly Once 要求不高时，可以设置 Flink 的 Checkpoint 语义是 At Least Once 来小幅度的提高应用程序的执行效率。Flink Web UI 的 Checkpoint 选项卡中可以看到 barrier 对齐的耗时，如果发现耗时比较长，且对 Exactly Once 语义要求不高时，可以考虑使用该优化方案。</p>
<p>一般为了高可用，会把状态里的数据比如 offset(0,60000) PV(app1,50000)(app2,10000) 信息保存到 HDFS 中，如果频繁访问 HDFS，肯定会造成吞吐量下降，所以一般我们的 Checkpoint 时间间隔可以设置为分钟级别，例如 1 分钟、3 分钟，对于状态很大的任务每次 Checkpoint 访问 HDFS 比较耗时，我们甚至可以设置为 5 分钟一次 Checkpoint，毕竟我们的应用程序挂的概率并不高，偶尔一次从 5 分钟前的状态恢复，我们是可以接受的。</p>
<p>可以根据业务场景合理地调节 Checkpoint 的间隔时长，对于状态很小的 Job Checkpoint 会很快，我们可以调小时间间隔，对于状态比较大的 Job Checkpoint 会比较慢，我们可以调大 Checkpoint 时间间隔。</p>
<h2 id="3-端对端保证-Exactly-Once"><a href="#3-端对端保证-Exactly-Once" class="headerlink" title="3. 端对端保证 Exactly Once"></a>3. 端对端保证 Exactly Once</h2><p>Flink 与外部存储介质之间进行数据交互统称为端对端或 end to end 数据传输。</p>
<p>正如上述 Flink 写 MySQL 的案例所示，在第 n 次 Checkpoint 结束后，第 n+1 次 Checkpoint 之前，如果 Flink 应用程序已经向外部的存储介质中成功写入并提交了一些数据后，Flink 应用程序由于某些原因挂了，导致任务从第 n 次 Checkpoint 处恢复。这种情况下，就会导致第 n 次 Checkpoint 结束后且任务失败之前往外部存储介质中写入的那一部分数据重复写入两次，可能会导致相同的数据在存储介质中存储了两份，从而端对端的一致性语义保证从 Exactly Once 退化为 At Least Once。</p>
<p>这里只考虑了数据重复的情况，为什么不考虑丢数据的情况呢？在写数据时可以对异常进行捕获增加重试策略，如果重试多次还没有成功可以让 Flink 任务失败，Flink 任务就会从最近一次成功的 Checkpoint 处恢复，就不会出现丢数据的情况，所以我们本节内容主要用来解决数据重复的问题。</p>
<p>针对上述端对端 Exactly Once 的问题，我们可以使用以下方案来解决：</p>
<ol>
<li>假如我们使用的存储介质支持按照全局主键去重，那么比较容易实现 Exactly Once，无论相同的数据往外部存储中写入了几次，外部存储都会进行去重，只保留一条数据。例如，app1 的 PV 值为 10，现在把（key=app1，value=10）往 Redis 中写入 10 次，只是说把 value 值覆盖了 10 次，并不会导致结果错误，这种方案属于幂等性写入。</li>
<li>我们上述案例中为什么会导致重复写入数据到外部存储呢？是因为在下一次 Checkpoint 之前如果任务失败时，一些数据已经成功写入到了外部存储中，没办法删除那些数据。既然问题是这样，那可以想办法把“向外部存储中提交数据”与 Checkpoint 强关联，两次 Checkpoint 之间不允许向外部存储介质中提交数据，Checkpoint 的时候再向外部存储提交。如果提交成功，则 Checkpoint 成功，提交失败，则 Checkpoint 也失败。这样在下一次 Checkpoint 之前，如果任务失败，也没有重复数据被提交到外部存储。这里只是描述一下大概思想，好多细节这里并没有详细描述，会在下文中详细描述。基于上述思想，Flink 实现了 TwoPhaseCommitSinkFunction，它提取了两阶段提交协议的通用逻辑，使得通过 Flink 来构建端到端的 Exactly Once 程序成为可能。它提供了一个抽象层，用户只需要实现少数方法就能实现端到端的 Exactly Once 语义。不过这种方案必须要求我们的输出端（Sink 端）必须支持事务。</li>
</ol>
<p>下面我们通过两部分来详细介绍上述两种方案。</p>
<h4 id="幂等性写入如何保证端对端的-Exactly-Once"><a href="#幂等性写入如何保证端对端的-Exactly-Once" class="headerlink" title="幂等性写入如何保证端对端的 Exactly Once"></a>幂等性写入如何保证端对端的 Exactly Once</h4><p>实时 ETL 当 HBase 做为 Sink 端时，就是典型的应用场景。把日志中的主键做为 HBase 的 rowkey，就可以保证数据不重复，实现比较简单，这里不多赘述。</p>
<p>继续探讨实时计算各 app PV 的案例，将统计结果以普通键值对的形式保存到 Redis 中供业务方查询。到底如何实现，才能保证 Redis 中的结果是精准的呢？在之前 Strom 或 Spark Streaming 的方案中，将统计的 PV 结果保存在 Redis 中，每来一条数据，从 Redis 中获取相应 app 对应的 PV 值然后内存中进行 +1 后，再将 PV 值 put 到 Redis 中。</p>
<p>例如：Redis 中保存 app1 的 PV 为 10，现在来了一条 app1 的日志，首先从 Redis 中获取 app1 的 PV 值 =10，内存中 10+1=11，将 (app1,11) put 到 Redis 中，这里的 11 就是我们统计的 app1 的 PV 结果。可以将这种方案优化为 incr 或 incrby，直接对 Redis 中的 10 进行累加，不需要手动在内存中进行累加操作。</p>
<p>当然 Flink 也可以用上述的这种方案来统计各 app 的 PV，但是上述方案并不能保证 Exactly Once，为什么呢？当第 n 次 Checkpoint 时，app1 的 PV 结果为 10000，第 n 次 Checkpoint 结束后运行了 10 秒，Redis 中 app1 的 PV 结果已经累加到了 10200。此时如果任务挂了，从第 n 次 Checkpoint 恢复任务时，会继续按照 Redis 中保存的 PV=10200 进行累加，但是正确的结果应该是从 PV=10000 开始累加。</p>
<p>如果按照上面的方案统计 PV，就可能会出现统计值偏高的情况。这里也证实了一点：并不是说 Flink 程序的 Checkpoint 语义设置为 Exactly Once，就能保证我们的统计结果或者各种输出结果都能满足 Exactly Once。为了编写真正满足 Exactly Once 的代码，我们需要对 Flink 的 Checkpoint 原理做一些了解，编写对 Exactly Once 友好的代码。</p>
<p>那如何编写代码才能使得最后在 Redis 中保存的 PV 结果满足 Exactly Once 呢？上一节中，讲述了 Flink 内部状态可以保证 Exactly Once，这里可以将统计的 PV 结果保存在 Flink 内部的状态里，每次基于状态进行累加操作，并将累加到的结果 put 到 Redis 中，这样当任务从 Checkpoint 处恢复时，并不是基于 Redis 中实时统计的 PV 值进行累加，而是基于 Checkpoint 中保存的 PV 值进行累加，Checkpoint 中会保存每次 Checkpoint 时对应的 PV 快照信息，例如：第 n 次 Checkpoint 会把当时 pv=10000 保存到快照信息里，同时状态后端还保存着一份实时的状态信息用于实时累加。</p>
<p>示例代码如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">// 1 分钟一次 Checkpoint</span></span><br><span class="line">env.enableCheckpointing(TimeUnit.MINUTES.toMillis(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">CheckpointConfig checkpointConf = env.getCheckpointConfig();</span><br><span class="line"><span class="comment">// Checkpoint 语义 EXACTLY ONCE</span></span><br><span class="line">checkpointConf.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line">checkpointConf.enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);</span><br><span class="line"></span><br><span class="line">Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;localhost:9092&quot;</span>);</span><br><span class="line">props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;app-pv-stat&quot;</span>);</span><br><span class="line"></span><br><span class="line">DataStreamSource&lt;String&gt; appInfoSource = env.addSource(<span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">        <span class="comment">// kafka topic， String 序列化</span></span><br><span class="line">        <span class="string">&quot;app-topic&quot;</span>,  <span class="keyword">new</span> SimpleStringSchema(), props));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 按照 appId 进行 keyBy</span></span><br><span class="line">appInfoSource.keyBy((KeySelector&lt;String, String&gt;) appId -&gt; appId)</span><br><span class="line">        .map(<span class="keyword">new</span> RichMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">            <span class="keyword">private</span> ValueState&lt;Long&gt; pvState;</span><br><span class="line">            <span class="keyword">private</span> <span class="keyword">long</span> pv = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">super</span>.open(parameters);</span><br><span class="line">                <span class="comment">// 初始化状态</span></span><br><span class="line">                pvState = getRuntimeContext().getState(</span><br><span class="line">                        <span class="keyword">new</span> ValueStateDescriptor&lt;&gt;(<span class="string">&quot;pvStat&quot;</span>,</span><br><span class="line">                        TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Long&gt;() &#123;&#125;)));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Long&gt; <span class="title">map</span><span class="params">(String appId)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="comment">// 从状态中获取该 app 的 PV 值，+1 后，update 到状态中</span></span><br><span class="line">                <span class="keyword">if</span>(<span class="keyword">null</span> == pvState.value())&#123;</span><br><span class="line">                    pv = <span class="number">1</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    pv = pvState.value();</span><br><span class="line">                    pv += <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                pvState.update(pv);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(appId, pv);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">        .print();</span><br><span class="line"></span><br><span class="line">env.execute(<span class="string">&quot;Flink PV stat&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>详细代码请参考：</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-examples/src/main/java/com/zhisheng/examples/streaming/checkpoint/PvStatExactlyOnce.java">PvStatExactlyOnce.java</a></p>
</blockquote>
<p>代码中设置 1 分钟一次 Checkpoint，Checkpoint 语义 EXACTLY ONCE，从 Kafka 中读取数据，这里为了简化代码，所以 Kafka 中读取的直接就是 String 类型的 appId，按照 appId KeyBy 后，执行 RichMapFunction，RichMapFunction 的 open 方法中会初始化 ValueState<Long> 类型的 pvState，pvState 就是上文一直强调的状态信息，每次 Checkpoint 的时候，会把 pvState 的状态信息快照一份到 HDFS 来提供恢复。</p>
<p>这里按照 appId 进行 keyBy，所以每一个 appId 都会对应一个 pvState，pvState 里存储着该 appId 对应的 pv 值。每来一条数据都会执行一次 map 方法，当这条数据对应的 appId 是新 app 时，pvState 里就没有存储这个 appId 当前的 pv 值，将 pv 值赋值为 1，当 pvState 里存储的 value 不为 null 时，拿出 pv 值 +1后 update 到 pvState 里。map 方法再将 appId 和 pv 值发送到下游算子，下游直接调用了 print 进行输出，这里完全可以替换成相应的 RedisSink 或 HBaseSink。</p>
<p>本案例中计算 pv 的工作交给了 Flink 内部的 ValueState，不依赖外部存储介质进行累加，外部介质承担的角色仅仅是提供数据给业务方查询，所以无论下游使用什么形式的 Sink，只要 Sink 端能够按照主键去重，该统计方案就可以保证 Exactly Once。本案例使用的 ValueState，关于 State 的详细使用请参阅第 3.1 节。</p>
<h4 id="TwoPhaseCommitSinkFunction-如何保证端对端的-Exactly-Once"><a href="#TwoPhaseCommitSinkFunction-如何保证端对端的-Exactly-Once" class="headerlink" title="TwoPhaseCommitSinkFunction 如何保证端对端的 Exactly Once"></a>TwoPhaseCommitSinkFunction 如何保证端对端的 Exactly Once</h4><p>Flink 的源码中有这么一段注释：</p>
<blockquote>
<p>This is a recommended base class for all of the {@link SinkFunction} that intend to implement exactly-once semantic.</p>
</blockquote>
<p>意思是对于打算实现 Exactly Once 语义的所有 SinkFunction 都推荐继承该抽象类。在介绍 TwoPhaseCommitSinkFunction 之前，先了解一下 2PC 分布式一致性协议。</p>
<p>在分布式系统中，每一个机器节点虽然都能明确地知道自己在进行事务操作过程中的结果是成功或失败，但无法直接获取到其他分布式节点的操作结果。因此，当一个事务操作需要跨越多个分布式节点的时候，为了让每个节点都能够获取到其他节点的事务执行状况，需要引入一个“协调者（Coordinator）”节点来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点被称为“参与者（Participant）”。协调者负责调度参与者的行为，并最终决定这些参与者是否要把事务真正的提交。</p>
<p>普通的事务可以保证单个事务内所有操作要么全部成功，要么全部失败，而分布式系统中具体如何保证多台节点上执行的事务要么所有节点事务都成功，要么所有节点事务都失败呢？先了解一下 2PC 一致性协议。</p>
<p>2PC 是 Two-Phase Commit 的缩写，即两阶段提交。2PC 将分布式事务分为了两个阶段，分别是提交事务请求（投票）和执行事务提交。协调者会根据参与者在第一阶段的投票结果，来决定第二阶段是否真正的执行事务，具体流程如下。</p>
<p><strong>提交事务请求（投票）阶段</strong></p>
<ol>
<li>协调者向所有参与者发送 prepare 请求与事务内容，询问是否可以准备事务提交，并等待参与者的响应。</li>
<li>各参与者执行事务操作，并记录 Undo 日志（用于回滚）和 Redo日志（用于重放），但不真正提交。</li>
<li>参与者向协调者返回事务操作的执行结果，执行成功返回 Yes，否则返回 No。</li>
</ol>
<p><strong>执行事务提交阶段</strong></p>
<p>分为成功与失败两种情况。</p>
<p>若第一阶段所有参与者都返回 Yes，说明事务可以提交：</p>
<ol>
<li>协调者向所有参与者发送 Commit 请求。</li>
<li>参与者收到 Commit 请求后，会正式执行事务提交操作，并在提交完成后释放事务资源。</li>
<li>完成事务提交后，向协调者发送 Ack 消息。</li>
<li>协调者收到所有参与者的 Ack 消息，完成事务。</li>
<li>参与者收到 Commit 请求后，将事务真正地提交上去，并释放占用的事务资源，并向协调者返回 Ack。</li>
<li>协调者收到所有参与者的 Ack 消息，事务成功完成。</li>
</ol>
<p>若第一阶段有参与者返回 No 或者超时未返回，说明事务中断，需要回滚：</p>
<ol>
<li>协调者向所有参与者发送 Rollback 请求。</li>
<li>参与者收到 Rollback 请求后，根据 Undo 日志回滚到事务执行前的状态，释放占用的事务资源。</li>
<li>参与者在完成事务回滚后，向协调者返回 Ack。</li>
<li>协调者收到所有参与者的 Ack 消息，事务回滚完成。</li>
</ol>
<p>简单来讲，2PC 讲一个事务的处理过程分为了投票和执行两个阶段，其核心是每个事务都采用先尝试后提交的处理方式。下面分别图示出这两种情况：</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151552.jpg" alt="img"></p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151557.jpg" alt="img"></p>
<p>2PC 的优点：原理简单，实现方便。</p>
<p>2PC 的缺点：</p>
<ul>
<li>协调者单点问题：协调者在整个 2PC 协议中非常重要，一旦协调者故障，则 2PC 将无法运转。</li>
<li>过于保守：在 2PC 的阶段一，如果参与者出现故障而导致协调者无法获取到参与者的响应信息，这时协调者只能依靠自身的超时机制来判断是否需要中断事务，这种策略比较保守。换言之，2PC 没有涉及较为完善的容错机制，任意一个节点失败都会导致整个事务的失败。</li>
<li>同步阻塞：执行过程是完全同步的，各个参与者在等待其他参与者投票响应的的过程中，将无法进行其他任何操作。</li>
<li>数据不一致：在二阶段提交协议的阶段二，当协调者向所有的参与者发送 Commit 请求后，出现了局部网络异常或局部参与者机器故障等因素导致一部分的参与者执行了 Commit 操作，而发生故障的参与者没有执行 Commit，于是整个分布式系统便出现了数据不一致现象。</li>
</ul>
<p>Flink 的 TwoPhaseCommitSinkFunction 是基于 2PC 实现的。Flink 的 JobManager 对应到 2PC 中的协调者，Operator 实例对应到 2PC 中的参与者。TwoPhaseCommitSinkFunction 实现了 CheckpointedFunction 和 CheckpointListener 接口。</p>
<p>CheckpointedFunction 接口中有两个方法 snapshotState 和 initializeState，snapshotState 方法会在 Checkpoint 时且做快照之前被调用，initializeState 方法会在自定义 Function 初始化恢复状态时被调用。</p>
<p>CheckpointListener 接口中有一个 notifyCheckpointComplete 方法，Operator 实例的 Checkpoint 成功后，会反馈给 JobManager，当 JobManager 接收到所有 Operator 实例 Checkpoint 成功的通知后，就认为本次 Checkpoint 成功了，会给所有 Operator 实例发送一个 Checkpoint 完成的通知，Operator 实例接收到通知后，就会调用 notifyCheckpointComplete 方法。</p>
<p>TwoPhaseCommitSinkFunction定义了如下 5 个抽象方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 处理每一条数据</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">(TXN transaction, IN value, Context context)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 开始一个事务，返回事务信息的句柄</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> TXN <span class="title">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 预提交（即提交请求）阶段的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">preCommit</span><span class="params">(TXN transaction)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line"><span class="comment">// 正式提交阶段的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">(TXN transaction)</span></span>;</span><br><span class="line"><span class="comment">// 取消事务，Rollback 相关的逻辑</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">abort</span><span class="params">(TXN transaction)</span></span>;</span><br></pre></td></tr></table></figure>

<p>TwoPhaseCommitSinkFunction 里这些方法什么时候会被执行呢？如下图所示，在状态初始化的 initializeState 方法内或者每次 Checkpoint 的 snapshotState 方法内都会调用 beginTransaction 方法开启新的事务。开启新的事务后，Flink 开始处理数据，每来一条数据都会调用 invoke 方法，按照业务逻辑将数据添加到本次的事务中。等到下一次 Checkpoint 执行 snapshotState 时，会调用 preCommit 方法进行预提交，预提交一般会对事务进行 flush 操作，到这里为止可以理解为 2PC 的第一阶段。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-15-TwoPhaseCommitSinkFunction%20%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5.png" alt="img">)</p>
<p>第一阶段运行期间无论是机器故障还是 invoke 失败或者 preCommit 对应预提交的 flush 失败都可以理解为 2PC 的第一阶段返回了 No，即投票失败就会执行 2PC 第二阶段的 Rollback，对应到 TwoPhaseCommitSinkFunction 中就是执行 abort 方法，abort 方法内一般会对本次事务进行 abortTransaction 操作。</p>
<p>只有当 2PC 的第一阶段所有参与者都完全成功，也就是说 Flink TwoPhaseCommitSinkFunction 对应的所有并行度在本次事务中 invoke 全部成功且 preCommit 对应预提交的 flush 也全部成功才认为 2PC 的第一阶段返回了Yes，即投票成功就会执行 2PC 第二阶段的 Commit，对应到 TwoPhaseCommitSinkFunction 中就是执行 Commit 方法，Commit 方法内一般会对本次事务进行 commitTransaction 操作，以上就是 Flink 中 TwoPhaseCommitSinkFunction 的大概执行流程。</p>
<p>在第一阶段结束时，数据被写入到了外部存储，但是当事务的隔离级别为读已提交（Read Committed）时，在外部存储中并读取不到我们写入的数据，因为并没有执行 Commit 操作。如下图所示，是第二阶段的两种情况。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-15-TwoPhaseCommitSinkFunction%20%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5.png" alt="img"></p>
<p>FlinkKafkaProducer011 继承了 TwoPhaseCommitSinkFunction，如下图所示，Flink 应用使用 FlinkKafkaProducer011 时，Checkpoint 的时候不仅要将快照保存到状态后端，还要执行 preCommit 操作将缓存中的数据 flush 到 Sink 端的 Kafka 中。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151549.jpg" alt="img"></p>
<p>当所有的实例快照完成且所有 Sink 实例执行完 preCommit 操作时，会把快照完成的消息发送给 JobManager，JobManager 收到所有实例的 Checkpoint 完成消息时，就认为这次 Checkpoint 完成了，会向所有的实例发送 Checkpoint 完成的通知（Notify Checkpoint Completed），当 FlinkKafkaProducer011 接收到 Checkpoint 完成的消息时，就会执行 Commit 方法。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-07-151550.jpg" alt="img"></p>
<p>上文提到过 2PC 有一些缺点存在，关于协调者和参与者故障的问题，对应到 Flink 中如果节点发生故障会申请资源并从最近一次成功的 Checkpoint 处恢复任务，所以，节点故障的问题 Flink 已经解决了。关于 2PC 同步阻塞的问题，2PC 算法在没有等到第一阶段所有参与者的投票之前肯定是不能执行第二阶段的 Commit，所以基于 2PC 实现原理同步阻塞的问题没有办法解决，除非使用其他算法。</p>
<p>那数据不一致的问题呢？</p>
<p>在整个的第一阶段不会真正地提交数据到 Kafka，所以只要设置事务隔离识别为读已提交（Read Committed），那么第一阶段就不会导致数据不一致的问题。</p>
<p>那 Flink 的第二阶段呢？</p>
<p>Flink 中，Checkpoint 成功后，会由 JobManager 给所有的实例发送 Checkpoint 完成的通知，然后 KafkaSink 在 notifyCheckpointComplete 方法内执行 commit。假如现在执行第 n 次 Checkpoint，快照完成且预提交完成，我们认为第 n 次 Checkpoint 已经成功了，这里一定要记住无论第二阶段是否 commit 成功，Flink 都会认为第 n 次 Checkpoint 已经结束了，换言之 Flink 可能会出现第 n 次 Checkpoint 成功了，但是第 n 次 Checkpoint 对应的事务 commit 并没有成功。</p>
<p>当 Checkpoint 成功后，JobManager 会向所有的 KafkaSink 发送 Checkpoint 完成的通知，所有的 KafkaSink 接收到通知后才会执行 Commit 操作。假如 JobManager 发送通知时出现了故障，导致 KafkaSink 的所有并行度都没有收到通知或者只有其中一部分 KafkaSink 接收到了通知，最后有一部分的 KafkaSink 执行了 Commit，另外一部分 KafkaSink 并没有执行 Commit，此时出现了 Checkpoint 成功，但是数据并没有完整地提交到 Kafka 的情况，出现了数据不一致的问题。</p>
<p>那 Flink 如何解决这个问题呢？</p>
<p>在任务执行过程中，如果因为各种原因导致有任意一个 KafkaSink 没有 Commit 成功，就会认为 Flink 任务出现故障，就会从最近一次成功的 Checkpoint 处恢复任务，也就是从第 n 次 Checkpoint 处恢复，TwoPhaseCommitSinkFunction 将每次 Checkpoint 时需要 Commit 的事务保存在状态里，当从第 n 次 Checkpoint 恢复时会从状态中拿到第 n 次 Checkpoint 可能没有提交的事务并执行 Commit，通过这种方式来保证所有的 KafkaSink 都能将事务进行 Commit，从而解决了 2PC 协议中可能出现的数据不一致的问题。</p>
<p>也就是说 Flink 任务重启后，会检查之前 Checkpoint 是否有未提交的事务，如果有则执行 Commit，从而保证了 Checkpoint 之前的数据被完整地提交。</p>
<p>简单描述一下 FlinkKafkaProducer011 的实现原理：</p>
<ul>
<li>FlinkKafkaProducer011 继承了 TwoPhaseCommitSinkFunction，所有并行度在 initializeState 初始化状态时，会开启新的事务，并把状态里保存的之前未提交事务进行 commit。</li>
<li>接下来开始调用 invoke 方法处理数据，会把数据通过事务 api 发送到 Kafka。一段时间后，开始 Checkpoint，checkpoint 时 snapshotState 方法会被执行，snapshotState 方法会调用 preCommit 方法并把当前还未 Commit 的事务添加到状态中来提供故障容错。</li>
<li>snapshotState 方法执行完成后，会对自身状态信息进行快照并上传到 HDFS 上来提供恢复。所有的实例都将状态信息备份完成后就认为本次 Checkpoint 结束了，此时 JobManager 会向所有的实例发送 Checkpoint 完成的通知，各实例收到通知后，会调用 notifyCheckpointComplete 方法把未提交的事务进行 commit。</li>
<li>期间如果出现其中某个并行度出现故障，JobManager 会停止此任务，向所有的实例发送通知，各实例收到通知后，调用 close 方法，关闭 Kafka 事务 Producer。</li>
</ul>
<p>以上就是 FlinkKafkaProducer011 实现原理的简单描述，具体实现细节请参考源码。</p>
<p>TwoPhaseCommitSinkFunction 还存在一个问题，假如我们设置的一分钟一次 Checkpoint，事务隔离级别设置为读已提交时，那么我们这一分钟内写入的数据，都必须等到 Checkpoint 结束后，下游才能读取到，导致我们的 Flink 任务数据延迟了一分钟。所以我们要结合这个特性，合理的设置我们的 Checkpoint 周期。</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">周晓晨</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://joccer.gitee.io/2019/12/10/Flink%20%E5%86%85%E9%83%A8%E4%BF%9D%E8%AF%81%20Exactly%20Once/">http://joccer.gitee.io/2019/12/10/Flink%20%E5%86%85%E9%83%A8%E4%BF%9D%E8%AF%81%20Exactly%20Once/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://joccer.gitee.io" target="_blank">周晓晨</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/image/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/image/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/image/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/image/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2019/12/10/Flink%20%E7%AB%AF%E5%AF%B9%E7%AB%AF%E4%BF%9D%E8%AF%81%20Exactly%20Once/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Flink 端对端保证 Exactly Once</div></div></a></div><div class="next-post pull-right"><a href="/2019/12/09/Flink-%E9%87%8D%E5%90%AF%E7%AD%96%E7%95%A5/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Flink 重启策略</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2021 By 周晓晨</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const initData = {
      el: '#vcomment',
      appId: 'os3tR4qQtIEkoK1S8XDHyBwY-gzGzoHsz',
      appKey: 'obbNIfixVI0uj7WoAqKy0hUv',
      placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
      avatar: 'monsterid',
      meta: 'nick,mail'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }

    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>