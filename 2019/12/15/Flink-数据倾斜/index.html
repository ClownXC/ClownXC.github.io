<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Flink 数据倾斜 | 周晓晨</title><meta name="author" content="周晓晨"><meta name="copyright" content="周晓晨"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="在大数据计算场景，无论使用 MapReduce、Spark 还是 Flink 计算框架，无论是批处理还是流处理都存在数据倾斜的问题，通过本节学习产生数据倾斜的原因及如何在生产环境解决数据倾斜。">
<meta property="og:type" content="article">
<meta property="og:title" content="Flink 数据倾斜">
<meta property="og:url" content="http://joccer.gitee.io/2019/12/15/Flink-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/index.html">
<meta property="og:site_name" content="周晓晨">
<meta property="og:description" content="在大数据计算场景，无论使用 MapReduce、Spark 还是 Flink 计算框架，无论是批处理还是流处理都存在数据倾斜的问题，通过本节学习产生数据倾斜的原因及如何在生产环境解决数据倾斜。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2019-12-15T09:32:16.000Z">
<meta property="article:modified_time" content="2021-01-06T02:30:50.820Z">
<meta property="article:author" content="周晓晨">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://joccer.gitee.io/2019/12/15/Flink-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":1,"position":"top","messagePrev":"这篇文章已经发表","messageNext":"天了，其中某些内容可能已经过时～"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-01-06 10:30:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><link rel="stylesheet" href="/css/iconfont.css"><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/chen.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">101</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">10</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">14</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 项目实战</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/playlist/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-folder-open"></i><span> 视频资料</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 数值分析</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 编译原理</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 操作系统</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机组成</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机网络</span></a></li><li><a class="site-page" href="/teach/jvm/"><i class="fa-fw fas fa-video"></i><span> JVM</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> MySQL数据库</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">数据倾斜简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">2.</span> <span class="toc-text">判断是否存在数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E5%92%8C%E8%A7%A3%E5%86%B3%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E9%97%AE%E9%A2%98"><span class="toc-number">3.</span> <span class="toc-text">分析和解决数据倾斜问题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#keyBy-%E5%90%8E%E7%9A%84%E8%81%9A%E5%90%88%E6%93%8D%E4%BD%9C%E5%AD%98%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">3.0.1.</span> <span class="toc-text">keyBy 后的聚合操作存在数据倾斜</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#keyBy-%E4%B9%8B%E5%89%8D%E5%8F%91%E7%94%9F%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">3.0.2.</span> <span class="toc-text">keyBy 之前发生数据倾斜</span></a></li></ol></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">周晓晨</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 项目实战</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/playlist/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-folder-open"></i><span> 视频资料</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 数值分析</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 编译原理</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 操作系统</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机组成</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> 计算机网络</span></a></li><li><a class="site-page" href="/teach/jvm/"><i class="fa-fw fas fa-video"></i><span> JVM</span></a></li><li><a class="site-page" href="/teach/"><i class="fa-fw fas fa-video"></i><span> MySQL数据库</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Flink 数据倾斜</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-12-15T09:32:16.000Z" title="发表于 2019-12-15 17:32:16">2019-12-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-01-06T02:30:50.820Z" title="更新于 2021-01-06 10:30:50">2021-01-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Flink/">Flink</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p>在大数据计算场景，无论使用 MapReduce、Spark 还是 Flink 计算框架，无论是批处理还是流处理都存在数据倾斜的问题，通过本节学习产生数据倾斜的原因及如何在生产环境解决数据倾斜。</p>
<a id="more"></a>

<h3 id="数据倾斜简介"><a href="#数据倾斜简介" class="headerlink" title="数据倾斜简介"></a>数据倾斜简介</h3><p>分析一个计算各 app PV 的案例，如下图所示，圆球表示 app1 的日志，方块表示 app2 的日志，Source 端从外部系统读取用户上报的各 app 行为日志，要计算各 app 的 PV，所以按照 app 进行 keyBy，相同 app 的数据发送到同一个 Operator 实例中处理，keyBy 后对 app 的 PV 值进行累加来，最后将计算的 PV 结果输出到外部 Sink 端。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004442.jpg" alt="img"></p>
<p>可以看到在任务运行过程中，计算 Count 的算子有两个并行度，其中一个并行度处理 app1 的数据，另一个并行度处理 app2 的数据。由于 app1 比较热门，所以 app1 的日志量远大于 app2 的日志量，造成计算 app1 PV 的并行度压力过大成为整个系统的瓶颈，而计算 app2 PV 的并行度数据量较少所以 CPU、内存以及网络资源的使用率整体都比较低，这就是产生数据倾斜的案例。</p>
<h3 id="判断是否存在数据倾斜"><a href="#判断是否存在数据倾斜" class="headerlink" title="判断是否存在数据倾斜"></a>判断是否存在数据倾斜</h3><p>这里再通过一个案例来讲述 Flink 任务如何来判断是否存在数据倾斜，如下图所示，是 Flink Web UI Job 页面展示的任务执行计划，可以看到任务经过 Operator Chain 后，总共有两个 Task，上游 Task 将数据 keyBy 后发送到下游 Task，如何判断第二个 Task 计算的数据是否存在数据呢？</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004443.jpg" alt="img"></p>
<p>如下图所示，通过 Flink Web UI 中 Job 页面的第一个 Subtasks 选项卡，可以看到任务的两个 Task，点击 Task，可以看到 Task 相应的 Subtask 详情。例如 Subtask 的启动时间、结束时间、持续时长、接收数据量的字节数以及接收数据的个数。图中可以看到，相同 Task 的多个 Subtask 中，有的 Subtask 接收到 1.69 TB 的数据量，有的 Subtask 接收到 17.6 TB 的数据量，通过 Flink Web UI 可以精确地看到每个 Subtask 处理了多少数据，即可判断出 Flink 任务是否存在数据倾斜，接下来学习 Flink 中如何来解决数据倾斜。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004431.jpg" alt="img"></p>
<h3 id="分析和解决数据倾斜问题"><a href="#分析和解决数据倾斜问题" class="headerlink" title="分析和解决数据倾斜问题"></a>分析和解决数据倾斜问题</h3><p>在 Flink 中，很多因素都会导致数据倾斜，例如 9.6.1 节描述的 keyBy 后的聚合操作存在数据倾斜。keyBy 之前的数据直接来自于数据源，一般不会出现数据倾斜，除非数据源中的数据发生了数据倾斜。本小节将从多个角度来解决数据倾斜。</p>
<h5 id="keyBy-后的聚合操作存在数据倾斜"><a href="#keyBy-后的聚合操作存在数据倾斜" class="headerlink" title="keyBy 后的聚合操作存在数据倾斜"></a>keyBy 后的聚合操作存在数据倾斜</h5><p>Flink 社区关于数据倾斜的解决方案炒得最热的也莫过于 LocalKeyBy 了。Flink 中数据倾斜一般发生于 keyBy 之后的聚合操作，LocalKeyBy 的思想是：在 keyBy 上游算子数据发送之前，首先在上游算子的本地对数据进行聚合后再发送到下游，使下游接收到的数据量大大减少，从而使得 keyBy 之后的聚合操作不再是任务的瓶颈。</p>
<p>如下图所示，Source 算子向下游发送数据之前，首先对数据进行预聚合，Source Subtask 0 预聚合后，圆圈 PV 值为 5、方块 PV 值为 2，Source Subtask 1 预聚合后，圆圈 PV 值为 6、方块 PV 值为 1。keyBy 后，Count 算子进行 PV 值的累加，计算圆圈 PV 的 Subtask 接收到 5 和 6，只需要将 5+6 即可计算出圆圈总 PV 值为 11，计算方块 PV 的 Subtask 接收到 2 和 1，只需要将 2 +1 即可计算出方块总 PV 值为 3，最后将圆圈和方块的 PV 结果输出到 Sink 端即可。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004439.jpg" alt="img"></p>
<p>使用该方案计算 PV，带来了两个非常大的好处。</p>
<ul>
<li>在上游算子中对数据进行了预聚合，因此大大减少了上游往下游发送的数据量，从而减少了网络间的数据传输，节省了集群的带宽资源。上图案例中如果不聚合，上游需要往下游发送 14 条数据，聚合后仅仅需要发送 4 条数据即可。如果上游算子接收 1 万条数据后聚合一次，那么数据的压缩比会更大，优化效果会更加明显。</li>
<li>下游拿到的直接是上游聚合好的中间结果，因此下游 Count 算子计算的数据量大大减少，而且 Count 算子不再会有数据倾斜的问题。</li>
</ul>
<p>上游算子相比之前多了一个聚合的工作，所以压力必然会增加，但是只要数据源不发生数据倾斜，那么上游 Source 算子的各并行度之间的负载就会比较均衡。</p>
<p>这里就是 MapReduce 中 Combiner 的思想嘛，在 Map 端对数据进行预聚合之后，再将预聚合后的数据发送到 Reduce 端去处理，从而大大减少了 shuffle 的数据量。</p>
<p>虽然思想一样，但 Flink 流处理的预聚合相比 MapReduce 的批处理而言，带来了一个新的挑战：Flink 是天然的流式处理，即来一条数据处理一条（这里不考虑 Flink 网络传输层的 Buffer 机制），但是聚合操作要求必须是多条数据或者一批数据才能聚合，单条数据没有办法通过聚合来减少数据量。</p>
<p>所以从 Flink LocalKeyBy 实现原理来讲，必然会存在一个积攒批次的过程，在上游算子中必须攒够一定的数据量，对这些数据聚合后再发送到下游。既然是积攒批次，那肯定有一个积攒批次的策略，上图案例可以理解为每个批次 7 条数据，当读取到 7 条数据后，将这 7 条数据聚合后发送到下游。</p>
<p><strong>具体实现逻辑是：内存里维护一个计数器，每来一条数据计数器加一，并将数据聚合放到内存 Buffer 中，当计数器到达 7 时，将内存 Buffer 中的数据发送到下游、计数器清零、Buffer 清空。</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LocalKeyByFlatMap</span> <span class="keyword">extends</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Long</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//本地 buffer，存放 local 端缓存的 app 的 pv 信息</span></span><br><span class="line">    <span class="keyword">private</span> HashMap&lt;String, Long&gt; localPvStat;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//缓存的数据量大小，即：缓存多少数据再向下游发送</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> batchSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计数器，获取当前批次接收的数据量</span></span><br><span class="line">    <span class="keyword">private</span> AtomicInteger currentSize = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);;</span><br><span class="line"></span><br><span class="line">    LocalKeyByFlatMap(<span class="keyword">int</span> batchSize)&#123;</span><br><span class="line">        <span class="keyword">this</span>.batchSize = batchSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String in, Collector collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//  将新来的数据添加到 buffer 中</span></span><br><span class="line">        Long pv = localPvStat.getOrDefault(in, <span class="number">0L</span>);</span><br><span class="line">        localPvStat.put(in, pv + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果到达设定的批次，则将 buffer 中的数据发送到下游</span></span><br><span class="line">        <span class="keyword">if</span>(currentSize.incrementAndGet() &gt;= batchSize)&#123;</span><br><span class="line">            <span class="comment">// 遍历 Buffer 中数据，发送到下游</span></span><br><span class="line">            <span class="keyword">for</span>(Map.Entry&lt;String, Long&gt; appIdPv: localPvStat.entrySet()) &#123;</span><br><span class="line">                collector.collect(Tuple2.of(appIdPv.getKey(), appIdPv.getValue()));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// buffer 清空，计数器清零</span></span><br><span class="line">            localPvStat.clear();</span><br><span class="line">            currentSize.set(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>代码逻辑比较简单，使用了 FlatMap 算子来做缓冲，每来一条数据都需要检索，为了提高检索效率，所以这里使用 HashMap 类型的 localPvStat 用来做 Buffer 来缓存数据，currentSize 记录当前批次已经往 localPvStat 中写入的数据量。在 LocalKeyByFlatMap 构造器中需要初始化 batchSize，即批次大小。flatMap 方法将新数据添加到 localPvStat 中，currentSize 进行加一操作，且 currentSize 加一后如果大于 batchSize 则表示当前批次的数据已经够了，需要将数据发送到下游，则遍历 localPvStat，将 Buffer 中的数据发送到下游，并将 localPvStat 清空且 currentSize 清零。</p>
<p>代码逻辑简单易懂，但是问题又来了，在积攒批次的过程中，如果发生故障，Flink 任务能保障 Exactly Once 吗？</p>
<p>直接给出答案：不能保证 Exactly Once，可能会丢数据，为什么呢？</p>
<p>如下图所示，batchSize 设置的 7，但是当 JobManager 触发 Checkpoint 的时候，Source Subtask 0 消费到 offset 为 13 的位置、Source Subtask 1 消费到 offset 为 12 的位置，所以 Source 0 会将 offset=13 保存到状态后端，Source 1 会将 offset=12 保存到状态后端。接着 Checkpoint barrier 跟随着数据往下游发送到 LocalKeyBy，此时 LocalKeyBy 0 的 Buffer 中只有 6 条数据、LocalKeyBy 1 的 Buffer 中只有 5 条数据，所以 LocalKeyBy 0 和 1 都不会将数据发送到下游。但是 barrier 会接着往下游传递到 Count 算子，Count 算子会对自身状态信息进行快照，Count 0 会将圆圈 PV=11 保存到状态后端、Count 1 会将圆圈 PV=3 保存到状态后端，各 task 向 JobManager 反馈，最后 Checkpoint 成功了，紧接着数据正常开始处理。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004433.jpg" alt="img"></p>
<p>数据正常处理一段时间后，由于机器故障 Flink 任务突然挂了，如下图所示，Flink 任务会从状态恢复，Source Subtask 0 从 offset 为 13 的位置开始消费 Kafka，Source Subtask 1 从 offset 为 12 的位置开始消费 Kafka。Count 0 恢复后保存圆圈的 PV 为 11，Count 1 恢复后保存方块的 PV 为 3。此时任务从状态中恢复完成，正常开始处理数据，请问 Flink 任务从状态恢复后丢数据了吗？</p>
<p>丢了，因为 Source 0 对应的 offset 13 表示 Source 0 消费了 13 条数据，但是其中有 6 条数据缓存在 LocalKeyBy 0 的 Buffer 中没及时发送到下游，所以这 6 条数据丢了，同理 Source 1 对应的 offset 12 表示 Source 1 消费了 12 条数据，其中还有 5 条数据缓存在 LocalKeyBy 1 的 Buffer 中没及时发送到下游，所以这 5 条数据也丢了。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-13-%E7%A7%AF%E6%94%92%E6%89%B9%E6%AC%A1%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%20Restore.png" alt="img"></p>
<p>通过上述详细案例分析，知道了我们设计的 LocalKeyBy 虽然能够提高性能，但存在丢数据的风险。，<strong>Flink 虽然支持 Exactly Once，但不是说你的代码随便瞎写 Flink 也能保证 Exactly Once，做为使用 Flink 的一员，我们应该根据原理书写出能保证 Flink Exactly Once 的代码。</strong></p>
<p>上述方案该如何完善才能保证 Exactly Once 呢？在 Checkpoint 时上述方案会把 LocalKeyBy 算子 Buffer 中的数据丢弃，所以重点应该是如何来保证 LocalKeyBy 算子 Buffer 中的数据不丢。在 Checkpoint 时可以将 Buffer 中还未发送到下游的数据保存到 Flink 的状态中，这样当 Flink 任务从 Checkpoint 处恢复时，可以将那些在 Buffer 中的数据从状态后端恢复。如下图所示，相比上述方案，Checkpoint 时会将 LocalKeyBy 算子 Buffer 中的数据也保存到状态后端。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-4434.jpg" alt="img"></p>
<p>如下图所示，当 Flink 任务从 Checkpoint 处恢复时，不仅恢复 offset 信息和 PV 信息，还需要把 LocalKeyBy 算子 Buffer 中的数据恢复，这样就可以保证不丢数据了。</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004436.jpg" alt="img"></p>
<p>具体代码如何实现呢？Checkpoint 时 LocalKeyBy 算子可能还有缓冲的数据没发送到下游，为了保证 Exactly Once，这里需要将 Buffer 中的数据保存在状态中。</p>
<p>Flink 有两种 State 分别是 OperatorState 和 KeyedState，OperatorState 是一个 Operator 实例对应一个State，KeyedState 是每个 key 对应一个 State，KeyedState 只能作用于 keyby 算子之后的 KeyedStream。</p>
<p>上图中我们可以看出，LocalKeyBy 算子位于 keyBy 算子之前，因此 LocalKeyBy 算子内部不能使用 KeyedState，只能使用 OperatorState，且 OperatorState 只支持一种数据结构，即 ListState，所以这里 buffer 中的数据只能保存在 OperatorState 类型的 ListState 中。当 Checkpoint 时，需要将内存 buffer 中的数据添加到 ListState，状态中需要保存 KV 类型的数据，key 是 appId、value 是 app 对应的 PV 值。</p>
<p>这里为了在 ListState 中保存 KV 格式的数据，需要将 buffer 中 KV 类型的数据转化为 Tuple2 类型后再添加到 ListState 中。代码具体实现如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LocalKeyByFlatMap</span> <span class="keyword">extends</span> <span class="title">RichFlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Long</span>&gt;&gt; <span class="keyword">implements</span> <span class="title">CheckpointedFunction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Checkpoint 时为了保证 Exactly Once，将 buffer 中的数据保存到该 ListState 中</span></span><br><span class="line">    <span class="keyword">private</span> ListState&lt;Tuple2&lt;String, Long&gt;&gt; localPvStatListState;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//本地 buffer，存放 local 端缓存的 app 的 pv 信息</span></span><br><span class="line">    <span class="keyword">private</span> HashMap&lt;String, Long&gt; localPvStat;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//缓存的数据量大小，即：缓存多少数据再向下游发送</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> batchSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计数器，获取当前批次接收的数据量</span></span><br><span class="line">    <span class="keyword">private</span> AtomicInteger currentSize;</span><br><span class="line"></span><br><span class="line">    LocalKeyByFlatMap(<span class="keyword">int</span> batchSize)&#123;</span><br><span class="line">        <span class="keyword">this</span>.batchSize = batchSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String in, Collector collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//  将新来的数据添加到 buffer 中</span></span><br><span class="line">        Long pv = localPvStat.getOrDefault(in, <span class="number">0L</span>);</span><br><span class="line">        localPvStat.put(in, pv + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果到达设定的批次，则将 buffer 中的数据发送到下游</span></span><br><span class="line">        <span class="keyword">if</span>(currentSize.incrementAndGet() &gt;= batchSize)&#123;</span><br><span class="line">            <span class="comment">// 遍历 Buffer 中数据，发送到下游</span></span><br><span class="line">            <span class="keyword">for</span>(Map.Entry&lt;String, Long&gt; appIdPv: localPvStat.entrySet()) &#123;</span><br><span class="line">                collector.collect(Tuple2.of(appIdPv.getKey(), appIdPv.getValue()));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// Buffer 清空，计数器清零</span></span><br><span class="line">            localPvStat.clear();</span><br><span class="line">            currentSize.set(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">snapshotState</span><span class="params">(FunctionSnapshotContext functionSnapshotContext)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 将 buffer 中的数据保存到状态中，来保证 Exactly Once</span></span><br><span class="line">        localPvStatListState.clear();</span><br><span class="line">        <span class="keyword">for</span>(Map.Entry&lt;String, Long&gt; appIdPv: localPvStat.entrySet()) &#123;</span><br><span class="line">            localPvStatListState.add(Tuple2.of(appIdPv.getKey(), appIdPv.getValue()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initializeState</span><span class="params">(FunctionInitializationContext context)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 从状态中恢复 buffer 中的数据</span></span><br><span class="line">        localPvStatListState = context.getOperatorStateStore().getListState(</span><br><span class="line">                <span class="keyword">new</span> ListStateDescriptor&lt;&gt;(<span class="string">&quot;localPvStat&quot;</span>,</span><br><span class="line">                        TypeInformation.of(<span class="keyword">new</span> TypeHint&lt;Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">                        &#125;)));</span><br><span class="line">        localPvStat = <span class="keyword">new</span> HashMap();</span><br><span class="line">        <span class="keyword">if</span>(context.isRestored()) &#123;</span><br><span class="line">            <span class="comment">// 从状态中恢复数据到 localPvStat 中</span></span><br><span class="line">            <span class="keyword">for</span>(Tuple2&lt;String, Long&gt; appIdPv: localPvStatListState.get())&#123;</span><br><span class="line">                localPvStat.put(appIdPv.f0, appIdPv.f1);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//  从状态恢复时，默认认为 buffer 中数据量达到了 batchSize，需要向下游发送数据了</span></span><br><span class="line">            currentSize = <span class="keyword">new</span> AtomicInteger(batchSize);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            currentSize = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述改进方案后的 LocalKeyByFlatMap 相比之前方案仅仅增加了一个属性，即：<code>ListState&gt;</code> 类型的 localPvStatListState 用来存放 Checkpoint 时 buffer 中那些可能丢失的数据。在 snapshotState 方法中将 buffer 中的数据保存到状态中，在 initializeState 方法中将状态中恢复的数据 put 到 buffer 中并初始化计数器 currentSize。代码相对比较简答，容易看懂。</p>
<p>请问上述代码能保障 buffer 中的数据不丢吗？如果不修改 Source Task 和 LocalKeyByFlatMap 算子的并行度，理论来讲可以保证 Exactly Once，但是一旦修改并行度，还能保证 Exactly Once 吗？当并行度降低后，getOperatorStateStore().getListState() 恢复 ListState 时，会把 ListState 中的状态信息均匀分布到各个 Operator 实例中。当上述案例中 LocalKeyBy 的并行度从 2 调节为 1 时，数据恢复如下图所示：</p>
<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-12-004441.jpg" alt="img"></p>
<p>首先 Source 端 partition 0 和 partition 1 的 offset 信息恢复没有问题，Count 算子圆圈和方块的 PV 信息恢复也没有问题。关键在于 LocalKeyBy 算子中 PV 信息恢复时会丢数据吗？状态恢复时，从状态中将 PV 信息恢复到 buffer 中的核心代码如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从状态中恢复数据到 localPvStat 中</span></span><br><span class="line"><span class="keyword">for</span>(Tuple2&lt;String, Long&gt; appIdPv: localPvStatListState.get())&#123;</span><br><span class="line">    localPvStat.put(appIdPv.f0, appIdPv.f1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从状态中会恢复 4 个 Tuple2，分别是 &lt;圆圈,4&gt;、&lt;方块,2&gt;、&lt;圆圈,4&gt;、&lt;方块,1&gt;，这里有两个圆圈、两个方块，恢复到 HashMap 类型的 localPvStat，HashMap 中相同的 key 不能重复，所以 HashMap 中不可能保存两个圆圈和两个方块。恢复时 app 相同的数据，应该将其 PV 值累加，所以恢复的结果应该是 &lt;圆圈,8&gt;、&lt;方块,3&gt;。但是上述代码，仅仅是覆盖操作，假如遍历状态时返回的顺序为 &lt;圆圈,4&gt;、&lt;方块,2&gt;、&lt;圆圈,4&gt;、&lt;方块,1&gt;，那么上述恢复流程为：将上述元素依次 put 到 HashMap 中，所以 HashMap 类型的 buffer 恢复完数据后，buffer 中保存的 PV 信息为 &lt;圆圈,4&gt;、&lt;方块,1&gt;。显然恢复过程中的覆盖操作将状态数据 &lt;圆圈,4&gt;、&lt;方块,2&gt; 丢了，所以上述方案如果不修改并行度时，不会丢数据，如果修改并行度时，可能会丢数据。</p>
<p>在使用状态来保证 Exactly Once 时，必须考虑修改并行度后，状态如何正常恢复的情况。优化后的代码如下所示，仅仅修改 initializeState 方法中恢复状态的逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从状态中恢复 buffer 中的数据</span></span><br><span class="line"><span class="keyword">for</span>(Tuple2&lt;String, Long&gt; appIdPv: localPvStatListState.get())&#123;</span><br><span class="line">    <span class="keyword">long</span> pv = localPvStat.getOrDefault(appIdPv.f0, <span class="number">0L</span>);</span><br><span class="line">    <span class="comment">// 如果出现 pv != 0，说明改变了并行度，</span></span><br><span class="line">    <span class="comment">// ListState 中的数据会被均匀分发到新的 subtask 中</span></span><br><span class="line">    <span class="comment">// 所以单个 subtask 恢复的状态中可能包含两个相同的 app 的数据</span></span><br><span class="line">    localPvStat.put(appIdPv.f0, pv + appIdPv.f1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>代码中，首先从 buffer 中获取当前 app 的 PV 数据，如果 buffer 中不包含当前 app 则 PV 值返回 0，如果 buffer 中包含了当前 app 则返回相应的 PV 值，将 buffer 中的 pv 加当前的 pv，put 到 buffer 中即可保证恢复时不丢数据。</p>
<p>到这里 LocalKeyBy 的思路及具体代码实现都讲完了，也带着大家分析了多种可能丢数据的情况，并一一解决。上述完整的代码实现请参阅。上述代码实现有个局限性，就是需要了解业务，按照下游的聚合逻辑，在上游 keyBy 之前同样也需要实现一遍。关于通用的 LocalKeyBy 实现，Flink 源码中目前还没有此功能，对具体实现原理感兴趣的可以参阅腾讯杨华老师贡献的 <a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-44%3A+Support+Local+Aggregation+in+Flink">FLIP-44</a>。</p>
<h5 id="keyBy-之前发生数据倾斜"><a href="#keyBy-之前发生数据倾斜" class="headerlink" title="keyBy 之前发生数据倾斜"></a>keyBy 之前发生数据倾斜</h5><p>上一部分分析了 keyBy 后由于数据本身的特征可能会发生数据倾斜，可以在 keyBy 之前进行一次预聚合，从而使得 keyBy 后的数据量大大降低。但是如果 keyBy 之前就存在数据倾斜呢？这样上游算子的某些实例可能处理的数据较多，某些实例可能处理的数据较少，产生该情况可能是因为数据源的数据本身就不均匀，例如由于某些原因 Kafka 的 topic 中某些 partition 的数据量较大，某些 partition 的数据量较少。对于不存在 keyBy 的 Flink 任务也会出现该情况，解决思路都一样，主要在于没有 shuffle 的 Flink 任务如何来解决数据倾斜。对于这种情况，需要让 Flink 任务强制进行 shuffle。如何强制 shuffle 呢？了解一下 DataStream 的物理分区策略。</p>
<table>
<thead>
<tr>
<th align="left">分区策略</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">dataStream.partitionCustom(partitioner, “someKey”); dataStream.partitionCustom(partitioner, 0);</td>
<td align="left">根据指定的字段进行分区，指定字段值相同的数据发送到同一个 Operator 实例处理</td>
</tr>
<tr>
<td align="left">dataStream.shuffle();</td>
<td align="left">将数据随机地分配到下游 Operator 实例</td>
</tr>
<tr>
<td align="left">dataStream.rebalance();</td>
<td align="left">使用轮循的策略将数据发送到下游 Operator 实例</td>
</tr>
<tr>
<td align="left">dataStream.rescale();</td>
<td align="left">基于 rebalance 优化的策略，依然使用轮循策略，但仅仅是 TaskManager 内的轮循，只会在 TaskManager 本地进行 shuffle 操作，减少了网络传输</td>
</tr>
<tr>
<td align="left">dataStream.broadcast();</td>
<td align="left">将数据广播到下游所有的 Operator 实例</td>
</tr>
</tbody></table>
<p>在这里需要解决数据倾斜，只需要使用 shuffle、rebalance 或 rescale 即可将数据均匀分配，从而解决数据倾斜的问题。</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">周晓晨</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://joccer.gitee.io/2019/12/15/Flink-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/">http://joccer.gitee.io/2019/12/15/Flink-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://joccer.gitee.io" target="_blank">周晓晨</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/image/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/image/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/image/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/image/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2019/12/15/Watermark-%E4%B8%8E-Window-%E7%BB%93%E5%90%88%E6%9D%A5%E5%A4%84%E7%90%86%E5%BB%B6%E8%BF%9F%E6%95%B0%E6%8D%AE/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Watermark 与 Window 结合来处理延迟数据</div></div></a></div><div class="next-post pull-right"><a href="/2019/12/13/Flink-WaterMark-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Flink WaterMark 深入理解</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2021 By 周晓晨</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const initData = {
      el: '#vcomment',
      appId: 'os3tR4qQtIEkoK1S8XDHyBwY-gzGzoHsz',
      appKey: 'obbNIfixVI0uj7WoAqKy0hUv',
      placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
      avatar: 'monsterid',
      meta: 'nick,mail'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }

    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/6d85e03d.js","daovoice")
</script><script>var isChatBtn = true
daovoice('init', {
  app_id: '6d85e03d',},{
  launcher: { 
     disableLauncherIcon: isChatBtn // 悬浮 ICON 是否显示
  },
});
daovoice('update');

if (isChatBtn) {
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      daovoice('show')
    });
  }
  chatBtnFn()
} else {
  if (false) {
    function chatBtnHide () {
      daovoice('update', {},{
        launcher: { 
        disableLauncherIcon: true // 悬浮 ICON 是否显示
        },
      });
    }
    function chatBtnShow () {
      daovoice('update', {},{
        launcher: { 
        disableLauncherIcon: false // 悬浮 ICON 是否显示
        },
      });
    }
  }
}</script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>